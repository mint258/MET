Using device: cuda
Selected target_properties: ['rot_A']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 2079, Training: 1664, Validation: 415
Actual heads number: 1
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1025539

Epoch 1/1000
Training Loss: 1.73273686, Training R2: -1.683922
Validation Loss: 1.27680564, Validation R2: -0.195577
Saved best model with validation loss 1.27680564 to best_model.pth

Epoch 2/1000
Training Loss: 1.24140692, Training R2: -0.070628
Validation Loss: 1.16756786, Validation R2: 0.000736
Saved best model with validation loss 1.16756786 to best_model.pth

Epoch 3/1000
Training Loss: 1.20518780, Training R2: -0.004650
Validation Loss: 1.17258920, Validation R2: -0.008108

Epoch 4/1000
Training Loss: 1.20695052, Training R2: -0.007100
Validation Loss: 1.19156793, Validation R2: -0.041470

Epoch 5/1000
Training Loss: 1.20983618, Training R2: -0.011477
Validation Loss: 1.17631990, Validation R2: -0.014643

Epoch 6/1000
Training Loss: 1.20526255, Training R2: -0.003314
Validation Loss: 1.16901618, Validation R2: -0.001630

Epoch 7/1000
Training Loss: 1.20888426, Training R2: -0.010490
Validation Loss: 1.17439740, Validation R2: -0.011278

Epoch 8/1000
Training Loss: 1.20623584, Training R2: -0.005027
Validation Loss: 1.16826338, Validation R2: -0.000524

Epoch 9/1000
Training Loss: 1.20263759, Training R2: -0.001268
Validation Loss: 1.16719967, Validation R2: 0.001424
Saved best model with validation loss 1.16719967 to best_model.pth

Epoch 10/1000
Training Loss: 1.21368388, Training R2: -0.018263
Validation Loss: 1.18521222, Validation R2: -0.029570

Epoch 11/1000
Training Loss: 1.21747171, Training R2: -0.024672
Validation Loss: 1.17598222, Validation R2: -0.013569

Epoch 12/1000
Training Loss: 1.20705158, Training R2: -0.009061
Validation Loss: 1.16692395, Validation R2: 0.001865
Saved best model with validation loss 1.16692395 to best_model.pth

Epoch 13/1000
Training Loss: 1.20034612, Training R2: 0.001825
Validation Loss: 1.19932715, Validation R2: -0.055254

Epoch 14/1000
Training Loss: 1.22902421, Training R2: -0.043977
Validation Loss: 1.23575339, Validation R2: -0.120901

Epoch 15/1000
Training Loss: 1.22565659, Training R2: -0.038707
Validation Loss: 1.16689687, Validation R2: 0.001885
Saved best model with validation loss 1.16689687 to best_model.pth

Epoch 16/1000
Training Loss: 1.20368655, Training R2: -0.001323
Validation Loss: 1.16790792, Validation R2: 0.000076

Epoch 17/1000
Training Loss: 1.20546049, Training R2: -0.003858
Validation Loss: 1.19416211, Validation R2: -0.045230

Epoch 18/1000
Training Loss: 1.21300693, Training R2: -0.017754
Validation Loss: 1.17592101, Validation R2: -0.013971

Epoch 19/1000
Training Loss: 1.20592978, Training R2: -0.005111
Validation Loss: 1.18435966, Validation R2: -0.028784

Epoch 20/1000
Training Loss: 1.20247282, Training R2: 0.000931
Validation Loss: 1.16559935, Validation R2: 0.004118
Saved best model with validation loss 1.16559935 to best_model.pth

Epoch 21/1000
Training Loss: 1.20065360, Training R2: 0.003965
Validation Loss: 1.17527675, Validation R2: -0.012902

Epoch 22/1000
Training Loss: 1.20627417, Training R2: -0.005394
Validation Loss: 1.17487954, Validation R2: -0.012246

Epoch 23/1000
Training Loss: 1.20595830, Training R2: -0.005839
Validation Loss: 1.15971975, Validation R2: 0.014179
Saved best model with validation loss 1.15971975 to best_model.pth

Epoch 24/1000
Training Loss: 1.20739588, Training R2: -0.007500
Validation Loss: 1.16879142, Validation R2: -0.001215

Epoch 25/1000
Training Loss: 1.19891978, Training R2: 0.002694
Validation Loss: 1.19311173, Validation R2: -0.043399

Epoch 26/1000
Training Loss: 1.18774891, Training R2: 0.024739
Validation Loss: 1.15321584, Validation R2: 0.025186
Saved best model with validation loss 1.15321584 to best_model.pth

Epoch 27/1000
Training Loss: 1.17635151, Training R2: 0.043262
Validation Loss: 1.20350511, Validation R2: -0.063006

Epoch 28/1000
Training Loss: 1.17809523, Training R2: 0.040493
Validation Loss: 1.17247969, Validation R2: -0.008433

Epoch 29/1000
Training Loss: 1.17408595, Training R2: 0.047338
Validation Loss: 1.12903571, Validation R2: 0.065647
Saved best model with validation loss 1.12903571 to best_model.pth

Epoch 30/1000
Training Loss: 1.15807298, Training R2: 0.073419
Validation Loss: 1.11650843, Validation R2: 0.085626
Saved best model with validation loss 1.11650843 to best_model.pth

Epoch 31/1000
Training Loss: 1.12967577, Training R2: 0.117786
Validation Loss: 1.12864642, Validation R2: 0.065935

Epoch 32/1000
Training Loss: 1.15358384, Training R2: 0.080493
Validation Loss: 1.19124854, Validation R2: -0.040056

Epoch 33/1000
Training Loss: 1.16869049, Training R2: 0.054891
Validation Loss: 1.17971751, Validation R2: -0.020061

Epoch 34/1000
Training Loss: 1.14629500, Training R2: 0.092024
Validation Loss: 1.12507500, Validation R2: 0.071482

Epoch 35/1000
Training Loss: 1.12058291, Training R2: 0.131962
Validation Loss: 1.10299744, Validation R2: 0.106855
Saved best model with validation loss 1.10299744 to best_model.pth

Epoch 36/1000
Training Loss: 1.11149115, Training R2: 0.146194
Validation Loss: 1.09951445, Validation R2: 0.112333
Saved best model with validation loss 1.09951445 to best_model.pth

Epoch 37/1000
Training Loss: 1.11990838, Training R2: 0.130488
Validation Loss: 1.07320937, Validation R2: 0.155827
Saved best model with validation loss 1.07320937 to best_model.pth

Epoch 38/1000
Training Loss: 1.15428963, Training R2: 0.078048
Validation Loss: 1.13211556, Validation R2: 0.060589

Epoch 39/1000
Training Loss: 1.09990234, Training R2: 0.161258
Validation Loss: 1.11833026, Validation R2: 0.081991

Epoch 40/1000
Training Loss: 1.07291649, Training R2: 0.204506
Validation Loss: 1.06167071, Validation R2: 0.173797
Saved best model with validation loss 1.06167071 to best_model.pth

Epoch 41/1000
Training Loss: 1.07330742, Training R2: 0.203988
Validation Loss: 1.08459136, Validation R2: 0.136595

Epoch 42/1000
Training Loss: 1.07183201, Training R2: 0.205623
Validation Loss: 1.09139927, Validation R2: 0.126590

Epoch 43/1000
Training Loss: 1.05851286, Training R2: 0.225544
Validation Loss: 1.09916226, Validation R2: 0.113327

Epoch 44/1000
Training Loss: 1.10237651, Training R2: 0.158554
Validation Loss: 1.08307904, Validation R2: 0.140239

Epoch 45/1000
Training Loss: 1.09290290, Training R2: 0.172128
Validation Loss: 1.18207144, Validation R2: -0.024193

Epoch 46/1000
Training Loss: 1.09374254, Training R2: 0.172509
Validation Loss: 1.07715919, Validation R2: 0.149343

Epoch 47/1000
Training Loss: 1.06442738, Training R2: 0.215103
Validation Loss: 1.04219728, Validation R2: 0.203303
Saved best model with validation loss 1.04219728 to best_model.pth

Epoch 48/1000
Training Loss: 1.05113306, Training R2: 0.234787
Validation Loss: 1.05930748, Validation R2: 0.176604

Epoch 49/1000
Training Loss: 1.04628144, Training R2: 0.243309
Validation Loss: 1.04219098, Validation R2: 0.202801
Saved best model with validation loss 1.04219098 to best_model.pth

Epoch 50/1000
Training Loss: 1.04432259, Training R2: 0.246642
Validation Loss: 1.12709038, Validation R2: 0.068214

Epoch 51/1000
Training Loss: 1.03539762, Training R2: 0.259055
Validation Loss: 1.03267983, Validation R2: 0.218131
Saved best model with validation loss 1.03267983 to best_model.pth

Epoch 52/1000
Training Loss: 1.01323563, Training R2: 0.290284
Validation Loss: 1.03049398, Validation R2: 0.220743
Saved best model with validation loss 1.03049398 to best_model.pth

Epoch 53/1000
Training Loss: 1.00695278, Training R2: 0.298397
Validation Loss: 1.02824992, Validation R2: 0.224769
Saved best model with validation loss 1.02824992 to best_model.pth

Epoch 54/1000
Training Loss: 0.99471367, Training R2: 0.315445
Validation Loss: 1.09431114, Validation R2: 0.122322

Epoch 55/1000
Training Loss: 1.01655958, Training R2: 0.285333
Validation Loss: 1.12063042, Validation R2: 0.079145

Epoch 56/1000
Training Loss: 1.02849432, Training R2: 0.266013
Validation Loss: 1.03911136, Validation R2: 0.208154

Epoch 57/1000
Training Loss: 0.98203601, Training R2: 0.333050
Validation Loss: 1.03446881, Validation R2: 0.215684

Epoch 58/1000
Training Loss: 0.97321748, Training R2: 0.345068
Validation Loss: 1.04565205, Validation R2: 0.198073

Epoch 59/1000
Training Loss: 1.01260641, Training R2: 0.290754
Validation Loss: 1.04647727, Validation R2: 0.197345

Epoch 60/1000
Training Loss: 0.99792714, Training R2: 0.309731
Validation Loss: 1.02558603, Validation R2: 0.228730
Saved best model with validation loss 1.02558603 to best_model.pth

Epoch 61/1000
Training Loss: 0.97227250, Training R2: 0.345786
Validation Loss: 1.02075262, Validation R2: 0.236066
Saved best model with validation loss 1.02075262 to best_model.pth

Epoch 62/1000
Training Loss: 0.96321309, Training R2: 0.356483
Validation Loss: 1.03984587, Validation R2: 0.207254

Epoch 63/1000
Training Loss: 0.95718054, Training R2: 0.366278
Validation Loss: 0.99356007, Validation R2: 0.276411
Saved best model with validation loss 0.99356007 to best_model.pth

Epoch 64/1000
Training Loss: 0.96398557, Training R2: 0.356666
Validation Loss: 1.01375320, Validation R2: 0.246614

Epoch 65/1000
Training Loss: 0.93880400, Training R2: 0.389817
Validation Loss: 1.01721543, Validation R2: 0.241585

Epoch 66/1000
Training Loss: 0.93679337, Training R2: 0.392657
Validation Loss: 1.02961690, Validation R2: 0.222270

Epoch 67/1000
Training Loss: 0.92370305, Training R2: 0.409824
Validation Loss: 1.06147842, Validation R2: 0.173992

Epoch 68/1000
Training Loss: 0.93255541, Training R2: 0.397581
Validation Loss: 1.01939402, Validation R2: 0.238337

Epoch 69/1000
Training Loss: 0.92207911, Training R2: 0.412534
Validation Loss: 1.01101081, Validation R2: 0.250271

Epoch 70/1000
Training Loss: 0.89648704, Training R2: 0.444654
Validation Loss: 1.00679617, Validation R2: 0.257089

Epoch 71/1000
Training Loss: 0.89212740, Training R2: 0.450074
Validation Loss: 1.04348154, Validation R2: 0.201878

Epoch 72/1000
Training Loss: 0.91835526, Training R2: 0.415154
Validation Loss: 1.07667961, Validation R2: 0.149720

Epoch 73/1000
Training Loss: 0.93304178, Training R2: 0.394345
Validation Loss: 1.17969271, Validation R2: -0.022283

Epoch 74/1000
Training Loss: 0.97148013, Training R2: 0.341339
Validation Loss: 0.99833284, Validation R2: 0.269389

Epoch 75/1000
Training Loss: 0.94812226, Training R2: 0.378097
Validation Loss: 1.04043779, Validation R2: 0.205537

Epoch 76/1000
Training Loss: 0.94275242, Training R2: 0.385663
Validation Loss: 1.00208225, Validation R2: 0.264026

Epoch 77/1000
Training Loss: 0.91479685, Training R2: 0.421370
Validation Loss: 1.08719180, Validation R2: 0.131312

Epoch 78/1000
Training Loss: 0.96591764, Training R2: 0.352482
Validation Loss: 1.08034605, Validation R2: 0.143540

Epoch 79/1000
Training Loss: 0.99475312, Training R2: 0.313058
Validation Loss: 1.11600669, Validation R2: 0.085363

Epoch 80/1000
Training Loss: 0.98610189, Training R2: 0.323323
Validation Loss: 1.00424598, Validation R2: 0.260485

Epoch 81/1000
Training Loss: 0.95750432, Training R2: 0.365132
Validation Loss: 1.06919365, Validation R2: 0.161890

Epoch 82/1000
Training Loss: 0.93553299, Training R2: 0.393616
Validation Loss: 1.02078375, Validation R2: 0.236264

Epoch 83/1000
Training Loss: 0.89623755, Training R2: 0.444973
Validation Loss: 1.01313561, Validation R2: 0.247042

Epoch 84/1000
Training Loss: 0.88894853, Training R2: 0.453680
Validation Loss: 1.06367098, Validation R2: 0.170740

Epoch 85/1000
Training Loss: 0.88493376, Training R2: 0.457679
Validation Loss: 1.02880800, Validation R2: 0.223372

Epoch 86/1000
Training Loss: 0.87955816, Training R2: 0.463460
Validation Loss: 1.00090723, Validation R2: 0.265449

Epoch 87/1000
Training Loss: 0.87005963, Training R2: 0.476926
Validation Loss: 1.04328098, Validation R2: 0.201977

Epoch 88/1000
Training Loss: 0.85193052, Training R2: 0.498612
Validation Loss: 1.04153380, Validation R2: 0.204898

Epoch 89/1000
Training Loss: 0.88442209, Training R2: 0.459739
Validation Loss: 1.01927206, Validation R2: 0.238402

Epoch 90/1000
Training Loss: 0.85034516, Training R2: 0.499498
Validation Loss: 1.04515957, Validation R2: 0.198973

Epoch 91/1000
Training Loss: 0.83362002, Training R2: 0.518657
Validation Loss: 1.00161738, Validation R2: 0.263826

Epoch 92/1000
Training Loss: 0.84370010, Training R2: 0.507253
Validation Loss: 0.97918913, Validation R2: 0.297036
Saved best model with validation loss 0.97918913 to best_model.pth

Epoch 93/1000
Training Loss: 0.82517935, Training R2: 0.528601
Validation Loss: 1.00589295, Validation R2: 0.257905

Epoch 94/1000
Training Loss: 0.82863306, Training R2: 0.524999
Validation Loss: 0.98500586, Validation R2: 0.287461

Epoch 95/1000
Training Loss: 0.86752014, Training R2: 0.476507
Validation Loss: 1.01672076, Validation R2: 0.242306

Epoch 96/1000
Training Loss: 0.83996510, Training R2: 0.512746
Validation Loss: 1.04708235, Validation R2: 0.195904

Epoch 97/1000
Training Loss: 0.86031189, Training R2: 0.487758
Validation Loss: 1.00892217, Validation R2: 0.252316

Epoch 98/1000
Training Loss: 0.83916392, Training R2: 0.512220
Validation Loss: 1.03837768, Validation R2: 0.208694

Epoch 99/1000
Training Loss: 0.84840460, Training R2: 0.502087
Validation Loss: 0.98316582, Validation R2: 0.290524

Epoch 100/1000
Training Loss: 0.81994994, Training R2: 0.534943
Validation Loss: 1.02738508, Validation R2: 0.225982

Epoch 101/1000
Training Loss: 0.80413344, Training R2: 0.553503
Validation Loss: 1.02795717, Validation R2: 0.224330

Epoch 102/1000
Training Loss: 0.80557043, Training R2: 0.551385
Validation Loss: 1.06081684, Validation R2: 0.174848

Epoch 103/1000
Training Loss: 0.85701100, Training R2: 0.490209
Validation Loss: 1.06609621, Validation R2: 0.166317

Epoch 104/1000
Training Loss: 0.85506234, Training R2: 0.492302
Validation Loss: 1.04157261, Validation R2: 0.204027

Epoch 105/1000
Training Loss: 0.85240912, Training R2: 0.496296
Validation Loss: 1.02583834, Validation R2: 0.227678

Epoch 106/1000
Training Loss: 0.81850608, Training R2: 0.534564
Validation Loss: 1.02551914, Validation R2: 0.229204

Epoch 107/1000
Training Loss: 0.80119424, Training R2: 0.556242
Validation Loss: 1.01978654, Validation R2: 0.237791

Epoch 108/1000
Training Loss: 0.78299458, Training R2: 0.575504
Validation Loss: 1.00977075, Validation R2: 0.251547

Epoch 109/1000
Training Loss: 0.80176676, Training R2: 0.555243
Validation Loss: 0.99066083, Validation R2: 0.280577

Epoch 110/1000
Training Loss: 0.76608288, Training R2: 0.593391
Validation Loss: 1.01828452, Validation R2: 0.238734

Epoch 111/1000
Training Loss: 0.75232713, Training R2: 0.608290
Validation Loss: 1.00752072, Validation R2: 0.255858

Epoch 112/1000
Training Loss: 0.76261776, Training R2: 0.596648
Validation Loss: 1.02663225, Validation R2: 0.227460

Epoch 113/1000
Training Loss: 0.81376993, Training R2: 0.541028
Validation Loss: 1.01625781, Validation R2: 0.243063

Epoch 114/1000
Training Loss: 0.78847831, Training R2: 0.569988
Validation Loss: 1.00926680, Validation R2: 0.252200

Epoch 115/1000
Training Loss: 0.74762868, Training R2: 0.613311
Validation Loss: 1.03279241, Validation R2: 0.218228

Epoch 116/1000
Training Loss: 0.76404157, Training R2: 0.596196
Validation Loss: 1.02610306, Validation R2: 0.228089

Epoch 117/1000
Training Loss: 0.73474360, Training R2: 0.627061
Validation Loss: 0.98842919, Validation R2: 0.283950

Epoch 118/1000
Training Loss: 0.72102066, Training R2: 0.640219
Validation Loss: 0.98459837, Validation R2: 0.289451

Epoch 119/1000
Training Loss: 0.73372684, Training R2: 0.627635
Validation Loss: 1.00811928, Validation R2: 0.254817

Epoch 120/1000
Training Loss: 0.74752113, Training R2: 0.613448
Validation Loss: 1.02793764, Validation R2: 0.225543

Epoch 121/1000
Training Loss: 0.70390327, Training R2: 0.657567
Validation Loss: 1.06436657, Validation R2: 0.169150

Epoch 122/1000
Training Loss: 0.71926812, Training R2: 0.642080
Validation Loss: 1.06077561, Validation R2: 0.174935

Epoch 123/1000
Epoch 00123: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 0.69661652, Training R2: 0.664383
Validation Loss: 1.05533161, Validation R2: 0.183588

Epoch 124/1000
学习率已减少 1 次
Training Loss: 0.72599664, Training R2: 0.634847
Validation Loss: 1.01096486, Validation R2: 0.250415

Epoch 125/1000
Training Loss: 0.71815122, Training R2: 0.643540
Validation Loss: 1.00066439, Validation R2: 0.266035

Epoch 126/1000
Training Loss: 0.70278335, Training R2: 0.657527
Validation Loss: 1.02133348, Validation R2: 0.235276

Epoch 127/1000
Training Loss: 0.69375614, Training R2: 0.666723
Validation Loss: 1.01414351, Validation R2: 0.246132

Epoch 128/1000
Training Loss: 0.67886297, Training R2: 0.681584
Validation Loss: 1.02341337, Validation R2: 0.232020

Epoch 129/1000
Training Loss: 0.64996558, Training R2: 0.707422
Validation Loss: 1.00126177, Validation R2: 0.265209

Epoch 130/1000
Training Loss: 0.62974020, Training R2: 0.725148
Validation Loss: 1.04326584, Validation R2: 0.202241

Epoch 131/1000
Training Loss: 0.64912940, Training R2: 0.708153
Validation Loss: 0.98289524, Validation R2: 0.291692

Epoch 132/1000
Training Loss: 0.62822370, Training R2: 0.726671
Validation Loss: 1.01648791, Validation R2: 0.242720

Epoch 133/1000
Training Loss: 0.60584590, Training R2: 0.744321
Validation Loss: 1.00437154, Validation R2: 0.260659

Epoch 134/1000
Training Loss: 0.58480328, Training R2: 0.762700
Validation Loss: 1.01005802, Validation R2: 0.252219

Epoch 135/1000
Training Loss: 0.57428233, Training R2: 0.771654
Validation Loss: 1.00829205, Validation R2: 0.254866

Epoch 136/1000
Training Loss: 0.56574534, Training R2: 0.778973
Validation Loss: 1.03625752, Validation R2: 0.212977

Epoch 137/1000
Training Loss: 0.56261171, Training R2: 0.780898
Validation Loss: 0.99180067, Validation R2: 0.278258

Epoch 138/1000
Training Loss: 0.56676716, Training R2: 0.777465
Validation Loss: 0.99955992, Validation R2: 0.267686

Epoch 139/1000
Training Loss: 0.58765127, Training R2: 0.760726
Validation Loss: 1.04092819, Validation R2: 0.204765

Epoch 140/1000
Training Loss: 0.57046506, Training R2: 0.774785
Validation Loss: 1.04360883, Validation R2: 0.201685

Epoch 141/1000
Training Loss: 0.56419482, Training R2: 0.779506
Validation Loss: 1.00198104, Validation R2: 0.264155

Epoch 142/1000
Training Loss: 0.55554771, Training R2: 0.786545
Validation Loss: 0.99985994, Validation R2: 0.267162

Epoch 143/1000
Training Loss: 0.53030118, Training R2: 0.805154
Validation Loss: 1.05038420, Validation R2: 0.191372

Epoch 144/1000
Training Loss: 0.53593739, Training R2: 0.801177
Validation Loss: 1.01922085, Validation R2: 0.238605

Epoch 145/1000
Training Loss: 0.55079308, Training R2: 0.789705
Validation Loss: 1.01248943, Validation R2: 0.248327

Epoch 146/1000
Training Loss: 0.55381857, Training R2: 0.787689
Validation Loss: 1.02444060, Validation R2: 0.230593

Epoch 147/1000
Training Loss: 0.52909567, Training R2: 0.806071
Validation Loss: 1.03920149, Validation R2: 0.208474

Epoch 148/1000
Training Loss: 0.51909805, Training R2: 0.813711
Validation Loss: 1.02688561, Validation R2: 0.227134

Epoch 149/1000
Training Loss: 0.53023916, Training R2: 0.805437
Validation Loss: 1.04771512, Validation R2: 0.194954

Epoch 150/1000
Training Loss: 0.51383531, Training R2: 0.816938
Validation Loss: 1.02161031, Validation R2: 0.234837

Epoch 151/1000
Training Loss: 0.49943168, Training R2: 0.827422
Validation Loss: 1.06084954, Validation R2: 0.175163

Epoch 152/1000
Training Loss: 0.47168767, Training R2: 0.846252
Validation Loss: 1.03328296, Validation R2: 0.217437

Epoch 153/1000
Training Loss: 0.47423237, Training R2: 0.844169
Validation Loss: 1.01407440, Validation R2: 0.246234

Epoch 154/1000
Epoch 00154: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 0.50829190, Training R2: 0.821496
Validation Loss: 1.04425071, Validation R2: 0.200587

Epoch 155/1000
学习率已减少 2 次
Training Loss: 0.45658946, Training R2: 0.855753
Validation Loss: 1.02488588, Validation R2: 0.230156

Epoch 156/1000
Training Loss: 0.43727181, Training R2: 0.867358
Validation Loss: 1.03798052, Validation R2: 0.210298

Epoch 157/1000
Training Loss: 0.42597540, Training R2: 0.874009
Validation Loss: 1.02648803, Validation R2: 0.227713

Epoch 158/1000
Training Loss: 0.41790985, Training R2: 0.879270
Validation Loss: 1.02472446, Validation R2: 0.229985

Epoch 159/1000
Training Loss: 0.41178877, Training R2: 0.882812
Validation Loss: 1.03702950, Validation R2: 0.211795

Epoch 160/1000
Training Loss: 0.39319505, Training R2: 0.892838
Validation Loss: 1.04019085, Validation R2: 0.206847

Epoch 161/1000
Training Loss: 0.38840564, Training R2: 0.895678
Validation Loss: 1.04339533, Validation R2: 0.201895

Epoch 162/1000
Training Loss: 0.39027094, Training R2: 0.894368
Validation Loss: 1.02723256, Validation R2: 0.226546

Epoch 163/1000
Training Loss: 0.38950843, Training R2: 0.894523
Validation Loss: 1.04444008, Validation R2: 0.200486

Epoch 164/1000
Training Loss: 0.37372182, Training R2: 0.902765
Validation Loss: 1.06617588, Validation R2: 0.166838

Epoch 165/1000
Training Loss: 0.37328890, Training R2: 0.903532
Validation Loss: 1.04026481, Validation R2: 0.206769

Epoch 166/1000
Training Loss: 0.36421855, Training R2: 0.907373
Validation Loss: 1.01631112, Validation R2: 0.242407

Epoch 167/1000
Training Loss: 0.36562870, Training R2: 0.906896
Validation Loss: 1.06163960, Validation R2: 0.173913

Epoch 168/1000
Training Loss: 0.36656076, Training R2: 0.906769
Validation Loss: 1.03618298, Validation R2: 0.212833

Epoch 169/1000
Training Loss: 0.35382391, Training R2: 0.913105
Validation Loss: 1.06539705, Validation R2: 0.167906

Epoch 170/1000
Training Loss: 0.34782215, Training R2: 0.916068
Validation Loss: 1.05991524, Validation R2: 0.176547

Epoch 171/1000
Training Loss: 0.36309625, Training R2: 0.908726
Validation Loss: 1.10406722, Validation R2: 0.106605

Epoch 172/1000
Training Loss: 0.37728923, Training R2: 0.901221
Validation Loss: 1.06992807, Validation R2: 0.160939

Epoch 173/1000
Training Loss: 0.35733647, Training R2: 0.911229
Validation Loss: 1.02839897, Validation R2: 0.224784

Epoch 174/1000
Training Loss: 0.35391640, Training R2: 0.913034
Validation Loss: 1.05248763, Validation R2: 0.188091

Epoch 175/1000
Training Loss: 0.32971510, Training R2: 0.924603
Validation Loss: 1.05069482, Validation R2: 0.190895

Epoch 176/1000
Training Loss: 0.33218175, Training R2: 0.923485
Validation Loss: 1.07504023, Validation R2: 0.152941

Epoch 177/1000
Training Loss: 0.32982390, Training R2: 0.924727
Validation Loss: 1.06773157, Validation R2: 0.164281

Epoch 178/1000
Training Loss: 0.32492126, Training R2: 0.926242
Validation Loss: 1.06698782, Validation R2: 0.165426

Epoch 179/1000
Training Loss: 0.32059007, Training R2: 0.928938
Validation Loss: 1.07000507, Validation R2: 0.160780

Epoch 180/1000
Training Loss: 0.33295221, Training R2: 0.923329
Validation Loss: 1.08109524, Validation R2: 0.143321

Epoch 181/1000
Training Loss: 0.31926238, Training R2: 0.929135
Validation Loss: 1.05154437, Validation R2: 0.189133

Epoch 182/1000
Training Loss: 0.31309802, Training R2: 0.931776
Validation Loss: 1.03558724, Validation R2: 0.213996

Epoch 183/1000
Training Loss: 0.29585807, Training R2: 0.938988
Validation Loss: 1.06237979, Validation R2: 0.172774

Epoch 184/1000
Training Loss: 0.29312950, Training R2: 0.940228
Validation Loss: 1.05860913, Validation R2: 0.178606

Epoch 185/1000
Epoch 00185: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 0.28893583, Training R2: 0.942198
Validation Loss: 1.05919505, Validation R2: 0.177751

Epoch 186/1000
学习率已减少 3 次
Training Loss: 0.26861770, Training R2: 0.949503
Validation Loss: 1.08910364, Validation R2: 0.130657

Epoch 187/1000
Training Loss: 0.25982653, Training R2: 0.952719
Validation Loss: 1.06872754, Validation R2: 0.162874

Epoch 188/1000
Training Loss: 0.25188592, Training R2: 0.955329
Validation Loss: 1.07327241, Validation R2: 0.155739

Epoch 189/1000
Training Loss: 0.25131424, Training R2: 0.956000
Validation Loss: 1.08732558, Validation R2: 0.133473

Epoch 190/1000
Training Loss: 0.24637277, Training R2: 0.956798
Validation Loss: 1.08086381, Validation R2: 0.143638

Epoch 191/1000
Training Loss: 0.24678123, Training R2: 0.957375
Validation Loss: 1.07936578, Validation R2: 0.146104

Epoch 192/1000
Training Loss: 0.24381131, Training R2: 0.958561
Validation Loss: 1.07002878, Validation R2: 0.160827

Epoch 193/1000
Training Loss: 0.23897729, Training R2: 0.959964
Validation Loss: 1.08080308, Validation R2: 0.143848

Epoch 194/1000
Training Loss: 0.23404277, Training R2: 0.961454
Validation Loss: 1.08527488, Validation R2: 0.136735

Epoch 195/1000
Training Loss: 0.23889464, Training R2: 0.960030
Validation Loss: 1.09214660, Validation R2: 0.125728

Epoch 196/1000
Training Loss: 0.23589187, Training R2: 0.961114
Validation Loss: 1.08119570, Validation R2: 0.143219

Epoch 197/1000
Training Loss: 0.23967047, Training R2: 0.959957
Validation Loss: 1.08530907, Validation R2: 0.136653

Epoch 198/1000
Training Loss: 0.23829419, Training R2: 0.960355
Validation Loss: 1.05867265, Validation R2: 0.178501

Epoch 199/1000
Training Loss: 0.23760092, Training R2: 0.960383
Validation Loss: 1.06661951, Validation R2: 0.166183

Epoch 200/1000
Training Loss: 0.23433637, Training R2: 0.961259
Validation Loss: 1.09740099, Validation R2: 0.117229

Epoch 201/1000
Training Loss: 0.22753508, Training R2: 0.963594
Validation Loss: 1.08698039, Validation R2: 0.133795

Epoch 202/1000
Training Loss: 0.22313530, Training R2: 0.965128
Validation Loss: 1.08151722, Validation R2: 0.142605

Epoch 203/1000
Training Loss: 0.22168613, Training R2: 0.965603
Validation Loss: 1.08368339, Validation R2: 0.139291

Epoch 204/1000
Training Loss: 0.21513966, Training R2: 0.967347
Validation Loss: 1.07908480, Validation R2: 0.146560

Epoch 205/1000
Training Loss: 0.21472048, Training R2: 0.967839
Validation Loss: 1.07807614, Validation R2: 0.147911

Epoch 206/1000
Training Loss: 0.20619152, Training R2: 0.969523
Validation Loss: 1.08729428, Validation R2: 0.133378

Epoch 207/1000
Training Loss: 0.21029666, Training R2: 0.969005
Validation Loss: 1.09671837, Validation R2: 0.118267

Epoch 208/1000
Training Loss: 0.20441898, Training R2: 0.970680
Validation Loss: 1.10027212, Validation R2: 0.112594

Epoch 209/1000
Training Loss: 0.20233012, Training R2: 0.971433
Validation Loss: 1.08621382, Validation R2: 0.135240

Epoch 210/1000
Training Loss: 0.20739680, Training R2: 0.969353
Validation Loss: 1.06661839, Validation R2: 0.165834

Epoch 211/1000
Training Loss: 0.19997703, Training R2: 0.971809
Validation Loss: 1.10594644, Validation R2: 0.103426

Epoch 212/1000
Training Loss: 0.19948096, Training R2: 0.972291
Validation Loss: 1.09113602, Validation R2: 0.127252

Epoch 213/1000
Training Loss: 0.20613742, Training R2: 0.970398
Validation Loss: 1.09434995, Validation R2: 0.122042

Epoch 214/1000
Training Loss: 0.19970992, Training R2: 0.971927
Validation Loss: 1.09608767, Validation R2: 0.119250

Epoch 215/1000
Training Loss: 0.18703460, Training R2: 0.975251
Validation Loss: 1.09188149, Validation R2: 0.126093

Epoch 216/1000
Epoch 00216: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 0.18669051, Training R2: 0.975629
Validation Loss: 1.09172501, Validation R2: 0.125995

Epoch 217/1000
学习率已减少 4 次
Training Loss: 0.17630198, Training R2: 0.977979
Validation Loss: 1.08939301, Validation R2: 0.130062

Epoch 218/1000
Training Loss: 0.16664157, Training R2: 0.980469
Validation Loss: 1.08189790, Validation R2: 0.141974

Epoch 219/1000
Training Loss: 0.16474555, Training R2: 0.980764
Validation Loss: 1.09568532, Validation R2: 0.119728

Epoch 220/1000
Training Loss: 0.16678389, Training R2: 0.980524
Validation Loss: 1.09065104, Validation R2: 0.128141

Epoch 221/1000
Training Loss: 0.16211285, Training R2: 0.981489
Validation Loss: 1.08914784, Validation R2: 0.130430

Epoch 222/1000
Training Loss: 0.15707228, Training R2: 0.982442
Validation Loss: 1.08927867, Validation R2: 0.130243

Epoch 223/1000
Training Loss: 0.15720609, Training R2: 0.982533
Validation Loss: 1.09190036, Validation R2: 0.126047

Epoch 224/1000
Training Loss: 0.15470347, Training R2: 0.983237
Validation Loss: 1.08925834, Validation R2: 0.130302

Epoch 225/1000
Training Loss: 0.14973324, Training R2: 0.984029
Validation Loss: 1.09371874, Validation R2: 0.123012

Epoch 226/1000
Training Loss: 0.14464658, Training R2: 0.984704
Validation Loss: 1.08943910, Validation R2: 0.130051

Epoch 227/1000
Training Loss: 0.14758782, Training R2: 0.984546
Validation Loss: 1.08869382, Validation R2: 0.131098

Epoch 228/1000
Training Loss: 0.14794485, Training R2: 0.984453
Validation Loss: 1.10465865, Validation R2: 0.105528

Epoch 229/1000
Training Loss: 0.14717007, Training R2: 0.984369
Validation Loss: 1.09365867, Validation R2: 0.123140

Epoch 230/1000
Training Loss: 0.14822375, Training R2: 0.984479
Validation Loss: 1.08760635, Validation R2: 0.132891

Epoch 231/1000
Training Loss: 0.14665110, Training R2: 0.984699
Validation Loss: 1.08982062, Validation R2: 0.129366

Epoch 232/1000
Training Loss: 0.14261837, Training R2: 0.985549
Validation Loss: 1.08517147, Validation R2: 0.136830

Epoch 233/1000
Training Loss: 0.14195494, Training R2: 0.985744
Validation Loss: 1.09242458, Validation R2: 0.125042

Epoch 234/1000
Training Loss: 0.14102217, Training R2: 0.985855
Validation Loss: 1.09592523, Validation R2: 0.119613

Epoch 235/1000
Training Loss: 0.13588019, Training R2: 0.986766
Validation Loss: 1.08880391, Validation R2: 0.130955

Epoch 236/1000
Training Loss: 0.13903307, Training R2: 0.986155
Validation Loss: 1.09738248, Validation R2: 0.117238

Epoch 237/1000
Training Loss: 0.13939694, Training R2: 0.986210
Validation Loss: 1.08903801, Validation R2: 0.130579

Epoch 238/1000
Training Loss: 0.13219129, Training R2: 0.987617
Validation Loss: 1.10026152, Validation R2: 0.112551

Epoch 239/1000
Training Loss: 0.12862947, Training R2: 0.988047
Validation Loss: 1.09491863, Validation R2: 0.121261

Epoch 240/1000
Training Loss: 0.12834223, Training R2: 0.988408
Validation Loss: 1.08303510, Validation R2: 0.140038

Epoch 241/1000
Training Loss: 0.12790659, Training R2: 0.988365
Validation Loss: 1.08900967, Validation R2: 0.130620

Epoch 242/1000
Training Loss: 0.12654012, Training R2: 0.988694
Validation Loss: 1.10073163, Validation R2: 0.111787

Epoch 243/1000
Training Loss: 0.12378205, Training R2: 0.989129
Validation Loss: 1.09630238, Validation R2: 0.118882

Epoch 244/1000
Training Loss: 0.12656623, Training R2: 0.988586
Validation Loss: 1.09177446, Validation R2: 0.126252

Epoch 245/1000
Training Loss: 0.12431306, Training R2: 0.988961
Validation Loss: 1.09718541, Validation R2: 0.117523

Epoch 246/1000
Training Loss: 0.12310085, Training R2: 0.989254
Validation Loss: 1.08869760, Validation R2: 0.131119

Epoch 247/1000
Epoch 00247: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 0.12431977, Training R2: 0.988881
Validation Loss: 1.09450330, Validation R2: 0.121671

Epoch 248/1000
学习率已减少 5 次
Training Loss: 0.11915422, Training R2: 0.989930
Validation Loss: 1.09080329, Validation R2: 0.127836

Epoch 249/1000
Training Loss: 0.11228248, Training R2: 0.990814
Validation Loss: 1.09683854, Validation R2: 0.118052

Epoch 250/1000
Training Loss: 0.11099616, Training R2: 0.991091
Validation Loss: 1.08814314, Validation R2: 0.132018

Epoch 251/1000
Training Loss: 0.11080691, Training R2: 0.991362
Validation Loss: 1.09558954, Validation R2: 0.120094

Epoch 252/1000
Training Loss: 0.10677532, Training R2: 0.991658
Validation Loss: 1.09401371, Validation R2: 0.122590

Epoch 253/1000
Training Loss: 0.10701131, Training R2: 0.991817
Validation Loss: 1.09574213, Validation R2: 0.119833

Epoch 254/1000
Training Loss: 0.10614911, Training R2: 0.991872
Validation Loss: 1.10137197, Validation R2: 0.110734

Epoch 255/1000
Training Loss: 0.10736479, Training R2: 0.991764
Validation Loss: 1.09310695, Validation R2: 0.123986

Epoch 256/1000
Training Loss: 0.10602611, Training R2: 0.992000
Validation Loss: 1.09785413, Validation R2: 0.116493

Epoch 257/1000
Training Loss: 0.10753993, Training R2: 0.991731
Validation Loss: 1.09872950, Validation R2: 0.114928

Epoch 258/1000
Training Loss: 0.11317721, Training R2: 0.990981
Validation Loss: 1.09913638, Validation R2: 0.114433

Epoch 259/1000
Training Loss: 0.10951175, Training R2: 0.991521
Validation Loss: 1.09035724, Validation R2: 0.128473

Epoch 260/1000
Training Loss: 0.10503228, Training R2: 0.992164
Validation Loss: 1.09896548, Validation R2: 0.114669

Epoch 261/1000
Training Loss: 0.10112711, Training R2: 0.992536
Validation Loss: 1.09904214, Validation R2: 0.114500

Epoch 262/1000
Training Loss: 0.10039712, Training R2: 0.992762
Validation Loss: 1.09492630, Validation R2: 0.121134

Epoch 263/1000
Training Loss: 0.09896031, Training R2: 0.992874
Validation Loss: 1.09760323, Validation R2: 0.116835

Epoch 264/1000
Training Loss: 0.09974209, Training R2: 0.992850
Validation Loss: 1.09786068, Validation R2: 0.116426

Epoch 265/1000
Training Loss: 0.09622941, Training R2: 0.993208
Validation Loss: 1.09782768, Validation R2: 0.116456

Epoch 266/1000
Training Loss: 0.09643550, Training R2: 0.993227
Validation Loss: 1.09315949, Validation R2: 0.123932

Epoch 267/1000
Training Loss: 0.09582001, Training R2: 0.993349
Validation Loss: 1.09903082, Validation R2: 0.114587

Epoch 268/1000
Training Loss: 0.09539874, Training R2: 0.993520
Validation Loss: 1.09482763, Validation R2: 0.121292

Epoch 269/1000
Training Loss: 0.09146489, Training R2: 0.993655
Validation Loss: 1.10221177, Validation R2: 0.109392

Epoch 270/1000
Training Loss: 0.09192943, Training R2: 0.993642
Validation Loss: 1.09519224, Validation R2: 0.120664

Epoch 271/1000
Training Loss: 0.09310800, Training R2: 0.993749
Validation Loss: 1.09612100, Validation R2: 0.119255

Epoch 272/1000
Training Loss: 0.09438194, Training R2: 0.993467
Validation Loss: 1.09467605, Validation R2: 0.121550

Epoch 273/1000
Training Loss: 0.09339046, Training R2: 0.993736
Validation Loss: 1.09508444, Validation R2: 0.120768

Epoch 274/1000
Training Loss: 0.09067831, Training R2: 0.993802
Validation Loss: 1.09954138, Validation R2: 0.113776

Epoch 275/1000
Training Loss: 0.09177132, Training R2: 0.993854
Validation Loss: 1.09513826, Validation R2: 0.120746

Epoch 276/1000
Training Loss: 0.09274492, Training R2: 0.993797
Validation Loss: 1.09776336, Validation R2: 0.116635

Epoch 277/1000
Training Loss: 0.08917434, Training R2: 0.994141
Validation Loss: 1.09886361, Validation R2: 0.114751

Epoch 278/1000
Epoch 00278: reducing learning rate of group 0 to 7.8125e-06.
Training Loss: 0.08936808, Training R2: 0.994291
Validation Loss: 1.10047846, Validation R2: 0.112218

Epoch 279/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/benchmark/result/Lipo/loss_curve_rot_A.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/benchmark/result/Lipo/r2_curve_rot_A.png
