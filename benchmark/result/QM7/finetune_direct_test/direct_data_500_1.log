Using device: cuda
Total samples: 500, Training: 400, Validation: 100
Total trainable parameters: 4577537
Epoch 1/200
Train Loss: 1560.35247621, Train R²: -51.245724, Val Loss: 1547.52509511, Val R²: -32.846584
Saved best model with validation R2 -32.846584 to best_finetuned_model.pth
Epoch 2/200
Train Loss: 1559.09478865, Train R²: -51.161537, Val Loss: 1545.87389525, Val R²: -32.774391
Saved best model with validation R2 -32.774391 to best_finetuned_model.pth
Epoch 3/200
Train Loss: 1557.20080272, Train R²: -51.034885, Val Loss: 1543.62301421, Val R²: -32.676105
Saved best model with validation R2 -32.676105 to best_finetuned_model.pth
Epoch 4/200
Train Loss: 1554.63617930, Train R²: -50.863621, Val Loss: 1540.49983122, Val R²: -32.539970
Saved best model with validation R2 -32.539970 to best_finetuned_model.pth
Epoch 5/200
Train Loss: 1551.06096592, Train R²: -50.625355, Val Loss: 1536.19812524, Val R²: -32.352921
Saved best model with validation R2 -32.352921 to best_finetuned_model.pth
Epoch 6/200
Train Loss: 1546.14819471, Train R²: -50.298840, Val Loss: 1530.28484277, Val R²: -32.096642
Saved best model with validation R2 -32.096642 to best_finetuned_model.pth
Epoch 7/200
Train Loss: 1539.43954087, Train R²: -49.854641, Val Loss: 1522.32406537, Val R²: -31.753185
Saved best model with validation R2 -31.753185 to best_finetuned_model.pth
Epoch 8/200
Train Loss: 1530.52973836, Train R²: -49.267689, Val Loss: 1511.83277845, Val R²: -31.303299
Saved best model with validation R2 -31.303299 to best_finetuned_model.pth
Epoch 9/200
Train Loss: 1518.84047879, Train R²: -48.502789, Val Loss: 1498.22881096, Val R²: -30.724564
Saved best model with validation R2 -30.724564 to best_finetuned_model.pth
Epoch 10/200
Train Loss: 1503.48996006, Train R²: -47.507221, Val Loss: 1480.38371377, Val R²: -29.973333
Saved best model with validation R2 -29.973333 to best_finetuned_model.pth
Epoch 11/200
Train Loss: 1483.77253648, Train R²: -46.243279, Val Loss: 1457.71442677, Val R²: -29.032003
Saved best model with validation R2 -29.032003 to best_finetuned_model.pth
Epoch 12/200
Train Loss: 1458.69889114, Train R²: -44.660076, Val Loss: 1428.79971655, Val R²: -27.852409
Saved best model with validation R2 -27.852409 to best_finetuned_model.pth
Epoch 13/200
Train Loss: 1426.83377448, Train R²: -42.686993, Val Loss: 1392.63674912, Val R²: -26.410381
Saved best model with validation R2 -26.410381 to best_finetuned_model.pth
Epoch 14/200
Train Loss: 1387.17430772, Train R²: -40.292145, Val Loss: 1347.95157925, Val R²: -24.679579
Saved best model with validation R2 -24.679579 to best_finetuned_model.pth
Epoch 15/200
Train Loss: 1338.35601019, Train R²: -37.436928, Val Loss: 1293.38409028, Val R²: -22.642551
Saved best model with validation R2 -22.642551 to best_finetuned_model.pth
Epoch 16/200
Train Loss: 1278.76066564, Train R²: -34.090046, Val Loss: 1227.64492831, Val R²: -20.300264
Saved best model with validation R2 -20.300264 to best_finetuned_model.pth
Epoch 17/200
Train Loss: 1207.93827657, Train R²: -30.310850, Val Loss: 1150.11485079, Val R²: -17.694841
Saved best model with validation R2 -17.694841 to best_finetuned_model.pth
Epoch 18/200
Train Loss: 1124.46548858, Train R²: -26.132986, Val Loss: 1059.50810993, Val R²: -14.865287
Saved best model with validation R2 -14.865287 to best_finetuned_model.pth
Epoch 19/200
Train Loss: 1027.33233304, Train R²: -21.647865, Val Loss: 956.99755747, Val R²: -11.943777
Saved best model with validation R2 -11.943777 to best_finetuned_model.pth
Epoch 20/200
Train Loss: 918.58944311, Train R²: -17.107071, Val Loss: 841.06578369, Val R²: -8.997681
Saved best model with validation R2 -8.997681 to best_finetuned_model.pth
Epoch 21/200
Train Loss: 798.68501066, Train R²: -12.688517, Val Loss: 719.67966832, Val R²: -6.320114
Saved best model with validation R2 -6.320114 to best_finetuned_model.pth
Epoch 22/200
Train Loss: 670.28842299, Train R²: -8.641149, Val Loss: 593.99535983, Val R²: -3.986611
Saved best model with validation R2 -3.986611 to best_finetuned_model.pth
Epoch 23/200
Train Loss: 541.25270438, Train R²: -5.286451, Val Loss: 471.00444863, Val R²: -2.135374
Saved best model with validation R2 -2.135374 to best_finetuned_model.pth
Epoch 24/200
Train Loss: 417.72697685, Train R²: -2.744470, Val Loss: 370.30698160, Val R²: -0.938042
Saved best model with validation R2 -0.938042 to best_finetuned_model.pth
Epoch 25/200
Train Loss: 316.74581982, Train R²: -1.152916, Val Loss: 302.12313715, Val R²: -0.290053
Saved best model with validation R2 -0.290053 to best_finetuned_model.pth
Epoch 26/200
Train Loss: 248.86488867, Train R²: -0.329023, Val Loss: 257.08085395, Val R²: 0.065931
Saved best model with validation R2 0.065931 to best_finetuned_model.pth
Epoch 27/200
Train Loss: 204.17349317, Train R²: 0.105451, Val Loss: 240.66160468, Val R²: 0.181435
Saved best model with validation R2 0.181435 to best_finetuned_model.pth
Epoch 28/200
Train Loss: 184.11374478, Train R²: 0.272592, Val Loss: 214.65990143, Val R²: 0.348760
Saved best model with validation R2 0.348760 to best_finetuned_model.pth
Epoch 29/200
Train Loss: 158.76877399, Train R²: 0.459077, Val Loss: 189.58550161, Val R²: 0.492016
Saved best model with validation R2 0.492016 to best_finetuned_model.pth
Epoch 30/200
Train Loss: 140.64952453, Train R²: 0.575496, Val Loss: 185.61744219, Val R²: 0.513058
Saved best model with validation R2 0.513058 to best_finetuned_model.pth
Epoch 31/200
Train Loss: 122.53430387, Train R²: 0.677804, Val Loss: 174.63685290, Val R²: 0.568966
Saved best model with validation R2 0.568966 to best_finetuned_model.pth
Epoch 32/200
Train Loss: 108.64974761, Train R²: 0.746684, Val Loss: 166.50631674, Val R²: 0.608167
Saved best model with validation R2 0.608167 to best_finetuned_model.pth
Epoch 33/200
Train Loss: 97.96121921, Train R²: 0.794073, Val Loss: 164.33989026, Val R²: 0.618297
Saved best model with validation R2 0.618297 to best_finetuned_model.pth
Epoch 34/200
Train Loss: 89.79190917, Train R²: 0.826987, Val Loss: 157.51391729, Val R²: 0.649347
Saved best model with validation R2 0.649347 to best_finetuned_model.pth
Epoch 35/200
Train Loss: 80.42386867, Train R²: 0.861205, Val Loss: 157.21693238, Val R²: 0.650668
Saved best model with validation R2 0.650668 to best_finetuned_model.pth
Epoch 36/200
Train Loss: 73.16612572, Train R²: 0.885125, Val Loss: 156.93534322, Val R²: 0.651919
Saved best model with validation R2 0.651919 to best_finetuned_model.pth
Epoch 37/200
Train Loss: 67.44502557, Train R²: 0.902388, Val Loss: 159.72242671, Val R²: 0.639445
Epoch 38/200
Train Loss: 66.49191240, Train R²: 0.905127, Val Loss: 154.60646438, Val R²: 0.662173
Saved best model with validation R2 0.662173 to best_finetuned_model.pth
Epoch 39/200
Train Loss: 59.57080223, Train R²: 0.923850, Val Loss: 150.66919554, Val R²: 0.679160
Saved best model with validation R2 0.679160 to best_finetuned_model.pth
Epoch 40/200
Train Loss: 55.63044601, Train R²: 0.933590, Val Loss: 152.07418112, Val R²: 0.673149
Epoch 41/200
Train Loss: 53.99352500, Train R²: 0.937441, Val Loss: 150.53510180, Val R²: 0.679731
Saved best model with validation R2 0.679731 to best_finetuned_model.pth
Epoch 42/200
Train Loss: 51.84549399, Train R²: 0.942320, Val Loss: 150.41200449, Val R²: 0.680254
Saved best model with validation R2 0.680254 to best_finetuned_model.pth
Epoch 43/200
Train Loss: 49.04675753, Train R²: 0.948379, Val Loss: 145.83569334, Val R²: 0.699415
Saved best model with validation R2 0.699415 to best_finetuned_model.pth
Epoch 44/200
Train Loss: 47.80134939, Train R²: 0.950967, Val Loss: 148.44019234, Val R²: 0.688583
Epoch 45/200
Train Loss: 44.89397030, Train R²: 0.956750, Val Loss: 145.43563519, Val R²: 0.701062
Saved best model with validation R2 0.701062 to best_finetuned_model.pth
Epoch 46/200
Train Loss: 42.31980240, Train R²: 0.961568, Val Loss: 146.40084955, Val R²: 0.697081
Epoch 47/200
Train Loss: 40.39695423, Train R²: 0.964981, Val Loss: 146.42271079, Val R²: 0.696990
Epoch 48/200
Train Loss: 39.02894818, Train R²: 0.967313, Val Loss: 144.39412130, Val R²: 0.705328
Saved best model with validation R2 0.705328 to best_finetuned_model.pth
Epoch 49/200
Train Loss: 37.37997338, Train R²: 0.970016, Val Loss: 143.58675595, Val R²: 0.708614
Saved best model with validation R2 0.708614 to best_finetuned_model.pth
Epoch 50/200
Train Loss: 35.90835760, Train R²: 0.972331, Val Loss: 145.62309119, Val R²: 0.700291
Epoch 51/200
Train Loss: 34.26352039, Train R²: 0.974808, Val Loss: 142.52776977, Val R²: 0.712897
Saved best model with validation R2 0.712897 to best_finetuned_model.pth
Epoch 52/200
Train Loss: 33.32251061, Train R²: 0.976172, Val Loss: 144.08891922, Val R²: 0.706573
Epoch 53/200
Train Loss: 32.14027116, Train R²: 0.977833, Val Loss: 143.03999359, Val R²: 0.710829
Epoch 54/200
Train Loss: 31.07129555, Train R²: 0.979283, Val Loss: 142.30721801, Val R²: 0.713784
Saved best model with validation R2 0.713784 to best_finetuned_model.pth
Epoch 55/200
Train Loss: 30.26299574, Train R²: 0.980347, Val Loss: 142.30384224, Val R²: 0.713798
Saved best model with validation R2 0.713798 to best_finetuned_model.pth
Epoch 56/200
Train Loss: 29.58666500, Train R²: 0.981216, Val Loss: 142.68686405, Val R²: 0.712255
Epoch 57/200
Train Loss: 29.01831776, Train R²: 0.981930, Val Loss: 141.95120200, Val R²: 0.715215
Saved best model with validation R2 0.715215 to best_finetuned_model.pth
Epoch 58/200
Train Loss: 28.09764831, Train R²: 0.983059, Val Loss: 142.64913085, Val R²: 0.712407
Epoch 59/200
Train Loss: 27.69079891, Train R²: 0.983546, Val Loss: 140.47464657, Val R²: 0.721109
Saved best model with validation R2 0.721109 to best_finetuned_model.pth
Epoch 60/200
Train Loss: 28.26963034, Train R²: 0.982851, Val Loss: 142.77961027, Val R²: 0.711881
Epoch 61/200
Train Loss: 27.23876010, Train R²: 0.984079, Val Loss: 141.88512602, Val R²: 0.715480
Epoch 62/200
Train Loss: 27.17032146, Train R²: 0.984159, Val Loss: 142.84014940, Val R²: 0.711637
Epoch 63/200
Train Loss: 26.35849306, Train R²: 0.985091, Val Loss: 139.94655704, Val R²: 0.723201
Saved best model with validation R2 0.723201 to best_finetuned_model.pth
Epoch 64/200
Train Loss: 26.30910751, Train R²: 0.985147, Val Loss: 142.32152941, Val R²: 0.713727
Epoch 65/200
Train Loss: 30.60994440, Train R²: 0.979894, Val Loss: 141.18500717, Val R²: 0.718281
Epoch 66/200
Train Loss: 30.83319530, Train R²: 0.979599, Val Loss: 144.65882356, Val R²: 0.704247
Epoch 67/200
Train Loss: 32.44192193, Train R²: 0.977415, Val Loss: 148.78018864, Val R²: 0.687155
Epoch 68/200
Train Loss: 34.39450885, Train R²: 0.974615, Val Loss: 141.79116300, Val R²: 0.715857
Epoch 69/200
Train Loss: 30.98441022, Train R²: 0.979399, Val Loss: 141.01015367, Val R²: 0.718978
Epoch 70/200
Train Loss: 30.93810550, Train R²: 0.979460, Val Loss: 141.47228886, Val R²: 0.717133
Epoch 71/200
Train Loss: 27.46108379, Train R²: 0.983818, Val Loss: 142.20694537, Val R²: 0.714188
Epoch 72/200
Train Loss: 27.95127731, Train R²: 0.983235, Val Loss: 139.67163305, Val R²: 0.724288
Saved best model with validation R2 0.724288 to best_finetuned_model.pth
Epoch 73/200
Train Loss: 26.42160336, Train R²: 0.985020, Val Loss: 144.04745149, Val R²: 0.706742
Epoch 74/200
Train Loss: 25.50686723, Train R²: 0.986039, Val Loss: 140.00006696, Val R²: 0.722990
Epoch 75/200
Train Loss: 24.51400792, Train R²: 0.987105, Val Loss: 142.45690055, Val R²: 0.713182
Epoch 76/200
Train Loss: 24.47068494, Train R²: 0.987150, Val Loss: 141.96851434, Val R²: 0.715145
Epoch 77/200
Train Loss: 23.68124106, Train R²: 0.987966, Val Loss: 139.81453033, Val R²: 0.723723
Epoch 78/200
Train Loss: 22.90124810, Train R²: 0.988746, Val Loss: 143.35420621, Val R²: 0.709557
Epoch 79/200
Train Loss: 24.52136559, Train R²: 0.987097, Val Loss: 141.09117038, Val R²: 0.718655
Epoch 80/200
Train Loss: 24.99363684, Train R²: 0.986595, Val Loss: 142.40120122, Val R²: 0.713406
Epoch 81/200
Train Loss: 22.32817642, Train R²: 0.989302, Val Loss: 140.33758350, Val R²: 0.721653
Epoch 82/200
Train Loss: 21.70434711, Train R²: 0.989891, Val Loss: 140.52587256, Val R²: 0.720905
Epoch 83/200
Train Loss: 22.25441770, Train R²: 0.989372, Val Loss: 140.64054692, Val R²: 0.720449
Epoch 00083: reducing learning rate of group 0 to 5.0000e-05.
Epoch 84/200
Train Loss: 20.65273027, Train R²: 0.990847, Val Loss: 140.91877342, Val R²: 0.719342
Epoch 85/200
Train Loss: 18.79130174, Train R²: 0.992423, Val Loss: 139.59941126, Val R²: 0.724573
Saved best model with validation R2 0.724573 to best_finetuned_model.pth
Epoch 86/200
Train Loss: 18.22194037, Train R²: 0.992875, Val Loss: 140.39766235, Val R²: 0.721414
Epoch 87/200
Train Loss: 17.88999371, Train R²: 0.993132, Val Loss: 139.95172187, Val R²: 0.723181
Epoch 88/200
Train Loss: 17.25154512, Train R²: 0.993614, Val Loss: 139.88009095, Val R²: 0.723464
Epoch 89/200
Train Loss: 16.87779282, Train R²: 0.993887, Val Loss: 139.30411454, Val R²: 0.725737
Saved best model with validation R2 0.725737 to best_finetuned_model.pth
Epoch 90/200
Train Loss: 16.61233817, Train R²: 0.994078, Val Loss: 139.78507414, Val R²: 0.723840
Epoch 91/200
Train Loss: 16.30028481, Train R²: 0.994298, Val Loss: 140.07260785, Val R²: 0.722703
Epoch 92/200
Train Loss: 16.07405072, Train R²: 0.994456, Val Loss: 139.83638039, Val R²: 0.723637
Epoch 93/200
Train Loss: 15.91583563, Train R²: 0.994564, Val Loss: 139.64942490, Val R²: 0.724376
Epoch 94/200
Train Loss: 15.69985614, Train R²: 0.994711, Val Loss: 139.70013002, Val R²: 0.724175
Epoch 95/200
Train Loss: 15.49137842, Train R²: 0.994850, Val Loss: 139.61930019, Val R²: 0.724495
Epoch 96/200
Train Loss: 15.33198089, Train R²: 0.994956, Val Loss: 139.74696693, Val R²: 0.723990
Epoch 97/200
Train Loss: 15.10227853, Train R²: 0.995106, Val Loss: 139.71958664, Val R²: 0.724099
Epoch 98/200
Train Loss: 14.88940460, Train R²: 0.995243, Val Loss: 139.55972400, Val R²: 0.724730
Epoch 99/200
Train Loss: 14.73203252, Train R²: 0.995343, Val Loss: 139.51743059, Val R²: 0.724896
Epoch 100/200
Train Loss: 14.53750411, Train R²: 0.995465, Val Loss: 139.47763094, Val R²: 0.725053
Epoch 00100: reducing learning rate of group 0 to 2.5000e-05.
Epoch 101/200
Train Loss: 14.41966770, Train R²: 0.995538, Val Loss: 139.42449514, Val R²: 0.725263
Epoch 102/200
Train Loss: 14.33948080, Train R²: 0.995588, Val Loss: 139.48252467, Val R²: 0.725034
Epoch 103/200
Train Loss: 14.25823922, Train R²: 0.995637, Val Loss: 139.52534240, Val R²: 0.724865
Epoch 104/200
Train Loss: 14.18654411, Train R²: 0.995681, Val Loss: 139.55444642, Val R²: 0.724750
Epoch 105/200
Train Loss: 14.12391028, Train R²: 0.995719, Val Loss: 139.46282127, Val R²: 0.725112
Epoch 106/200
Train Loss: 14.02084995, Train R²: 0.995782, Val Loss: 139.44265931, Val R²: 0.725191
Epoch 107/200
Train Loss: 13.93419668, Train R²: 0.995834, Val Loss: 139.37180574, Val R²: 0.725470
Epoch 108/200
Train Loss: 13.83106059, Train R²: 0.995895, Val Loss: 139.30925944, Val R²: 0.725717
Epoch 109/200
Train Loss: 13.74996694, Train R²: 0.995943, Val Loss: 139.34979032, Val R²: 0.725557
Epoch 110/200
Train Loss: 13.67850779, Train R²: 0.995985, Val Loss: 139.29539459, Val R²: 0.725771
Saved best model with validation R2 0.725771 to best_finetuned_model.pth
Epoch 111/200
Train Loss: 13.59396843, Train R²: 0.996035, Val Loss: 139.31852696, Val R²: 0.725680
Epoch 00111: reducing learning rate of group 0 to 1.2500e-05.
Epoch 112/200
Train Loss: 13.52399177, Train R²: 0.996075, Val Loss: 139.34032136, Val R²: 0.725594
Epoch 113/200
Train Loss: 13.48419400, Train R²: 0.996098, Val Loss: 139.29375098, Val R²: 0.725778
Saved best model with validation R2 0.725778 to best_finetuned_model.pth
Epoch 114/200
Train Loss: 13.44930437, Train R²: 0.996118, Val Loss: 139.26306267, Val R²: 0.725899
Saved best model with validation R2 0.725899 to best_finetuned_model.pth
Epoch 115/200
Train Loss: 13.40412936, Train R²: 0.996144, Val Loss: 139.31811900, Val R²: 0.725682
Epoch 116/200
Train Loss: 13.37686773, Train R²: 0.996160, Val Loss: 139.24523107, Val R²: 0.725969
Saved best model with validation R2 0.725969 to best_finetuned_model.pth
Epoch 117/200
Train Loss: 13.32822186, Train R²: 0.996188, Val Loss: 139.22552663, Val R²: 0.726046
Saved best model with validation R2 0.726046 to best_finetuned_model.pth
Epoch 118/200
Train Loss: 13.28416548, Train R²: 0.996213, Val Loss: 139.26902585, Val R²: 0.725875
Epoch 119/200
Train Loss: 13.24233406, Train R²: 0.996237, Val Loss: 139.27900197, Val R²: 0.725836
Epoch 120/200
Train Loss: 13.20603602, Train R²: 0.996258, Val Loss: 139.21781635, Val R²: 0.726077
Saved best model with validation R2 0.726077 to best_finetuned_model.pth
Epoch 121/200
Train Loss: 13.16222121, Train R²: 0.996282, Val Loss: 139.27981755, Val R²: 0.725833
Epoch 122/200
Train Loss: 13.12630194, Train R²: 0.996303, Val Loss: 139.19625001, Val R²: 0.726162
Saved best model with validation R2 0.726162 to best_finetuned_model.pth
Epoch 123/200
Train Loss: 13.08673907, Train R²: 0.996325, Val Loss: 139.18246483, Val R²: 0.726216
Saved best model with validation R2 0.726216 to best_finetuned_model.pth
Epoch 124/200
Train Loss: 13.02868921, Train R²: 0.996357, Val Loss: 139.22533360, Val R²: 0.726047
Epoch 125/200
Train Loss: 12.98460795, Train R²: 0.996382, Val Loss: 139.20884014, Val R²: 0.726112
Epoch 126/200
Train Loss: 12.94519053, Train R²: 0.996404, Val Loss: 139.20814817, Val R²: 0.726115
Epoch 127/200
Train Loss: 12.90194886, Train R²: 0.996428, Val Loss: 139.24393894, Val R²: 0.725974
Epoch 128/200
Train Loss: 12.86248465, Train R²: 0.996450, Val Loss: 139.15343684, Val R²: 0.726330
Saved best model with validation R2 0.726330 to best_finetuned_model.pth
Epoch 129/200
Train Loss: 12.81933299, Train R²: 0.996474, Val Loss: 139.13433117, Val R²: 0.726405
Saved best model with validation R2 0.726405 to best_finetuned_model.pth
Epoch 130/200
Train Loss: 12.76446986, Train R²: 0.996504, Val Loss: 139.17576623, Val R²: 0.726242
Epoch 131/200
Train Loss: 12.71409346, Train R²: 0.996531, Val Loss: 139.12521198, Val R²: 0.726441
Saved best model with validation R2 0.726441 to best_finetuned_model.pth
Epoch 132/200
Train Loss: 12.65611080, Train R²: 0.996563, Val Loss: 139.11705868, Val R²: 0.726473
Saved best model with validation R2 0.726473 to best_finetuned_model.pth
Epoch 133/200
Train Loss: 12.60692339, Train R²: 0.996589, Val Loss: 139.13939447, Val R²: 0.726385
Epoch 134/200
Train Loss: 12.55712780, Train R²: 0.996616, Val Loss: 139.12137995, Val R²: 0.726456
Epoch 135/200
Train Loss: 12.51132367, Train R²: 0.996641, Val Loss: 139.13064201, Val R²: 0.726420
Epoch 136/200
Train Loss: 12.47437601, Train R²: 0.996661, Val Loss: 139.14558810, Val R²: 0.726361
Epoch 137/200
Train Loss: 12.43116057, Train R²: 0.996684, Val Loss: 139.11810883, Val R²: 0.726469
Epoch 138/200
Train Loss: 12.39151775, Train R²: 0.996705, Val Loss: 139.10803019, Val R²: 0.726509
Saved best model with validation R2 0.726509 to best_finetuned_model.pth
Epoch 139/200
Train Loss: 12.34591136, Train R²: 0.996729, Val Loss: 139.07468654, Val R²: 0.726640
Saved best model with validation R2 0.726640 to best_finetuned_model.pth
Epoch 140/200
Train Loss: 12.28530595, Train R²: 0.996761, Val Loss: 139.08785190, Val R²: 0.726588
Epoch 141/200
Train Loss: 12.23824990, Train R²: 0.996786, Val Loss: 139.08200032, Val R²: 0.726611
Epoch 142/200
Train Loss: 12.19954052, Train R²: 0.996806, Val Loss: 139.06907372, Val R²: 0.726662
Saved best model with validation R2 0.726662 to best_finetuned_model.pth
Epoch 143/200
Train Loss: 12.15521303, Train R²: 0.996830, Val Loss: 139.06481065, Val R²: 0.726678
Saved best model with validation R2 0.726678 to best_finetuned_model.pth
Epoch 144/200
Train Loss: 12.11927387, Train R²: 0.996848, Val Loss: 139.05635380, Val R²: 0.726712
Saved best model with validation R2 0.726712 to best_finetuned_model.pth
Epoch 145/200
Train Loss: 12.05964683, Train R²: 0.996879, Val Loss: 139.02133941, Val R²: 0.726849
Saved best model with validation R2 0.726849 to best_finetuned_model.pth
Epoch 146/200
Train Loss: 12.01653940, Train R²: 0.996901, Val Loss: 139.02407334, Val R²: 0.726839
Epoch 147/200
Train Loss: 11.96050712, Train R²: 0.996930, Val Loss: 139.05559253, Val R²: 0.726715
Epoch 148/200
Train Loss: 11.92067983, Train R²: 0.996951, Val Loss: 139.00556110, Val R²: 0.726911
Saved best model with validation R2 0.726911 to best_finetuned_model.pth
Epoch 149/200
Train Loss: 11.85868517, Train R²: 0.996982, Val Loss: 138.97537214, Val R²: 0.727030
Saved best model with validation R2 0.727030 to best_finetuned_model.pth
Epoch 150/200
Train Loss: 11.80141972, Train R²: 0.997011, Val Loss: 138.97552617, Val R²: 0.727029
Epoch 151/200
Train Loss: 11.73215461, Train R²: 0.997046, Val Loss: 138.99698794, Val R²: 0.726945
Epoch 152/200
Train Loss: 11.67301539, Train R²: 0.997076, Val Loss: 139.03956749, Val R²: 0.726778
Epoch 153/200
Train Loss: 11.62634760, Train R²: 0.997099, Val Loss: 138.98947661, Val R²: 0.726975
Epoch 154/200
Train Loss: 11.57073393, Train R²: 0.997127, Val Loss: 138.95267208, Val R²: 0.727119
Saved best model with validation R2 0.727119 to best_finetuned_model.pth
Epoch 155/200
Train Loss: 11.51840779, Train R²: 0.997153, Val Loss: 138.94536303, Val R²: 0.727148
Saved best model with validation R2 0.727148 to best_finetuned_model.pth
Epoch 156/200
Train Loss: 11.48261673, Train R²: 0.997171, Val Loss: 138.95034635, Val R²: 0.727128
Epoch 157/200
Train Loss: 11.41898162, Train R²: 0.997202, Val Loss: 138.96289663, Val R²: 0.727079
Epoch 158/200
Train Loss: 11.38147637, Train R²: 0.997220, Val Loss: 138.95994252, Val R²: 0.727090
Epoch 159/200
Train Loss: 11.33396945, Train R²: 0.997243, Val Loss: 138.95224056, Val R²: 0.727121
Epoch 160/200
Train Loss: 11.29682974, Train R²: 0.997261, Val Loss: 138.93243693, Val R²: 0.727198
Saved best model with validation R2 0.727198 to best_finetuned_model.pth
Epoch 161/200
Train Loss: 11.25536525, Train R²: 0.997282, Val Loss: 138.88214709, Val R²: 0.727396
Saved best model with validation R2 0.727396 to best_finetuned_model.pth
Epoch 162/200
Train Loss: 11.20971715, Train R²: 0.997304, Val Loss: 138.87836292, Val R²: 0.727411
Saved best model with validation R2 0.727411 to best_finetuned_model.pth
Epoch 163/200
Train Loss: 11.16460988, Train R²: 0.997325, Val Loss: 138.91209619, Val R²: 0.727278
Epoch 164/200
Train Loss: 11.12777644, Train R²: 0.997343, Val Loss: 138.91899112, Val R²: 0.727251
Epoch 165/200
Train Loss: 11.09108836, Train R²: 0.997360, Val Loss: 138.89771670, Val R²: 0.727335
Epoch 166/200
Train Loss: 11.05431676, Train R²: 0.997378, Val Loss: 138.88004576, Val R²: 0.727404
Epoch 167/200
Train Loss: 11.00576371, Train R²: 0.997401, Val Loss: 138.89169454, Val R²: 0.727359
Epoch 168/200
Train Loss: 10.96321872, Train R²: 0.997421, Val Loss: 138.86759853, Val R²: 0.727453
Saved best model with validation R2 0.727453 to best_finetuned_model.pth
Epoch 169/200
Train Loss: 10.92172489, Train R²: 0.997440, Val Loss: 138.85900223, Val R²: 0.727487
Saved best model with validation R2 0.727487 to best_finetuned_model.pth
Epoch 170/200
Train Loss: 10.87742431, Train R²: 0.997461, Val Loss: 138.85046954, Val R²: 0.727520
Saved best model with validation R2 0.727520 to best_finetuned_model.pth
Epoch 171/200
Train Loss: 10.82729618, Train R²: 0.997484, Val Loss: 138.85074777, Val R²: 0.727519
Epoch 172/200
Train Loss: 10.77923950, Train R²: 0.997507, Val Loss: 138.85594998, Val R²: 0.727499
Epoch 173/200
Train Loss: 10.73241270, Train R²: 0.997528, Val Loss: 138.82226103, Val R²: 0.727631
Saved best model with validation R2 0.727631 to best_finetuned_model.pth
Epoch 174/200
Train Loss: 10.68526646, Train R²: 0.997550, Val Loss: 138.82162875, Val R²: 0.727634
Saved best model with validation R2 0.727634 to best_finetuned_model.pth
Epoch 175/200
Train Loss: 10.64602071, Train R²: 0.997568, Val Loss: 138.80450028, Val R²: 0.727701
Saved best model with validation R2 0.727701 to best_finetuned_model.pth
Epoch 176/200
Train Loss: 10.60060016, Train R²: 0.997589, Val Loss: 138.80423574, Val R²: 0.727702
Saved best model with validation R2 0.727702 to best_finetuned_model.pth
Epoch 177/200
Train Loss: 10.55882885, Train R²: 0.997608, Val Loss: 138.81319648, Val R²: 0.727667
Epoch 178/200
Train Loss: 10.51292940, Train R²: 0.997628, Val Loss: 138.79273694, Val R²: 0.727747
Saved best model with validation R2 0.727747 to best_finetuned_model.pth
Epoch 179/200
Train Loss: 10.47782353, Train R²: 0.997644, Val Loss: 138.79391507, Val R²: 0.727742
Epoch 180/200
Train Loss: 10.42946511, Train R²: 0.997666, Val Loss: 138.77982590, Val R²: 0.727798
Saved best model with validation R2 0.727798 to best_finetuned_model.pth
Epoch 181/200
Train Loss: 10.39044315, Train R²: 0.997683, Val Loss: 138.75101295, Val R²: 0.727911
Saved best model with validation R2 0.727911 to best_finetuned_model.pth
Epoch 182/200
Train Loss: 10.34487146, Train R²: 0.997704, Val Loss: 138.73166236, Val R²: 0.727986
Saved best model with validation R2 0.727986 to best_finetuned_model.pth
Epoch 183/200
Train Loss: 10.30608835, Train R²: 0.997721, Val Loss: 138.72682943, Val R²: 0.728005
Saved best model with validation R2 0.728005 to best_finetuned_model.pth
Epoch 184/200
Train Loss: 10.26606080, Train R²: 0.997738, Val Loss: 138.74289762, Val R²: 0.727942
Epoch 185/200
Train Loss: 10.23046024, Train R²: 0.997754, Val Loss: 138.73296911, Val R²: 0.727981
Epoch 186/200
Train Loss: 10.17986049, Train R²: 0.997776, Val Loss: 138.76381125, Val R²: 0.727860
Epoch 187/200
Train Loss: 10.14650127, Train R²: 0.997791, Val Loss: 138.72042168, Val R²: 0.728031
Saved best model with validation R2 0.728031 to best_finetuned_model.pth
Epoch 188/200
Train Loss: 10.08629575, Train R²: 0.997817, Val Loss: 138.69518089, Val R²: 0.728130
Saved best model with validation R2 0.728130 to best_finetuned_model.pth
Epoch 189/200
Train Loss: 10.02590722, Train R²: 0.997843, Val Loss: 138.70902464, Val R²: 0.728075
Epoch 190/200
Train Loss: 9.97201571, Train R²: 0.997866, Val Loss: 138.70247891, Val R²: 0.728101
Epoch 191/200
Train Loss: 9.91620702, Train R²: 0.997890, Val Loss: 138.71197170, Val R²: 0.728064
Epoch 192/200
Train Loss: 9.87002281, Train R²: 0.997910, Val Loss: 138.67329439, Val R²: 0.728215
Saved best model with validation R2 0.728215 to best_finetuned_model.pth
Epoch 193/200
Train Loss: 9.82394479, Train R²: 0.997929, Val Loss: 138.64720601, Val R²: 0.728317
Saved best model with validation R2 0.728317 to best_finetuned_model.pth
Epoch 194/200
Train Loss: 9.77958780, Train R²: 0.997948, Val Loss: 138.62560556, Val R²: 0.728402
Saved best model with validation R2 0.728402 to best_finetuned_model.pth
Epoch 195/200
Train Loss: 9.73291913, Train R²: 0.997967, Val Loss: 138.63034875, Val R²: 0.728384
Epoch 196/200
Train Loss: 9.68915318, Train R²: 0.997985, Val Loss: 138.65193043, Val R²: 0.728299
Epoch 197/200
Train Loss: 9.64974783, Train R²: 0.998002, Val Loss: 138.65978232, Val R²: 0.728268
Epoch 198/200
Train Loss: 9.61138855, Train R²: 0.998018, Val Loss: 138.65066855, Val R²: 0.728304
Epoch 199/200
Train Loss: 9.57120736, Train R²: 0.998034, Val Loss: 138.64274543, Val R²: 0.728335
Epoch 200/200
Train Loss: 9.52677543, Train R²: 0.998052, Val Loss: 138.63061080, Val R²: 0.728383
Training Complete. Best Val Loss: 138.62560555548532
训练时间: 111.36 秒
