Using device: cuda
Selected target_properties: ['rot_A']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Actual heads number: 1
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Trainable
interaction_blocks.2.conv1.lin_rel.bias: Trainable
interaction_blocks.2.conv1.lin_root.weight: Trainable
interaction_blocks.2.conv2.lin_rel.weight: Trainable
interaction_blocks.2.conv2.lin_rel.bias: Trainable
interaction_blocks.2.conv2.lin_root.weight: Trainable
interaction_blocks.2.lin1.weight: Trainable
interaction_blocks.2.lin1.bias: Trainable
interaction_blocks.2.lin2.weight: Trainable
interaction_blocks.2.lin2.bias: Trainable
interaction_blocks.2.lin_cat.weight: Trainable
interaction_blocks.2.lin_cat.bias: Trainable
interaction_blocks.2.norm.weight: Trainable
interaction_blocks.2.norm.bias: Trainable
interaction_blocks.2.norm.mean_scale: Trainable
interaction_blocks.2.lin_feature1.lin1.weight: Trainable
interaction_blocks.2.lin_feature1.lin2.weight: Trainable
interaction_blocks.2.lin_feature2.lin1.weight: Trainable
interaction_blocks.2.lin_feature2.lin2.weight: Trainable
interaction_blocks.2.lin.weight: Trainable
interaction_blocks.2.lin.bias: Trainable
interaction_blocks.2.lins.0.weight: Trainable
interaction_blocks.2.lins.0.bias: Trainable
interaction_blocks.2.lins.1.weight: Trainable
interaction_blocks.2.lins.1.bias: Trainable
interaction_blocks.2.lins.2.weight: Trainable
interaction_blocks.2.lins.2.bias: Trainable
interaction_blocks.2.lins.3.weight: Trainable
interaction_blocks.2.lins.3.bias: Trainable
interaction_blocks.2.final.weight: Trainable
interaction_blocks.2.final.bias: Trainable
interaction_blocks.3.conv1.lin_rel.weight: Trainable
interaction_blocks.3.conv1.lin_rel.bias: Trainable
interaction_blocks.3.conv1.lin_root.weight: Trainable
interaction_blocks.3.conv2.lin_rel.weight: Trainable
interaction_blocks.3.conv2.lin_rel.bias: Trainable
interaction_blocks.3.conv2.lin_root.weight: Trainable
interaction_blocks.3.lin1.weight: Trainable
interaction_blocks.3.lin1.bias: Trainable
interaction_blocks.3.lin2.weight: Trainable
interaction_blocks.3.lin2.bias: Trainable
interaction_blocks.3.lin_cat.weight: Trainable
interaction_blocks.3.lin_cat.bias: Trainable
interaction_blocks.3.norm.weight: Trainable
interaction_blocks.3.norm.bias: Trainable
interaction_blocks.3.norm.mean_scale: Trainable
interaction_blocks.3.lin_feature1.lin1.weight: Trainable
interaction_blocks.3.lin_feature1.lin2.weight: Trainable
interaction_blocks.3.lin_feature2.lin1.weight: Trainable
interaction_blocks.3.lin_feature2.lin2.weight: Trainable
interaction_blocks.3.lin.weight: Trainable
interaction_blocks.3.lin.bias: Trainable
interaction_blocks.3.lins.0.weight: Trainable
interaction_blocks.3.lins.0.bias: Trainable
interaction_blocks.3.lins.1.weight: Trainable
interaction_blocks.3.lins.1.bias: Trainable
interaction_blocks.3.lins.2.weight: Trainable
interaction_blocks.3.lins.2.bias: Trainable
interaction_blocks.3.lins.3.weight: Trainable
interaction_blocks.3.lins.3.bias: Trainable
interaction_blocks.3.final.weight: Trainable
interaction_blocks.3.final.bias: Trainable
lins.0.weight: Trainable
lins.0.bias: Trainable
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 2656131

Epoch 1/200
Training Loss: 1363.15146352, Training R2: -33.842899
Validation Loss: 550.16116957, Validation R2: -4.485531
Saved best model with validation loss 550.16116957 to best_qm7_layer_4_data1000.pth

Epoch 2/200
Training Loss: 346.19504280, Training R2: -1.247334
Validation Loss: 227.52656940, Validation R2: 0.061783
Saved best model with validation loss 227.52656940 to best_qm7_layer_4_data1000.pth

Epoch 3/200
Training Loss: 218.52857972, Training R2: 0.104548
Validation Loss: 200.05312712, Validation R2: 0.274680
Saved best model with validation loss 200.05312712 to best_qm7_layer_4_data1000.pth

Epoch 4/200
Training Loss: 183.92880416, Training R2: 0.365655
Validation Loss: 184.41396432, Validation R2: 0.383651
Saved best model with validation loss 184.41396432 to best_qm7_layer_4_data1000.pth

Epoch 5/200
Training Loss: 161.11214456, Training R2: 0.513276
Validation Loss: 154.10761998, Validation R2: 0.569585
Saved best model with validation loss 154.10761998 to best_qm7_layer_4_data1000.pth

Epoch 6/200
Training Loss: 131.16479898, Training R2: 0.677403
Validation Loss: 150.95760981, Validation R2: 0.587001
Saved best model with validation loss 150.95760981 to best_qm7_layer_4_data1000.pth

Epoch 7/200
Training Loss: 115.97724504, Training R2: 0.747785
Validation Loss: 143.15223294, Validation R2: 0.628606
Saved best model with validation loss 143.15223294 to best_qm7_layer_4_data1000.pth

Epoch 8/200
Training Loss: 119.93379782, Training R2: 0.730282
Validation Loss: 139.68342080, Validation R2: 0.646387
Saved best model with validation loss 139.68342080 to best_qm7_layer_4_data1000.pth

Epoch 9/200
Training Loss: 122.97677070, Training R2: 0.716422
Validation Loss: 126.24560516, Validation R2: 0.711151
Saved best model with validation loss 126.24560516 to best_qm7_layer_4_data1000.pth

Epoch 10/200
Training Loss: 95.15753632, Training R2: 0.830210
Validation Loss: 114.79410032, Validation R2: 0.761176
Saved best model with validation loss 114.79410032 to best_qm7_layer_4_data1000.pth

Epoch 11/200
Training Loss: 85.38197149, Training R2: 0.863303
Validation Loss: 112.05868405, Validation R2: 0.772422
Saved best model with validation loss 112.05868405 to best_qm7_layer_4_data1000.pth

Epoch 12/200
Training Loss: 93.30486029, Training R2: 0.836757
Validation Loss: 126.94408479, Validation R2: 0.707946

Epoch 13/200
Training Loss: 86.92843017, Training R2: 0.858307
Validation Loss: 139.13906151, Validation R2: 0.649137

Epoch 14/200
Training Loss: 76.60187686, Training R2: 0.889972
Validation Loss: 111.11451643, Validation R2: 0.776241
Saved best model with validation loss 111.11451643 to best_qm7_layer_4_data1000.pth

Epoch 15/200
Training Loss: 67.98248123, Training R2: 0.913340
Validation Loss: 98.62429103, Validation R2: 0.823719
Saved best model with validation loss 98.62429103 to best_qm7_layer_4_data1000.pth

Epoch 16/200
Training Loss: 70.74920632, Training R2: 0.906142
Validation Loss: 100.19643012, Validation R2: 0.818054

Epoch 17/200
Training Loss: 57.47666994, Training R2: 0.938055
Validation Loss: 100.77468506, Validation R2: 0.815947

Epoch 18/200
Training Loss: 50.24807322, Training R2: 0.952656
Validation Loss: 96.35955616, Validation R2: 0.831722
Saved best model with validation loss 96.35955616 to best_qm7_layer_4_data1000.pth

Epoch 19/200
Training Loss: 44.99796219, Training R2: 0.962032
Validation Loss: 92.76620089, Validation R2: 0.844038
Saved best model with validation loss 92.76620089 to best_qm7_layer_4_data1000.pth

Epoch 20/200
Training Loss: 53.20017861, Training R2: 0.946930
Validation Loss: 101.37391048, Validation R2: 0.813752

Epoch 21/200
Training Loss: 56.89378656, Training R2: 0.939305
Validation Loss: 106.58024009, Validation R2: 0.794130

Epoch 22/200
Training Loss: 59.57937277, Training R2: 0.933439
Validation Loss: 92.60712758, Validation R2: 0.844573
Saved best model with validation loss 92.60712758 to best_qm7_layer_4_data1000.pth

Epoch 23/200
Training Loss: 45.67335916, Training R2: 0.960884
Validation Loss: 91.26512482, Validation R2: 0.849045
Saved best model with validation loss 91.26512482 to best_qm7_layer_4_data1000.pth

Epoch 24/200
Training Loss: 43.20841565, Training R2: 0.964992
Validation Loss: 89.93804943, Validation R2: 0.853403
Saved best model with validation loss 89.93804943 to best_qm7_layer_4_data1000.pth

Epoch 25/200
Training Loss: 37.61351809, Training R2: 0.973471
Validation Loss: 91.69788221, Validation R2: 0.847610

Epoch 26/200
Training Loss: 37.37719403, Training R2: 0.973804
Validation Loss: 89.21009130, Validation R2: 0.855766
Saved best model with validation loss 89.21009130 to best_qm7_layer_4_data1000.pth

Epoch 27/200
Training Loss: 37.20608792, Training R2: 0.974043
Validation Loss: 90.00999044, Validation R2: 0.853168

Epoch 28/200
Training Loss: 40.88565419, Training R2: 0.968655
Validation Loss: 90.29786841, Validation R2: 0.852227

Epoch 29/200
Training Loss: 38.64478837, Training R2: 0.971997
Validation Loss: 86.39232641, Validation R2: 0.864734
Saved best model with validation loss 86.39232641 to best_qm7_layer_4_data1000.pth

Epoch 30/200
Training Loss: 55.20117920, Training R2: 0.942862
Validation Loss: 90.09814701, Validation R2: 0.852880

Epoch 31/200
Training Loss: 40.14977647, Training R2: 0.969773
Validation Loss: 87.16876725, Validation R2: 0.862292

Epoch 32/200
Training Loss: 33.15661110, Training R2: 0.979386
Validation Loss: 88.01830842, Validation R2: 0.859594

Epoch 33/200
Training Loss: 30.65291306, Training R2: 0.982381
Validation Loss: 90.66284318, Validation R2: 0.851030

Epoch 34/200
Training Loss: 30.38401298, Training R2: 0.982689
Validation Loss: 87.98078381, Validation R2: 0.859714

Epoch 35/200
Training Loss: 35.68344281, Training R2: 0.976124
Validation Loss: 88.12665712, Validation R2: 0.859248

Epoch 36/200
Training Loss: 33.46299178, Training R2: 0.979003
Validation Loss: 97.25736506, Validation R2: 0.828571

Epoch 37/200
Training Loss: 30.67297243, Training R2: 0.982358
Validation Loss: 87.72938560, Validation R2: 0.860515

Epoch 38/200
Training Loss: 24.00629271, Training R2: 0.989194
Validation Loss: 86.67550769, Validation R2: 0.863846

Epoch 39/200
Training Loss: 25.07935214, Training R2: 0.988206
Validation Loss: 90.56321428, Validation R2: 0.851358

Epoch 40/200
Training Loss: 27.01301300, Training R2: 0.986317
Validation Loss: 88.58417894, Validation R2: 0.857783

Epoch 41/200
Training Loss: 23.77661646, Training R2: 0.989399
Validation Loss: 84.37447164, Validation R2: 0.870979
Saved best model with validation loss 84.37447164 to best_qm7_layer_4_data1000.pth

Epoch 42/200
Training Loss: 28.14350129, Training R2: 0.985148
Validation Loss: 88.32267303, Validation R2: 0.858622

Epoch 43/200
Training Loss: 24.48323486, Training R2: 0.988760
Validation Loss: 85.24764064, Validation R2: 0.868295

Epoch 44/200
Training Loss: 20.34023077, Training R2: 0.992242
Validation Loss: 85.23137649, Validation R2: 0.868345

Epoch 45/200
Training Loss: 22.86144354, Training R2: 0.990200
Validation Loss: 91.30730981, Validation R2: 0.848905

Epoch 46/200
Training Loss: 23.50950763, Training R2: 0.989636
Validation Loss: 85.91698801, Validation R2: 0.866218

Epoch 47/200
Training Loss: 18.11480992, Training R2: 0.993847
Validation Loss: 85.94641533, Validation R2: 0.866127

Epoch 48/200
Training Loss: 14.48649604, Training R2: 0.996065
Validation Loss: 86.44299998, Validation R2: 0.864575

Epoch 49/200
Training Loss: 17.97739432, Training R2: 0.993940
Validation Loss: 87.30735870, Validation R2: 0.861853

Epoch 50/200
Training Loss: 19.59313309, Training R2: 0.992802
Validation Loss: 87.13294485, Validation R2: 0.862405

Epoch 51/200
Training Loss: 19.99429637, Training R2: 0.992504
Validation Loss: 92.34570070, Validation R2: 0.845449

Epoch 52/200
Training Loss: 20.26955008, Training R2: 0.992296
Validation Loss: 86.73992872, Validation R2: 0.863643

Epoch 53/200
Training Loss: 18.62815257, Training R2: 0.993493
Validation Loss: 85.65146443, Validation R2: 0.867044

Epoch 54/200
Training Loss: 14.74042213, Training R2: 0.995926
Validation Loss: 87.10379999, Validation R2: 0.862497

Epoch 55/200
Training Loss: 11.15680898, Training R2: 0.997666
Validation Loss: 85.01064318, Validation R2: 0.869026

Epoch 56/200
Training Loss: 12.44794329, Training R2: 0.997095
Validation Loss: 88.31720861, Validation R2: 0.858639

Epoch 57/200
Training Loss: 11.25853294, Training R2: 0.997623
Validation Loss: 85.46260821, Validation R2: 0.867630

Epoch 58/200
Training Loss: 10.54512580, Training R2: 0.997915
Validation Loss: 86.52182573, Validation R2: 0.864328

Epoch 59/200
Training Loss: 10.52238734, Training R2: 0.997924
Validation Loss: 85.48379804, Validation R2: 0.867564

Epoch 60/200
Training Loss: 7.46508393, Training R2: 0.998955
Validation Loss: 84.84488926, Validation R2: 0.869536

Epoch 61/200
Training Loss: 13.71822530, Training R2: 0.996471
Validation Loss: 86.92098524, Validation R2: 0.863073

Epoch 62/200
Training Loss: 11.21812213, Training R2: 0.997640
Validation Loss: 84.30587307, Validation R2: 0.871189
Saved best model with validation R2 0.871189 to best_qm7_layer_4_data1000.pth

Epoch 63/200
Training Loss: 11.79556399, Training R2: 0.997391
Validation Loss: 84.66718299, Validation R2: 0.870082

Epoch 64/200
Training Loss: 10.79915630, Training R2: 0.997813
Validation Loss: 86.40945044, Validation R2: 0.864680

Epoch 65/200
Training Loss: 12.65004051, Training R2: 0.996999
Validation Loss: 85.03662802, Validation R2: 0.868946

Epoch 66/200
Training Loss: 13.04128555, Training R2: 0.996811
Validation Loss: 85.32847366, Validation R2: 0.868045

Epoch 67/200
Training Loss: 8.76632766, Training R2: 0.998559
Validation Loss: 86.79529482, Validation R2: 0.863469

Epoch 68/200
Training Loss: 16.63330634, Training R2: 0.994812
Validation Loss: 87.28596590, Validation R2: 0.861921

Epoch 69/200
Training Loss: 32.28900152, Training R2: 0.980451
Validation Loss: 89.09329292, Validation R2: 0.856144

Epoch 70/200
Training Loss: 62.88259203, Training R2: 0.925854
Validation Loss: 151.69399399, Validation R2: 0.582962

Epoch 71/200
Training Loss: 105.26404226, Training R2: 0.792228
Validation Loss: 113.59048912, Validation R2: 0.766158

Epoch 72/200
Training Loss: 107.22656367, Training R2: 0.784409
Validation Loss: 139.61330972, Validation R2: 0.646742

Epoch 73/200
Training Loss: 89.03522466, Training R2: 0.851355
Validation Loss: 116.49342088, Validation R2: 0.754053

Epoch 74/200
Training Loss: 77.01801268, Training R2: 0.888773
Validation Loss: 106.10344341, Validation R2: 0.795968

Epoch 75/200
Training Loss: 64.82813291, Training R2: 0.921195
Validation Loss: 96.38089476, Validation R2: 0.831647

Epoch 76/200
Training Loss: 43.55031763, Training R2: 0.964436
Validation Loss: 93.57370528, Validation R2: 0.841311

Epoch 77/200
Training Loss: 35.21002907, Training R2: 0.976753
Validation Loss: 87.61349537, Validation R2: 0.860883

Epoch 78/200
Training Loss: 30.60043355, Training R2: 0.982442
Validation Loss: 92.72764197, Validation R2: 0.844168

Epoch 79/200
Training Loss: 27.10102352, Training R2: 0.986228
Validation Loss: 96.59963525, Validation R2: 0.830882

Epoch 80/200
Training Loss: 37.57801364, Training R2: 0.973521
Validation Loss: 96.95600484, Validation R2: 0.829632

Epoch 81/200
Training Loss: 30.58495389, Training R2: 0.982459
Validation Loss: 90.72054769, Validation R2: 0.850841

Epoch 82/200
Training Loss: 21.92208880, Training R2: 0.990989
Validation Loss: 85.98531147, Validation R2: 0.866005

Epoch 83/200
Training Loss: 18.21637517, Training R2: 0.993778
Validation Loss: 88.09243359, Validation R2: 0.859358

Epoch 84/200
Training Loss: 15.30401323, Training R2: 0.995608
Validation Loss: 88.72749759, Validation R2: 0.857323

Epoch 85/200
Training Loss: 16.18467375, Training R2: 0.995088
Validation Loss: 87.59891864, Validation R2: 0.860929

Epoch 86/200
Training Loss: 19.68125974, Training R2: 0.992737
Validation Loss: 88.20889469, Validation R2: 0.858986

Epoch 87/200
Training Loss: 16.09499565, Training R2: 0.995143
Validation Loss: 88.02583772, Validation R2: 0.859570

Epoch 88/200
Training Loss: 15.30417577, Training R2: 0.995608
Validation Loss: 86.03352522, Validation R2: 0.865855

Epoch 89/200
Training Loss: 14.99697871, Training R2: 0.995783
Validation Loss: 88.10854478, Validation R2: 0.859306

Epoch 90/200
Training Loss: 10.79857832, Training R2: 0.997813
Validation Loss: 86.52848328, Validation R2: 0.864307

Epoch 91/200
Training Loss: 8.39780627, Training R2: 0.998678
Validation Loss: 86.11988952, Validation R2: 0.865586

Epoch 92/200
Training Loss: 9.69918718, Training R2: 0.998236
Validation Loss: 86.52662772, Validation R2: 0.864313

Epoch 93/200
Epoch 00093: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 7.54627339, Training R2: 0.998932
Validation Loss: 86.64600755, Validation R2: 0.863938

Epoch 94/200
学习率已减少 1 次
Training Loss: 4.98155978, Training R2: 0.999535
Validation Loss: 86.17026976, Validation R2: 0.865428

Epoch 95/200
