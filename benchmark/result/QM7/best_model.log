Using device: cuda
Selected target_properties: ['rot_A']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 7165, Training: 5732, Validation: 1433
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1025539

Epoch 1/1000
Training Loss: 1517.41370498, Training R2: -45.296466
Validation Loss: 1501.80378743, Validation R2: -47.625409
Saved best model with validation R2 -47.625409 to best_model.pth

Epoch 2/1000
Training Loss: 1492.66767929, Training R2: -43.832584
Validation Loss: 1471.60675718, Validation R2: -45.729440
Saved best model with validation R2 -45.729440 to best_model.pth

Epoch 3/1000
Training Loss: 1456.05026750, Training R2: -41.711394
Validation Loss: 1427.24102149, Validation R2: -43.013716
Saved best model with validation R2 -43.013716 to best_model.pth

Epoch 4/1000
Training Loss: 1404.49584944, Training R2: -38.809734
Validation Loss: 1367.23809180, Validation R2: -39.473046
Saved best model with validation R2 -39.473046 to best_model.pth

Epoch 5/1000
Training Loss: 1336.90447133, Training R2: -35.170143
Validation Loss: 1290.81572852, Validation R2: -35.183645
Saved best model with validation R2 -35.183645 to best_model.pth

Epoch 6/1000
Training Loss: 1252.64865302, Training R2: -30.884310
Validation Loss: 1197.48266406, Validation R2: -30.279645
Saved best model with validation R2 -30.279645 to best_model.pth

Epoch 7/1000
Training Loss: 1151.31899971, Training R2: -26.098033
Validation Loss: 1086.90730306, Validation R2: -24.945794
Saved best model with validation R2 -24.945794 to best_model.pth

Epoch 8/1000
Training Loss: 1032.71504922, Training R2: -21.002118
Validation Loss: 958.88606934, Validation R2: -19.415400
Saved best model with validation R2 -19.415400 to best_model.pth

Epoch 9/1000
Training Loss: 896.66122694, Training R2: -15.843148
Validation Loss: 813.38138480, Validation R2: -13.966867
Saved best model with validation R2 -13.966867 to best_model.pth

Epoch 10/1000
Training Loss: 743.47807688, Training R2: -10.897461
Validation Loss: 650.87425459, Validation R2: -8.927717
Saved best model with validation R2 -8.927717 to best_model.pth

Epoch 11/1000
Training Loss: 574.61379538, Training R2: -6.484128
Validation Loss: 473.83182840, Validation R2: -4.683112
Saved best model with validation R2 -4.683112 to best_model.pth

Epoch 12/1000
Training Loss: 398.49968230, Training R2: -3.015739
Validation Loss: 302.35262058, Validation R2: -1.676192
Saved best model with validation R2 -1.676192 to best_model.pth

Epoch 13/1000
Training Loss: 252.49741132, Training R2: -0.869340
Validation Loss: 198.56828245, Validation R2: -0.281504
Saved best model with validation R2 -0.281504 to best_model.pth

Epoch 14/1000
Training Loss: 190.17449145, Training R2: -0.105896
Validation Loss: 175.04758528, Validation R2: -0.008635
Saved best model with validation R2 -0.008635 to best_model.pth

Epoch 15/1000
Training Loss: 180.40411622, Training R2: -0.001897
Validation Loss: 174.43255162, Validation R2: -0.001722
Saved best model with validation R2 -0.001722 to best_model.pth

Epoch 16/1000
Training Loss: 180.07908423, Training R2: -0.001637
Validation Loss: 174.67703715, Validation R2: -0.004575

Epoch 17/1000
Training Loss: 180.08537115, Training R2: -0.001168
Validation Loss: 174.51355837, Validation R2: -0.002752

Epoch 18/1000
Training Loss: 180.17104856, Training R2: -0.001582
Validation Loss: 174.53315637, Validation R2: -0.002984

Epoch 19/1000
Training Loss: 180.12740371, Training R2: -0.001594
Validation Loss: 174.67132071, Validation R2: -0.004510

Epoch 20/1000
Training Loss: 179.98287687, Training R2: -0.001378
Validation Loss: 174.93432888, Validation R2: -0.007339

Epoch 21/1000
Training Loss: 180.37087452, Training R2: -0.003495
Validation Loss: 174.42561040, Validation R2: -0.001601
Saved best model with validation R2 -0.001601 to best_model.pth

Epoch 22/1000
Training Loss: 180.17213524, Training R2: -0.001658
Validation Loss: 174.52084078, Validation R2: -0.002839

Epoch 23/1000
Training Loss: 180.11641349, Training R2: -0.001599
Validation Loss: 174.55025016, Validation R2: -0.003172

Epoch 24/1000
Training Loss: 180.11370096, Training R2: -0.000870
Validation Loss: 174.53404899, Validation R2: -0.002994

Epoch 25/1000
Training Loss: 180.09793435, Training R2: -0.002231
Validation Loss: 174.54590352, Validation R2: -0.003124

Epoch 26/1000
Training Loss: 180.08495590, Training R2: -0.002074
Validation Loss: 174.52540513, Validation R2: -0.002894

Epoch 27/1000
Training Loss: 180.14832577, Training R2: -0.000744
Validation Loss: 174.50315107, Validation R2: -0.002623

Epoch 28/1000
Training Loss: 180.11807630, Training R2: -0.002341
Validation Loss: 174.37388761, Validation R2: -0.000045
Saved best model with validation R2 -0.000045 to best_model.pth

Epoch 29/1000
Training Loss: 180.26677929, Training R2: -0.001495
Validation Loss: 174.35935200, Validation R2: -0.000052

Epoch 30/1000
Training Loss: 180.17182904, Training R2: -0.001456
Validation Loss: 174.79890934, Validation R2: -0.006009

Epoch 31/1000
Training Loss: 180.11139671, Training R2: -0.001894
Validation Loss: 174.48801932, Validation R2: -0.002437

Epoch 32/1000
Training Loss: 180.11693587, Training R2: -0.001117
Validation Loss: 174.72376097, Validation R2: -0.005117

Epoch 33/1000
Training Loss: 180.10445825, Training R2: -0.001910
Validation Loss: 174.48431566, Validation R2: -0.002390

Epoch 34/1000
Training Loss: 180.10870535, Training R2: -0.002248
Validation Loss: 174.54879529, Validation R2: -0.003156

Epoch 35/1000
Training Loss: 180.08779221, Training R2: -0.000676
Validation Loss: 174.47220794, Validation R2: -0.002239

Epoch 36/1000
Training Loss: 180.07647024, Training R2: -0.001150
Validation Loss: 174.49170499, Validation R2: -0.002483

Epoch 37/1000
Training Loss: 180.07635385, Training R2: -0.001409
Validation Loss: 174.58051721, Validation R2: -0.003512

Epoch 38/1000
Training Loss: 180.06941386, Training R2: -0.001143
Validation Loss: 174.45695222, Validation R2: -0.002047

Epoch 39/1000
Training Loss: 180.07556671, Training R2: -0.001195
Validation Loss: 174.55946276, Validation R2: -0.003275

Epoch 40/1000
Training Loss: 180.07489567, Training R2: -0.001249
Validation Loss: 174.47801030, Validation R2: -0.002311

Epoch 41/1000
Training Loss: 180.08384756, Training R2: -0.001731
Validation Loss: 174.58600504, Validation R2: -0.003573

Epoch 42/1000
Training Loss: 180.08924937, Training R2: -0.001412
Validation Loss: 174.52607376, Validation R2: -0.002902

Epoch 43/1000
Training Loss: 180.06703706, Training R2: -0.001080
Validation Loss: 174.50283067, Validation R2: -0.002619

Epoch 44/1000
Training Loss: 180.10974698, Training R2: -0.001262
Validation Loss: 174.51248380, Validation R2: -0.002739

Epoch 45/1000
Training Loss: 180.11948166, Training R2: -0.000603
Validation Loss: 174.44516329, Validation R2: -0.001896

Epoch 46/1000
Training Loss: 180.21093825, Training R2: -0.003221
Validation Loss: 174.60466959, Validation R2: -0.003780

Epoch 47/1000
Training Loss: 180.14367363, Training R2: -0.000785
Validation Loss: 174.36389965, Validation R2: -0.000466

Epoch 48/1000
Training Loss: 180.12641313, Training R2: -0.000808
Validation Loss: 174.54015921, Validation R2: -0.003061

Epoch 49/1000
Epoch 00049: reducing learning rate of group 0 to 2.5000e-03.
Training Loss: 180.09347243, Training R2: -0.001922
Validation Loss: 174.46791574, Validation R2: -0.002186

Epoch 50/1000
学习率已减少 1 次
Training Loss: 180.07830052, Training R2: -0.000645
Validation Loss: 174.45120401, Validation R2: -0.001975

Epoch 51/1000
Training Loss: 180.06832344, Training R2: -0.000814
Validation Loss: 174.51887957, Validation R2: -0.002816

Epoch 52/1000
Training Loss: 180.06803272, Training R2: -0.001276
Validation Loss: 174.51364174, Validation R2: -0.002753

Epoch 53/1000
Training Loss: 180.06482583, Training R2: -0.001250
Validation Loss: 174.53527841, Validation R2: -0.003008

Epoch 54/1000
Training Loss: 180.08647006, Training R2: -0.001179
Validation Loss: 174.52952212, Validation R2: -0.002942

Epoch 55/1000
Training Loss: 180.07025238, Training R2: -0.000963
Validation Loss: 174.48740132, Validation R2: -0.002429

Epoch 56/1000
Training Loss: 180.08292947, Training R2: -0.001396
Validation Loss: 174.54696825, Validation R2: -0.003136

Epoch 57/1000
Training Loss: 180.09364172, Training R2: -0.001112
Validation Loss: 174.49834058, Validation R2: -0.002564

Epoch 58/1000
Training Loss: 180.07549933, Training R2: -0.001212
Validation Loss: 174.53406698, Validation R2: -0.002994

Epoch 59/1000
Training Loss: 180.07837899, Training R2: -0.001183
Validation Loss: 174.47830404, Validation R2: -0.002314

Epoch 60/1000
Training Loss: 180.08208033, Training R2: -0.001685
Validation Loss: 174.55156555, Validation R2: -0.003187

Epoch 61/1000
Training Loss: 180.13840225, Training R2: -0.001252
Validation Loss: 174.50633010, Validation R2: -0.002662

Epoch 62/1000
Training Loss: 180.08863151, Training R2: -0.002068
Validation Loss: 174.61481560, Validation R2: -0.003890

Epoch 63/1000
Training Loss: 180.07222881, Training R2: -0.001044
Validation Loss: 174.43273469, Validation R2: -0.001725

Epoch 64/1000
Training Loss: 180.07168329, Training R2: -0.001003
Validation Loss: 174.51295842, Validation R2: -0.002744

Epoch 65/1000
Training Loss: 180.06590043, Training R2: -0.001246
Validation Loss: 174.53123379, Validation R2: -0.002962

Epoch 66/1000
Training Loss: 180.08914008, Training R2: -0.001168
Validation Loss: 174.50358646, Validation R2: -0.002628

Epoch 67/1000
Training Loss: 180.07868894, Training R2: -0.001395
Validation Loss: 174.50556177, Validation R2: -0.002652

Epoch 68/1000
Training Loss: 180.06564744, Training R2: -0.001239
Validation Loss: 174.54009109, Validation R2: -0.003060

Epoch 69/1000
Training Loss: 180.08086780, Training R2: -0.001720
Validation Loss: 174.52410437, Validation R2: -0.002878

Epoch 70/1000
Epoch 00070: reducing learning rate of group 0 to 1.2500e-03.
Training Loss: 180.07887180, Training R2: -0.001469
Validation Loss: 174.51387006, Validation R2: -0.002756

Epoch 71/1000
学习率已减少 2 次
Training Loss: 180.12292579, Training R2: -0.000806
Validation Loss: 174.43362339, Validation R2: -0.001739

Epoch 72/1000
Training Loss: 180.05720559, Training R2: -0.001162
Validation Loss: 174.56210932, Validation R2: -0.003305

Epoch 73/1000
Training Loss: 180.07829570, Training R2: -0.001767
Validation Loss: 174.58122015, Validation R2: -0.003520

Epoch 74/1000
Training Loss: 180.06536775, Training R2: -0.001281
Validation Loss: 174.50624237, Validation R2: -0.002661

Epoch 75/1000
Training Loss: 180.08966107, Training R2: -0.001485
Validation Loss: 174.51460079, Validation R2: -0.002765

Epoch 76/1000
Training Loss: 180.07527129, Training R2: -0.000932
Validation Loss: 174.48766890, Validation R2: -0.002432

Epoch 77/1000
Training Loss: 180.07196875, Training R2: -0.000786
Validation Loss: 174.46515167, Validation R2: -0.002152

Epoch 78/1000
Training Loss: 180.08225980, Training R2: -0.001505
Validation Loss: 174.55122553, Validation R2: -0.003183

Epoch 79/1000
Training Loss: 180.06626346, Training R2: -0.001221
Validation Loss: 174.49241673, Validation R2: -0.002493

Epoch 80/1000
Training Loss: 180.06618901, Training R2: -0.001061
Validation Loss: 174.50186182, Validation R2: -0.002607

Epoch 81/1000
Training Loss: 180.06745677, Training R2: -0.001017
Validation Loss: 174.49062647, Validation R2: -0.002470

Epoch 82/1000
Training Loss: 180.06705460, Training R2: -0.001140
Validation Loss: 174.51529774, Validation R2: -0.002774

Epoch 83/1000
Training Loss: 180.07143564, Training R2: -0.001434
Validation Loss: 174.52067948, Validation R2: -0.002837

Epoch 84/1000
Training Loss: 180.09082087, Training R2: -0.001702
Validation Loss: 174.55891513, Validation R2: -0.003269

Epoch 85/1000
Training Loss: 180.06574468, Training R2: -0.000844
Validation Loss: 174.44401020, Validation R2: -0.001881

Epoch 86/1000
Training Loss: 180.07585095, Training R2: -0.000625
Validation Loss: 174.48233903, Validation R2: -0.002365

Epoch 87/1000
Training Loss: 180.07770555, Training R2: -0.001613
Validation Loss: 174.57196654, Validation R2: -0.003416

Epoch 88/1000
Training Loss: 180.06819182, Training R2: -0.001158
Validation Loss: 174.48518381, Validation R2: -0.002401

Epoch 89/1000
Training Loss: 180.06893976, Training R2: -0.000895
Validation Loss: 174.46739312, Validation R2: -0.002180

Epoch 90/1000
Training Loss: 180.07339936, Training R2: -0.000958
Validation Loss: 174.49108753, Validation R2: -0.002476

Epoch 91/1000
Epoch 00091: reducing learning rate of group 0 to 6.2500e-04.
Training Loss: 180.06776922, Training R2: -0.001107
Validation Loss: 174.52857338, Validation R2: -0.002931

Epoch 92/1000
学习率已减少 3 次
Training Loss: 180.06456633, Training R2: -0.001307
Validation Loss: 174.53388224, Validation R2: -0.002992

Epoch 93/1000
Training Loss: 180.06627300, Training R2: -0.001171
Validation Loss: 174.51013414, Validation R2: -0.002709

Epoch 94/1000
Training Loss: 180.07514974, Training R2: -0.001469
Validation Loss: 174.52642687, Validation R2: -0.002906

Epoch 95/1000
Training Loss: 180.06605439, Training R2: -0.001199
Validation Loss: 174.52557351, Validation R2: -0.002896

Epoch 96/1000
Training Loss: 180.07941587, Training R2: -0.001483
Validation Loss: 174.54926771, Validation R2: -0.003161

Epoch 97/1000
Training Loss: 180.06120089, Training R2: -0.001126
Validation Loss: 174.49113875, Validation R2: -0.002476

Epoch 98/1000
Training Loss: 180.07162283, Training R2: -0.001147
Validation Loss: 174.50396790, Validation R2: -0.002633

Epoch 99/1000
Training Loss: 180.06624147, Training R2: -0.000955
Validation Loss: 174.47973351, Validation R2: -0.002332

Epoch 100/1000
Training Loss: 180.06445628, Training R2: -0.000918
Validation Loss: 174.50021945, Validation R2: -0.002587

Epoch 101/1000
Training Loss: 180.06820668, Training R2: -0.001249
Validation Loss: 174.53868089, Validation R2: -0.003045

Epoch 102/1000
Training Loss: 180.07108996, Training R2: -0.001121
Validation Loss: 174.50038237, Validation R2: -0.002589

Epoch 103/1000
Training Loss: 180.06384955, Training R2: -0.001085
Validation Loss: 174.51502528, Validation R2: -0.002770

Epoch 104/1000
Training Loss: 180.06879722, Training R2: -0.001081
Validation Loss: 174.51598435, Validation R2: -0.002782

Epoch 105/1000
Training Loss: 180.07276140, Training R2: -0.001420
Validation Loss: 174.54210067, Validation R2: -0.003082

Epoch 106/1000
Training Loss: 180.07002502, Training R2: -0.001070
Validation Loss: 174.49324347, Validation R2: -0.002503

Epoch 107/1000
Training Loss: 180.06563116, Training R2: -0.001030
Validation Loss: 174.50924048, Validation R2: -0.002698

Epoch 108/1000
Training Loss: 180.08456106, Training R2: -0.001702
Validation Loss: 174.57078137, Validation R2: -0.003403

Epoch 109/1000
Training Loss: 180.06360417, Training R2: -0.001266
Validation Loss: 174.51022187, Validation R2: -0.002710

Epoch 110/1000
Training Loss: 180.06871464, Training R2: -0.001307
Validation Loss: 174.52304939, Validation R2: -0.002866

Epoch 111/1000
Training Loss: 180.08010122, Training R2: -0.001149
Validation Loss: 174.49035889, Validation R2: -0.002466

Epoch 112/1000
Epoch 00112: reducing learning rate of group 0 to 3.1250e-04.
Training Loss: 180.06371316, Training R2: -0.001273
Validation Loss: 174.55672846, Validation R2: -0.003244

Epoch 113/1000
学习率已减少 4 次
Training Loss: 180.06737919, Training R2: -0.001368
Validation Loss: 174.53598739, Validation R2: -0.003016

Epoch 114/1000
Training Loss: 180.06365482, Training R2: -0.001310
Validation Loss: 174.52776632, Validation R2: -0.002922

Epoch 115/1000
Training Loss: 180.06716624, Training R2: -0.001184
Validation Loss: 174.51779680, Validation R2: -0.002803

Epoch 116/1000
Training Loss: 180.06270218, Training R2: -0.001166
Validation Loss: 174.51292082, Validation R2: -0.002744

Epoch 117/1000
Training Loss: 180.06332488, Training R2: -0.001168
Validation Loss: 174.51239444, Validation R2: -0.002737

Epoch 118/1000
Training Loss: 180.06553838, Training R2: -0.001084
Validation Loss: 174.50448012, Validation R2: -0.002639

Epoch 119/1000
Training Loss: 180.06300190, Training R2: -0.001037
Validation Loss: 174.49636528, Validation R2: -0.002540

Epoch 120/1000
Training Loss: 180.06440527, Training R2: -0.001021
Validation Loss: 174.49259113, Validation R2: -0.002495

Epoch 121/1000
Training Loss: 180.07031485, Training R2: -0.000952
Validation Loss: 174.47985940, Validation R2: -0.002334

Epoch 122/1000
