Using device: cuda
Total samples: 20000, Training: 16000, Validation: 4000
Total trainable parameters: 4577537
Epoch 1/200
Train Loss: 2.53045825, Train R²: -0.197085, Val Loss: 1.54268765, Val R²: 0.286381
Saved best model with validation R2 0.286381 to best_finetuned_model.pth
Epoch 2/200
Train Loss: 0.99037451, Train R²: 0.531483, Val Loss: 0.69366085, Val R²: 0.679125
Saved best model with validation R2 0.679125 to best_finetuned_model.pth
Epoch 3/200
Train Loss: 0.49058333, Train R²: 0.767920, Val Loss: 0.44051231, Val R²: 0.796227
Saved best model with validation R2 0.796227 to best_finetuned_model.pth
Epoch 4/200
Train Loss: 0.26915729, Train R²: 0.872670, Val Loss: 0.42438847, Val R²: 0.803686
Saved best model with validation R2 0.803686 to best_finetuned_model.pth
Epoch 5/200
Train Loss: 0.17554151, Train R²: 0.916957, Val Loss: 0.31619759, Val R²: 0.853733
Saved best model with validation R2 0.853733 to best_finetuned_model.pth
Epoch 6/200
Train Loss: 0.10729602, Train R²: 0.949241, Val Loss: 0.30053293, Val R²: 0.860979
Saved best model with validation R2 0.860979 to best_finetuned_model.pth
Epoch 7/200
Train Loss: 0.06575831, Train R²: 0.968892, Val Loss: 0.29262292, Val R²: 0.864638
Saved best model with validation R2 0.864638 to best_finetuned_model.pth
Epoch 8/200
Train Loss: 0.04139770, Train R²: 0.980416, Val Loss: 0.27368695, Val R²: 0.873398
Saved best model with validation R2 0.873398 to best_finetuned_model.pth
Epoch 9/200
Train Loss: 0.02803064, Train R²: 0.986740, Val Loss: 0.27085254, Val R²: 0.874709
Saved best model with validation R2 0.874709 to best_finetuned_model.pth
Epoch 10/200
Train Loss: 0.02026909, Train R²: 0.990411, Val Loss: 0.26986704, Val R²: 0.875165
Saved best model with validation R2 0.875165 to best_finetuned_model.pth
Epoch 11/200
Train Loss: 0.01751167, Train R²: 0.991716, Val Loss: 0.27052084, Val R²: 0.874862
Epoch 12/200
Train Loss: 0.01588035, Train R²: 0.992487, Val Loss: 0.26452257, Val R²: 0.877637
Saved best model with validation R2 0.877637 to best_finetuned_model.pth
Epoch 13/200
Train Loss: 0.01592138, Train R²: 0.992468, Val Loss: 0.26065502, Val R²: 0.879426
Saved best model with validation R2 0.879426 to best_finetuned_model.pth
Epoch 14/200
Train Loss: 0.01347523, Train R²: 0.993625, Val Loss: 0.26088903, Val R²: 0.879318
Epoch 15/200
Train Loss: 0.01136875, Train R²: 0.994622, Val Loss: 0.25434082, Val R²: 0.882347
Saved best model with validation R2 0.882347 to best_finetuned_model.pth
Epoch 16/200
Train Loss: 0.01186630, Train R²: 0.994386, Val Loss: 0.25595058, Val R²: 0.881602
Epoch 17/200
Train Loss: 0.00990249, Train R²: 0.995315, Val Loss: 0.25506953, Val R²: 0.882010
Epoch 18/200
Train Loss: 0.00870546, Train R²: 0.995882, Val Loss: 0.25132429, Val R²: 0.883742
Saved best model with validation R2 0.883742 to best_finetuned_model.pth
Epoch 19/200
Train Loss: 0.00770626, Train R²: 0.996354, Val Loss: 0.25613046, Val R²: 0.881519
Epoch 20/200
Train Loss: 0.00717824, Train R²: 0.996604, Val Loss: 0.25369165, Val R²: 0.882647
Epoch 21/200
Train Loss: 0.00536174, Train R²: 0.997464, Val Loss: 0.24867933, Val R²: 0.884966
Saved best model with validation R2 0.884966 to best_finetuned_model.pth
Epoch 22/200
Train Loss: 0.00530095, Train R²: 0.997492, Val Loss: 0.24740776, Val R²: 0.885554
Saved best model with validation R2 0.885554 to best_finetuned_model.pth
Epoch 23/200
Train Loss: 0.00450811, Train R²: 0.997867, Val Loss: 0.24621001, Val R²: 0.886108
Saved best model with validation R2 0.886108 to best_finetuned_model.pth
Epoch 24/200
Train Loss: 0.00389718, Train R²: 0.998156, Val Loss: 0.24614605, Val R²: 0.886137
Saved best model with validation R2 0.886137 to best_finetuned_model.pth
Epoch 25/200
Train Loss: 0.00582539, Train R²: 0.997244, Val Loss: 0.25269925, Val R²: 0.883106
Epoch 26/200
Train Loss: 0.00708160, Train R²: 0.996650, Val Loss: 0.24723954, Val R²: 0.885632
Epoch 27/200
Train Loss: 0.00850355, Train R²: 0.995977, Val Loss: 0.24162954, Val R²: 0.888227
Saved best model with validation R2 0.888227 to best_finetuned_model.pth
Epoch 28/200
Train Loss: 0.01003533, Train R²: 0.995253, Val Loss: 0.24303607, Val R²: 0.887576
Epoch 29/200
Train Loss: 0.00818199, Train R²: 0.996129, Val Loss: 0.24963748, Val R²: 0.884522
Epoch 30/200
Train Loss: 0.00754525, Train R²: 0.996431, Val Loss: 0.24179989, Val R²: 0.888148
Epoch 31/200
Train Loss: 0.00679692, Train R²: 0.996785, Val Loss: 0.25037917, Val R²: 0.884179
Epoch 32/200
Train Loss: 0.00645367, Train R²: 0.996947, Val Loss: 0.23884322, Val R²: 0.889516
Saved best model with validation R2 0.889516 to best_finetuned_model.pth
Epoch 33/200
Train Loss: 0.00557318, Train R²: 0.997364, Val Loss: 0.23876293, Val R²: 0.889553
Saved best model with validation R2 0.889553 to best_finetuned_model.pth
Epoch 34/200
Train Loss: 0.00743205, Train R²: 0.996484, Val Loss: 0.23689965, Val R²: 0.890415
Saved best model with validation R2 0.890415 to best_finetuned_model.pth
Epoch 35/200
Train Loss: 0.00726557, Train R²: 0.996563, Val Loss: 0.23539862, Val R²: 0.891109
Saved best model with validation R2 0.891109 to best_finetuned_model.pth
Epoch 36/200
Train Loss: 0.00563606, Train R²: 0.997334, Val Loss: 0.23912341, Val R²: 0.889386
Epoch 37/200
Train Loss: 0.01140870, Train R²: 0.994603, Val Loss: 0.23367619, Val R²: 0.891906
Saved best model with validation R2 0.891906 to best_finetuned_model.pth
Epoch 38/200
Train Loss: 0.01012741, Train R²: 0.995209, Val Loss: 0.23369959, Val R²: 0.891895
Epoch 39/200
Train Loss: 0.00809035, Train R²: 0.996173, Val Loss: 0.23056854, Val R²: 0.893343
Saved best model with validation R2 0.893343 to best_finetuned_model.pth
Epoch 40/200
Train Loss: 0.00643791, Train R²: 0.996954, Val Loss: 0.23148291, Val R²: 0.892920
Epoch 41/200
Train Loss: 0.00518978, Train R²: 0.997545, Val Loss: 0.22892507, Val R²: 0.894104
Saved best model with validation R2 0.894104 to best_finetuned_model.pth
Epoch 42/200
Train Loss: 0.00550913, Train R²: 0.997394, Val Loss: 0.22785812, Val R²: 0.894597
Saved best model with validation R2 0.894597 to best_finetuned_model.pth
Epoch 43/200
Train Loss: 0.03005388, Train R²: 0.985782, Val Loss: 0.25376866, Val R²: 0.882611
Epoch 44/200
Train Loss: 0.04241718, Train R²: 0.979934, Val Loss: 0.22176480, Val R²: 0.897416
Saved best model with validation R2 0.897416 to best_finetuned_model.pth
Epoch 45/200
Train Loss: 0.02249604, Train R²: 0.989358, Val Loss: 0.21923939, Val R²: 0.898584
Saved best model with validation R2 0.898584 to best_finetuned_model.pth
Epoch 46/200
Train Loss: 0.01452311, Train R²: 0.993130, Val Loss: 0.21518372, Val R²: 0.900460
Saved best model with validation R2 0.900460 to best_finetuned_model.pth
Epoch 47/200
Train Loss: 0.01020028, Train R²: 0.995175, Val Loss: 0.21088317, Val R²: 0.902449
Saved best model with validation R2 0.902449 to best_finetuned_model.pth
Epoch 48/200
Train Loss: 0.00677518, Train R²: 0.996795, Val Loss: 0.21861702, Val R²: 0.898872
Epoch 49/200
Train Loss: 0.00504014, Train R²: 0.997616, Val Loss: 0.21318576, Val R²: 0.901384
Epoch 50/200
Train Loss: 0.00291061, Train R²: 0.998623, Val Loss: 0.21063079, Val R²: 0.902566
Saved best model with validation R2 0.902566 to best_finetuned_model.pth
Epoch 51/200
Train Loss: 0.00177376, Train R²: 0.999161, Val Loss: 0.21072895, Val R²: 0.902521
Epoch 52/200
Train Loss: 0.00137797, Train R²: 0.999348, Val Loss: 0.21265636, Val R²: 0.901629
Epoch 53/200
Train Loss: 0.00247750, Train R²: 0.998828, Val Loss: 0.21567237, Val R²: 0.900234
Epoch 54/200
Train Loss: 0.00610992, Train R²: 0.997110, Val Loss: 0.20853725, Val R²: 0.903535
Saved best model with validation R2 0.903535 to best_finetuned_model.pth
Epoch 55/200
Train Loss: 0.00497778, Train R²: 0.997645, Val Loss: 0.20709404, Val R²: 0.904202
Saved best model with validation R2 0.904202 to best_finetuned_model.pth
Epoch 56/200
Train Loss: 0.00481223, Train R²: 0.997723, Val Loss: 0.21104104, Val R²: 0.902376
Epoch 57/200
Train Loss: 0.00386278, Train R²: 0.998173, Val Loss: 0.21529685, Val R²: 0.900408
Epoch 58/200
Train Loss: 0.00341893, Train R²: 0.998383, Val Loss: 0.20339324, Val R²: 0.905914
Saved best model with validation R2 0.905914 to best_finetuned_model.pth
Epoch 59/200
Train Loss: 0.00347919, Train R²: 0.998354, Val Loss: 0.21293932, Val R²: 0.901498
Epoch 60/200
Train Loss: 0.00313663, Train R²: 0.998516, Val Loss: 0.20485961, Val R²: 0.905236
Epoch 61/200
Train Loss: 0.00388639, Train R²: 0.998161, Val Loss: 0.20800466, Val R²: 0.903781
Epoch 62/200
Train Loss: 0.00376308, Train R²: 0.998220, Val Loss: 0.20670429, Val R²: 0.904382
Epoch 63/200
Train Loss: 0.00316988, Train R²: 0.998500, Val Loss: 0.20554969, Val R²: 0.904917
Epoch 64/200
Train Loss: 0.00291057, Train R²: 0.998623, Val Loss: 0.20489889, Val R²: 0.905218
Epoch 65/200
Train Loss: 0.00350900, Train R²: 0.998340, Val Loss: 0.20381640, Val R²: 0.905718
Epoch 66/200
Train Loss: 0.00602994, Train R²: 0.997147, Val Loss: 0.20326069, Val R²: 0.905975
Saved best model with validation R2 0.905975 to best_finetuned_model.pth
Epoch 67/200
Train Loss: 0.00553349, Train R²: 0.997382, Val Loss: 0.20665919, Val R²: 0.904403
Epoch 68/200
Train Loss: 0.00467764, Train R²: 0.997787, Val Loss: 0.20512543, Val R²: 0.905113
Epoch 69/200
Train Loss: 0.00534740, Train R²: 0.997470, Val Loss: 0.20225352, Val R²: 0.906441
Saved best model with validation R2 0.906441 to best_finetuned_model.pth
Epoch 70/200
Train Loss: 0.00554605, Train R²: 0.997376, Val Loss: 0.20348159, Val R²: 0.905873
Epoch 71/200
Train Loss: 0.00465185, Train R²: 0.997799, Val Loss: 0.20240732, Val R²: 0.906370
Epoch 72/200
Train Loss: 0.00426397, Train R²: 0.997983, Val Loss: 0.20225428, Val R²: 0.906441
Epoch 73/200
Train Loss: 0.00454629, Train R²: 0.997849, Val Loss: 0.21418079, Val R²: 0.900924
Epoch 74/200
Train Loss: 0.00624763, Train R²: 0.997044, Val Loss: 0.20473289, Val R²: 0.905294
Epoch 75/200
Train Loss: 0.00602444, Train R²: 0.997150, Val Loss: 0.20118349, Val R²: 0.906936
Saved best model with validation R2 0.906936 to best_finetuned_model.pth
Epoch 76/200
Train Loss: 0.00799193, Train R²: 0.996219, Val Loss: 0.20508299, Val R²: 0.905132
Epoch 77/200
Train Loss: 0.00671484, Train R²: 0.996823, Val Loss: 0.19810100, Val R²: 0.908362
Saved best model with validation R2 0.908362 to best_finetuned_model.pth
Epoch 78/200
Train Loss: 0.00538377, Train R²: 0.997453, Val Loss: 0.20238579, Val R²: 0.906380
Epoch 79/200
Train Loss: 0.00474981, Train R²: 0.997753, Val Loss: 0.20602185, Val R²: 0.904698
Epoch 80/200
Train Loss: 0.00483639, Train R²: 0.997712, Val Loss: 0.19801211, Val R²: 0.908403
Saved best model with validation R2 0.908403 to best_finetuned_model.pth
Epoch 81/200
Train Loss: 0.00427414, Train R²: 0.997978, Val Loss: 0.19927424, Val R²: 0.907819
Epoch 82/200
Train Loss: 0.00529359, Train R²: 0.997496, Val Loss: 0.19689959, Val R²: 0.908918
Saved best model with validation R2 0.908918 to best_finetuned_model.pth
Epoch 83/200
Train Loss: 0.00549778, Train R²: 0.997399, Val Loss: 0.19298865, Val R²: 0.910727
Saved best model with validation R2 0.910727 to best_finetuned_model.pth
Epoch 84/200
Train Loss: 0.00531804, Train R²: 0.997484, Val Loss: 0.20045054, Val R²: 0.907275
Epoch 85/200
Train Loss: 0.00766275, Train R²: 0.996375, Val Loss: 0.19573829, Val R²: 0.909455
Epoch 86/200
Train Loss: 0.00667249, Train R²: 0.996843, Val Loss: 0.19685349, Val R²: 0.908939
Epoch 87/200
Train Loss: 0.00626897, Train R²: 0.997034, Val Loss: 0.20028039, Val R²: 0.907354
Epoch 88/200
Train Loss: 0.00700927, Train R²: 0.996684, Val Loss: 0.19929553, Val R²: 0.907810
Epoch 89/200
Train Loss: 0.00700399, Train R²: 0.996687, Val Loss: 0.19795444, Val R²: 0.908430
Epoch 90/200
Train Loss: 0.00796823, Train R²: 0.996230, Val Loss: 0.20710809, Val R²: 0.904196
Epoch 91/200
Train Loss: 0.00772988, Train R²: 0.996343, Val Loss: 0.19393871, Val R²: 0.910288
Epoch 92/200
Train Loss: 0.00543687, Train R²: 0.997428, Val Loss: 0.19265769, Val R²: 0.910880
Saved best model with validation R2 0.910880 to best_finetuned_model.pth
Epoch 93/200
Train Loss: 0.00390495, Train R²: 0.998153, Val Loss: 0.19078660, Val R²: 0.911746
Saved best model with validation R2 0.911746 to best_finetuned_model.pth
Epoch 94/200
Train Loss: 0.00314925, Train R²: 0.998510, Val Loss: 0.19434451, Val R²: 0.910100
Epoch 95/200
Train Loss: 0.00257385, Train R²: 0.998782, Val Loss: 0.19280160, Val R²: 0.910814
Epoch 96/200
Train Loss: 0.00183617, Train R²: 0.999131, Val Loss: 0.19321201, Val R²: 0.910624
Epoch 97/200
Train Loss: 0.00260374, Train R²: 0.998768, Val Loss: 0.18841606, Val R²: 0.912842
Saved best model with validation R2 0.912842 to best_finetuned_model.pth
Epoch 98/200
Train Loss: 0.00266638, Train R²: 0.998739, Val Loss: 0.18905037, Val R²: 0.912549
Epoch 99/200
Train Loss: 0.00245251, Train R²: 0.998840, Val Loss: 0.18926661, Val R²: 0.912449
Epoch 100/200
Train Loss: 0.00226329, Train R²: 0.998929, Val Loss: 0.19244919, Val R²: 0.910977
Epoch 101/200
Train Loss: 0.00250782, Train R²: 0.998814, Val Loss: 0.18714107, Val R²: 0.913432
Saved best model with validation R2 0.913432 to best_finetuned_model.pth
Epoch 102/200
Train Loss: 0.00437817, Train R²: 0.997929, Val Loss: 0.18479552, Val R²: 0.914517
Saved best model with validation R2 0.914517 to best_finetuned_model.pth
Epoch 103/200
Train Loss: 0.00678179, Train R²: 0.996792, Val Loss: 0.19735905, Val R²: 0.908705
Epoch 104/200
Train Loss: 0.00923515, Train R²: 0.995631, Val Loss: 0.19682031, Val R²: 0.908955
Epoch 105/200
Train Loss: 0.01320770, Train R²: 0.993752, Val Loss: 0.18487707, Val R²: 0.914479
Epoch 106/200
Train Loss: 0.01176939, Train R²: 0.994432, Val Loss: 0.18925651, Val R²: 0.912453
Epoch 107/200
Train Loss: 0.00740567, Train R²: 0.996497, Val Loss: 0.18048478, Val R²: 0.916511
Saved best model with validation R2 0.916511 to best_finetuned_model.pth
Epoch 108/200
Train Loss: 0.00556829, Train R²: 0.997366, Val Loss: 0.18113439, Val R²: 0.916211
Epoch 109/200
Train Loss: 0.00377771, Train R²: 0.998213, Val Loss: 0.18202825, Val R²: 0.915797
Epoch 110/200
Train Loss: 0.00303430, Train R²: 0.998565, Val Loss: 0.18174982, Val R²: 0.915926
Epoch 111/200
Train Loss: 0.00276634, Train R²: 0.998691, Val Loss: 0.17935023, Val R²: 0.917036
Saved best model with validation R2 0.917036 to best_finetuned_model.pth
Epoch 112/200
Train Loss: 0.00275600, Train R²: 0.998696, Val Loss: 0.18027841, Val R²: 0.916607
Epoch 113/200
Train Loss: 0.00317329, Train R²: 0.998499, Val Loss: 0.18189931, Val R²: 0.915857
Epoch 114/200
Train Loss: 0.00349918, Train R²: 0.998345, Val Loss: 0.18498421, Val R²: 0.914430
Epoch 115/200
Train Loss: 0.00332160, Train R²: 0.998429, Val Loss: 0.18244732, Val R²: 0.915603
Epoch 116/200
Train Loss: 0.00257323, Train R²: 0.998783, Val Loss: 0.17873769, Val R²: 0.917319
Saved best model with validation R2 0.917319 to best_finetuned_model.pth
Epoch 117/200
Train Loss: 0.00293375, Train R²: 0.998612, Val Loss: 0.18195109, Val R²: 0.915833
Epoch 118/200
Train Loss: 0.00402271, Train R²: 0.998097, Val Loss: 0.18597230, Val R²: 0.913973
Epoch 119/200
Train Loss: 0.00446034, Train R²: 0.997890, Val Loss: 0.18000939, Val R²: 0.916731
Epoch 120/200
Train Loss: 0.00392424, Train R²: 0.998144, Val Loss: 0.18114338, Val R²: 0.916206
Epoch 121/200
Train Loss: 0.00325570, Train R²: 0.998460, Val Loss: 0.17852297, Val R²: 0.917419
Saved best model with validation R2 0.917419 to best_finetuned_model.pth
Epoch 122/200
Train Loss: 0.00287595, Train R²: 0.998639, Val Loss: 0.17685918, Val R²: 0.918188
Saved best model with validation R2 0.918188 to best_finetuned_model.pth
Epoch 123/200
Train Loss: 0.00323521, Train R²: 0.998470, Val Loss: 0.17668715, Val R²: 0.918268
Saved best model with validation R2 0.918268 to best_finetuned_model.pth
Epoch 124/200
Train Loss: 0.00398939, Train R²: 0.998113, Val Loss: 0.17937584, Val R²: 0.917024
Epoch 125/200
Train Loss: 0.00671127, Train R²: 0.996825, Val Loss: 0.17896374, Val R²: 0.917215
Epoch 126/200
Train Loss: 0.00581539, Train R²: 0.997249, Val Loss: 0.18759827, Val R²: 0.913221
Epoch 127/200
Train Loss: 0.00473964, Train R²: 0.997758, Val Loss: 0.18139384, Val R²: 0.916091
Epoch 128/200
Train Loss: 0.00475453, Train R²: 0.997751, Val Loss: 0.17327508, Val R²: 0.919846
Saved best model with validation R2 0.919846 to best_finetuned_model.pth
Epoch 129/200
Train Loss: 0.00401432, Train R²: 0.998101, Val Loss: 0.17643196, Val R²: 0.918386
Epoch 130/200
Train Loss: 0.00310850, Train R²: 0.998529, Val Loss: 0.17703649, Val R²: 0.918106
Epoch 131/200
Train Loss: 0.00233282, Train R²: 0.998896, Val Loss: 0.17452840, Val R²: 0.919266
Epoch 132/200
Train Loss: 0.00259144, Train R²: 0.998774, Val Loss: 0.17691035, Val R²: 0.918165
Epoch 133/200
Train Loss: 0.00500629, Train R²: 0.997632, Val Loss: 0.18876787, Val R²: 0.912679
Epoch 134/200
Train Loss: 0.00868883, Train R²: 0.995890, Val Loss: 0.17282894, Val R²: 0.920053
Saved best model with validation R2 0.920053 to best_finetuned_model.pth
Epoch 135/200
Train Loss: 0.00748841, Train R²: 0.996457, Val Loss: 0.17721234, Val R²: 0.918025
Epoch 136/200
Train Loss: 0.00618971, Train R²: 0.997072, Val Loss: 0.17680411, Val R²: 0.918214
Epoch 137/200
Train Loss: 0.00545784, Train R²: 0.997418, Val Loss: 0.17177087, Val R²: 0.920542
Saved best model with validation R2 0.920542 to best_finetuned_model.pth
Epoch 138/200
Train Loss: 0.00418075, Train R²: 0.998022, Val Loss: 0.17337601, Val R²: 0.919800
Epoch 139/200
Train Loss: 0.00369398, Train R²: 0.998253, Val Loss: 0.16914641, Val R²: 0.921756
Saved best model with validation R2 0.921756 to best_finetuned_model.pth
Epoch 140/200
Train Loss: 0.00359597, Train R²: 0.998299, Val Loss: 0.16389952, Val R²: 0.924183
Saved best model with validation R2 0.924183 to best_finetuned_model.pth
Epoch 141/200
Train Loss: 0.00291149, Train R²: 0.998623, Val Loss: 0.16565573, Val R²: 0.923371
Epoch 142/200
Train Loss: 0.00242652, Train R²: 0.998852, Val Loss: 0.16445570, Val R²: 0.923926
Epoch 143/200
Train Loss: 0.00339620, Train R²: 0.998393, Val Loss: 0.16514688, Val R²: 0.923606
Epoch 144/200
Train Loss: 0.00392585, Train R²: 0.998143, Val Loss: 0.18056699, Val R²: 0.916473
Epoch 145/200
Train Loss: 0.00412376, Train R²: 0.998049, Val Loss: 0.17136187, Val R²: 0.920731
Epoch 146/200
Train Loss: 0.00345814, Train R²: 0.998364, Val Loss: 0.17052202, Val R²: 0.921120
Epoch 147/200
Train Loss: 0.00352923, Train R²: 0.998330, Val Loss: 0.16511242, Val R²: 0.923622
Epoch 148/200
Train Loss: 0.00347515, Train R²: 0.998356, Val Loss: 0.16230989, Val R²: 0.924918
Saved best model with validation R2 0.924918 to best_finetuned_model.pth
Epoch 149/200
Train Loss: 0.00279955, Train R²: 0.998676, Val Loss: 0.16836271, Val R²: 0.922119
Epoch 150/200
Train Loss: 0.00266228, Train R²: 0.998741, Val Loss: 0.16648023, Val R²: 0.922989
Epoch 151/200
Train Loss: 0.00229955, Train R²: 0.998912, Val Loss: 0.16974757, Val R²: 0.921478
Epoch 152/200
Train Loss: 0.00256880, Train R²: 0.998785, Val Loss: 0.16458760, Val R²: 0.923865
Epoch 153/200
Train Loss: 0.00245678, Train R²: 0.998838, Val Loss: 0.16919118, Val R²: 0.921735
Epoch 154/200
Train Loss: 0.00216740, Train R²: 0.998975, Val Loss: 0.16584867, Val R²: 0.923281
Epoch 155/200
Train Loss: 0.00203103, Train R²: 0.999039, Val Loss: 0.16426856, Val R²: 0.924012
Epoch 156/200
Train Loss: 0.00189687, Train R²: 0.999103, Val Loss: 0.16826265, Val R²: 0.922165
Epoch 157/200
Train Loss: 0.00161337, Train R²: 0.999237, Val Loss: 0.16724537, Val R²: 0.922635
Epoch 158/200
Train Loss: 0.00187157, Train R²: 0.999115, Val Loss: 0.16600297, Val R²: 0.923210
Epoch 159/200
Train Loss: 0.00214283, Train R²: 0.998986, Val Loss: 0.16777832, Val R²: 0.922389
Epoch 00159: reducing learning rate of group 0 to 5.0000e-05.
Epoch 160/200
Train Loss: 0.00148452, Train R²: 0.999298, Val Loss: 0.16405986, Val R²: 0.924109
Epoch 161/200
Train Loss: 0.00048113, Train R²: 0.999772, Val Loss: 0.16681558, Val R²: 0.922834
Epoch 162/200
Train Loss: 0.00018629, Train R²: 0.999912, Val Loss: 0.16621017, Val R²: 0.923114
Epoch 163/200
Train Loss: 0.00008671, Train R²: 0.999959, Val Loss: 0.16637321, Val R²: 0.923039
Epoch 164/200
Train Loss: 0.00005635, Train R²: 0.999973, Val Loss: 0.16612053, Val R²: 0.923156
Epoch 165/200
Train Loss: 0.00003631, Train R²: 0.999983, Val Loss: 0.16604847, Val R²: 0.923189
Epoch 166/200
Train Loss: 0.00002443, Train R²: 0.999988, Val Loss: 0.16601386, Val R²: 0.923205
Epoch 167/200
Train Loss: 0.00001586, Train R²: 0.999992, Val Loss: 0.16599023, Val R²: 0.923216
Epoch 168/200
Train Loss: 0.00001256, Train R²: 0.999994, Val Loss: 0.16567324, Val R²: 0.923363
Epoch 169/200
Train Loss: 0.00001029, Train R²: 0.999995, Val Loss: 0.16583733, Val R²: 0.923287
Epoch 170/200
Train Loss: 0.00000949, Train R²: 0.999996, Val Loss: 0.16581492, Val R²: 0.923297
Epoch 00170: reducing learning rate of group 0 to 2.5000e-05.
Epoch 171/200
Train Loss: 0.00000793, Train R²: 0.999996, Val Loss: 0.16592214, Val R²: 0.923248
Epoch 172/200
Train Loss: 0.00000627, Train R²: 0.999997, Val Loss: 0.16586427, Val R²: 0.923274
Epoch 173/200
Train Loss: 0.00000543, Train R²: 0.999997, Val Loss: 0.16599609, Val R²: 0.923213
Epoch 174/200
Train Loss: 0.00000607, Train R²: 0.999997, Val Loss: 0.16582592, Val R²: 0.923292
Epoch 175/200
Train Loss: 0.00000518, Train R²: 0.999998, Val Loss: 0.16573864, Val R²: 0.923332
Epoch 176/200
Train Loss: 0.00000606, Train R²: 0.999997, Val Loss: 0.16590587, Val R²: 0.923255
Epoch 177/200
Train Loss: 0.00000528, Train R²: 0.999997, Val Loss: 0.16591854, Val R²: 0.923249
Epoch 178/200
Train Loss: 0.00000595, Train R²: 0.999997, Val Loss: 0.16596418, Val R²: 0.923228
Epoch 179/200
Train Loss: 0.00000552, Train R²: 0.999997, Val Loss: 0.16586048, Val R²: 0.923276
Epoch 180/200
Train Loss: 0.00000482, Train R²: 0.999998, Val Loss: 0.16573376, Val R²: 0.923335
Epoch 181/200
Train Loss: 0.00001257, Train R²: 0.999994, Val Loss: 0.16565788, Val R²: 0.923370
Epoch 00181: reducing learning rate of group 0 to 1.2500e-05.
Epoch 182/200
Train Loss: 0.00000531, Train R²: 0.999997, Val Loss: 0.16567404, Val R²: 0.923362
Epoch 183/200
Train Loss: 0.00000461, Train R²: 0.999998, Val Loss: 0.16584545, Val R²: 0.923283
Epoch 184/200
Train Loss: 0.00000361, Train R²: 0.999998, Val Loss: 0.16586541, Val R²: 0.923274
Epoch 185/200
Train Loss: 0.00000392, Train R²: 0.999998, Val Loss: 0.16589369, Val R²: 0.923261
Epoch 186/200
Train Loss: 0.00000594, Train R²: 0.999997, Val Loss: 0.16575152, Val R²: 0.923326
Epoch 187/200
Train Loss: 0.00000350, Train R²: 0.999998, Val Loss: 0.16573995, Val R²: 0.923332
Epoch 188/200
Train Loss: 0.00000391, Train R²: 0.999998, Val Loss: 0.16584436, Val R²: 0.923283
Epoch 189/200
Train Loss: 0.00000255, Train R²: 0.999999, Val Loss: 0.16583993, Val R²: 0.923286
Epoch 190/200
Train Loss: 0.00000362, Train R²: 0.999998, Val Loss: 0.16586898, Val R²: 0.923272
Epoch 191/200
Train Loss: 0.00000389, Train R²: 0.999998, Val Loss: 0.16580275, Val R²: 0.923303
Epoch 192/200
Train Loss: 0.00000343, Train R²: 0.999998, Val Loss: 0.16586861, Val R²: 0.923272
Epoch 00192: reducing learning rate of group 0 to 6.2500e-06.
Epoch 193/200
Train Loss: 0.00000371, Train R²: 0.999998, Val Loss: 0.16580733, Val R²: 0.923301
Epoch 194/200
Train Loss: 0.00000293, Train R²: 0.999999, Val Loss: 0.16589928, Val R²: 0.923258
Epoch 195/200
Train Loss: 0.00000334, Train R²: 0.999998, Val Loss: 0.16586368, Val R²: 0.923275
Epoch 196/200
Train Loss: 0.00000230, Train R²: 0.999999, Val Loss: 0.16583186, Val R²: 0.923289
Epoch 197/200
Train Loss: 0.00000283, Train R²: 0.999999, Val Loss: 0.16582197, Val R²: 0.923294
Epoch 198/200
Train Loss: 0.00000226, Train R²: 0.999999, Val Loss: 0.16582078, Val R²: 0.923294
Epoch 199/200
Train Loss: 0.00000285, Train R²: 0.999999, Val Loss: 0.16592068, Val R²: 0.923248
Epoch 200/200
Train Loss: 0.00000305, Train R²: 0.999999, Val Loss: 0.16583837, Val R²: 0.923286
Training Complete. Best Val Loss: 0.16230988949537278
训练时间: 3345.00 秒
