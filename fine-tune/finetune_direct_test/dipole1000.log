Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1025539

Epoch 1/1000
Training Loss: 2.45311918, Training R2: -3.359359
Validation Loss: 1.24149895, Validation R2: -0.081848
Saved best model with validation R2 -0.081848 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.20125151, Training R2: -0.142641
Validation Loss: 1.22946167, Validation R2: -0.045014
Saved best model with validation R2 -0.045014 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.18173809, Training R2: -0.239169
Validation Loss: 1.22965717, Validation R2: -0.025481
Saved best model with validation R2 -0.025481 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.17350139, Training R2: -0.062525
Validation Loss: 1.29207253, Validation R2: -0.016745
Saved best model with validation R2 -0.016745 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.13148488, Training R2: -0.006826
Validation Loss: 1.26544940, Validation R2: -0.128378

Epoch 6/1000
Training Loss: 1.13757797, Training R2: -0.121915
Validation Loss: 1.23122633, Validation R2: -0.041549

Epoch 7/1000
Training Loss: 1.11911562, Training R2: -0.073399
Validation Loss: 1.23263896, Validation R2: -0.048447

Epoch 8/1000
Training Loss: 1.11706949, Training R2: -0.022383
Validation Loss: 1.23405600, Validation R2: -0.007961
Saved best model with validation R2 -0.007961 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.11666581, Training R2: -0.028549
Validation Loss: 1.24869609, Validation R2: -0.093411

Epoch 10/1000
Training Loss: 1.12291088, Training R2: -0.098426
Validation Loss: 1.23173249, Validation R2: -0.012303

Epoch 11/1000
Training Loss: 1.13768680, Training R2: -0.015711
Validation Loss: 1.26023877, Validation R2: 0.000167
Saved best model with validation R2 0.000167 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.13266565, Training R2: -0.003637
Validation Loss: 1.23120439, Validation R2: -0.044233

Epoch 13/1000
Training Loss: 1.11903647, Training R2: -0.075719
Validation Loss: 1.23044395, Validation R2: -0.041030

Epoch 14/1000
Training Loss: 1.11648698, Training R2: -0.018244
Validation Loss: 1.23735321, Validation R2: -0.001302

Epoch 15/1000
Training Loss: 1.12087711, Training R2: -0.018495
Validation Loss: 1.22861338, Validation R2: -0.031867

Epoch 16/1000
Training Loss: 1.11279564, Training R2: -0.014685
Validation Loss: 1.23470354, Validation R2: -0.000528

Epoch 17/1000
Training Loss: 1.11888648, Training R2: 0.004316
Validation Loss: 1.22536826, Validation R2: -0.023161

Epoch 18/1000
Training Loss: 1.10884255, Training R2: -0.037317
Validation Loss: 1.24619746, Validation R2: -0.095171

Epoch 19/1000
Training Loss: 1.12362496, Training R2: -0.113290
Validation Loss: 1.22691846, Validation R2: 0.005889
Saved best model with validation R2 0.005889 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 1.14344431, Training R2: -0.001553
Validation Loss: 1.21723688, Validation R2: -0.000499

Epoch 21/1000
Training Loss: 1.11729689, Training R2: -0.075776
Validation Loss: 1.22431350, Validation R2: -0.048725

Epoch 22/1000
Training Loss: 1.11359218, Training R2: -0.006145
Validation Loss: 1.26131165, Validation R2: 0.010356
Saved best model with validation R2 0.010356 to best_finetuned_model.pth

Epoch 23/1000
Training Loss: 1.11371412, Training R2: 0.037710
Validation Loss: 1.24065232, Validation R2: -0.105274

Epoch 24/1000
Training Loss: 1.13145284, Training R2: -0.138647
Validation Loss: 1.20130265, Validation R2: 0.043393
Saved best model with validation R2 0.043393 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 1.08910017, Training R2: 0.086605
Validation Loss: 1.17385495, Validation R2: 0.080264
Saved best model with validation R2 0.080264 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 1.03170889, Training R2: 0.131447
Validation Loss: 1.12387455, Validation R2: 0.072046

Epoch 27/1000
Training Loss: 0.99844098, Training R2: 0.162126
Validation Loss: 1.13571191, Validation R2: 0.112088
Saved best model with validation R2 0.112088 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 1.00991458, Training R2: 0.152462
Validation Loss: 1.14260995, Validation R2: 0.095504

Epoch 29/1000
Training Loss: 1.07723316, Training R2: 0.083481
Validation Loss: 1.20141757, Validation R2: -0.036356

Epoch 30/1000
Training Loss: 1.14046747, Training R2: -0.174699
Validation Loss: 1.19169283, Validation R2: 0.051503

Epoch 31/1000
Training Loss: 1.08361881, Training R2: 0.086777
Validation Loss: 1.20834804, Validation R2: 0.032544

Epoch 32/1000
Training Loss: 1.04058307, Training R2: 0.107767
Validation Loss: 1.23175669, Validation R2: 0.050335

Epoch 33/1000
Training Loss: 1.03877371, Training R2: 0.135758
Validation Loss: 1.15913856, Validation R2: 0.056560

Epoch 34/1000
Training Loss: 1.01835514, Training R2: 0.123002
Validation Loss: 1.16600990, Validation R2: 0.095412

Epoch 35/1000
Training Loss: 1.00871995, Training R2: 0.174673
Validation Loss: 1.13520610, Validation R2: 0.080385

Epoch 36/1000
Training Loss: 1.00475226, Training R2: 0.139485
Validation Loss: 1.19220948, Validation R2: 0.093257

Epoch 37/1000
Training Loss: 1.00185750, Training R2: 0.181638
Validation Loss: 1.12039936, Validation R2: 0.102831

Epoch 38/1000
Training Loss: 0.99589195, Training R2: 0.171264
Validation Loss: 1.13424301, Validation R2: 0.117049
Saved best model with validation R2 0.117049 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.99012756, Training R2: 0.165258
Validation Loss: 1.25756228, Validation R2: 0.029039

Epoch 40/1000
Training Loss: 1.01965509, Training R2: 0.146987
Validation Loss: 1.15296388, Validation R2: 0.068027

Epoch 41/1000
Training Loss: 0.98074450, Training R2: 0.171362
Validation Loss: 1.12317550, Validation R2: 0.140150
Saved best model with validation R2 0.140150 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 0.99410533, Training R2: 0.141566
Validation Loss: 1.15692830, Validation R2: 0.127974

Epoch 43/1000
Training Loss: 0.98172221, Training R2: 0.205184
Validation Loss: 1.11656106, Validation R2: 0.124831

Epoch 44/1000
Training Loss: 0.96283839, Training R2: 0.209131
Validation Loss: 1.11891067, Validation R2: 0.146919
Saved best model with validation R2 0.146919 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.95279440, Training R2: 0.222754
Validation Loss: 1.10286999, Validation R2: 0.154714
Saved best model with validation R2 0.154714 to best_finetuned_model.pth

Epoch 46/1000
Training Loss: 0.94407957, Training R2: 0.231628
Validation Loss: 1.10402846, Validation R2: 0.143352

Epoch 47/1000
Training Loss: 0.93820408, Training R2: 0.226568
Validation Loss: 1.07881081, Validation R2: 0.138910

Epoch 48/1000
Training Loss: 0.93694600, Training R2: 0.213513
Validation Loss: 1.07884598, Validation R2: 0.162879
Saved best model with validation R2 0.162879 to best_finetuned_model.pth

Epoch 49/1000
Training Loss: 0.92071728, Training R2: 0.233760
Validation Loss: 1.07533157, Validation R2: 0.153879

Epoch 50/1000
Training Loss: 0.93032818, Training R2: 0.237772
Validation Loss: 1.09130669, Validation R2: 0.156691

Epoch 51/1000
Training Loss: 0.92510951, Training R2: 0.245388
Validation Loss: 1.06522560, Validation R2: 0.192189
Saved best model with validation R2 0.192189 to best_finetuned_model.pth

Epoch 52/1000
Training Loss: 0.90224069, Training R2: 0.281605
Validation Loss: 1.07850778, Validation R2: 0.173464

Epoch 53/1000
Training Loss: 0.92364165, Training R2: 0.255445
Validation Loss: 1.03716528, Validation R2: 0.192604
Saved best model with validation R2 0.192604 to best_finetuned_model.pth

Epoch 54/1000
Training Loss: 0.92505693, Training R2: 0.249760
Validation Loss: 1.04632866, Validation R2: 0.202367
Saved best model with validation R2 0.202367 to best_finetuned_model.pth

Epoch 55/1000
Training Loss: 0.88846544, Training R2: 0.288483
Validation Loss: 1.09997416, Validation R2: 0.187605

Epoch 56/1000
Training Loss: 0.95751686, Training R2: 0.205815
Validation Loss: 1.13252819, Validation R2: 0.022665

Epoch 57/1000
Training Loss: 0.98186604, Training R2: 0.140347
Validation Loss: 1.17540085, Validation R2: 0.122861

Epoch 58/1000
Training Loss: 1.00174071, Training R2: 0.186853
Validation Loss: 1.06347322, Validation R2: 0.202848
Saved best model with validation R2 0.202848 to best_finetuned_model.pth

Epoch 59/1000
Training Loss: 0.97457289, Training R2: 0.213401
Validation Loss: 1.09944725, Validation R2: 0.094137

Epoch 60/1000
Training Loss: 1.04005184, Training R2: 0.029541
Validation Loss: 1.15173578, Validation R2: 0.132690

Epoch 61/1000
Training Loss: 1.03805542, Training R2: 0.130914
Validation Loss: 1.10639703, Validation R2: 0.158221

Epoch 62/1000
Training Loss: 1.00127885, Training R2: 0.169020
Validation Loss: 1.21133649, Validation R2: 0.087062

Epoch 63/1000
Training Loss: 1.10366323, Training R2: 0.065075
Validation Loss: 1.19086301, Validation R2: 0.015456

Epoch 64/1000
Training Loss: 1.08733153, Training R2: -0.040090
Validation Loss: 1.19132507, Validation R2: -0.001157

Epoch 65/1000
Training Loss: 1.03947591, Training R2: 0.088255
Validation Loss: 1.14894807, Validation R2: 0.128482

Epoch 66/1000
Training Loss: 0.98856441, Training R2: 0.188876
Validation Loss: 1.10689628, Validation R2: 0.159511

Epoch 67/1000
Training Loss: 0.98048973, Training R2: 0.198454
Validation Loss: 1.46288753, Validation R2: -0.226867

Epoch 68/1000
Training Loss: 1.09138559, Training R2: 0.014255
Validation Loss: 1.17351699, Validation R2: 0.013487

Epoch 69/1000
Training Loss: 1.00444267, Training R2: 0.116792
Validation Loss: 1.23223519, Validation R2: 0.056439

Epoch 70/1000
Training Loss: 1.04651961, Training R2: 0.131224
Validation Loss: 1.10165513, Validation R2: 0.131378

Epoch 71/1000
Training Loss: 0.97044220, Training R2: 0.190607
Validation Loss: 1.13938248, Validation R2: 0.138638

Epoch 72/1000
Training Loss: 0.96221962, Training R2: 0.215768
Validation Loss: 1.10304332, Validation R2: 0.173626

Epoch 73/1000
Training Loss: 0.94306854, Training R2: 0.245343
Validation Loss: 1.11955690, Validation R2: 0.152505

Epoch 74/1000
Training Loss: 0.92407194, Training R2: 0.256400
Validation Loss: 1.06038296, Validation R2: 0.196315

Epoch 75/1000
Training Loss: 0.90782283, Training R2: 0.279350
Validation Loss: 1.05544245, Validation R2: 0.206336
Saved best model with validation R2 0.206336 to best_finetuned_model.pth

Epoch 76/1000
Training Loss: 0.89031062, Training R2: 0.300020
Validation Loss: 1.05034471, Validation R2: 0.182441

Epoch 77/1000
Training Loss: 0.90659496, Training R2: 0.267011
Validation Loss: 1.14287400, Validation R2: 0.149234

Epoch 78/1000
Training Loss: 0.91371572, Training R2: 0.276898
Validation Loss: 1.05320227, Validation R2: 0.165459

Epoch 79/1000
Training Loss: 0.87331290, Training R2: 0.301783
Validation Loss: 1.06425869, Validation R2: 0.193612

Epoch 80/1000
Training Loss: 0.89520276, Training R2: 0.273938
Validation Loss: 1.09373116, Validation R2: 0.142646

Epoch 81/1000
Training Loss: 0.92400342, Training R2: 0.236193
Validation Loss: 1.14627147, Validation R2: 0.140649

Epoch 82/1000
Training Loss: 0.93900840, Training R2: 0.250373
Validation Loss: 1.05978060, Validation R2: 0.170042

Epoch 83/1000
Training Loss: 0.88559733, Training R2: 0.292944
Validation Loss: 1.02197456, Validation R2: 0.234144
Saved best model with validation R2 0.234144 to best_finetuned_model.pth

Epoch 84/1000
Training Loss: 0.86042349, Training R2: 0.321734
Validation Loss: 1.07797289, Validation R2: 0.181344

Epoch 85/1000
Training Loss: 0.90862926, Training R2: 0.276523
Validation Loss: 1.01104772, Validation R2: 0.249463
Saved best model with validation R2 0.249463 to best_finetuned_model.pth

Epoch 86/1000
Training Loss: 0.87060855, Training R2: 0.324981
Validation Loss: 1.01876509, Validation R2: 0.235035

Epoch 87/1000
Training Loss: 0.84958215, Training R2: 0.342541
Validation Loss: 1.02880085, Validation R2: 0.215916

Epoch 88/1000
Training Loss: 0.84635637, Training R2: 0.344318
Validation Loss: 1.14210141, Validation R2: 0.123014

Epoch 89/1000
Training Loss: 0.89282810, Training R2: 0.277932
Validation Loss: 0.98517132, Validation R2: 0.259273
Saved best model with validation R2 0.259273 to best_finetuned_model.pth

Epoch 90/1000
Training Loss: 0.81899900, Training R2: 0.373289
Validation Loss: 0.97122085, Validation R2: 0.285281
Saved best model with validation R2 0.285281 to best_finetuned_model.pth

Epoch 91/1000
Training Loss: 0.81500684, Training R2: 0.376703
Validation Loss: 0.95336080, Validation R2: 0.292280
Saved best model with validation R2 0.292280 to best_finetuned_model.pth

Epoch 92/1000
Training Loss: 0.79824769, Training R2: 0.399285
Validation Loss: 0.96700191, Validation R2: 0.278736

Epoch 93/1000
Training Loss: 0.81468435, Training R2: 0.353441
Validation Loss: 1.05817449, Validation R2: 0.196279

Epoch 94/1000
Training Loss: 0.89989258, Training R2: 0.249599
Validation Loss: 1.11028588, Validation R2: 0.184933

Epoch 95/1000
Training Loss: 0.95876223, Training R2: 0.210482
Validation Loss: 1.11855936, Validation R2: 0.067587

Epoch 96/1000
Training Loss: 0.96311632, Training R2: 0.172026
Validation Loss: 1.05312526, Validation R2: 0.211022

Epoch 97/1000
Training Loss: 0.89414237, Training R2: 0.273639
Validation Loss: 1.07776272, Validation R2: 0.152336

Epoch 98/1000
Training Loss: 0.87006949, Training R2: 0.286986
Validation Loss: 1.07060397, Validation R2: 0.187088

Epoch 99/1000
Training Loss: 0.86521253, Training R2: 0.288087
Validation Loss: 1.05035865, Validation R2: 0.208422

Epoch 100/1000
Training Loss: 0.86395146, Training R2: 0.296864
Validation Loss: 1.07015955, Validation R2: 0.115956

Epoch 101/1000
Training Loss: 0.90122391, Training R2: 0.244809
Validation Loss: 1.09039247, Validation R2: 0.186136

Epoch 102/1000
Training Loss: 0.87549123, Training R2: 0.317754
Validation Loss: 1.04589319, Validation R2: 0.207729

Epoch 103/1000
Training Loss: 0.86984107, Training R2: 0.301202
Validation Loss: 1.02459502, Validation R2: 0.226537

Epoch 104/1000
Training Loss: 0.87268657, Training R2: 0.322153
Validation Loss: 1.01287723, Validation R2: 0.227287

Epoch 105/1000
Training Loss: 0.88389301, Training R2: 0.291421
Validation Loss: 1.02444458, Validation R2: 0.251779

Epoch 106/1000
Training Loss: 0.85416898, Training R2: 0.345667
Validation Loss: 1.03990877, Validation R2: 0.221677

Epoch 107/1000
Training Loss: 0.85964721, Training R2: 0.327649
Validation Loss: 1.00372684, Validation R2: 0.246199

Epoch 108/1000
Training Loss: 0.84942047, Training R2: 0.333520
Validation Loss: 1.06198609, Validation R2: 0.141474

Epoch 109/1000
Training Loss: 0.89606848, Training R2: 0.246986
Validation Loss: 1.11772871, Validation R2: 0.151148

Epoch 110/1000
Training Loss: 0.91637267, Training R2: 0.274643
Validation Loss: 1.06450343, Validation R2: 0.126562

Epoch 111/1000
Training Loss: 0.92102935, Training R2: 0.267563
Validation Loss: 1.01678157, Validation R2: 0.226329

Epoch 112/1000
Epoch 00112: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 0.86148836, Training R2: 0.321014
Validation Loss: 0.96529663, Validation R2: 0.266012

Epoch 113/1000
学习率已减少 1 次
Training Loss: 0.80401356, Training R2: 0.392410
Validation Loss: 0.93125319, Validation R2: 0.301969
Saved best model with validation R2 0.301969 to best_finetuned_model.pth

Epoch 114/1000
Training Loss: 0.78018247, Training R2: 0.387819
Validation Loss: 0.94117278, Validation R2: 0.303734
Saved best model with validation R2 0.303734 to best_finetuned_model.pth

Epoch 115/1000
Training Loss: 0.79325091, Training R2: 0.365310
Validation Loss: 0.94617289, Validation R2: 0.291972

Epoch 116/1000
Training Loss: 0.78001044, Training R2: 0.382477
Validation Loss: 0.89773428, Validation R2: 0.332915
Saved best model with validation R2 0.332915 to best_finetuned_model.pth

Epoch 117/1000
Training Loss: 0.77609212, Training R2: 0.397962
Validation Loss: 0.90765423, Validation R2: 0.320652

Epoch 118/1000
Training Loss: 0.77680696, Training R2: 0.403156
Validation Loss: 0.92562634, Validation R2: 0.306351

Epoch 119/1000
Training Loss: 0.77807931, Training R2: 0.412178
Validation Loss: 0.89128059, Validation R2: 0.335206
Saved best model with validation R2 0.335206 to best_finetuned_model.pth

Epoch 120/1000
Training Loss: 0.77244148, Training R2: 0.384006
Validation Loss: 0.89877927, Validation R2: 0.339379
Saved best model with validation R2 0.339379 to best_finetuned_model.pth

Epoch 121/1000
Training Loss: 0.76097741, Training R2: 0.419151
Validation Loss: 0.87580341, Validation R2: 0.353890
Saved best model with validation R2 0.353890 to best_finetuned_model.pth

Epoch 122/1000
Training Loss: 0.74817120, Training R2: 0.427905
Validation Loss: 0.89752269, Validation R2: 0.340173

Epoch 123/1000
Training Loss: 0.74236579, Training R2: 0.446031
Validation Loss: 0.85416484, Validation R2: 0.375740
Saved best model with validation R2 0.375740 to best_finetuned_model.pth

Epoch 124/1000
Training Loss: 0.72734474, Training R2: 0.457998
Validation Loss: 0.94823498, Validation R2: 0.313081

Epoch 125/1000
Training Loss: 0.75538596, Training R2: 0.437240
Validation Loss: 0.83452451, Validation R2: 0.385892
Saved best model with validation R2 0.385892 to best_finetuned_model.pth

Epoch 126/1000
Training Loss: 0.71723225, Training R2: 0.470522
Validation Loss: 0.83868337, Validation R2: 0.380888

Epoch 127/1000
Training Loss: 0.73822538, Training R2: 0.426996
Validation Loss: 0.85401058, Validation R2: 0.376159

Epoch 128/1000
Training Loss: 0.71398490, Training R2: 0.457161
Validation Loss: 0.82039768, Validation R2: 0.391516
Saved best model with validation R2 0.391516 to best_finetuned_model.pth

Epoch 129/1000
Training Loss: 0.70443588, Training R2: 0.469299
Validation Loss: 0.83497757, Validation R2: 0.385619

Epoch 130/1000
Training Loss: 0.69277573, Training R2: 0.486457
Validation Loss: 0.81131387, Validation R2: 0.396156
Saved best model with validation R2 0.396156 to best_finetuned_model.pth

Epoch 131/1000
Training Loss: 0.68945347, Training R2: 0.478208
Validation Loss: 0.80875075, Validation R2: 0.411853
Saved best model with validation R2 0.411853 to best_finetuned_model.pth

Epoch 132/1000
Training Loss: 0.67813569, Training R2: 0.488958
Validation Loss: 0.90405774, Validation R2: 0.272433

Epoch 133/1000
Training Loss: 0.75309411, Training R2: 0.394721
Validation Loss: 0.80350620, Validation R2: 0.419174
Saved best model with validation R2 0.419174 to best_finetuned_model.pth

Epoch 134/1000
Training Loss: 0.67629403, Training R2: 0.474921
Validation Loss: 0.81241727, Validation R2: 0.391635

Epoch 135/1000
Training Loss: 0.71563107, Training R2: 0.446917
Validation Loss: 0.85810578, Validation R2: 0.383282

Epoch 136/1000
Training Loss: 0.70929061, Training R2: 0.463149
Validation Loss: 0.83436728, Validation R2: 0.385730

Epoch 137/1000
Training Loss: 0.69813024, Training R2: 0.492697
Validation Loss: 0.86174840, Validation R2: 0.357017

Epoch 138/1000
Training Loss: 0.69639524, Training R2: 0.494613
Validation Loss: 0.82045048, Validation R2: 0.357576

Epoch 139/1000
Training Loss: 0.67349217, Training R2: 0.505400
Validation Loss: 0.81987542, Validation R2: 0.363229

Epoch 140/1000
Training Loss: 0.68758986, Training R2: 0.486664
Validation Loss: 0.87566769, Validation R2: 0.345438

Epoch 141/1000
Training Loss: 0.71392391, Training R2: 0.463721
Validation Loss: 0.84013534, Validation R2: 0.376273

Epoch 142/1000
Training Loss: 0.74430280, Training R2: 0.436653
Validation Loss: 0.89407879, Validation R2: 0.356155

Epoch 143/1000
Training Loss: 0.78273066, Training R2: 0.434626
Validation Loss: 0.84145063, Validation R2: 0.371400

Epoch 144/1000
Training Loss: 0.74472691, Training R2: 0.457687
Validation Loss: 0.81727201, Validation R2: 0.404288

Epoch 145/1000
Training Loss: 0.72258777, Training R2: 0.456398
Validation Loss: 0.84323883, Validation R2: 0.383472

Epoch 146/1000
Training Loss: 0.69756638, Training R2: 0.489785
Validation Loss: 0.82275909, Validation R2: 0.320135

Epoch 147/1000
Training Loss: 0.68218433, Training R2: 0.500647
Validation Loss: 0.91712350, Validation R2: 0.332009

Epoch 148/1000
Training Loss: 0.74229951, Training R2: 0.437409
Validation Loss: 0.85573643, Validation R2: 0.356747

Epoch 149/1000
Training Loss: 0.73724283, Training R2: 0.445599
Validation Loss: 0.84138089, Validation R2: 0.400199

Epoch 150/1000
Training Loss: 0.69075577, Training R2: 0.505768
Validation Loss: 0.93436080, Validation R2: 0.226489

Epoch 151/1000
Training Loss: 0.73877893, Training R2: 0.424578
Validation Loss: 0.93987316, Validation R2: 0.326187

Epoch 152/1000
Training Loss: 0.74782078, Training R2: 0.437086
Validation Loss: 0.91046011, Validation R2: 0.331496

Epoch 153/1000
Training Loss: 0.76640455, Training R2: 0.421687
Validation Loss: 0.90131468, Validation R2: 0.368723

Epoch 154/1000
Epoch 00154: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 0.74659021, Training R2: 0.473053
Validation Loss: 0.84479457, Validation R2: 0.363832

Epoch 155/1000
学习率已减少 2 次
Training Loss: 0.69497898, Training R2: 0.477103
Validation Loss: 0.82326031, Validation R2: 0.398067

Epoch 156/1000
Training Loss: 0.65372007, Training R2: 0.525860
Validation Loss: 0.83032298, Validation R2: 0.400761

Epoch 157/1000
Training Loss: 0.66276467, Training R2: 0.516980
Validation Loss: 0.80899799, Validation R2: 0.391723

Epoch 158/1000
Training Loss: 0.65395905, Training R2: 0.509097
Validation Loss: 0.80669248, Validation R2: 0.391367

Epoch 159/1000
Training Loss: 0.65459388, Training R2: 0.528432
Validation Loss: 0.80489498, Validation R2: 0.410934

Epoch 160/1000
Training Loss: 0.63781093, Training R2: 0.532916
Validation Loss: 0.79068601, Validation R2: 0.400115

Epoch 161/1000
Training Loss: 0.64019583, Training R2: 0.530721
Validation Loss: 0.79409909, Validation R2: 0.408659

Epoch 162/1000
Training Loss: 0.63054479, Training R2: 0.540383
Validation Loss: 0.79527116, Validation R2: 0.398915

Epoch 163/1000
Training Loss: 0.62754995, Training R2: 0.546987
Validation Loss: 0.78516066, Validation R2: 0.415503

Epoch 164/1000
Training Loss: 0.62341173, Training R2: 0.550030
Validation Loss: 0.77799726, Validation R2: 0.412399

Epoch 165/1000
Training Loss: 0.62214579, Training R2: 0.549503
Validation Loss: 0.77621275, Validation R2: 0.426916
Saved best model with validation R2 0.426916 to best_finetuned_model.pth

Epoch 166/1000
Training Loss: 0.61978345, Training R2: 0.552069
Validation Loss: 0.77721745, Validation R2: 0.424713

Epoch 167/1000
Training Loss: 0.61644309, Training R2: 0.551936
Validation Loss: 0.77556843, Validation R2: 0.428203
Saved best model with validation R2 0.428203 to best_finetuned_model.pth

Epoch 168/1000
Training Loss: 0.62906352, Training R2: 0.538838
Validation Loss: 0.78632849, Validation R2: 0.417575

Epoch 169/1000
Training Loss: 0.64830297, Training R2: 0.525011
Validation Loss: 0.78449231, Validation R2: 0.413048

Epoch 170/1000
Training Loss: 0.63872907, Training R2: 0.532011
Validation Loss: 0.80625701, Validation R2: 0.410979

Epoch 171/1000
Training Loss: 0.64261304, Training R2: 0.524789
Validation Loss: 0.78913659, Validation R2: 0.410779

Epoch 172/1000
Training Loss: 0.63383065, Training R2: 0.533599
Validation Loss: 0.77729523, Validation R2: 0.425113

Epoch 173/1000
Training Loss: 0.62489165, Training R2: 0.543317
Validation Loss: 0.77805638, Validation R2: 0.402127

Epoch 174/1000
Training Loss: 0.62922330, Training R2: 0.539548
Validation Loss: 0.76363438, Validation R2: 0.400980

Epoch 175/1000
Training Loss: 0.61702861, Training R2: 0.545883
Validation Loss: 0.76441771, Validation R2: 0.412083

Epoch 176/1000
Training Loss: 0.62115598, Training R2: 0.553595
Validation Loss: 0.77113301, Validation R2: 0.390003

Epoch 177/1000
Training Loss: 0.65735118, Training R2: 0.499118
Validation Loss: 0.77065283, Validation R2: 0.416442

Epoch 178/1000
Training Loss: 0.62939539, Training R2: 0.549094
Validation Loss: 0.77207851, Validation R2: 0.421864

Epoch 179/1000
Training Loss: 0.61509495, Training R2: 0.557968
Validation Loss: 0.75260466, Validation R2: 0.418922

Epoch 180/1000
Training Loss: 0.61309238, Training R2: 0.556825
Validation Loss: 0.77381682, Validation R2: 0.434439
Saved best model with validation R2 0.434439 to best_finetuned_model.pth

Epoch 181/1000
Training Loss: 0.61437622, Training R2: 0.552323
Validation Loss: 0.76297456, Validation R2: 0.416113

Epoch 182/1000
Training Loss: 0.61642556, Training R2: 0.549834
Validation Loss: 0.76493961, Validation R2: 0.431640

Epoch 183/1000
Training Loss: 0.60355810, Training R2: 0.563310
Validation Loss: 0.75620413, Validation R2: 0.417222

Epoch 184/1000
Training Loss: 0.60730557, Training R2: 0.562319
Validation Loss: 0.75714576, Validation R2: 0.426189

Epoch 185/1000
Training Loss: 0.60101644, Training R2: 0.568984
Validation Loss: 0.76292270, Validation R2: 0.410931

Epoch 186/1000
Training Loss: 0.59565043, Training R2: 0.571342
Validation Loss: 0.75049728, Validation R2: 0.430512

Epoch 187/1000
Training Loss: 0.59691590, Training R2: 0.570960
Validation Loss: 0.76382756, Validation R2: 0.433088

Epoch 188/1000
Training Loss: 0.59859862, Training R2: 0.576977
Validation Loss: 0.73374891, Validation R2: 0.454378
Saved best model with validation R2 0.454378 to best_finetuned_model.pth

Epoch 189/1000
Training Loss: 0.60996282, Training R2: 0.563727
Validation Loss: 0.75111085, Validation R2: 0.458939
Saved best model with validation R2 0.458939 to best_finetuned_model.pth

Epoch 190/1000
Training Loss: 0.60527401, Training R2: 0.574810
Validation Loss: 0.72413933, Validation R2: 0.455487

Epoch 191/1000
Training Loss: 0.59491092, Training R2: 0.562149
Validation Loss: 0.73934406, Validation R2: 0.438836

Epoch 192/1000
Training Loss: 0.57947218, Training R2: 0.592324
Validation Loss: 0.74056792, Validation R2: 0.448711

Epoch 193/1000
Training Loss: 0.57798326, Training R2: 0.589194
Validation Loss: 0.72725034, Validation R2: 0.453928

Epoch 194/1000
Training Loss: 0.57324949, Training R2: 0.594756
Validation Loss: 0.74265546, Validation R2: 0.453204

Epoch 195/1000
Training Loss: 0.57637827, Training R2: 0.591161
Validation Loss: 0.73149639, Validation R2: 0.449111

Epoch 196/1000
Training Loss: 0.57044236, Training R2: 0.599220
Validation Loss: 0.72909856, Validation R2: 0.451227

Epoch 197/1000
Training Loss: 0.58192339, Training R2: 0.590019
Validation Loss: 0.72511536, Validation R2: 0.454507

Epoch 198/1000
Training Loss: 0.57277616, Training R2: 0.595013
Validation Loss: 0.73644161, Validation R2: 0.456704

Epoch 199/1000
Training Loss: 0.57912325, Training R2: 0.586891
Validation Loss: 0.72422773, Validation R2: 0.470542
Saved best model with validation R2 0.470542 to best_finetuned_model.pth

Epoch 200/1000
Training Loss: 0.57554008, Training R2: 0.596562
Validation Loss: 0.72380185, Validation R2: 0.459935

Epoch 201/1000
Training Loss: 0.58113255, Training R2: 0.587037
Validation Loss: 0.73834175, Validation R2: 0.456558

Epoch 202/1000
Training Loss: 0.57938764, Training R2: 0.590869
Validation Loss: 0.75415254, Validation R2: 0.448748

Epoch 203/1000
Training Loss: 0.57914900, Training R2: 0.593256
Validation Loss: 0.73627526, Validation R2: 0.453310

Epoch 204/1000
Training Loss: 0.60985528, Training R2: 0.556157
Validation Loss: 0.78252560, Validation R2: 0.398965

Epoch 205/1000
Training Loss: 0.61884776, Training R2: 0.549837
Validation Loss: 0.77770215, Validation R2: 0.411662

Epoch 206/1000
Training Loss: 0.60285232, Training R2: 0.564735
Validation Loss: 0.76461643, Validation R2: 0.417108

Epoch 207/1000
Training Loss: 0.58889199, Training R2: 0.575030
Validation Loss: 0.75286549, Validation R2: 0.430303

Epoch 208/1000
Training Loss: 0.58399890, Training R2: 0.585253
Validation Loss: 0.74465358, Validation R2: 0.452848

Epoch 209/1000
Training Loss: 0.58978948, Training R2: 0.592334
Validation Loss: 0.72218519, Validation R2: 0.475528
Saved best model with validation R2 0.475528 to best_finetuned_model.pth

Epoch 210/1000
Training Loss: 0.58860055, Training R2: 0.587052
Validation Loss: 0.72136277, Validation R2: 0.478039
Saved best model with validation R2 0.478039 to best_finetuned_model.pth

Epoch 211/1000
Training Loss: 0.56996439, Training R2: 0.609507
Validation Loss: 0.71461439, Validation R2: 0.474010

Epoch 212/1000
Training Loss: 0.56100116, Training R2: 0.610691
Validation Loss: 0.71722090, Validation R2: 0.465182

Epoch 213/1000
Training Loss: 0.55233708, Training R2: 0.616684
Validation Loss: 0.70867550, Validation R2: 0.467238

Epoch 214/1000
Training Loss: 0.55434358, Training R2: 0.615586
Validation Loss: 0.71984214, Validation R2: 0.466440

Epoch 215/1000
Training Loss: 0.55759695, Training R2: 0.616915
Validation Loss: 0.71452987, Validation R2: 0.472950

Epoch 216/1000
Training Loss: 0.56242975, Training R2: 0.610140
Validation Loss: 0.71937346, Validation R2: 0.473478

Epoch 217/1000
Training Loss: 0.58037887, Training R2: 0.600507
Validation Loss: 0.71075219, Validation R2: 0.470220

Epoch 218/1000
Training Loss: 0.56019062, Training R2: 0.610253
Validation Loss: 0.74078202, Validation R2: 0.441436

Epoch 219/1000
Training Loss: 0.57986331, Training R2: 0.601997
Validation Loss: 0.73286849, Validation R2: 0.453011

Epoch 220/1000
Training Loss: 0.56384454, Training R2: 0.614685
Validation Loss: 0.73175681, Validation R2: 0.455048

Epoch 221/1000
Training Loss: 0.60034653, Training R2: 0.570393
Validation Loss: 0.74386579, Validation R2: 0.463409

Epoch 222/1000
Training Loss: 0.58383656, Training R2: 0.589728
Validation Loss: 0.73940945, Validation R2: 0.467468

Epoch 223/1000
Training Loss: 0.57706022, Training R2: 0.611682
Validation Loss: 0.73564178, Validation R2: 0.452865

Epoch 224/1000
Training Loss: 0.57593909, Training R2: 0.604035
Validation Loss: 0.74801964, Validation R2: 0.458842

Epoch 225/1000
Training Loss: 0.59194230, Training R2: 0.604936
Validation Loss: 0.70112377, Validation R2: 0.473512

Epoch 226/1000
Training Loss: 0.57415713, Training R2: 0.602851
Validation Loss: 0.68611938, Validation R2: 0.493894
Saved best model with validation R2 0.493894 to best_finetuned_model.pth

Epoch 227/1000
Training Loss: 0.55917820, Training R2: 0.614605
Validation Loss: 0.70687908, Validation R2: 0.472810

Epoch 228/1000
Training Loss: 0.56335282, Training R2: 0.615353
Validation Loss: 0.73670220, Validation R2: 0.453336

Epoch 229/1000
Training Loss: 0.55978718, Training R2: 0.618208
Validation Loss: 0.69700867, Validation R2: 0.472835

Epoch 230/1000
Training Loss: 0.55018785, Training R2: 0.614825
Validation Loss: 0.70930684, Validation R2: 0.484546

Epoch 231/1000
Training Loss: 0.55630964, Training R2: 0.619319
Validation Loss: 0.68937820, Validation R2: 0.490520

Epoch 232/1000
Training Loss: 0.54908095, Training R2: 0.631586
Validation Loss: 0.71202838, Validation R2: 0.472118

Epoch 233/1000
Training Loss: 0.54647336, Training R2: 0.632679
Validation Loss: 0.70574582, Validation R2: 0.467609

Epoch 234/1000
Training Loss: 0.53655019, Training R2: 0.632089
Validation Loss: 0.69691640, Validation R2: 0.483327

Epoch 235/1000
Training Loss: 0.53299061, Training R2: 0.634462
Validation Loss: 0.71136999, Validation R2: 0.479406

Epoch 236/1000
Training Loss: 0.52987170, Training R2: 0.645337
Validation Loss: 0.70045686, Validation R2: 0.476659

Epoch 237/1000
Training Loss: 0.52251268, Training R2: 0.650614
Validation Loss: 0.71275419, Validation R2: 0.470491

Epoch 238/1000
Training Loss: 0.51857650, Training R2: 0.653607
Validation Loss: 0.70590627, Validation R2: 0.479733

Epoch 239/1000
Training Loss: 0.51037404, Training R2: 0.659944
Validation Loss: 0.70383358, Validation R2: 0.478298

Epoch 240/1000
Training Loss: 0.51310811, Training R2: 0.657133
Validation Loss: 0.70379752, Validation R2: 0.475789

Epoch 241/1000
Training Loss: 0.53275730, Training R2: 0.639068
Validation Loss: 0.71465999, Validation R2: 0.467781

Epoch 242/1000
Training Loss: 0.52739234, Training R2: 0.646760
Validation Loss: 0.69481885, Validation R2: 0.489779

Epoch 243/1000
Training Loss: 0.53920016, Training R2: 0.635001
Validation Loss: 0.72478950, Validation R2: 0.461367

Epoch 244/1000
Training Loss: 0.55011919, Training R2: 0.631712
Validation Loss: 0.71641892, Validation R2: 0.469078

Epoch 245/1000
Training Loss: 0.52795043, Training R2: 0.648932
Validation Loss: 0.72781157, Validation R2: 0.467437

Epoch 246/1000
Training Loss: 0.52502171, Training R2: 0.649885
Validation Loss: 0.74450010, Validation R2: 0.450317

Epoch 247/1000
Epoch 00247: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 0.53006320, Training R2: 0.646051
Validation Loss: 0.74314022, Validation R2: 0.445547

Epoch 248/1000
学习率已减少 3 次
Training Loss: 0.54332095, Training R2: 0.634892
Validation Loss: 0.73342270, Validation R2: 0.453371

Epoch 249/1000
Training Loss: 0.53100925, Training R2: 0.646354
Validation Loss: 0.71047217, Validation R2: 0.467940

Epoch 250/1000
Training Loss: 0.51354991, Training R2: 0.661539
Validation Loss: 0.69307089, Validation R2: 0.480864

Epoch 251/1000
Training Loss: 0.51115676, Training R2: 0.663709
Validation Loss: 0.69683594, Validation R2: 0.477818

Epoch 252/1000
Training Loss: 0.51595881, Training R2: 0.662110
Validation Loss: 0.71252441, Validation R2: 0.469543

Epoch 253/1000
Training Loss: 0.51051782, Training R2: 0.665197
Validation Loss: 0.68856609, Validation R2: 0.481938

Epoch 254/1000
Training Loss: 0.51129914, Training R2: 0.665214
Validation Loss: 0.70777798, Validation R2: 0.472143

Epoch 255/1000
Training Loss: 0.50737463, Training R2: 0.672187
Validation Loss: 0.70564055, Validation R2: 0.471601

Epoch 256/1000
Training Loss: 0.49702023, Training R2: 0.677814
Validation Loss: 0.70513994, Validation R2: 0.469757

Epoch 257/1000
Training Loss: 0.49599856, Training R2: 0.682119
Validation Loss: 0.69951719, Validation R2: 0.478710

Epoch 258/1000
Training Loss: 0.53070298, Training R2: 0.641105
Validation Loss: 0.73549330, Validation R2: 0.443629

Epoch 259/1000
Training Loss: 0.50999288, Training R2: 0.655124
Validation Loss: 0.74808609, Validation R2: 0.445939

Epoch 260/1000
Training Loss: 0.51343271, Training R2: 0.664130
Validation Loss: 0.72948492, Validation R2: 0.455734

Epoch 261/1000
Training Loss: 0.51376923, Training R2: 0.668017
Validation Loss: 0.73831582, Validation R2: 0.438643

Epoch 262/1000
Training Loss: 0.54847437, Training R2: 0.634687
Validation Loss: 0.74223679, Validation R2: 0.436312

Epoch 263/1000
Training Loss: 0.49521287, Training R2: 0.676019
Validation Loss: 0.73564589, Validation R2: 0.441166

Epoch 264/1000
Training Loss: 0.50553919, Training R2: 0.671824
Validation Loss: 0.74053061, Validation R2: 0.450380

Epoch 265/1000
Training Loss: 0.50215917, Training R2: 0.677512
Validation Loss: 0.72745389, Validation R2: 0.459772

Epoch 266/1000
Training Loss: 0.49374466, Training R2: 0.683569
Validation Loss: 0.72933853, Validation R2: 0.453568

Epoch 267/1000
Training Loss: 0.48606964, Training R2: 0.687776
Validation Loss: 0.71933109, Validation R2: 0.464935

Epoch 268/1000
Epoch 00268: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 0.48730476, Training R2: 0.686151
Validation Loss: 0.73285902, Validation R2: 0.450517

Epoch 269/1000
学习率已减少 4 次
Training Loss: 0.48891716, Training R2: 0.680633
Validation Loss: 0.72990173, Validation R2: 0.454819

Epoch 270/1000
Training Loss: 0.47547964, Training R2: 0.694220
Validation Loss: 0.73184401, Validation R2: 0.463132

Epoch 271/1000
Training Loss: 0.48924607, Training R2: 0.683860
Validation Loss: 0.72179967, Validation R2: 0.466683

Epoch 272/1000
Training Loss: 0.46950377, Training R2: 0.702025
Validation Loss: 0.71733749, Validation R2: 0.465235

Epoch 273/1000
Training Loss: 0.46448452, Training R2: 0.703560
Validation Loss: 0.71111053, Validation R2: 0.468671

Epoch 274/1000
Training Loss: 0.45706737, Training R2: 0.706117
Validation Loss: 0.71414441, Validation R2: 0.470872

Epoch 275/1000
Training Loss: 0.45601832, Training R2: 0.705130
Validation Loss: 0.71314770, Validation R2: 0.473314

Epoch 276/1000
Training Loss: 0.45555345, Training R2: 0.705560
Validation Loss: 0.71807569, Validation R2: 0.468422

Epoch 277/1000
Training Loss: 0.45558976, Training R2: 0.707274
Validation Loss: 0.73500621, Validation R2: 0.457249

Epoch 278/1000
Training Loss: 0.46155785, Training R2: 0.701936
Validation Loss: 0.72963387, Validation R2: 0.459770

Epoch 279/1000
Training Loss: 0.44826212, Training R2: 0.711644
Validation Loss: 0.72359329, Validation R2: 0.460991

Epoch 280/1000
Training Loss: 0.45458951, Training R2: 0.706770
Validation Loss: 0.71606427, Validation R2: 0.470455

Epoch 281/1000
Training Loss: 0.44904444, Training R2: 0.714008
Validation Loss: 0.71614659, Validation R2: 0.457702

Epoch 282/1000
Training Loss: 0.45813179, Training R2: 0.707763
Validation Loss: 0.71482527, Validation R2: 0.464968

Epoch 283/1000
Training Loss: 0.44832355, Training R2: 0.712057
Validation Loss: 0.71287549, Validation R2: 0.472596

Epoch 284/1000
Training Loss: 0.45065301, Training R2: 0.712204
Validation Loss: 0.72509301, Validation R2: 0.463912

Epoch 285/1000
Training Loss: 0.45323078, Training R2: 0.714045
Validation Loss: 0.71375006, Validation R2: 0.470233

Epoch 286/1000
Training Loss: 0.45089895, Training R2: 0.717772
Validation Loss: 0.71413285, Validation R2: 0.467700

Epoch 287/1000
Training Loss: 0.44686795, Training R2: 0.718319
Validation Loss: 0.72494900, Validation R2: 0.460435

Epoch 288/1000
Training Loss: 0.44523134, Training R2: 0.717458
Validation Loss: 0.72554266, Validation R2: 0.466493

Epoch 289/1000
Epoch 00289: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 0.43913316, Training R2: 0.722862
Validation Loss: 0.71823293, Validation R2: 0.467753

Epoch 290/1000
学习率已减少 5 次
Training Loss: 0.43654945, Training R2: 0.726610
Validation Loss: 0.71609175, Validation R2: 0.467444

Epoch 291/1000
Training Loss: 0.43183805, Training R2: 0.727697
Validation Loss: 0.71763444, Validation R2: 0.466019

Epoch 292/1000
Training Loss: 0.42918788, Training R2: 0.729742
Validation Loss: 0.71748960, Validation R2: 0.466290

Epoch 293/1000
Training Loss: 0.42680690, Training R2: 0.730831
Validation Loss: 0.71822262, Validation R2: 0.466971

Epoch 294/1000
Training Loss: 0.42497288, Training R2: 0.731966
Validation Loss: 0.71922135, Validation R2: 0.467985

Epoch 295/1000
Training Loss: 0.42229619, Training R2: 0.732460
Validation Loss: 0.71519548, Validation R2: 0.471117

Epoch 296/1000
Training Loss: 0.42022462, Training R2: 0.733435
Validation Loss: 0.71448803, Validation R2: 0.471901

Epoch 297/1000
Training Loss: 0.41781470, Training R2: 0.734608
Validation Loss: 0.71688038, Validation R2: 0.467160

Epoch 298/1000
Training Loss: 0.41920184, Training R2: 0.733799
Validation Loss: 0.72118253, Validation R2: 0.461270

Epoch 299/1000
Training Loss: 0.41790578, Training R2: 0.735542
Validation Loss: 0.72056180, Validation R2: 0.463760

Epoch 300/1000
Training Loss: 0.42027510, Training R2: 0.733331
Validation Loss: 0.72139764, Validation R2: 0.466200

Epoch 301/1000
Training Loss: 0.41695138, Training R2: 0.735354
Validation Loss: 0.72009397, Validation R2: 0.465266

Epoch 302/1000
Training Loss: 0.41424253, Training R2: 0.737628
Validation Loss: 0.72040266, Validation R2: 0.463778

Epoch 303/1000
Training Loss: 0.41136752, Training R2: 0.738773
Validation Loss: 0.72599900, Validation R2: 0.461739

Epoch 304/1000
Training Loss: 0.41117796, Training R2: 0.739129
Validation Loss: 0.72689909, Validation R2: 0.461031

Epoch 305/1000
Training Loss: 0.40819917, Training R2: 0.740707
Validation Loss: 0.73066163, Validation R2: 0.458445

Epoch 306/1000
Training Loss: 0.41096621, Training R2: 0.739820
Validation Loss: 0.73007309, Validation R2: 0.460505

Epoch 307/1000
Training Loss: 0.41282047, Training R2: 0.739889
Validation Loss: 0.72301877, Validation R2: 0.464415

Epoch 308/1000
Training Loss: 0.40952314, Training R2: 0.741879
Validation Loss: 0.72561681, Validation R2: 0.459523

Epoch 309/1000
Training Loss: 0.40549555, Training R2: 0.743394
Validation Loss: 0.72848141, Validation R2: 0.457572

Epoch 310/1000
Epoch 00310: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 0.40449709, Training R2: 0.744684
Validation Loss: 0.72960007, Validation R2: 0.454758

Epoch 311/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/r2_curve_dipole.png
