Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 20000, Training: 16000, Validation: 4000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1025539

Epoch 1/1000
Training Loss: 1.26386989, Training R2: -0.307198
Validation Loss: 1.10445715, Validation R2: 0.014980
Saved best model with validation R2 0.014980 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.03465338, Training R2: 0.141024
Validation Loss: 0.91568738, Validation R2: 0.301112
Saved best model with validation R2 0.301112 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 0.80357319, Training R2: 0.419667
Validation Loss: 0.73482290, Validation R2: 0.474574
Saved best model with validation R2 0.474574 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 0.74933991, Training R2: 0.476751
Validation Loss: 0.75211477, Validation R2: 0.456192

Epoch 5/1000
Training Loss: 0.70575761, Training R2: 0.515945
Validation Loss: 0.69024459, Validation R2: 0.514402
Saved best model with validation R2 0.514402 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 0.70168649, Training R2: 0.521587
Validation Loss: 0.70502932, Validation R2: 0.513208

Epoch 7/1000
Training Loss: 0.69665512, Training R2: 0.526208
Validation Loss: 0.73043989, Validation R2: 0.478167

Epoch 8/1000
Training Loss: 0.69356189, Training R2: 0.532904
Validation Loss: 0.68046683, Validation R2: 0.539729
Saved best model with validation R2 0.539729 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 0.66833213, Training R2: 0.555657
Validation Loss: 0.65395102, Validation R2: 0.559667
Saved best model with validation R2 0.559667 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.66945027, Training R2: 0.566010
Validation Loss: 0.71464817, Validation R2: 0.506918

Epoch 11/1000
Training Loss: 0.65423885, Training R2: 0.583954
Validation Loss: 0.68637683, Validation R2: 0.552158

Epoch 12/1000
Training Loss: 0.65385897, Training R2: 0.595023
Validation Loss: 0.62984193, Validation R2: 0.598742
Saved best model with validation R2 0.598742 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 0.62992784, Training R2: 0.618169
Validation Loss: 0.63180837, Validation R2: 0.601152
Saved best model with validation R2 0.601152 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 0.63845519, Training R2: 0.615568
Validation Loss: 0.64778550, Validation R2: 0.594843

Epoch 15/1000
Training Loss: 0.62853331, Training R2: 0.617612
Validation Loss: 0.62740733, Validation R2: 0.605483
Saved best model with validation R2 0.605483 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 0.61578740, Training R2: 0.638043
Validation Loss: 0.63242451, Validation R2: 0.618890
Saved best model with validation R2 0.618890 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.62576104, Training R2: 0.630853
Validation Loss: 0.66054795, Validation R2: 0.579115

Epoch 18/1000
Training Loss: 0.61993977, Training R2: 0.641487
Validation Loss: 0.61459768, Validation R2: 0.633733
Saved best model with validation R2 0.633733 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.60130380, Training R2: 0.657269
Validation Loss: 0.60212991, Validation R2: 0.645259
Saved best model with validation R2 0.645259 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 0.58659493, Training R2: 0.673918
Validation Loss: 0.59745579, Validation R2: 0.661855
Saved best model with validation R2 0.661855 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.58711195, Training R2: 0.686417
Validation Loss: 0.60410925, Validation R2: 0.642041

Epoch 22/1000
Training Loss: 0.56961038, Training R2: 0.703581
Validation Loss: 0.59839560, Validation R2: 0.629673

Epoch 23/1000
Training Loss: 0.60659269, Training R2: 0.653798
Validation Loss: 0.64827423, Validation R2: 0.599754

Epoch 24/1000
Training Loss: 0.59197718, Training R2: 0.679659
Validation Loss: 0.63956940, Validation R2: 0.604336

Epoch 25/1000
Training Loss: 0.58308919, Training R2: 0.679308
Validation Loss: 0.62318152, Validation R2: 0.621345

Epoch 26/1000
Training Loss: 0.59450262, Training R2: 0.652268
Validation Loss: 0.59529367, Validation R2: 0.648668

Epoch 27/1000
Training Loss: 0.56232836, Training R2: 0.689651
Validation Loss: 0.60791241, Validation R2: 0.633575

Epoch 28/1000
Training Loss: 0.55779815, Training R2: 0.696903
Validation Loss: 0.56554230, Validation R2: 0.680777
Saved best model with validation R2 0.680777 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 0.58527446, Training R2: 0.670802
Validation Loss: 0.55423618, Validation R2: 0.691298
Saved best model with validation R2 0.691298 to best_finetuned_model.pth

Epoch 30/1000
Training Loss: 0.55930960, Training R2: 0.700008
Validation Loss: 0.60789035, Validation R2: 0.639609

Epoch 31/1000
Training Loss: 0.55697643, Training R2: 0.704617
Validation Loss: 0.66026690, Validation R2: 0.599142

Epoch 32/1000
Training Loss: 0.56816879, Training R2: 0.687530
Validation Loss: 0.63379163, Validation R2: 0.640414

Epoch 33/1000
Training Loss: 0.59792848, Training R2: 0.668748
Validation Loss: 0.63277991, Validation R2: 0.633414

Epoch 34/1000
Training Loss: 0.57289806, Training R2: 0.704127
Validation Loss: 0.63906536, Validation R2: 0.613383

Epoch 35/1000
Training Loss: 0.58936194, Training R2: 0.669878
Validation Loss: 0.57357362, Validation R2: 0.680114

Epoch 36/1000
Training Loss: 0.57009819, Training R2: 0.700620
Validation Loss: 0.57392468, Validation R2: 0.691041

Epoch 37/1000
Training Loss: 0.57907385, Training R2: 0.701993
Validation Loss: 0.61414088, Validation R2: 0.633203

Epoch 38/1000
Training Loss: 0.58849300, Training R2: 0.681904
Validation Loss: 0.59141858, Validation R2: 0.655688

Epoch 39/1000
Training Loss: 0.57620423, Training R2: 0.697554
Validation Loss: 0.57485063, Validation R2: 0.685974

Epoch 40/1000
Training Loss: 0.56754666, Training R2: 0.698717
Validation Loss: 0.57523669, Validation R2: 0.671557

Epoch 41/1000
Training Loss: 0.54257484, Training R2: 0.712347
Validation Loss: 0.57311462, Validation R2: 0.672290

Epoch 42/1000
Training Loss: 0.56028434, Training R2: 0.698761
Validation Loss: 0.55649244, Validation R2: 0.694154
Saved best model with validation R2 0.694154 to best_finetuned_model.pth

Epoch 43/1000
Training Loss: 0.54978700, Training R2: 0.718241
Validation Loss: 0.64996250, Validation R2: 0.616085

Epoch 44/1000
Training Loss: 0.63260887, Training R2: 0.633189
Validation Loss: 0.80261914, Validation R2: 0.416544

Epoch 45/1000
Training Loss: 0.67248296, Training R2: 0.587127
Validation Loss: 0.66512093, Validation R2: 0.573603

Epoch 46/1000
Training Loss: 0.72408470, Training R2: 0.526587
Validation Loss: 0.78571149, Validation R2: 0.446240

Epoch 47/1000
Training Loss: 0.84429842, Training R2: 0.392238
Validation Loss: 0.78099070, Validation R2: 0.441741

Epoch 48/1000
Training Loss: 0.86750450, Training R2: 0.346886
Validation Loss: 1.14287869, Validation R2: -0.082253

Epoch 49/1000
Training Loss: 1.15965149, Training R2: -0.031227
Validation Loss: 1.13812683, Validation R2: -0.002816

Epoch 50/1000
Training Loss: 1.15569009, Training R2: -0.023161
Validation Loss: 1.13563865, Validation R2: -0.039199

Epoch 51/1000
Training Loss: 1.15472094, Training R2: -0.022709
Validation Loss: 1.13578129, Validation R2: -0.040539

Epoch 52/1000
Training Loss: 1.15508638, Training R2: -0.026126
Validation Loss: 1.13454989, Validation R2: -0.024963

Epoch 53/1000
Training Loss: 1.15474667, Training R2: -0.022535
Validation Loss: 1.13459659, Validation R2: -0.017362

Epoch 54/1000
Training Loss: 1.15501629, Training R2: -0.023785
Validation Loss: 1.13506510, Validation R2: -0.033947

Epoch 55/1000
Training Loss: 1.15637084, Training R2: -0.026986
Validation Loss: 1.13697224, Validation R2: -0.050086

Epoch 56/1000
Training Loss: 1.15769533, Training R2: -0.027151
Validation Loss: 1.13446534, Validation R2: -0.024202

Epoch 57/1000
Training Loss: 1.15593561, Training R2: -0.024226
Validation Loss: 1.13493940, Validation R2: -0.011872

Epoch 58/1000
Training Loss: 1.15514816, Training R2: -0.024546
Validation Loss: 1.13457328, Validation R2: -0.013109

Epoch 59/1000
Training Loss: 1.15566265, Training R2: -0.024307
Validation Loss: 1.13329088, Validation R2: -0.008230

Epoch 60/1000
Training Loss: 1.04194642, Training R2: 0.115721
Validation Loss: 0.85735198, Validation R2: 0.339764

Epoch 61/1000
Training Loss: 0.81788587, Training R2: 0.411162
Validation Loss: 0.87491481, Validation R2: 0.323902

Epoch 62/1000
Training Loss: 0.87662949, Training R2: 0.342615
Validation Loss: 0.85267763, Validation R2: 0.360723

Epoch 63/1000
Epoch 00063: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 0.99334865, Training R2: 0.178905
Validation Loss: 0.96930278, Validation R2: 0.189824

Epoch 64/1000
学习率已减少 1 次
Training Loss: 0.99160466, Training R2: 0.192743
Validation Loss: 0.97279879, Validation R2: 0.194823

Epoch 65/1000
Training Loss: 0.96613091, Training R2: 0.224705
Validation Loss: 0.91808820, Validation R2: 0.263190

Epoch 66/1000
Training Loss: 0.88292434, Training R2: 0.330560
Validation Loss: 0.84731910, Validation R2: 0.360557

Epoch 67/1000
Training Loss: 0.81065447, Training R2: 0.415730
Validation Loss: 0.79492130, Validation R2: 0.426760

Epoch 68/1000
Training Loss: 0.82387139, Training R2: 0.399002
Validation Loss: 0.84123629, Validation R2: 0.360231

Epoch 69/1000
Training Loss: 0.82015423, Training R2: 0.402495
Validation Loss: 0.81997841, Validation R2: 0.397767

Epoch 70/1000
Training Loss: 0.82016155, Training R2: 0.404559
Validation Loss: 0.86602131, Validation R2: 0.326429

Epoch 71/1000
Training Loss: 0.82392181, Training R2: 0.390177
Validation Loss: 0.84199119, Validation R2: 0.374907

Epoch 72/1000
Training Loss: 0.82958442, Training R2: 0.400543
Validation Loss: 0.81673328, Validation R2: 0.397841

Epoch 73/1000
Training Loss: 0.82433615, Training R2: 0.400301
Validation Loss: 0.82904770, Validation R2: 0.379089

Epoch 74/1000
Training Loss: 0.88251553, Training R2: 0.327316
Validation Loss: 0.96434657, Validation R2: 0.210358

Epoch 75/1000
Training Loss: 0.88629009, Training R2: 0.311441
Validation Loss: 0.81231497, Validation R2: 0.391341

Epoch 76/1000
Training Loss: 0.79528448, Training R2: 0.425614
Validation Loss: 0.78704652, Validation R2: 0.425795

Epoch 77/1000
Training Loss: 0.78282481, Training R2: 0.439710
Validation Loss: 0.80672625, Validation R2: 0.402782

Epoch 78/1000
Training Loss: 0.77117361, Training R2: 0.456704
Validation Loss: 0.77704972, Validation R2: 0.432878

Epoch 79/1000
Training Loss: 0.78123923, Training R2: 0.443336
Validation Loss: 0.80722276, Validation R2: 0.389536

Epoch 80/1000
Training Loss: 0.79170241, Training R2: 0.429555
Validation Loss: 0.77722463, Validation R2: 0.430769

Epoch 81/1000
Training Loss: 0.78906109, Training R2: 0.431458
Validation Loss: 0.78343853, Validation R2: 0.423541

Epoch 82/1000
Training Loss: 0.77697919, Training R2: 0.446655
Validation Loss: 0.79014555, Validation R2: 0.420776

Epoch 83/1000
Training Loss: 0.78264441, Training R2: 0.442328
Validation Loss: 0.78203857, Validation R2: 0.430125

Epoch 84/1000
Epoch 00084: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 0.78851952, Training R2: 0.431992
Validation Loss: 0.77956559, Validation R2: 0.439892

Epoch 85/1000
学习率已减少 2 次
Training Loss: 0.77681143, Training R2: 0.444327
Validation Loss: 0.77472623, Validation R2: 0.437335

Epoch 86/1000
Training Loss: 0.80313706, Training R2: 0.414544
Validation Loss: 0.93422942, Validation R2: 0.212279

Epoch 87/1000
Training Loss: 0.90029602, Training R2: 0.288885
Validation Loss: 0.86974975, Validation R2: 0.322046

Epoch 88/1000
Training Loss: 0.83745980, Training R2: 0.378599
Validation Loss: 0.83969887, Validation R2: 0.359644

Epoch 89/1000
Training Loss: 0.81713054, Training R2: 0.401932
Validation Loss: 0.81116330, Validation R2: 0.396006

Epoch 90/1000
Training Loss: 0.83082946, Training R2: 0.384297
Validation Loss: 0.82203851, Validation R2: 0.379389

Epoch 91/1000
Training Loss: 0.79914847, Training R2: 0.421503
Validation Loss: 0.79834182, Validation R2: 0.413271

Epoch 92/1000
Training Loss: 0.79425483, Training R2: 0.432256
Validation Loss: 0.78604353, Validation R2: 0.428608

Epoch 93/1000
Training Loss: 0.82984718, Training R2: 0.391803
Validation Loss: 0.84678158, Validation R2: 0.353112

Epoch 94/1000
Training Loss: 0.82545758, Training R2: 0.388113
Validation Loss: 0.80855689, Validation R2: 0.402449

Epoch 95/1000
Training Loss: 0.79176539, Training R2: 0.429691
Validation Loss: 0.78290973, Validation R2: 0.430967

Epoch 96/1000
Training Loss: 0.79541960, Training R2: 0.425028
Validation Loss: 0.78664089, Validation R2: 0.426373

Epoch 97/1000
Training Loss: 0.77543841, Training R2: 0.456446
Validation Loss: 0.79296889, Validation R2: 0.410197

Epoch 98/1000
Training Loss: 0.79253743, Training R2: 0.433641
Validation Loss: 0.78894367, Validation R2: 0.434227

Epoch 99/1000
Training Loss: 0.78273845, Training R2: 0.444703
Validation Loss: 0.77157807, Validation R2: 0.444135

Epoch 100/1000
Training Loss: 0.79407963, Training R2: 0.432116
Validation Loss: 0.86415697, Validation R2: 0.326137

Epoch 101/1000
Training Loss: 0.89622043, Training R2: 0.289138
Validation Loss: 0.84388377, Validation R2: 0.356121

Epoch 102/1000
Training Loss: 0.99214618, Training R2: 0.159569
Validation Loss: 0.99110404, Validation R2: 0.183402

Epoch 103/1000
Training Loss: 1.04136952, Training R2: 0.108033
Validation Loss: 1.06713563, Validation R2: 0.071280

Epoch 104/1000
Training Loss: 0.99139720, Training R2: 0.175696
Validation Loss: 0.96700897, Validation R2: 0.230341

Epoch 105/1000
Epoch 00105: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 0.90554511, Training R2: 0.296873
Validation Loss: 0.87278727, Validation R2: 0.336844

Epoch 106/1000
学习率已减少 3 次
Training Loss: 0.84644493, Training R2: 0.371854
Validation Loss: 0.83485571, Validation R2: 0.379564

Epoch 107/1000
Training Loss: 0.82603888, Training R2: 0.393163
Validation Loss: 0.82447641, Validation R2: 0.390748

Epoch 108/1000
Training Loss: 0.82203478, Training R2: 0.397220
Validation Loss: 0.82388621, Validation R2: 0.386081

Epoch 109/1000
Training Loss: 0.80951228, Training R2: 0.412023
Validation Loss: 0.80920582, Validation R2: 0.401501

Epoch 110/1000
Training Loss: 0.80790026, Training R2: 0.413809
Validation Loss: 0.82611665, Validation R2: 0.386356

Epoch 111/1000
Training Loss: 0.80376196, Training R2: 0.418917
Validation Loss: 0.81061616, Validation R2: 0.404149

Epoch 112/1000
Training Loss: 0.79810790, Training R2: 0.423578
Validation Loss: 0.79883254, Validation R2: 0.408063

Epoch 113/1000
Training Loss: 0.78942111, Training R2: 0.431611
Validation Loss: 0.80576528, Validation R2: 0.406936

Epoch 114/1000
Training Loss: 0.78749888, Training R2: 0.432183
Validation Loss: 0.79603084, Validation R2: 0.415229

Epoch 115/1000
Training Loss: 0.79028753, Training R2: 0.431121
Validation Loss: 0.82257339, Validation R2: 0.384459

Epoch 116/1000
Training Loss: 0.81846157, Training R2: 0.395592
Validation Loss: 0.85733856, Validation R2: 0.336802

Epoch 117/1000
Training Loss: 0.80858254, Training R2: 0.410324
Validation Loss: 0.81089684, Validation R2: 0.398367

Epoch 118/1000
Training Loss: 0.79838326, Training R2: 0.421298
Validation Loss: 0.83298815, Validation R2: 0.367759

Epoch 119/1000
Training Loss: 0.79758031, Training R2: 0.422342
Validation Loss: 0.79795764, Validation R2: 0.412878

Epoch 120/1000
Training Loss: 0.79276894, Training R2: 0.427176
Validation Loss: 0.78741494, Validation R2: 0.425504

Epoch 121/1000
Training Loss: 0.79310636, Training R2: 0.428865
Validation Loss: 0.79826092, Validation R2: 0.419388

Epoch 122/1000
Training Loss: 0.78991615, Training R2: 0.430592
Validation Loss: 0.83890344, Validation R2: 0.362172

Epoch 123/1000
Training Loss: 0.81732348, Training R2: 0.408261
Validation Loss: 0.82389721, Validation R2: 0.374958

Epoch 124/1000
Training Loss: 0.80802329, Training R2: 0.417549
Validation Loss: 0.80308702, Validation R2: 0.408143

Epoch 125/1000
Training Loss: 0.80202652, Training R2: 0.423777
Validation Loss: 0.79823931, Validation R2: 0.410532

Epoch 126/1000
Epoch 00126: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 0.79867772, Training R2: 0.426350
Validation Loss: 0.82224527, Validation R2: 0.380438

Epoch 127/1000
学习率已减少 4 次
Training Loss: 0.79731045, Training R2: 0.429143
Validation Loss: 0.80148507, Validation R2: 0.410622

Epoch 128/1000
Training Loss: 0.78863370, Training R2: 0.437930
Validation Loss: 0.80128335, Validation R2: 0.406815

Epoch 129/1000
Training Loss: 0.78363304, Training R2: 0.444280
Validation Loss: 0.79795673, Validation R2: 0.409274

Epoch 130/1000
Training Loss: 0.77972795, Training R2: 0.445807
Validation Loss: 0.78747850, Validation R2: 0.422796

Epoch 131/1000
Training Loss: 0.77359118, Training R2: 0.451807
Validation Loss: 0.79030112, Validation R2: 0.422119

Epoch 132/1000
Training Loss: 0.77743708, Training R2: 0.448106
Validation Loss: 0.79269610, Validation R2: 0.417144

Epoch 133/1000
Training Loss: 0.78229250, Training R2: 0.442151
Validation Loss: 0.79244952, Validation R2: 0.416108

Epoch 134/1000
Training Loss: 0.78085240, Training R2: 0.443269
Validation Loss: 0.78952239, Validation R2: 0.425884

Epoch 135/1000
Training Loss: 0.77696247, Training R2: 0.446490
Validation Loss: 0.78003289, Validation R2: 0.432647

Epoch 136/1000
Training Loss: 0.77572820, Training R2: 0.448404
Validation Loss: 0.78377486, Validation R2: 0.423339

Epoch 137/1000
Training Loss: 0.77600653, Training R2: 0.446316
Validation Loss: 0.78872110, Validation R2: 0.422300

Epoch 138/1000
Training Loss: 0.77396733, Training R2: 0.450317
Validation Loss: 0.77835583, Validation R2: 0.432021

Epoch 139/1000
Training Loss: 0.77079476, Training R2: 0.451933
Validation Loss: 0.79046337, Validation R2: 0.418955

Epoch 140/1000
Training Loss: 0.77239486, Training R2: 0.450911
Validation Loss: 0.77732704, Validation R2: 0.434060

Epoch 141/1000
Training Loss: 0.77191429, Training R2: 0.451061
Validation Loss: 0.79415385, Validation R2: 0.411528

Epoch 142/1000
Training Loss: 0.77121309, Training R2: 0.450140
Validation Loss: 0.77658259, Validation R2: 0.432244

Epoch 143/1000
Training Loss: 0.77221799, Training R2: 0.450050
Validation Loss: 0.78644094, Validation R2: 0.422295

Epoch 144/1000
Training Loss: 0.76929755, Training R2: 0.453945
Validation Loss: 0.77999783, Validation R2: 0.427962

Epoch 145/1000
Training Loss: 0.76912517, Training R2: 0.453436
Validation Loss: 0.77433769, Validation R2: 0.433429

Epoch 146/1000
Training Loss: 0.76378430, Training R2: 0.459733
Validation Loss: 0.78621308, Validation R2: 0.424629

Epoch 147/1000
Epoch 00147: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 0.76600837, Training R2: 0.457157
Validation Loss: 0.77732433, Validation R2: 0.426303

Epoch 148/1000
学习率已减少 5 次
Training Loss: 0.76092717, Training R2: 0.461464
Validation Loss: 0.77971497, Validation R2: 0.432181

Epoch 149/1000
Training Loss: 0.76627916, Training R2: 0.458083
Validation Loss: 0.77349356, Validation R2: 0.436206

Epoch 150/1000
Training Loss: 0.75825737, Training R2: 0.464280
Validation Loss: 0.77597593, Validation R2: 0.427601

Epoch 151/1000
Training Loss: 0.76042390, Training R2: 0.462362
Validation Loss: 0.77631575, Validation R2: 0.431646

Epoch 152/1000
Training Loss: 0.75735242, Training R2: 0.464306
Validation Loss: 0.78269930, Validation R2: 0.429120

Epoch 153/1000
Training Loss: 0.75996732, Training R2: 0.463108
Validation Loss: 0.77379561, Validation R2: 0.432950

Epoch 154/1000
Training Loss: 0.75699544, Training R2: 0.465893
Validation Loss: 0.77247053, Validation R2: 0.431898

Epoch 155/1000
Training Loss: 0.76049536, Training R2: 0.462220
Validation Loss: 0.77851782, Validation R2: 0.430612

Epoch 156/1000
Training Loss: 0.75676813, Training R2: 0.466174
Validation Loss: 0.77080119, Validation R2: 0.435850

Epoch 157/1000
Training Loss: 0.75837250, Training R2: 0.463631
Validation Loss: 0.77719856, Validation R2: 0.426566

Epoch 158/1000
Training Loss: 0.75542642, Training R2: 0.467066
Validation Loss: 0.76714555, Validation R2: 0.442442

Epoch 159/1000
Training Loss: 0.75238932, Training R2: 0.469850
Validation Loss: 0.77170556, Validation R2: 0.438354

Epoch 160/1000
Training Loss: 0.75316230, Training R2: 0.469414
Validation Loss: 0.76885267, Validation R2: 0.441590

Epoch 161/1000
Training Loss: 0.75560064, Training R2: 0.466339
Validation Loss: 0.78300237, Validation R2: 0.427954

Epoch 162/1000
Training Loss: 0.75219762, Training R2: 0.469896
Validation Loss: 0.76417402, Validation R2: 0.444862

Epoch 163/1000
Training Loss: 0.74754663, Training R2: 0.473540
Validation Loss: 0.76165691, Validation R2: 0.443662

Epoch 164/1000
Training Loss: 0.75064843, Training R2: 0.470635
Validation Loss: 0.76343914, Validation R2: 0.444430

Epoch 165/1000
Training Loss: 0.75344283, Training R2: 0.469370
Validation Loss: 0.75954640, Validation R2: 0.448140

Epoch 166/1000
Training Loss: 0.74972830, Training R2: 0.472843
Validation Loss: 0.76866477, Validation R2: 0.438164

Epoch 167/1000
Training Loss: 0.75257897, Training R2: 0.471068
Validation Loss: 0.75835431, Validation R2: 0.449407

Epoch 168/1000
Epoch 00168: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 0.74963735, Training R2: 0.471685
Validation Loss: 0.77025895, Validation R2: 0.444038

Epoch 169/1000
学习率已减少 6 次
Training Loss: 0.74758615, Training R2: 0.474486
Validation Loss: 0.75866056, Validation R2: 0.447187

Epoch 170/1000
Training Loss: 0.74412145, Training R2: 0.476745
Validation Loss: 0.76046747, Validation R2: 0.448650

Epoch 171/1000
Training Loss: 0.74269041, Training R2: 0.478020
Validation Loss: 0.75852479, Validation R2: 0.447513

Epoch 172/1000
Training Loss: 0.74255040, Training R2: 0.477669
Validation Loss: 0.75851689, Validation R2: 0.447494

Epoch 173/1000
Training Loss: 0.74182307, Training R2: 0.478444
Validation Loss: 0.76436976, Validation R2: 0.446051

Epoch 174/1000
Training Loss: 0.74218725, Training R2: 0.478717
Validation Loss: 0.76346519, Validation R2: 0.445148

Epoch 175/1000
Training Loss: 0.74249959, Training R2: 0.478734
Validation Loss: 0.75674146, Validation R2: 0.449326

Epoch 176/1000
Training Loss: 0.74098066, Training R2: 0.480188
Validation Loss: 0.75921569, Validation R2: 0.449095

Epoch 177/1000
Training Loss: 0.73964804, Training R2: 0.481121
Validation Loss: 0.75556720, Validation R2: 0.451346

Epoch 178/1000
Training Loss: 0.74049010, Training R2: 0.480386
Validation Loss: 0.75803714, Validation R2: 0.449924

Epoch 179/1000
Training Loss: 0.73947452, Training R2: 0.480124
Validation Loss: 0.75489329, Validation R2: 0.452942

Epoch 180/1000
Training Loss: 0.73844192, Training R2: 0.482041
Validation Loss: 0.75461460, Validation R2: 0.453412

Epoch 181/1000
Training Loss: 0.74032759, Training R2: 0.480510
Validation Loss: 0.75698398, Validation R2: 0.449253

Epoch 182/1000
Training Loss: 0.73757397, Training R2: 0.484348
Validation Loss: 0.75215395, Validation R2: 0.454719

Epoch 183/1000
Training Loss: 0.73697335, Training R2: 0.483683
Validation Loss: 0.75248651, Validation R2: 0.453493

Epoch 184/1000
Training Loss: 0.73905934, Training R2: 0.482511
Validation Loss: 0.77505388, Validation R2: 0.436457

Epoch 185/1000
Training Loss: 0.73908812, Training R2: 0.483000
Validation Loss: 0.75282468, Validation R2: 0.453055

Epoch 186/1000
Training Loss: 0.73527180, Training R2: 0.485153
Validation Loss: 0.75208366, Validation R2: 0.458058

Epoch 187/1000
Training Loss: 0.73487311, Training R2: 0.485526
Validation Loss: 0.75566824, Validation R2: 0.454854

Epoch 188/1000
Training Loss: 0.73428644, Training R2: 0.486110
Validation Loss: 0.74988794, Validation R2: 0.457105

Epoch 189/1000
Epoch 00189: reducing learning rate of group 0 to 7.8125e-06.
Training Loss: 0.73458224, Training R2: 0.486035
Validation Loss: 0.75228436, Validation R2: 0.458959

Epoch 190/1000
学习率已减少 7 次
Training Loss: 0.73378008, Training R2: 0.487390
Validation Loss: 0.74943255, Validation R2: 0.455993

Epoch 191/1000
Training Loss: 0.73227178, Training R2: 0.487981
Validation Loss: 0.74897387, Validation R2: 0.457622

Epoch 192/1000
Training Loss: 0.73115768, Training R2: 0.489049
Validation Loss: 0.74933173, Validation R2: 0.457893

Epoch 193/1000
Training Loss: 0.73186230, Training R2: 0.488287
Validation Loss: 0.75343464, Validation R2: 0.457391

Epoch 194/1000
Training Loss: 0.73278203, Training R2: 0.488161
Validation Loss: 0.75023468, Validation R2: 0.459242

Epoch 195/1000
Training Loss: 0.73126046, Training R2: 0.488588
Validation Loss: 0.74817455, Validation R2: 0.460667

Epoch 196/1000
Training Loss: 0.72979804, Training R2: 0.490117
Validation Loss: 0.74802220, Validation R2: 0.458209

Epoch 197/1000
Training Loss: 0.73119267, Training R2: 0.489832
Validation Loss: 0.74802170, Validation R2: 0.459089

Epoch 198/1000
Training Loss: 0.73063740, Training R2: 0.490038
Validation Loss: 0.75016651, Validation R2: 0.456115

Epoch 199/1000
Training Loss: 0.73155888, Training R2: 0.488783
Validation Loss: 0.74755316, Validation R2: 0.459241

Epoch 200/1000
Training Loss: 0.72979113, Training R2: 0.490724
Validation Loss: 0.75025250, Validation R2: 0.456516

Epoch 201/1000
Training Loss: 0.73081002, Training R2: 0.489948
Validation Loss: 0.74939920, Validation R2: 0.459695

Epoch 202/1000
Training Loss: 0.73131066, Training R2: 0.490376
Validation Loss: 0.74960565, Validation R2: 0.456186

Epoch 203/1000
Training Loss: 0.72905074, Training R2: 0.490750
Validation Loss: 0.74707390, Validation R2: 0.459153

Epoch 204/1000
Training Loss: 0.72890059, Training R2: 0.491756
Validation Loss: 0.74748979, Validation R2: 0.459356

Epoch 205/1000
Training Loss: 0.72860748, Training R2: 0.492005
Validation Loss: 0.75088107, Validation R2: 0.459569

Epoch 206/1000
Training Loss: 0.72793018, Training R2: 0.492427
Validation Loss: 0.74683513, Validation R2: 0.458762

Epoch 207/1000
Training Loss: 0.72818545, Training R2: 0.491825
Validation Loss: 0.74841832, Validation R2: 0.456196

Epoch 208/1000
Training Loss: 0.72745186, Training R2: 0.492583
Validation Loss: 0.74634808, Validation R2: 0.460144

Epoch 209/1000
Training Loss: 0.72675807, Training R2: 0.493328
Validation Loss: 0.74709255, Validation R2: 0.458669

Epoch 210/1000
Epoch 00210: reducing learning rate of group 0 to 3.9063e-06.
Training Loss: 0.72714224, Training R2: 0.492598
Validation Loss: 0.74899188, Validation R2: 0.456213

Epoch 211/1000
学习率已减少 8 次
学习率已减少 8 次，达到最大允许次数 7，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
