Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.39222383, Training R2: -0.453732
Validation Loss: 1.17877470, Validation R2: 0.017571
Saved best model with validation R2 0.017571 to finetune_dipole5000.pth

Epoch 2/1000
Training Loss: 1.18025535, Training R2: -0.006656
Validation Loss: 1.14514197, Validation R2: 0.051651
Saved best model with validation R2 0.051651 to finetune_dipole5000.pth

Epoch 3/1000
Training Loss: 1.13753963, Training R2: 0.071715
Validation Loss: 1.06234420, Validation R2: 0.091438
Saved best model with validation R2 0.091438 to finetune_dipole5000.pth

Epoch 4/1000
Training Loss: 1.05942761, Training R2: 0.169974
Validation Loss: 1.02504309, Validation R2: 0.207937
Saved best model with validation R2 0.207937 to finetune_dipole5000.pth

Epoch 5/1000
Training Loss: 1.02274694, Training R2: 0.225775
Validation Loss: 1.00919582, Validation R2: 0.215191
Saved best model with validation R2 0.215191 to finetune_dipole5000.pth

Epoch 6/1000
Training Loss: 0.99442932, Training R2: 0.259894
Validation Loss: 0.96828453, Validation R2: 0.262105
Saved best model with validation R2 0.262105 to finetune_dipole5000.pth

Epoch 7/1000
Training Loss: 0.97240302, Training R2: 0.292295
Validation Loss: 0.93343593, Validation R2: 0.305280
Saved best model with validation R2 0.305280 to finetune_dipole5000.pth

Epoch 8/1000
Training Loss: 0.95524493, Training R2: 0.310786
Validation Loss: 0.94155169, Validation R2: 0.300432

Epoch 9/1000
Training Loss: 0.93517001, Training R2: 0.325911
Validation Loss: 0.90501916, Validation R2: 0.336278
Saved best model with validation R2 0.336278 to finetune_dipole5000.pth

Epoch 10/1000
Training Loss: 0.92430271, Training R2: 0.348928
Validation Loss: 0.87088570, Validation R2: 0.375652
Saved best model with validation R2 0.375652 to finetune_dipole5000.pth

Epoch 11/1000
Training Loss: 0.89369542, Training R2: 0.383128
Validation Loss: 0.86636618, Validation R2: 0.379622
Saved best model with validation R2 0.379622 to finetune_dipole5000.pth

Epoch 12/1000
Training Loss: 0.85422723, Training R2: 0.424610
Validation Loss: 0.83609256, Validation R2: 0.414214
Saved best model with validation R2 0.414214 to finetune_dipole5000.pth

Epoch 13/1000
Training Loss: 0.83196843, Training R2: 0.441744
Validation Loss: 0.84878304, Validation R2: 0.391626

Epoch 14/1000
Training Loss: 0.84371836, Training R2: 0.425937
Validation Loss: 0.79768197, Validation R2: 0.453378
Saved best model with validation R2 0.453378 to finetune_dipole5000.pth

Epoch 15/1000
Training Loss: 0.80822373, Training R2: 0.464709
Validation Loss: 0.77712745, Validation R2: 0.473026
Saved best model with validation R2 0.473026 to finetune_dipole5000.pth

Epoch 16/1000
Training Loss: 0.79254324, Training R2: 0.480037
Validation Loss: 0.78649006, Validation R2: 0.464164

Epoch 17/1000
Training Loss: 0.77684956, Training R2: 0.497098
Validation Loss: 0.79222371, Validation R2: 0.463897

Epoch 18/1000
Training Loss: 0.80377616, Training R2: 0.464290
Validation Loss: 0.80440066, Validation R2: 0.452215

Epoch 19/1000
Training Loss: 0.80943160, Training R2: 0.463112
Validation Loss: 0.75744036, Validation R2: 0.486525
Saved best model with validation R2 0.486525 to finetune_dipole5000.pth

Epoch 20/1000
Training Loss: 0.77356890, Training R2: 0.494307
Validation Loss: 0.76450670, Validation R2: 0.477866

Epoch 21/1000
Training Loss: 0.75366690, Training R2: 0.514210
Validation Loss: 0.76979148, Validation R2: 0.469707

Epoch 22/1000
Training Loss: 0.75656644, Training R2: 0.506063
Validation Loss: 0.75681077, Validation R2: 0.488010
Saved best model with validation R2 0.488010 to finetune_dipole5000.pth

Epoch 23/1000
Training Loss: 0.75626987, Training R2: 0.510383
Validation Loss: 0.75603462, Validation R2: 0.488083
Saved best model with validation R2 0.488083 to finetune_dipole5000.pth

Epoch 24/1000
Training Loss: 0.74349624, Training R2: 0.519443
Validation Loss: 0.75664702, Validation R2: 0.490827
Saved best model with validation R2 0.490827 to finetune_dipole5000.pth

Epoch 25/1000
Training Loss: 0.77381348, Training R2: 0.492400
Validation Loss: 0.77465335, Validation R2: 0.475025

Epoch 26/1000
Training Loss: 0.75538128, Training R2: 0.510779
Validation Loss: 0.73782731, Validation R2: 0.502049
Saved best model with validation R2 0.502049 to finetune_dipole5000.pth

Epoch 27/1000
Training Loss: 0.72977139, Training R2: 0.533887
Validation Loss: 0.75283217, Validation R2: 0.497946

Epoch 28/1000
Training Loss: 0.72067679, Training R2: 0.542652
Validation Loss: 0.73744038, Validation R2: 0.507320
Saved best model with validation R2 0.507320 to finetune_dipole5000.pth

Epoch 29/1000
Training Loss: 0.71280403, Training R2: 0.547846
Validation Loss: 0.73232359, Validation R2: 0.512703
Saved best model with validation R2 0.512703 to finetune_dipole5000.pth

Epoch 30/1000
Training Loss: 0.70945263, Training R2: 0.549653
Validation Loss: 0.72751162, Validation R2: 0.511471

Epoch 31/1000
Training Loss: 0.70000057, Training R2: 0.558148
Validation Loss: 0.71362941, Validation R2: 0.528699
Saved best model with validation R2 0.528699 to finetune_dipole5000.pth

Epoch 32/1000
Training Loss: 0.70180437, Training R2: 0.560466
Validation Loss: 0.73832245, Validation R2: 0.524949

Epoch 33/1000
Training Loss: 0.69179081, Training R2: 0.568114
Validation Loss: 0.71068829, Validation R2: 0.533335
Saved best model with validation R2 0.533335 to finetune_dipole5000.pth

Epoch 34/1000
Training Loss: 0.67880609, Training R2: 0.577986
Validation Loss: 0.79569557, Validation R2: 0.472168

Epoch 35/1000
Training Loss: 0.77191674, Training R2: 0.504461
Validation Loss: 0.70577803, Validation R2: 0.535975
Saved best model with validation R2 0.535975 to finetune_dipole5000.pth

Epoch 36/1000
Training Loss: 0.72449400, Training R2: 0.542161
Validation Loss: 0.81318997, Validation R2: 0.434933

Epoch 37/1000
Training Loss: 0.71592409, Training R2: 0.550155
Validation Loss: 0.75121418, Validation R2: 0.498429

Epoch 38/1000
Training Loss: 0.70607866, Training R2: 0.556560
Validation Loss: 0.71263318, Validation R2: 0.539357
Saved best model with validation R2 0.539357 to finetune_dipole5000.pth

Epoch 39/1000
Training Loss: 0.70003586, Training R2: 0.568556
Validation Loss: 0.72291461, Validation R2: 0.513992

Epoch 40/1000
Training Loss: 0.71463335, Training R2: 0.549641
Validation Loss: 0.74535545, Validation R2: 0.523172

Epoch 41/1000
Training Loss: 0.70601724, Training R2: 0.561412
Validation Loss: 0.69829055, Validation R2: 0.550883
Saved best model with validation R2 0.550883 to finetune_dipole5000.pth

Epoch 42/1000
Training Loss: 0.68256840, Training R2: 0.583380
Validation Loss: 0.75375134, Validation R2: 0.499576

Epoch 43/1000
Training Loss: 0.66546506, Training R2: 0.594846
Validation Loss: 0.69498765, Validation R2: 0.559899
Saved best model with validation R2 0.559899 to finetune_dipole5000.pth

Epoch 44/1000
Training Loss: 0.66486822, Training R2: 0.594557
Validation Loss: 0.78387921, Validation R2: 0.471029

Epoch 45/1000
Training Loss: 0.69763604, Training R2: 0.571889
Validation Loss: 0.71222830, Validation R2: 0.540012

Epoch 46/1000
Training Loss: 0.69130267, Training R2: 0.574703
Validation Loss: 0.70076427, Validation R2: 0.556480

Epoch 47/1000
Training Loss: 0.65464824, Training R2: 0.608232
Validation Loss: 0.67723406, Validation R2: 0.586733
Saved best model with validation R2 0.586733 to finetune_dipole5000.pth

Epoch 48/1000
Training Loss: 0.64302459, Training R2: 0.616991
Validation Loss: 0.67885753, Validation R2: 0.580215

Epoch 49/1000
Training Loss: 0.64478216, Training R2: 0.614168
Validation Loss: 0.69699809, Validation R2: 0.572189

Epoch 50/1000
Training Loss: 0.65260611, Training R2: 0.612922
Validation Loss: 0.68297877, Validation R2: 0.577959

Epoch 51/1000
Training Loss: 0.65881654, Training R2: 0.602097
Validation Loss: 0.69130569, Validation R2: 0.579688

Epoch 52/1000
Training Loss: 0.66112098, Training R2: 0.602632
Validation Loss: 0.67812044, Validation R2: 0.587922
Saved best model with validation R2 0.587922 to finetune_dipole5000.pth

Epoch 53/1000
Training Loss: 0.62115200, Training R2: 0.636813
Validation Loss: 0.66053937, Validation R2: 0.603013
Saved best model with validation R2 0.603013 to finetune_dipole5000.pth

Epoch 54/1000
Training Loss: 0.67584151, Training R2: 0.592093
Validation Loss: 0.72183065, Validation R2: 0.537267

Epoch 55/1000
Training Loss: 0.64389919, Training R2: 0.620391
Validation Loss: 0.72892479, Validation R2: 0.538034

Epoch 56/1000
Training Loss: 0.63504955, Training R2: 0.626520
Validation Loss: 0.70479311, Validation R2: 0.557611

Epoch 57/1000
Training Loss: 0.64617170, Training R2: 0.622091
Validation Loss: 0.67712871, Validation R2: 0.585732

Epoch 58/1000
Training Loss: 0.62852024, Training R2: 0.635671
Validation Loss: 0.67936033, Validation R2: 0.586607

Epoch 59/1000
Training Loss: 0.61118132, Training R2: 0.648574
Validation Loss: 0.66969725, Validation R2: 0.586627

Epoch 60/1000
Training Loss: 0.63902296, Training R2: 0.629829
Validation Loss: 0.68966324, Validation R2: 0.575485

Epoch 61/1000
Training Loss: 0.60952540, Training R2: 0.647078
Validation Loss: 0.64916850, Validation R2: 0.611149
Saved best model with validation R2 0.611149 to finetune_dipole5000.pth

Epoch 62/1000
Training Loss: 0.64087964, Training R2: 0.625486
Validation Loss: 0.67506839, Validation R2: 0.594756

Epoch 63/1000
Training Loss: 0.61673493, Training R2: 0.646841
Validation Loss: 0.64730084, Validation R2: 0.613285
Saved best model with validation R2 0.613285 to finetune_dipole5000.pth

Epoch 64/1000
Training Loss: 0.60148673, Training R2: 0.656520
Validation Loss: 0.66535850, Validation R2: 0.590729

Epoch 65/1000
Training Loss: 0.59361420, Training R2: 0.664205
Validation Loss: 0.65559308, Validation R2: 0.608568

Epoch 66/1000
Training Loss: 0.58856357, Training R2: 0.668525
Validation Loss: 0.65323439, Validation R2: 0.614344
Saved best model with validation R2 0.614344 to finetune_dipole5000.pth

Epoch 67/1000
Training Loss: 0.58533304, Training R2: 0.669335
Validation Loss: 0.65469558, Validation R2: 0.615007
Saved best model with validation R2 0.615007 to finetune_dipole5000.pth

Epoch 68/1000
Training Loss: 0.58427027, Training R2: 0.673457
Validation Loss: 0.65468517, Validation R2: 0.606687

Epoch 69/1000
Training Loss: 0.57903044, Training R2: 0.677236
Validation Loss: 0.66865552, Validation R2: 0.581926

Epoch 70/1000
Training Loss: 0.58994499, Training R2: 0.670732
Validation Loss: 0.68815032, Validation R2: 0.573747

Epoch 71/1000
Training Loss: 0.58762415, Training R2: 0.668601
Validation Loss: 0.63900179, Validation R2: 0.617260
Saved best model with validation R2 0.617260 to finetune_dipole5000.pth

Epoch 72/1000
Training Loss: 0.58574207, Training R2: 0.673915
Validation Loss: 0.72139444, Validation R2: 0.526720

Epoch 73/1000
Training Loss: 0.60659121, Training R2: 0.660436
Validation Loss: 0.63259131, Validation R2: 0.631328
Saved best model with validation R2 0.631328 to finetune_dipole5000.pth

Epoch 74/1000
Training Loss: 0.57892222, Training R2: 0.680928
Validation Loss: 0.66475052, Validation R2: 0.602863

Epoch 75/1000
Training Loss: 0.57458501, Training R2: 0.683458
Validation Loss: 0.63606158, Validation R2: 0.631051

Epoch 76/1000
Training Loss: 0.58847118, Training R2: 0.674408
Validation Loss: 0.62594133, Validation R2: 0.636007
Saved best model with validation R2 0.636007 to finetune_dipole5000.pth

Epoch 77/1000
Training Loss: 0.56685246, Training R2: 0.689482
Validation Loss: 0.64518661, Validation R2: 0.625119

Epoch 78/1000
Training Loss: 0.61660518, Training R2: 0.650853
Validation Loss: 0.69918946, Validation R2: 0.555208

Epoch 79/1000
Training Loss: 0.57420753, Training R2: 0.682950
Validation Loss: 0.66749092, Validation R2: 0.591813

Epoch 80/1000
Training Loss: 0.57405154, Training R2: 0.685488
Validation Loss: 0.65093863, Validation R2: 0.618889

Epoch 81/1000
Training Loss: 0.57357606, Training R2: 0.687752
Validation Loss: 0.65137378, Validation R2: 0.622303

Epoch 82/1000
Training Loss: 0.56973626, Training R2: 0.686487
Validation Loss: 0.64175921, Validation R2: 0.635472

Epoch 83/1000
Training Loss: 0.56223496, Training R2: 0.692696
Validation Loss: 0.67584409, Validation R2: 0.588366

Epoch 84/1000
Training Loss: 0.55717544, Training R2: 0.700491
Validation Loss: 0.66247961, Validation R2: 0.590348

Epoch 85/1000
Training Loss: 0.57087559, Training R2: 0.690295
Validation Loss: 0.65540454, Validation R2: 0.616491

Epoch 86/1000
Training Loss: 0.55658867, Training R2: 0.702664
Validation Loss: 0.64785530, Validation R2: 0.617862

Epoch 87/1000
Training Loss: 0.54691041, Training R2: 0.707319
Validation Loss: 0.66700914, Validation R2: 0.595691

Epoch 88/1000
Training Loss: 0.57771946, Training R2: 0.689370
Validation Loss: 0.61371130, Validation R2: 0.645009
Saved best model with validation R2 0.645009 to finetune_dipole5000.pth

Epoch 89/1000
Training Loss: 0.55729243, Training R2: 0.702314
Validation Loss: 0.73437131, Validation R2: 0.537189

Epoch 90/1000
Training Loss: 0.57042321, Training R2: 0.692625
Validation Loss: 0.63007910, Validation R2: 0.637539

Epoch 91/1000
Training Loss: 0.54742716, Training R2: 0.708705
Validation Loss: 0.62144193, Validation R2: 0.638661

Epoch 92/1000
Training Loss: 0.54236722, Training R2: 0.712241
Validation Loss: 0.62659839, Validation R2: 0.636476

Epoch 93/1000
Training Loss: 0.53621366, Training R2: 0.715791
Validation Loss: 0.60995140, Validation R2: 0.653505
Saved best model with validation R2 0.653505 to finetune_dipole5000.pth

Epoch 94/1000
Training Loss: 0.58276552, Training R2: 0.681978
Validation Loss: 0.68986412, Validation R2: 0.566350

Epoch 95/1000
Training Loss: 0.55204642, Training R2: 0.710945
Validation Loss: 0.62328083, Validation R2: 0.647913

Epoch 96/1000
Training Loss: 0.53899642, Training R2: 0.715796
Validation Loss: 0.62670295, Validation R2: 0.634621

Epoch 97/1000
Training Loss: 0.54543183, Training R2: 0.715272
Validation Loss: 0.69553268, Validation R2: 0.544424

Epoch 98/1000
Training Loss: 0.54411717, Training R2: 0.714123
Validation Loss: 0.61354498, Validation R2: 0.652147

Epoch 99/1000
Training Loss: 0.53915379, Training R2: 0.721593
Validation Loss: 0.61672251, Validation R2: 0.653038

Epoch 100/1000
Training Loss: 0.54959507, Training R2: 0.713227
Validation Loss: 0.62507783, Validation R2: 0.653432

Epoch 101/1000
Training Loss: 0.53737517, Training R2: 0.720544
Validation Loss: 0.61537645, Validation R2: 0.652372

Epoch 102/1000
Training Loss: 0.54337723, Training R2: 0.715493
Validation Loss: 0.64848610, Validation R2: 0.624141

Epoch 103/1000
Training Loss: 0.55007857, Training R2: 0.712275
Validation Loss: 0.62006250, Validation R2: 0.642389

Epoch 104/1000
Training Loss: 0.52892025, Training R2: 0.726731
Validation Loss: 0.61421971, Validation R2: 0.641076

Epoch 105/1000
Training Loss: 0.52080956, Training R2: 0.735135
Validation Loss: 0.63494772, Validation R2: 0.623711

Epoch 106/1000
Training Loss: 0.52180143, Training R2: 0.732802
Validation Loss: 0.62134523, Validation R2: 0.646874

Epoch 107/1000
Training Loss: 0.51886357, Training R2: 0.734016
Validation Loss: 0.61829308, Validation R2: 0.644629

Epoch 108/1000
Training Loss: 0.51490029, Training R2: 0.737974
Validation Loss: 0.63045357, Validation R2: 0.629926

Epoch 109/1000
Training Loss: 0.51067842, Training R2: 0.738220
Validation Loss: 0.65291441, Validation R2: 0.607236

Epoch 110/1000
Training Loss: 0.52922958, Training R2: 0.724622
Validation Loss: 0.64158274, Validation R2: 0.628320

Epoch 111/1000
Training Loss: 0.53458456, Training R2: 0.722501
Validation Loss: 0.68416413, Validation R2: 0.583482

Epoch 112/1000
Training Loss: 0.53275300, Training R2: 0.724871
Validation Loss: 0.60261702, Validation R2: 0.650037

Epoch 113/1000
Training Loss: 0.50675678, Training R2: 0.742093
Validation Loss: 0.61042298, Validation R2: 0.643632

Epoch 114/1000
Epoch 00114: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.49634253, Training R2: 0.752110
Validation Loss: 0.61076682, Validation R2: 0.645291

Epoch 115/1000
学习率已减少 1 次
Training Loss: 0.48727659, Training R2: 0.755737
Validation Loss: 0.60627025, Validation R2: 0.652013

Epoch 116/1000
Training Loss: 0.48254396, Training R2: 0.758569
Validation Loss: 0.62131476, Validation R2: 0.632886

Epoch 117/1000
Training Loss: 0.48176872, Training R2: 0.760211
Validation Loss: 0.60676489, Validation R2: 0.646513

Epoch 118/1000
Training Loss: 0.48290744, Training R2: 0.759650
Validation Loss: 0.60164102, Validation R2: 0.652734

Epoch 119/1000
Training Loss: 0.47788456, Training R2: 0.762933
Validation Loss: 0.61177045, Validation R2: 0.653216

Epoch 120/1000
Training Loss: 0.48501861, Training R2: 0.761705
Validation Loss: 0.59186384, Validation R2: 0.664873
Saved best model with validation R2 0.664873 to finetune_dipole5000.pth

Epoch 121/1000
Training Loss: 0.47575747, Training R2: 0.764189
Validation Loss: 0.61693600, Validation R2: 0.629325

Epoch 122/1000
Training Loss: 0.47194867, Training R2: 0.766010
Validation Loss: 0.59750424, Validation R2: 0.655894

Epoch 123/1000
Training Loss: 0.47083360, Training R2: 0.769983
Validation Loss: 0.59728892, Validation R2: 0.659308

Epoch 124/1000
Training Loss: 0.50029201, Training R2: 0.751190
Validation Loss: 0.62158566, Validation R2: 0.641284

Epoch 125/1000
Training Loss: 0.47404397, Training R2: 0.769546
Validation Loss: 0.60232714, Validation R2: 0.657488

Epoch 126/1000
Training Loss: 0.47024434, Training R2: 0.768083
Validation Loss: 0.65001753, Validation R2: 0.590958

Epoch 127/1000
Training Loss: 0.47323923, Training R2: 0.768293
Validation Loss: 0.59988257, Validation R2: 0.656354

Epoch 128/1000
Training Loss: 0.46773997, Training R2: 0.772649
Validation Loss: 0.60864184, Validation R2: 0.639692

Epoch 129/1000
Training Loss: 0.46566809, Training R2: 0.773253
Validation Loss: 0.60747923, Validation R2: 0.645260

Epoch 130/1000
Training Loss: 0.47307056, Training R2: 0.768283
Validation Loss: 0.61580380, Validation R2: 0.636124

Epoch 131/1000
Training Loss: 0.46689958, Training R2: 0.772893
Validation Loss: 0.60440942, Validation R2: 0.645639

Epoch 132/1000
Training Loss: 0.45559762, Training R2: 0.778717
Validation Loss: 0.60375263, Validation R2: 0.645132

Epoch 133/1000
Training Loss: 0.46704427, Training R2: 0.776425
Validation Loss: 0.59721551, Validation R2: 0.653729

Epoch 134/1000
Training Loss: 0.48161699, Training R2: 0.764638
Validation Loss: 0.59390512, Validation R2: 0.660796

Epoch 135/1000
Training Loss: 0.46884411, Training R2: 0.773654
Validation Loss: 0.59452231, Validation R2: 0.659732

Epoch 136/1000
Training Loss: 0.47047391, Training R2: 0.774979
Validation Loss: 0.59015107, Validation R2: 0.666658
Saved best model with validation R2 0.666658 to finetune_dipole5000.pth

Epoch 137/1000
Training Loss: 0.46995831, Training R2: 0.771523
Validation Loss: 0.61470703, Validation R2: 0.633091

Epoch 138/1000
Training Loss: 0.46494133, Training R2: 0.772688
Validation Loss: 0.61583569, Validation R2: 0.633181

Epoch 139/1000
Training Loss: 0.46274600, Training R2: 0.775551
Validation Loss: 0.59176262, Validation R2: 0.657856

Epoch 140/1000
Training Loss: 0.45641065, Training R2: 0.781652
Validation Loss: 0.60943805, Validation R2: 0.633463

Epoch 141/1000
Training Loss: 0.46783912, Training R2: 0.772654
Validation Loss: 0.60794039, Validation R2: 0.646257

Epoch 142/1000
Training Loss: 0.46119306, Training R2: 0.780824
Validation Loss: 0.61320391, Validation R2: 0.637794

Epoch 143/1000
Training Loss: 0.45941534, Training R2: 0.780106
Validation Loss: 0.60030380, Validation R2: 0.648879

Epoch 144/1000
Training Loss: 0.44784279, Training R2: 0.785696
Validation Loss: 0.60050700, Validation R2: 0.654213

Epoch 145/1000
Training Loss: 0.45119234, Training R2: 0.784222
Validation Loss: 0.61989478, Validation R2: 0.629585

Epoch 146/1000
Training Loss: 0.45426853, Training R2: 0.783269
Validation Loss: 0.60744937, Validation R2: 0.643596

Epoch 147/1000
Training Loss: 0.46191138, Training R2: 0.778202
Validation Loss: 0.61359314, Validation R2: 0.646411

Epoch 148/1000
Training Loss: 0.48185397, Training R2: 0.767228
Validation Loss: 0.60132120, Validation R2: 0.649816

Epoch 149/1000
Training Loss: 0.46414772, Training R2: 0.781725
Validation Loss: 0.59168330, Validation R2: 0.666284

Epoch 150/1000
Training Loss: 0.44774187, Training R2: 0.787105
Validation Loss: 0.60148375, Validation R2: 0.647798

Epoch 151/1000
Training Loss: 0.45876817, Training R2: 0.785339
Validation Loss: 0.61241588, Validation R2: 0.636311

Epoch 152/1000
Training Loss: 0.44856505, Training R2: 0.786911
Validation Loss: 0.62253411, Validation R2: 0.626164

Epoch 153/1000
Training Loss: 0.44294580, Training R2: 0.792271
Validation Loss: 0.59188536, Validation R2: 0.661337

Epoch 154/1000
Training Loss: 0.44830697, Training R2: 0.790220
Validation Loss: 0.59234602, Validation R2: 0.658051

Epoch 155/1000
Training Loss: 0.43976338, Training R2: 0.794080
Validation Loss: 0.60225426, Validation R2: 0.644897

Epoch 156/1000
Training Loss: 0.43987997, Training R2: 0.795581
Validation Loss: 0.59700279, Validation R2: 0.647326

Epoch 157/1000
Epoch 00157: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.43517627, Training R2: 0.798838
Validation Loss: 0.59201449, Validation R2: 0.652219

Epoch 158/1000
学习率已减少 2 次
Training Loss: 0.42751616, Training R2: 0.800653
Validation Loss: 0.59088543, Validation R2: 0.656664

Epoch 159/1000
Training Loss: 0.42499371, Training R2: 0.803565
Validation Loss: 0.59880985, Validation R2: 0.648354

Epoch 160/1000
Training Loss: 0.42085235, Training R2: 0.805967
Validation Loss: 0.59551057, Validation R2: 0.654108

Epoch 161/1000
Training Loss: 0.42380927, Training R2: 0.803447
Validation Loss: 0.59173111, Validation R2: 0.654673

Epoch 162/1000
Training Loss: 0.42192436, Training R2: 0.805310
Validation Loss: 0.59141970, Validation R2: 0.656371

Epoch 163/1000
Training Loss: 0.41955200, Training R2: 0.808070
Validation Loss: 0.59108576, Validation R2: 0.655906

Epoch 164/1000
Training Loss: 0.41610643, Training R2: 0.809083
Validation Loss: 0.59546400, Validation R2: 0.653613

Epoch 165/1000
Training Loss: 0.41937649, Training R2: 0.807569
Validation Loss: 0.59139525, Validation R2: 0.659810

Epoch 166/1000
Training Loss: 0.42367963, Training R2: 0.804969
Validation Loss: 0.59409245, Validation R2: 0.654172

Epoch 167/1000
Training Loss: 0.42027217, Training R2: 0.807318
Validation Loss: 0.59541826, Validation R2: 0.659614

Epoch 168/1000
Training Loss: 0.41986567, Training R2: 0.808497
Validation Loss: 0.59640115, Validation R2: 0.654262

Epoch 169/1000
Training Loss: 0.41669616, Training R2: 0.809551
Validation Loss: 0.59892376, Validation R2: 0.642642

Epoch 170/1000
Training Loss: 0.41216209, Training R2: 0.810013
Validation Loss: 0.59671237, Validation R2: 0.652766

Epoch 171/1000
Training Loss: 0.41502368, Training R2: 0.810891
Validation Loss: 0.59699112, Validation R2: 0.649128

Epoch 172/1000
Training Loss: 0.42088049, Training R2: 0.807002
Validation Loss: 0.58552744, Validation R2: 0.663759

Epoch 173/1000
Training Loss: 0.41916194, Training R2: 0.808290
Validation Loss: 0.59683875, Validation R2: 0.647989

Epoch 174/1000
Training Loss: 0.41207919, Training R2: 0.813033
Validation Loss: 0.59924678, Validation R2: 0.645110

Epoch 175/1000
Training Loss: 0.41078095, Training R2: 0.813336
Validation Loss: 0.59504212, Validation R2: 0.648235

Epoch 176/1000
Training Loss: 0.41179227, Training R2: 0.812890
Validation Loss: 0.58558291, Validation R2: 0.662428

Epoch 177/1000
Training Loss: 0.41389195, Training R2: 0.812525
Validation Loss: 0.59836846, Validation R2: 0.649269

Epoch 178/1000
Epoch 00178: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.41168358, Training R2: 0.815426
Validation Loss: 0.60106790, Validation R2: 0.645727

Epoch 179/1000
学习率已减少 3 次
Training Loss: 0.40800252, Training R2: 0.815681
Validation Loss: 0.60714016, Validation R2: 0.639110

Epoch 180/1000
Training Loss: 0.41763506, Training R2: 0.811782
Validation Loss: 0.59334781, Validation R2: 0.653411

Epoch 181/1000
Training Loss: 0.40356937, Training R2: 0.817169
Validation Loss: 0.59120195, Validation R2: 0.654846

Epoch 182/1000
Training Loss: 0.40193887, Training R2: 0.818785
Validation Loss: 0.58936635, Validation R2: 0.656982

Epoch 183/1000
Training Loss: 0.39946191, Training R2: 0.819270
Validation Loss: 0.59098655, Validation R2: 0.655235

Epoch 184/1000
Training Loss: 0.40322966, Training R2: 0.817242
Validation Loss: 0.58634461, Validation R2: 0.662496

Epoch 185/1000
Training Loss: 0.40568999, Training R2: 0.816516
Validation Loss: 0.59061114, Validation R2: 0.660429

Epoch 186/1000
Training Loss: 0.40403600, Training R2: 0.817776
Validation Loss: 0.58840355, Validation R2: 0.657003

Epoch 187/1000
Training Loss: 0.39942951, Training R2: 0.819364
Validation Loss: 0.58702050, Validation R2: 0.659737

Epoch 188/1000
Training Loss: 0.39855309, Training R2: 0.820938
Validation Loss: 0.58822536, Validation R2: 0.659347

Epoch 189/1000
Training Loss: 0.40393805, Training R2: 0.818117
Validation Loss: 0.58851634, Validation R2: 0.659113

Epoch 190/1000
Training Loss: 0.40212597, Training R2: 0.818305
Validation Loss: 0.59235808, Validation R2: 0.654738

Epoch 191/1000
Training Loss: 0.39788066, Training R2: 0.820421
Validation Loss: 0.58945132, Validation R2: 0.656720

Epoch 192/1000
Training Loss: 0.39833572, Training R2: 0.821133
Validation Loss: 0.58757850, Validation R2: 0.658091

Epoch 193/1000
Training Loss: 0.40651210, Training R2: 0.816951
Validation Loss: 0.59490844, Validation R2: 0.650386

Epoch 194/1000
Training Loss: 0.40011044, Training R2: 0.820200
Validation Loss: 0.59088973, Validation R2: 0.655477

Epoch 195/1000
Training Loss: 0.39701094, Training R2: 0.821062
Validation Loss: 0.59280029, Validation R2: 0.653232

Epoch 196/1000
Training Loss: 0.39713380, Training R2: 0.820843
Validation Loss: 0.59151487, Validation R2: 0.656144

Epoch 197/1000
Training Loss: 0.39381542, Training R2: 0.822838
Validation Loss: 0.59077354, Validation R2: 0.656185

Epoch 198/1000
Training Loss: 0.39420386, Training R2: 0.822813
Validation Loss: 0.59173804, Validation R2: 0.653486

Epoch 199/1000
Epoch 00199: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.39368526, Training R2: 0.823407
Validation Loss: 0.59399556, Validation R2: 0.652385

Epoch 200/1000
学习率已减少 4 次
Training Loss: 0.39065044, Training R2: 0.824368
Validation Loss: 0.59212376, Validation R2: 0.653423

Epoch 201/1000
Training Loss: 0.39075173, Training R2: 0.824020
Validation Loss: 0.58950283, Validation R2: 0.655574

Epoch 202/1000
Training Loss: 0.38946197, Training R2: 0.825410
Validation Loss: 0.59068909, Validation R2: 0.655350

Epoch 203/1000
Training Loss: 0.38976047, Training R2: 0.824928
Validation Loss: 0.59052475, Validation R2: 0.656151

Epoch 204/1000
Training Loss: 0.38990276, Training R2: 0.825069
Validation Loss: 0.59054762, Validation R2: 0.655944

Epoch 205/1000
Training Loss: 0.38854319, Training R2: 0.825579
Validation Loss: 0.59189211, Validation R2: 0.653438

Epoch 206/1000
Training Loss: 0.38899379, Training R2: 0.825252
Validation Loss: 0.59558746, Validation R2: 0.648481

Epoch 207/1000
Training Loss: 0.39200019, Training R2: 0.824070
Validation Loss: 0.58691514, Validation R2: 0.659134

Epoch 208/1000
Training Loss: 0.39114472, Training R2: 0.825329
Validation Loss: 0.58744883, Validation R2: 0.658574

Epoch 209/1000
Training Loss: 0.39201851, Training R2: 0.824953
Validation Loss: 0.59653529, Validation R2: 0.649219

Epoch 210/1000
Training Loss: 0.38865083, Training R2: 0.826394
Validation Loss: 0.58700092, Validation R2: 0.659757

Epoch 211/1000
Training Loss: 0.38980038, Training R2: 0.824700
Validation Loss: 0.58785446, Validation R2: 0.657262

Epoch 212/1000
Training Loss: 0.38689828, Training R2: 0.825968
Validation Loss: 0.59154350, Validation R2: 0.653839

Epoch 213/1000
Training Loss: 0.38681600, Training R2: 0.826230
Validation Loss: 0.59380308, Validation R2: 0.650758

Epoch 214/1000
Training Loss: 0.38751817, Training R2: 0.826469
Validation Loss: 0.59038258, Validation R2: 0.655882

Epoch 215/1000
Training Loss: 0.39012975, Training R2: 0.825718
Validation Loss: 0.58918735, Validation R2: 0.656033

Epoch 216/1000
Training Loss: 0.38925756, Training R2: 0.826186
Validation Loss: 0.58672786, Validation R2: 0.658766

Epoch 217/1000
Training Loss: 0.38736144, Training R2: 0.826434
Validation Loss: 0.58957891, Validation R2: 0.654684

Epoch 218/1000
Training Loss: 0.38606820, Training R2: 0.826619
Validation Loss: 0.59352817, Validation R2: 0.651043

Epoch 219/1000
Training Loss: 0.38597242, Training R2: 0.826517
Validation Loss: 0.58843333, Validation R2: 0.657905

Epoch 220/1000
Epoch 00220: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.38706038, Training R2: 0.827340
Validation Loss: 0.59024157, Validation R2: 0.655745

Epoch 221/1000
学习率已减少 5 次
Training Loss: 0.38359516, Training R2: 0.827932
Validation Loss: 0.58971393, Validation R2: 0.655080

Epoch 222/1000
Training Loss: 0.38249870, Training R2: 0.828395
Validation Loss: 0.58973346, Validation R2: 0.654862

Epoch 223/1000
Training Loss: 0.38271758, Training R2: 0.828372
Validation Loss: 0.59216844, Validation R2: 0.652206

Epoch 224/1000
Training Loss: 0.38510008, Training R2: 0.827781
Validation Loss: 0.58882780, Validation R2: 0.656009

Epoch 225/1000
Training Loss: 0.38360937, Training R2: 0.828073
Validation Loss: 0.58779217, Validation R2: 0.657234

Epoch 226/1000
Training Loss: 0.38230081, Training R2: 0.828187
Validation Loss: 0.59132074, Validation R2: 0.653566

Epoch 227/1000
Training Loss: 0.38231517, Training R2: 0.828326
Validation Loss: 0.58929416, Validation R2: 0.655663

Epoch 228/1000
Training Loss: 0.38204029, Training R2: 0.828467
Validation Loss: 0.59012842, Validation R2: 0.654558

Epoch 229/1000
Training Loss: 0.38207019, Training R2: 0.828799
Validation Loss: 0.59057760, Validation R2: 0.654063

Epoch 230/1000
Training Loss: 0.38200299, Training R2: 0.828694
Validation Loss: 0.59155948, Validation R2: 0.652672

Epoch 231/1000
Training Loss: 0.38158367, Training R2: 0.828731
Validation Loss: 0.58936311, Validation R2: 0.655543

Epoch 232/1000
Training Loss: 0.38226119, Training R2: 0.828513
Validation Loss: 0.59220865, Validation R2: 0.652534

Epoch 233/1000
Training Loss: 0.38252104, Training R2: 0.828863
Validation Loss: 0.58915169, Validation R2: 0.655290

Epoch 234/1000
Training Loss: 0.38271248, Training R2: 0.828847
Validation Loss: 0.58893954, Validation R2: 0.655878

Epoch 235/1000
Training Loss: 0.38144655, Training R2: 0.829183
Validation Loss: 0.59047850, Validation R2: 0.654389

Epoch 236/1000
Training Loss: 0.38080595, Training R2: 0.829271
Validation Loss: 0.58945747, Validation R2: 0.654832

Epoch 237/1000
Training Loss: 0.38054942, Training R2: 0.829313
Validation Loss: 0.59052545, Validation R2: 0.654558

Epoch 238/1000
Training Loss: 0.38093006, Training R2: 0.829481
Validation Loss: 0.58993965, Validation R2: 0.655039

Epoch 239/1000
Training Loss: 0.38070996, Training R2: 0.829191
Validation Loss: 0.59067164, Validation R2: 0.653953

Epoch 240/1000
Training Loss: 0.38068329, Training R2: 0.829355
Validation Loss: 0.58864946, Validation R2: 0.655978

Epoch 241/1000
Epoch 00241: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.38099461, Training R2: 0.829223
Validation Loss: 0.59267859, Validation R2: 0.651848

Epoch 242/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
