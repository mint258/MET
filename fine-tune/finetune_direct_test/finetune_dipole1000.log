Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.27565477, Training R2: -0.256756
Validation Loss: 1.15189743, Validation R2: -0.040555
Saved best model with validation R2 -0.040555 to finetune_dipole1000.pth

Epoch 2/1000
Training Loss: 1.17437122, Training R2: -0.161776
Validation Loss: 1.14777935, Validation R2: -0.063145

Epoch 3/1000
Training Loss: 1.12193376, Training R2: 0.001039
Validation Loss: 1.12019384, Validation R2: 0.025664
Saved best model with validation R2 0.025664 to finetune_dipole1000.pth

Epoch 4/1000
Training Loss: 1.09001557, Training R2: 0.001327
Validation Loss: 1.09671116, Validation R2: 0.039074
Saved best model with validation R2 0.039074 to finetune_dipole1000.pth

Epoch 5/1000
Training Loss: 1.07267858, Training R2: 0.084554
Validation Loss: 1.07648909, Validation R2: 0.047719
Saved best model with validation R2 0.047719 to finetune_dipole1000.pth

Epoch 6/1000
Training Loss: 1.03642560, Training R2: 0.069614
Validation Loss: 1.05341303, Validation R2: 0.122539
Saved best model with validation R2 0.122539 to finetune_dipole1000.pth

Epoch 7/1000
Training Loss: 1.04002410, Training R2: 0.140300
Validation Loss: 1.15530288, Validation R2: -0.115888

Epoch 8/1000
Training Loss: 1.07434792, Training R2: 0.030787
Validation Loss: 1.04490387, Validation R2: 0.119220

Epoch 9/1000
Training Loss: 1.01215192, Training R2: 0.121253
Validation Loss: 1.03830743, Validation R2: 0.100427

Epoch 10/1000
Training Loss: 1.00334640, Training R2: 0.160288
Validation Loss: 1.05844867, Validation R2: 0.119933

Epoch 11/1000
Training Loss: 1.00436641, Training R2: 0.171174
Validation Loss: 1.04561758, Validation R2: 0.083428

Epoch 12/1000
Training Loss: 0.98363868, Training R2: 0.187320
Validation Loss: 1.03119659, Validation R2: 0.104528

Epoch 13/1000
Training Loss: 0.97722485, Training R2: 0.172346
Validation Loss: 1.06385934, Validation R2: 0.124346
Saved best model with validation R2 0.124346 to finetune_dipole1000.pth

Epoch 14/1000
Training Loss: 0.99805818, Training R2: 0.191444
Validation Loss: 1.01977265, Validation R2: 0.122955

Epoch 15/1000
Training Loss: 0.95421631, Training R2: 0.232107
Validation Loss: 0.99763417, Validation R2: 0.175180
Saved best model with validation R2 0.175180 to finetune_dipole1000.pth

Epoch 16/1000
Training Loss: 0.95561621, Training R2: 0.210513
Validation Loss: 1.00620723, Validation R2: 0.177637
Saved best model with validation R2 0.177637 to finetune_dipole1000.pth

Epoch 17/1000
Training Loss: 0.95686611, Training R2: 0.247263
Validation Loss: 1.26937783, Validation R2: -0.260346

Epoch 18/1000
Training Loss: 1.03856193, Training R2: 0.096880
Validation Loss: 1.12505245, Validation R2: 0.061525

Epoch 19/1000
Training Loss: 1.00072143, Training R2: 0.201567
Validation Loss: 1.07975817, Validation R2: 0.020397

Epoch 20/1000
Training Loss: 0.95470129, Training R2: 0.191317
Validation Loss: 1.03463054, Validation R2: 0.170726

Epoch 21/1000
Training Loss: 0.94865941, Training R2: 0.252114
Validation Loss: 1.07660460, Validation R2: 0.030846

Epoch 22/1000
Training Loss: 0.94792023, Training R2: 0.222310
Validation Loss: 1.12029052, Validation R2: 0.050664

Epoch 23/1000
Training Loss: 1.05760788, Training R2: 0.120971
Validation Loss: 1.12876785, Validation R2: -0.049219

Epoch 24/1000
Training Loss: 1.05103551, Training R2: 0.075049
Validation Loss: 0.97165191, Validation R2: 0.235308
Saved best model with validation R2 0.235308 to finetune_dipole1000.pth

Epoch 25/1000
Training Loss: 0.97161263, Training R2: 0.244832
Validation Loss: 0.96498609, Validation R2: 0.207780

Epoch 26/1000
Training Loss: 0.99077099, Training R2: 0.149268
Validation Loss: 1.03027642, Validation R2: 0.105019

Epoch 27/1000
Training Loss: 0.90007287, Training R2: 0.291858
Validation Loss: 1.01103020, Validation R2: 0.199028

Epoch 28/1000
Training Loss: 0.92238252, Training R2: 0.292116
Validation Loss: 0.96706784, Validation R2: 0.204120

Epoch 29/1000
Training Loss: 0.85971037, Training R2: 0.350808
Validation Loss: 0.94378340, Validation R2: 0.247179
Saved best model with validation R2 0.247179 to finetune_dipole1000.pth

Epoch 30/1000
Training Loss: 0.86614145, Training R2: 0.345300
Validation Loss: 0.92280376, Validation R2: 0.255117
Saved best model with validation R2 0.255117 to finetune_dipole1000.pth

Epoch 31/1000
Training Loss: 0.82156948, Training R2: 0.384777
Validation Loss: 0.90824133, Validation R2: 0.273618
Saved best model with validation R2 0.273618 to finetune_dipole1000.pth

Epoch 32/1000
Training Loss: 0.81389516, Training R2: 0.397389
Validation Loss: 0.89330578, Validation R2: 0.284197
Saved best model with validation R2 0.284197 to finetune_dipole1000.pth

Epoch 33/1000
Training Loss: 0.79363549, Training R2: 0.415270
Validation Loss: 0.89734954, Validation R2: 0.283822

Epoch 34/1000
Training Loss: 0.79199781, Training R2: 0.420549
Validation Loss: 0.89436460, Validation R2: 0.279846

Epoch 35/1000
Training Loss: 0.79726626, Training R2: 0.420841
Validation Loss: 0.86540687, Validation R2: 0.310818
Saved best model with validation R2 0.310818 to finetune_dipole1000.pth

Epoch 36/1000
Training Loss: 0.77974955, Training R2: 0.439061
Validation Loss: 0.88242888, Validation R2: 0.293576

Epoch 37/1000
Training Loss: 0.78381747, Training R2: 0.431681
Validation Loss: 0.89777815, Validation R2: 0.268917

Epoch 38/1000
Training Loss: 0.78931462, Training R2: 0.423351
Validation Loss: 0.87367141, Validation R2: 0.314652
Saved best model with validation R2 0.314652 to finetune_dipole1000.pth

Epoch 39/1000
Training Loss: 0.79115177, Training R2: 0.420584
Validation Loss: 0.88545728, Validation R2: 0.312952

Epoch 40/1000
Training Loss: 0.80371126, Training R2: 0.412519
Validation Loss: 0.90961075, Validation R2: 0.271507

Epoch 41/1000
Training Loss: 0.80537661, Training R2: 0.397232
Validation Loss: 0.88347316, Validation R2: 0.317690
Saved best model with validation R2 0.317690 to finetune_dipole1000.pth

Epoch 42/1000
Training Loss: 0.78774786, Training R2: 0.428410
Validation Loss: 0.86245728, Validation R2: 0.319070
Saved best model with validation R2 0.319070 to finetune_dipole1000.pth

Epoch 43/1000
Training Loss: 0.74359782, Training R2: 0.465993
Validation Loss: 0.90976346, Validation R2: 0.263705

Epoch 44/1000
Training Loss: 0.77862343, Training R2: 0.434346
Validation Loss: 0.88785261, Validation R2: 0.294665

Epoch 45/1000
Training Loss: 0.76002579, Training R2: 0.452581
Validation Loss: 0.85728413, Validation R2: 0.321990
Saved best model with validation R2 0.321990 to finetune_dipole1000.pth

Epoch 46/1000
Training Loss: 0.73879917, Training R2: 0.464778
Validation Loss: 0.89420772, Validation R2: 0.285908

Epoch 47/1000
Training Loss: 0.75486833, Training R2: 0.461729
Validation Loss: 0.91438401, Validation R2: 0.297526

Epoch 48/1000
Training Loss: 0.79460609, Training R2: 0.422695
Validation Loss: 0.94623154, Validation R2: 0.228957

Epoch 49/1000
Training Loss: 0.77090195, Training R2: 0.439915
Validation Loss: 0.89990628, Validation R2: 0.300779

Epoch 50/1000
Training Loss: 0.78036175, Training R2: 0.432866
Validation Loss: 0.92439395, Validation R2: 0.262013

Epoch 51/1000
Training Loss: 0.76190880, Training R2: 0.450823
Validation Loss: 0.84521264, Validation R2: 0.362584
Saved best model with validation R2 0.362584 to finetune_dipole1000.pth

Epoch 52/1000
Training Loss: 0.73775031, Training R2: 0.458845
Validation Loss: 0.87442052, Validation R2: 0.319406

Epoch 53/1000
Training Loss: 0.73264143, Training R2: 0.463260
Validation Loss: 0.83288223, Validation R2: 0.346377

Epoch 54/1000
Training Loss: 0.71016733, Training R2: 0.487021
Validation Loss: 0.90331817, Validation R2: 0.274513

Epoch 55/1000
Training Loss: 0.72993973, Training R2: 0.468873
Validation Loss: 0.93110335, Validation R2: 0.271735

Epoch 56/1000
Training Loss: 0.77585118, Training R2: 0.444615
Validation Loss: 0.90326679, Validation R2: 0.280191

Epoch 57/1000
Training Loss: 0.75481759, Training R2: 0.459260
Validation Loss: 0.87363857, Validation R2: 0.369399
Saved best model with validation R2 0.369399 to finetune_dipole1000.pth

Epoch 58/1000
Training Loss: 0.77606383, Training R2: 0.426422
Validation Loss: 0.83893406, Validation R2: 0.388313
Saved best model with validation R2 0.388313 to finetune_dipole1000.pth

Epoch 59/1000
Training Loss: 0.72588993, Training R2: 0.494344
Validation Loss: 0.83237362, Validation R2: 0.359523

Epoch 60/1000
Training Loss: 0.72530735, Training R2: 0.489014
Validation Loss: 0.83547896, Validation R2: 0.354144

Epoch 61/1000
Training Loss: 0.72098624, Training R2: 0.466884
Validation Loss: 0.90704268, Validation R2: 0.287701

Epoch 62/1000
Training Loss: 0.78498166, Training R2: 0.395959
Validation Loss: 0.87109405, Validation R2: 0.339044

Epoch 63/1000
Training Loss: 0.73670466, Training R2: 0.453124
Validation Loss: 0.86302572, Validation R2: 0.333980

Epoch 64/1000
Training Loss: 0.72027283, Training R2: 0.468637
Validation Loss: 0.83274639, Validation R2: 0.367279

Epoch 65/1000
Training Loss: 0.69990989, Training R2: 0.489516
Validation Loss: 0.82675910, Validation R2: 0.362565

Epoch 66/1000
Training Loss: 0.67876050, Training R2: 0.500554
Validation Loss: 0.82439357, Validation R2: 0.370123

Epoch 67/1000
Training Loss: 0.67018872, Training R2: 0.517873
Validation Loss: 0.82725203, Validation R2: 0.370503

Epoch 68/1000
Training Loss: 0.67403678, Training R2: 0.518030
Validation Loss: 0.83086187, Validation R2: 0.355111

Epoch 69/1000
Training Loss: 0.67572904, Training R2: 0.521828
Validation Loss: 0.83808297, Validation R2: 0.348793

Epoch 70/1000
Training Loss: 0.68665489, Training R2: 0.494661
Validation Loss: 0.85856843, Validation R2: 0.315626

Epoch 71/1000
Training Loss: 0.68971432, Training R2: 0.498571
Validation Loss: 0.82882935, Validation R2: 0.350400

Epoch 72/1000
Training Loss: 0.69949474, Training R2: 0.505016
Validation Loss: 0.85403866, Validation R2: 0.331365

Epoch 73/1000
Training Loss: 0.72719416, Training R2: 0.480948
Validation Loss: 0.86298996, Validation R2: 0.324774

Epoch 74/1000
Training Loss: 0.71849259, Training R2: 0.492227
Validation Loss: 0.85481453, Validation R2: 0.359894

Epoch 75/1000
Training Loss: 0.71271653, Training R2: 0.500572
Validation Loss: 0.84449452, Validation R2: 0.351985

Epoch 76/1000
Training Loss: 0.71432253, Training R2: 0.509749
Validation Loss: 0.82751435, Validation R2: 0.380219

Epoch 77/1000
Training Loss: 0.71299370, Training R2: 0.496221
Validation Loss: 0.88143879, Validation R2: 0.289667

Epoch 78/1000
Training Loss: 0.72105598, Training R2: 0.475810
Validation Loss: 0.84129447, Validation R2: 0.334267

Epoch 79/1000
Epoch 00079: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.67635284, Training R2: 0.519963
Validation Loss: 0.83624882, Validation R2: 0.345891

Epoch 80/1000
学习率已减少 1 次
Training Loss: 0.67287101, Training R2: 0.527676
Validation Loss: 0.82235318, Validation R2: 0.367864

Epoch 81/1000
Training Loss: 0.67594570, Training R2: 0.527773
Validation Loss: 0.82071018, Validation R2: 0.362212

Epoch 82/1000
Training Loss: 0.66237956, Training R2: 0.537373
Validation Loss: 0.84089649, Validation R2: 0.326305

Epoch 83/1000
Training Loss: 0.67647378, Training R2: 0.521955
Validation Loss: 0.82638288, Validation R2: 0.335703

Epoch 84/1000
Training Loss: 0.66209387, Training R2: 0.536330
Validation Loss: 0.82944626, Validation R2: 0.347807

Epoch 85/1000
Training Loss: 0.65844976, Training R2: 0.542053
Validation Loss: 0.81104863, Validation R2: 0.375416

Epoch 86/1000
Training Loss: 0.65687227, Training R2: 0.538224
Validation Loss: 0.80422282, Validation R2: 0.387436

Epoch 87/1000
Training Loss: 0.64333682, Training R2: 0.553544
Validation Loss: 0.83118588, Validation R2: 0.362889

Epoch 88/1000
Training Loss: 0.65721848, Training R2: 0.542971
Validation Loss: 0.82050627, Validation R2: 0.381691

Epoch 89/1000
Training Loss: 0.65219461, Training R2: 0.538168
Validation Loss: 0.82235181, Validation R2: 0.368139

Epoch 90/1000
Training Loss: 0.65446392, Training R2: 0.548485
Validation Loss: 0.82988876, Validation R2: 0.361955

Epoch 91/1000
Training Loss: 0.65377811, Training R2: 0.547442
Validation Loss: 0.82733738, Validation R2: 0.359779

Epoch 92/1000
Training Loss: 0.64395170, Training R2: 0.549056
Validation Loss: 0.82631469, Validation R2: 0.351438

Epoch 93/1000
Training Loss: 0.64055660, Training R2: 0.558673
Validation Loss: 0.80740851, Validation R2: 0.365795

Epoch 94/1000
Training Loss: 0.63827304, Training R2: 0.551924
Validation Loss: 0.84349424, Validation R2: 0.336648

Epoch 95/1000
Training Loss: 0.68887315, Training R2: 0.520427
Validation Loss: 0.82882279, Validation R2: 0.371993

Epoch 96/1000
Training Loss: 0.66974476, Training R2: 0.540053
Validation Loss: 0.81437230, Validation R2: 0.370549

Epoch 97/1000
Training Loss: 0.66163293, Training R2: 0.550517
Validation Loss: 0.82081282, Validation R2: 0.366843

Epoch 98/1000
Training Loss: 0.63884504, Training R2: 0.560480
Validation Loss: 0.84261537, Validation R2: 0.356611

Epoch 99/1000
Training Loss: 0.66296084, Training R2: 0.547790
Validation Loss: 0.80269593, Validation R2: 0.377595

Epoch 100/1000
Epoch 00100: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.63846114, Training R2: 0.567073
Validation Loss: 0.78840405, Validation R2: 0.382708

Epoch 101/1000
学习率已减少 2 次
Training Loss: 0.63790040, Training R2: 0.557900
Validation Loss: 0.79313183, Validation R2: 0.382785

Epoch 102/1000
Training Loss: 0.62607875, Training R2: 0.566780
Validation Loss: 0.79530251, Validation R2: 0.388199

Epoch 103/1000
Training Loss: 0.61986403, Training R2: 0.575910
Validation Loss: 0.79972655, Validation R2: 0.383601

Epoch 104/1000
Training Loss: 0.62034479, Training R2: 0.574090
Validation Loss: 0.79741257, Validation R2: 0.381087

Epoch 105/1000
Training Loss: 0.61727645, Training R2: 0.575194
Validation Loss: 0.79846722, Validation R2: 0.381062

Epoch 106/1000
Training Loss: 0.61381927, Training R2: 0.576506
Validation Loss: 0.79990721, Validation R2: 0.384856

Epoch 107/1000
Training Loss: 0.61414237, Training R2: 0.576696
Validation Loss: 0.80137938, Validation R2: 0.382710

Epoch 108/1000
Training Loss: 0.61141607, Training R2: 0.579470
Validation Loss: 0.80543739, Validation R2: 0.375602

Epoch 109/1000
Training Loss: 0.61046159, Training R2: 0.580095
Validation Loss: 0.80745697, Validation R2: 0.373384

Epoch 110/1000
Training Loss: 0.61100032, Training R2: 0.580462
Validation Loss: 0.80673695, Validation R2: 0.374830

Epoch 111/1000
Training Loss: 0.61369400, Training R2: 0.576941
Validation Loss: 0.80271679, Validation R2: 0.381549

Epoch 112/1000
Training Loss: 0.61395602, Training R2: 0.580406
Validation Loss: 0.79635125, Validation R2: 0.387647

Epoch 113/1000
Training Loss: 0.61054245, Training R2: 0.584273
Validation Loss: 0.79672146, Validation R2: 0.382968

Epoch 114/1000
Training Loss: 0.61495167, Training R2: 0.577335
Validation Loss: 0.79312623, Validation R2: 0.387583

Epoch 115/1000
Training Loss: 0.60422863, Training R2: 0.584491
Validation Loss: 0.80123508, Validation R2: 0.385224

Epoch 116/1000
Training Loss: 0.60587841, Training R2: 0.582546
Validation Loss: 0.80609524, Validation R2: 0.383797

Epoch 117/1000
Training Loss: 0.60932574, Training R2: 0.579172
Validation Loss: 0.80187309, Validation R2: 0.383038

Epoch 118/1000
Training Loss: 0.60267488, Training R2: 0.584480
Validation Loss: 0.79780847, Validation R2: 0.382879

Epoch 119/1000
Training Loss: 0.60106147, Training R2: 0.589255
Validation Loss: 0.79078078, Validation R2: 0.387747

Epoch 120/1000
Training Loss: 0.60225915, Training R2: 0.587849
Validation Loss: 0.78865439, Validation R2: 0.395973
Saved best model with validation R2 0.395973 to finetune_dipole1000.pth

Epoch 121/1000
Training Loss: 0.60109791, Training R2: 0.589240
Validation Loss: 0.78703505, Validation R2: 0.394561

Epoch 122/1000
Training Loss: 0.60033973, Training R2: 0.591148
Validation Loss: 0.79532683, Validation R2: 0.372963

Epoch 123/1000
Training Loss: 0.60985199, Training R2: 0.579181
Validation Loss: 0.79719055, Validation R2: 0.369395

Epoch 124/1000
Training Loss: 0.60844827, Training R2: 0.582722
Validation Loss: 0.79521483, Validation R2: 0.384660

Epoch 125/1000
Training Loss: 0.59744055, Training R2: 0.591773
Validation Loss: 0.78743237, Validation R2: 0.381539

Epoch 126/1000
Training Loss: 0.60836862, Training R2: 0.587684
Validation Loss: 0.78814876, Validation R2: 0.396983
Saved best model with validation R2 0.396983 to finetune_dipole1000.pth

Epoch 127/1000
Training Loss: 0.60713056, Training R2: 0.592428
Validation Loss: 0.79730541, Validation R2: 0.396128

Epoch 128/1000
Training Loss: 0.59870321, Training R2: 0.595696
Validation Loss: 0.79690152, Validation R2: 0.377753

Epoch 129/1000
Training Loss: 0.59498317, Training R2: 0.594921
Validation Loss: 0.80057281, Validation R2: 0.374562

Epoch 130/1000
Training Loss: 0.59832523, Training R2: 0.595653
Validation Loss: 0.80186337, Validation R2: 0.373173

Epoch 131/1000
Training Loss: 0.59258578, Training R2: 0.596391
Validation Loss: 0.80734146, Validation R2: 0.366822

Epoch 132/1000
Training Loss: 0.59532073, Training R2: 0.595495
Validation Loss: 0.80412877, Validation R2: 0.367684

Epoch 133/1000
Training Loss: 0.59296788, Training R2: 0.597066
Validation Loss: 0.79533112, Validation R2: 0.369190

Epoch 134/1000
Training Loss: 0.59618155, Training R2: 0.593319
Validation Loss: 0.78350264, Validation R2: 0.387674

Epoch 135/1000
Training Loss: 0.59563677, Training R2: 0.593780
Validation Loss: 0.77937841, Validation R2: 0.400952
Saved best model with validation R2 0.400952 to finetune_dipole1000.pth

Epoch 136/1000
Training Loss: 0.59623140, Training R2: 0.593546
Validation Loss: 0.78548461, Validation R2: 0.401124
Saved best model with validation R2 0.401124 to finetune_dipole1000.pth

Epoch 137/1000
Training Loss: 0.59639704, Training R2: 0.596184
Validation Loss: 0.78814238, Validation R2: 0.398654

Epoch 138/1000
Training Loss: 0.59043384, Training R2: 0.598352
Validation Loss: 0.80013627, Validation R2: 0.378273

Epoch 139/1000
Training Loss: 0.59101865, Training R2: 0.596147
Validation Loss: 0.80126494, Validation R2: 0.371297

Epoch 140/1000
Training Loss: 0.59388204, Training R2: 0.594418
Validation Loss: 0.79622662, Validation R2: 0.375654

Epoch 141/1000
Training Loss: 0.58797388, Training R2: 0.598212
Validation Loss: 0.79430312, Validation R2: 0.389171

Epoch 142/1000
Training Loss: 0.58614679, Training R2: 0.600593
Validation Loss: 0.77905655, Validation R2: 0.394497

Epoch 143/1000
Training Loss: 0.58598238, Training R2: 0.601051
Validation Loss: 0.78039712, Validation R2: 0.388693

Epoch 144/1000
Training Loss: 0.59088694, Training R2: 0.596112
Validation Loss: 0.78360540, Validation R2: 0.395757

Epoch 145/1000
Training Loss: 0.58583365, Training R2: 0.603557
Validation Loss: 0.78179413, Validation R2: 0.394752

Epoch 146/1000
Training Loss: 0.58539392, Training R2: 0.604422
Validation Loss: 0.78358382, Validation R2: 0.394388

Epoch 147/1000
Training Loss: 0.59382698, Training R2: 0.595654
Validation Loss: 0.77980131, Validation R2: 0.400092

Epoch 148/1000
Training Loss: 0.58632880, Training R2: 0.602886
Validation Loss: 0.78167593, Validation R2: 0.398980

Epoch 149/1000
Training Loss: 0.58867105, Training R2: 0.602277
Validation Loss: 0.77880454, Validation R2: 0.397022

Epoch 150/1000
Training Loss: 0.59784066, Training R2: 0.593924
Validation Loss: 0.76788884, Validation R2: 0.409094
Saved best model with validation R2 0.409094 to finetune_dipole1000.pth

Epoch 151/1000
Training Loss: 0.58481008, Training R2: 0.606695
Validation Loss: 0.76978636, Validation R2: 0.403805

Epoch 152/1000
Training Loss: 0.58941155, Training R2: 0.603035
Validation Loss: 0.77258748, Validation R2: 0.396125

Epoch 153/1000
Training Loss: 0.58951858, Training R2: 0.604459
Validation Loss: 0.76529962, Validation R2: 0.414164
Saved best model with validation R2 0.414164 to finetune_dipole1000.pth

Epoch 154/1000
Training Loss: 0.58632447, Training R2: 0.605695
Validation Loss: 0.76713014, Validation R2: 0.409067

Epoch 155/1000
Training Loss: 0.58464912, Training R2: 0.606571
Validation Loss: 0.76300329, Validation R2: 0.424886
Saved best model with validation R2 0.424886 to finetune_dipole1000.pth

Epoch 156/1000
Training Loss: 0.57736701, Training R2: 0.611220
Validation Loss: 0.77022594, Validation R2: 0.415298

Epoch 157/1000
Training Loss: 0.57738831, Training R2: 0.607732
Validation Loss: 0.77461028, Validation R2: 0.403653

Epoch 158/1000
Training Loss: 0.57616872, Training R2: 0.607530
Validation Loss: 0.77739042, Validation R2: 0.394709

Epoch 159/1000
Training Loss: 0.57975631, Training R2: 0.607123
Validation Loss: 0.77507406, Validation R2: 0.397845

Epoch 160/1000
Training Loss: 0.57300230, Training R2: 0.611139
Validation Loss: 0.77699202, Validation R2: 0.399090

Epoch 161/1000
Training Loss: 0.57210611, Training R2: 0.610980
Validation Loss: 0.77656144, Validation R2: 0.403155

Epoch 162/1000
Training Loss: 0.57180188, Training R2: 0.611730
Validation Loss: 0.77719432, Validation R2: 0.399218

Epoch 163/1000
Training Loss: 0.57155954, Training R2: 0.612930
Validation Loss: 0.77952969, Validation R2: 0.396536

Epoch 164/1000
Training Loss: 0.56989151, Training R2: 0.615256
Validation Loss: 0.77249062, Validation R2: 0.394390

Epoch 165/1000
Training Loss: 0.56815540, Training R2: 0.617199
Validation Loss: 0.77260482, Validation R2: 0.396650

Epoch 166/1000
Training Loss: 0.56883782, Training R2: 0.617888
Validation Loss: 0.77343965, Validation R2: 0.390720

Epoch 167/1000
Training Loss: 0.57091486, Training R2: 0.613520
Validation Loss: 0.77113706, Validation R2: 0.396307

Epoch 168/1000
Training Loss: 0.56865595, Training R2: 0.616813
Validation Loss: 0.77297032, Validation R2: 0.396634

Epoch 169/1000
Training Loss: 0.56751082, Training R2: 0.617277
Validation Loss: 0.77241790, Validation R2: 0.385920

Epoch 170/1000
Training Loss: 0.56669721, Training R2: 0.616642
Validation Loss: 0.77357352, Validation R2: 0.396334

Epoch 171/1000
Training Loss: 0.56648453, Training R2: 0.616661
Validation Loss: 0.77869475, Validation R2: 0.403681

Epoch 172/1000
Training Loss: 0.58716257, Training R2: 0.607092
Validation Loss: 0.77086419, Validation R2: 0.404843

Epoch 173/1000
Training Loss: 0.57181598, Training R2: 0.614453
Validation Loss: 0.76917493, Validation R2: 0.404708

Epoch 174/1000
Training Loss: 0.57670230, Training R2: 0.614582
Validation Loss: 0.77852368, Validation R2: 0.401586

Epoch 175/1000
Training Loss: 0.57029187, Training R2: 0.617234
Validation Loss: 0.77417266, Validation R2: 0.392341

Epoch 176/1000
Epoch 00176: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.56753808, Training R2: 0.621122
Validation Loss: 0.77088940, Validation R2: 0.403175

Epoch 177/1000
学习率已减少 3 次
Training Loss: 0.56861732, Training R2: 0.617646
Validation Loss: 0.75823003, Validation R2: 0.408567

Epoch 178/1000
Training Loss: 0.56184972, Training R2: 0.618887
Validation Loss: 0.75973141, Validation R2: 0.409334

Epoch 179/1000
Training Loss: 0.55994112, Training R2: 0.621500
Validation Loss: 0.76042151, Validation R2: 0.416552

Epoch 180/1000
Training Loss: 0.56201942, Training R2: 0.621611
Validation Loss: 0.75782377, Validation R2: 0.416471

Epoch 181/1000
Training Loss: 0.55896513, Training R2: 0.620525
Validation Loss: 0.75969642, Validation R2: 0.412127

Epoch 182/1000
Training Loss: 0.55717690, Training R2: 0.622159
Validation Loss: 0.76378959, Validation R2: 0.412788

Epoch 183/1000
Training Loss: 0.56651656, Training R2: 0.619429
Validation Loss: 0.76483107, Validation R2: 0.409464

Epoch 184/1000
Training Loss: 0.55877698, Training R2: 0.620025
Validation Loss: 0.76702780, Validation R2: 0.398758

Epoch 185/1000
Training Loss: 0.56168827, Training R2: 0.620484
Validation Loss: 0.76929027, Validation R2: 0.401107

Epoch 186/1000
Training Loss: 0.55437907, Training R2: 0.625333
Validation Loss: 0.76762038, Validation R2: 0.401557

Epoch 187/1000
Training Loss: 0.55529490, Training R2: 0.624884
Validation Loss: 0.76510763, Validation R2: 0.402915

Epoch 188/1000
Training Loss: 0.55517865, Training R2: 0.625434
Validation Loss: 0.76724488, Validation R2: 0.404501

Epoch 189/1000
Training Loss: 0.55485694, Training R2: 0.626887
Validation Loss: 0.76870376, Validation R2: 0.402156

Epoch 190/1000
Training Loss: 0.55683589, Training R2: 0.624099
Validation Loss: 0.76592481, Validation R2: 0.404991

Epoch 191/1000
Training Loss: 0.55485990, Training R2: 0.626432
Validation Loss: 0.76082373, Validation R2: 0.408855

Epoch 192/1000
Training Loss: 0.55599148, Training R2: 0.627251
Validation Loss: 0.75604117, Validation R2: 0.406589

Epoch 193/1000
Training Loss: 0.55359095, Training R2: 0.626406
Validation Loss: 0.76016343, Validation R2: 0.407820

Epoch 194/1000
Training Loss: 0.55199664, Training R2: 0.628937
Validation Loss: 0.76319456, Validation R2: 0.401190

Epoch 195/1000
Training Loss: 0.55473315, Training R2: 0.627010
Validation Loss: 0.76848632, Validation R2: 0.396615

Epoch 196/1000
Training Loss: 0.55359739, Training R2: 0.625911
Validation Loss: 0.77033573, Validation R2: 0.394637

Epoch 197/1000
Epoch 00197: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.55350148, Training R2: 0.626769
Validation Loss: 0.76661175, Validation R2: 0.394076

Epoch 198/1000
学习率已减少 4 次
Training Loss: 0.55294892, Training R2: 0.627620
Validation Loss: 0.76427764, Validation R2: 0.396844

Epoch 199/1000
Training Loss: 0.55045373, Training R2: 0.628750
Validation Loss: 0.76309645, Validation R2: 0.400632

Epoch 200/1000
Training Loss: 0.55062758, Training R2: 0.627855
Validation Loss: 0.76122421, Validation R2: 0.402667

Epoch 201/1000
Training Loss: 0.55256505, Training R2: 0.625102
Validation Loss: 0.76117635, Validation R2: 0.405466

Epoch 202/1000
Training Loss: 0.55091094, Training R2: 0.626298
Validation Loss: 0.76172704, Validation R2: 0.413166

Epoch 203/1000
Training Loss: 0.55131090, Training R2: 0.628036
Validation Loss: 0.75853837, Validation R2: 0.416006

Epoch 204/1000
Training Loss: 0.55264716, Training R2: 0.628590
Validation Loss: 0.75752908, Validation R2: 0.413319

Epoch 205/1000
Training Loss: 0.55305442, Training R2: 0.629429
Validation Loss: 0.75712699, Validation R2: 0.415756

Epoch 206/1000
Training Loss: 0.55160418, Training R2: 0.630216
Validation Loss: 0.75705171, Validation R2: 0.410622

Epoch 207/1000
Training Loss: 0.54880648, Training R2: 0.630616
Validation Loss: 0.75922483, Validation R2: 0.406978

Epoch 208/1000
Training Loss: 0.54910791, Training R2: 0.630701
Validation Loss: 0.76344359, Validation R2: 0.409066

Epoch 209/1000
Training Loss: 0.55014599, Training R2: 0.631780
Validation Loss: 0.76197320, Validation R2: 0.409218

Epoch 210/1000
Training Loss: 0.54803729, Training R2: 0.631801
Validation Loss: 0.75931478, Validation R2: 0.408873

Epoch 211/1000
Training Loss: 0.54654793, Training R2: 0.631451
Validation Loss: 0.75976706, Validation R2: 0.411247

Epoch 212/1000
Training Loss: 0.54836926, Training R2: 0.630332
Validation Loss: 0.75817639, Validation R2: 0.414000

Epoch 213/1000
Training Loss: 0.55000191, Training R2: 0.628994
Validation Loss: 0.75695693, Validation R2: 0.413604

Epoch 214/1000
Training Loss: 0.54723245, Training R2: 0.630093
Validation Loss: 0.75800580, Validation R2: 0.415263

Epoch 215/1000
Training Loss: 0.54911440, Training R2: 0.631032
Validation Loss: 0.75669223, Validation R2: 0.413317

Epoch 216/1000
Training Loss: 0.54608753, Training R2: 0.631039
Validation Loss: 0.75707000, Validation R2: 0.408674

Epoch 217/1000
Training Loss: 0.54778592, Training R2: 0.630547
Validation Loss: 0.75848770, Validation R2: 0.410856

Epoch 218/1000
Epoch 00218: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.54520179, Training R2: 0.632186
Validation Loss: 0.76010358, Validation R2: 0.408029

Epoch 219/1000
学习率已减少 5 次
Training Loss: 0.54550841, Training R2: 0.632160
Validation Loss: 0.76007110, Validation R2: 0.405046

Epoch 220/1000
Training Loss: 0.54508502, Training R2: 0.632449
Validation Loss: 0.76103234, Validation R2: 0.405001

Epoch 221/1000
Training Loss: 0.54496845, Training R2: 0.632499
Validation Loss: 0.76290250, Validation R2: 0.404150

Epoch 222/1000
Training Loss: 0.54449038, Training R2: 0.632856
Validation Loss: 0.76272941, Validation R2: 0.403056

Epoch 223/1000
Training Loss: 0.54430302, Training R2: 0.632638
Validation Loss: 0.76148820, Validation R2: 0.403115

Epoch 224/1000
Training Loss: 0.54400068, Training R2: 0.632780
Validation Loss: 0.76056564, Validation R2: 0.404149

Epoch 225/1000
Training Loss: 0.54421999, Training R2: 0.632558
Validation Loss: 0.75995237, Validation R2: 0.405235

Epoch 226/1000
Training Loss: 0.54440803, Training R2: 0.632551
Validation Loss: 0.76019394, Validation R2: 0.406396

Epoch 227/1000
Training Loss: 0.54410872, Training R2: 0.632283
Validation Loss: 0.76048398, Validation R2: 0.407211

Epoch 228/1000
Training Loss: 0.54440434, Training R2: 0.632154
Validation Loss: 0.76059556, Validation R2: 0.407629

Epoch 229/1000
Training Loss: 0.54441581, Training R2: 0.632119
Validation Loss: 0.75995284, Validation R2: 0.407410

Epoch 230/1000
Training Loss: 0.54358936, Training R2: 0.632850
Validation Loss: 0.76046765, Validation R2: 0.407615

Epoch 231/1000
Training Loss: 0.54384633, Training R2: 0.633270
Validation Loss: 0.76111168, Validation R2: 0.407253

Epoch 232/1000
Training Loss: 0.54412879, Training R2: 0.632954
Validation Loss: 0.76146454, Validation R2: 0.406921

Epoch 233/1000
Training Loss: 0.54333117, Training R2: 0.633413
Validation Loss: 0.76110864, Validation R2: 0.403875

Epoch 234/1000
Training Loss: 0.54384944, Training R2: 0.632765
Validation Loss: 0.76166314, Validation R2: 0.404379

Epoch 235/1000
Training Loss: 0.54324565, Training R2: 0.633680
Validation Loss: 0.76139283, Validation R2: 0.405140

Epoch 236/1000
Training Loss: 0.54371915, Training R2: 0.633920
Validation Loss: 0.76115227, Validation R2: 0.406002

Epoch 237/1000
Training Loss: 0.54318851, Training R2: 0.634329
Validation Loss: 0.76064008, Validation R2: 0.406430

Epoch 238/1000
Training Loss: 0.54282721, Training R2: 0.634475
Validation Loss: 0.76008302, Validation R2: 0.406853

Epoch 239/1000
Epoch 00239: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.54239922, Training R2: 0.634686
Validation Loss: 0.75830013, Validation R2: 0.406611

Epoch 240/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
