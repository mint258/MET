Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)
冻结层 9: lins.2 (Linear)
冻结层 10: encoder (Sequential)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Frozen
lins.2.bias: Frozen
encoder.0.weight: Frozen
encoder.0.bias: Frozen
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 993539

Epoch 1/1000
Training Loss: 1.27848110, Training R2: -0.262365
Validation Loss: 1.14612973, Validation R2: -0.013311
Saved best model with validation R2 -0.013311 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.16667336, Training R2: -0.143576
Validation Loss: 1.14901125, Validation R2: -0.076561

Epoch 3/1000
Training Loss: 1.11704683, Training R2: -0.003257
Validation Loss: 1.12109721, Validation R2: 0.022808
Saved best model with validation R2 0.022808 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.08544690, Training R2: 0.014786
Validation Loss: 1.10207641, Validation R2: 0.043814
Saved best model with validation R2 0.043814 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.07271891, Training R2: 0.085251
Validation Loss: 1.08483744, Validation R2: 0.024342

Epoch 6/1000
Training Loss: 1.04471143, Training R2: 0.062026
Validation Loss: 1.06774843, Validation R2: 0.135773
Saved best model with validation R2 0.135773 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 1.05904536, Training R2: 0.130487
Validation Loss: 1.14056611, Validation R2: -0.088720

Epoch 8/1000
Training Loss: 1.06934357, Training R2: 0.032746
Validation Loss: 1.05276287, Validation R2: 0.118838

Epoch 9/1000
Training Loss: 1.00856304, Training R2: 0.135537
Validation Loss: 1.05683959, Validation R2: 0.080972

Epoch 10/1000
Training Loss: 1.00233814, Training R2: 0.147988
Validation Loss: 1.03971124, Validation R2: 0.132269

Epoch 11/1000
Training Loss: 1.00350881, Training R2: 0.158054
Validation Loss: 1.03721499, Validation R2: 0.122523

Epoch 12/1000
Training Loss: 1.00193903, Training R2: 0.177106
Validation Loss: 1.07423651, Validation R2: 0.019569

Epoch 13/1000
Training Loss: 1.02557674, Training R2: 0.088933
Validation Loss: 1.10670328, Validation R2: 0.096045

Epoch 14/1000
Training Loss: 1.07519981, Training R2: 0.124786
Validation Loss: 1.07062197, Validation R2: 0.055646

Epoch 15/1000
Training Loss: 1.02066947, Training R2: 0.100629
Validation Loss: 1.04921472, Validation R2: 0.140966
Saved best model with validation R2 0.140966 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 1.02717203, Training R2: 0.168989
Validation Loss: 1.04501283, Validation R2: 0.144227
Saved best model with validation R2 0.144227 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.98933512, Training R2: 0.186571
Validation Loss: 1.06222808, Validation R2: 0.030987

Epoch 18/1000
Training Loss: 0.98602113, Training R2: 0.137952
Validation Loss: 1.03730667, Validation R2: 0.145773
Saved best model with validation R2 0.145773 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.99517243, Training R2: 0.197497
Validation Loss: 1.03245783, Validation R2: 0.118240

Epoch 20/1000
Training Loss: 0.96840445, Training R2: 0.198212
Validation Loss: 1.04499519, Validation R2: 0.088595

Epoch 21/1000
Training Loss: 0.96926510, Training R2: 0.171772
Validation Loss: 1.04169059, Validation R2: 0.101427

Epoch 22/1000
Training Loss: 0.96283236, Training R2: 0.184568
Validation Loss: 1.08921158, Validation R2: 0.103676

Epoch 23/1000
Training Loss: 1.06308698, Training R2: 0.126029
Validation Loss: 1.17367625, Validation R2: -0.162274

Epoch 24/1000
Training Loss: 1.05337894, Training R2: 0.026169
Validation Loss: 1.11719072, Validation R2: 0.079174

Epoch 25/1000
Training Loss: 1.05196603, Training R2: 0.150447
Validation Loss: 1.16211879, Validation R2: -0.147859

Epoch 26/1000
Training Loss: 1.21368392, Training R2: -0.248832
Validation Loss: 1.08061099, Validation R2: 0.033804

Epoch 27/1000
Training Loss: 1.03802019, Training R2: 0.133764
Validation Loss: 1.12718081, Validation R2: 0.079574

Epoch 28/1000
Training Loss: 1.07030478, Training R2: 0.122832
Validation Loss: 1.07947540, Validation R2: 0.033235

Epoch 29/1000
Training Loss: 1.02724699, Training R2: 0.059694
Validation Loss: 1.04857361, Validation R2: 0.125310

Epoch 30/1000
Training Loss: 0.99585114, Training R2: 0.192498
Validation Loss: 1.06845331, Validation R2: 0.136842

Epoch 31/1000
Training Loss: 1.01808775, Training R2: 0.177054
Validation Loss: 1.11925232, Validation R2: -0.023417

Epoch 32/1000
Training Loss: 1.07469467, Training R2: 0.039196
Validation Loss: 1.03861833, Validation R2: 0.156278
Saved best model with validation R2 0.156278 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 1.01437586, Training R2: 0.181857
Validation Loss: 1.04042804, Validation R2: 0.136543

Epoch 34/1000
Training Loss: 0.99271630, Training R2: 0.133021
Validation Loss: 1.06527817, Validation R2: 0.034481

Epoch 35/1000
Training Loss: 0.97629272, Training R2: 0.151808
Validation Loss: 1.03917718, Validation R2: 0.155098

Epoch 36/1000
Training Loss: 0.97128093, Training R2: 0.211029
Validation Loss: 1.06514597, Validation R2: 0.039911

Epoch 37/1000
Training Loss: 1.00549224, Training R2: 0.104686
Validation Loss: 1.03762245, Validation R2: 0.125387

Epoch 38/1000
Training Loss: 0.97502850, Training R2: 0.207492
Validation Loss: 1.03856683, Validation R2: 0.099401

Epoch 39/1000
Training Loss: 0.98052973, Training R2: 0.128897
Validation Loss: 1.03451693, Validation R2: 0.113909

Epoch 40/1000
Training Loss: 0.98683572, Training R2: 0.191688
Validation Loss: 1.03647113, Validation R2: 0.131542

Epoch 41/1000
Training Loss: 0.97745280, Training R2: 0.154868
Validation Loss: 1.04826629, Validation R2: 0.084682

Epoch 42/1000
Training Loss: 0.95948452, Training R2: 0.211786
Validation Loss: 1.04802883, Validation R2: 0.139895

Epoch 43/1000
Training Loss: 0.96967684, Training R2: 0.210496
Validation Loss: 1.07448900, Validation R2: 0.021566

Epoch 44/1000
Training Loss: 0.99148654, Training R2: 0.134025
Validation Loss: 1.04003358, Validation R2: 0.138787

Epoch 45/1000
Training Loss: 0.97403923, Training R2: 0.208385
Validation Loss: 1.04337680, Validation R2: 0.122295

Epoch 46/1000
Training Loss: 0.96715966, Training R2: 0.181606
Validation Loss: 1.04434919, Validation R2: 0.079871

Epoch 47/1000
Training Loss: 0.94721999, Training R2: 0.203552
Validation Loss: 1.03103721, Validation R2: 0.122162

Epoch 48/1000
Training Loss: 0.94418421, Training R2: 0.220892
Validation Loss: 1.06582582, Validation R2: 0.031204

Epoch 49/1000
Training Loss: 0.95791151, Training R2: 0.185860
Validation Loss: 1.03701425, Validation R2: 0.114503

Epoch 50/1000
Training Loss: 0.94085640, Training R2: 0.228662
Validation Loss: 1.03375232, Validation R2: 0.097318

Epoch 51/1000
Training Loss: 0.93668516, Training R2: 0.223237
Validation Loss: 1.02797890, Validation R2: 0.118111

Epoch 52/1000
Training Loss: 0.93813995, Training R2: 0.222747
Validation Loss: 1.04828644, Validation R2: 0.054293

Epoch 53/1000
Epoch 00053: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.97505122, Training R2: 0.143654
Validation Loss: 1.03111756, Validation R2: 0.131430

Epoch 54/1000
学习率已减少 1 次
Training Loss: 0.93827603, Training R2: 0.232913
Validation Loss: 1.03476894, Validation R2: 0.098934

Epoch 55/1000
Training Loss: 0.94149223, Training R2: 0.197428
Validation Loss: 1.03008735, Validation R2: 0.122869

Epoch 56/1000
Training Loss: 0.96350932, Training R2: 0.221719
Validation Loss: 1.04538751, Validation R2: 0.127122

Epoch 57/1000
Training Loss: 0.93424657, Training R2: 0.234608
Validation Loss: 1.05380988, Validation R2: 0.045102

Epoch 58/1000
Training Loss: 0.94499469, Training R2: 0.186362
Validation Loss: 1.03773296, Validation R2: 0.117857

Epoch 59/1000
Training Loss: 0.95768996, Training R2: 0.234647
Validation Loss: 1.03695643, Validation R2: 0.115081

Epoch 60/1000
Training Loss: 0.93747486, Training R2: 0.206667
Validation Loss: 1.04865384, Validation R2: 0.054105

Epoch 61/1000
Training Loss: 0.92940604, Training R2: 0.219878
Validation Loss: 1.05531716, Validation R2: 0.115441

Epoch 62/1000
Training Loss: 0.94480211, Training R2: 0.240505
Validation Loss: 1.03643799, Validation R2: 0.096747

Epoch 63/1000
Training Loss: 0.92788754, Training R2: 0.225696
Validation Loss: 1.03850174, Validation R2: 0.087198

Epoch 64/1000
Training Loss: 0.92328506, Training R2: 0.234552
Validation Loss: 1.03507817, Validation R2: 0.100272

Epoch 65/1000
Training Loss: 0.92114130, Training R2: 0.234771
Validation Loss: 1.03909910, Validation R2: 0.094241

Epoch 66/1000
Training Loss: 0.92052725, Training R2: 0.237176
Validation Loss: 1.04063141, Validation R2: 0.101011

Epoch 67/1000
Training Loss: 0.92127888, Training R2: 0.244013
Validation Loss: 1.04148221, Validation R2: 0.092462

Epoch 68/1000
Training Loss: 0.91931256, Training R2: 0.231155
Validation Loss: 1.04441249, Validation R2: 0.071336

Epoch 69/1000
Training Loss: 0.91566740, Training R2: 0.235723
Validation Loss: 1.04241395, Validation R2: 0.101737

Epoch 70/1000
Training Loss: 0.92624989, Training R2: 0.254814
Validation Loss: 1.03661132, Validation R2: 0.089299

Epoch 71/1000
Training Loss: 0.91095068, Training R2: 0.241020
Validation Loss: 1.05578554, Validation R2: 0.041307

Epoch 72/1000
Training Loss: 0.93279884, Training R2: 0.206428
Validation Loss: 1.06511390, Validation R2: 0.070973

Epoch 73/1000
Training Loss: 0.93227833, Training R2: 0.242570
Validation Loss: 1.04553950, Validation R2: 0.089446

Epoch 74/1000
Epoch 00074: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.91956462, Training R2: 0.226896
Validation Loss: 1.04132140, Validation R2: 0.070372

Epoch 75/1000
学习率已减少 2 次
Training Loss: 0.91822806, Training R2: 0.226946
Validation Loss: 1.03551316, Validation R2: 0.100428

Epoch 76/1000
Training Loss: 0.90715338, Training R2: 0.256921
Validation Loss: 1.03910637, Validation R2: 0.094815

Epoch 77/1000
Training Loss: 0.90352324, Training R2: 0.260397
Validation Loss: 1.04639375, Validation R2: 0.073584

Epoch 78/1000
Training Loss: 0.90396208, Training R2: 0.253526
Validation Loss: 1.04563773, Validation R2: 0.072974

Epoch 79/1000
Training Loss: 0.90151332, Training R2: 0.255783
Validation Loss: 1.04076934, Validation R2: 0.087010

Epoch 80/1000
Training Loss: 0.90001161, Training R2: 0.263808
Validation Loss: 1.04786301, Validation R2: 0.094438

Epoch 81/1000
Training Loss: 0.90657795, Training R2: 0.268456
Validation Loss: 1.04190516, Validation R2: 0.089687

Epoch 82/1000
Training Loss: 0.90371114, Training R2: 0.251938
Validation Loss: 1.04469812, Validation R2: 0.073509

Epoch 83/1000
Training Loss: 0.91175284, Training R2: 0.245201
Validation Loss: 1.05958462, Validation R2: 0.061340

Epoch 84/1000
Training Loss: 0.90031245, Training R2: 0.257389
Validation Loss: 1.04540563, Validation R2: 0.055994

Epoch 85/1000
Training Loss: 0.90590484, Training R2: 0.242068
Validation Loss: 1.03954637, Validation R2: 0.085941

Epoch 86/1000
Training Loss: 0.90503406, Training R2: 0.268540
Validation Loss: 1.04109275, Validation R2: 0.087344

Epoch 87/1000
Training Loss: 0.90613829, Training R2: 0.253265
Validation Loss: 1.04710889, Validation R2: 0.058616

Epoch 88/1000
Training Loss: 0.90180182, Training R2: 0.251519
Validation Loss: 1.05696070, Validation R2: 0.073515

Epoch 89/1000
Training Loss: 0.89595510, Training R2: 0.265404
Validation Loss: 1.04952049, Validation R2: 0.057068

Epoch 90/1000
Training Loss: 0.89812248, Training R2: 0.249121
Validation Loss: 1.04676712, Validation R2: 0.066537

Epoch 91/1000
Training Loss: 0.89032259, Training R2: 0.263999
Validation Loss: 1.03784955, Validation R2: 0.077691

Epoch 92/1000
Training Loss: 0.89452264, Training R2: 0.258757
Validation Loss: 1.03542054, Validation R2: 0.084621

Epoch 93/1000
Training Loss: 0.88848441, Training R2: 0.278005
Validation Loss: 1.06103396, Validation R2: 0.068664

Epoch 94/1000
Training Loss: 0.90425340, Training R2: 0.268610
Validation Loss: 1.03414702, Validation R2: 0.078579

Epoch 95/1000
Epoch 00095: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.89667412, Training R2: 0.257992
Validation Loss: 1.03127909, Validation R2: 0.085482

Epoch 96/1000
学习率已减少 3 次
Training Loss: 0.89162216, Training R2: 0.274568
Validation Loss: 1.04331744, Validation R2: 0.087727

Epoch 97/1000
Training Loss: 0.88858253, Training R2: 0.278792
Validation Loss: 1.03698599, Validation R2: 0.085291

Epoch 98/1000
Training Loss: 0.88906766, Training R2: 0.265946
Validation Loss: 1.04031777, Validation R2: 0.078345

Epoch 99/1000
Training Loss: 0.88988912, Training R2: 0.271453
Validation Loss: 1.05698264, Validation R2: 0.076756

Epoch 100/1000
Training Loss: 0.89112450, Training R2: 0.273443
Validation Loss: 1.04443514, Validation R2: 0.079596

Epoch 101/1000
Training Loss: 0.88889714, Training R2: 0.264525
Validation Loss: 1.04272842, Validation R2: 0.073848

Epoch 102/1000
Training Loss: 0.88786159, Training R2: 0.268250
Validation Loss: 1.04922974, Validation R2: 0.071953

Epoch 103/1000
Training Loss: 0.88814525, Training R2: 0.268634
Validation Loss: 1.03811908, Validation R2: 0.075542

Epoch 104/1000
Training Loss: 0.88717963, Training R2: 0.267140
Validation Loss: 1.03272080, Validation R2: 0.088964

Epoch 105/1000
Training Loss: 0.88749761, Training R2: 0.273332
Validation Loss: 1.03176403, Validation R2: 0.091405

Epoch 106/1000
Training Loss: 0.88418964, Training R2: 0.281086
Validation Loss: 1.05399537, Validation R2: 0.075913

Epoch 107/1000
Training Loss: 0.89631708, Training R2: 0.273599
Validation Loss: 1.05666459, Validation R2: 0.063429

Epoch 108/1000
Training Loss: 0.88305935, Training R2: 0.275306
Validation Loss: 1.04954195, Validation R2: 0.048077

Epoch 109/1000
Training Loss: 0.89956580, Training R2: 0.241088
Validation Loss: 1.04658389, Validation R2: 0.062445

Epoch 110/1000
Training Loss: 0.88624311, Training R2: 0.265903
Validation Loss: 1.06342578, Validation R2: 0.066615

Epoch 111/1000
Training Loss: 0.89500672, Training R2: 0.274103
Validation Loss: 1.04711914, Validation R2: 0.078902

Epoch 112/1000
Training Loss: 0.88319617, Training R2: 0.275344
Validation Loss: 1.03862834, Validation R2: 0.073694

Epoch 113/1000
Training Loss: 0.88363654, Training R2: 0.270440
Validation Loss: 1.03816187, Validation R2: 0.079763

Epoch 114/1000
Training Loss: 0.88244600, Training R2: 0.282646
Validation Loss: 1.04694140, Validation R2: 0.075652

Epoch 115/1000
Training Loss: 0.87933295, Training R2: 0.282546
Validation Loss: 1.03954315, Validation R2: 0.075550

Epoch 116/1000
Epoch 00116: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.88018789, Training R2: 0.272865
Validation Loss: 1.04139650, Validation R2: 0.075689

Epoch 117/1000
学习率已减少 4 次
Training Loss: 0.88007624, Training R2: 0.273761
Validation Loss: 1.04321015, Validation R2: 0.079682

Epoch 118/1000
Training Loss: 0.87935539, Training R2: 0.280071
Validation Loss: 1.04556644, Validation R2: 0.085280

Epoch 119/1000
Training Loss: 0.87883985, Training R2: 0.285375
Validation Loss: 1.04276562, Validation R2: 0.087091

Epoch 120/1000
Training Loss: 0.87824485, Training R2: 0.285616
Validation Loss: 1.03976810, Validation R2: 0.086296

Epoch 121/1000
Training Loss: 0.87797430, Training R2: 0.282521
Validation Loss: 1.03790855, Validation R2: 0.079279

Epoch 122/1000
Training Loss: 0.87771840, Training R2: 0.277315
Validation Loss: 1.04048693, Validation R2: 0.071994

Epoch 123/1000
Training Loss: 0.87849678, Training R2: 0.274492
Validation Loss: 1.04288161, Validation R2: 0.068731

Epoch 124/1000
Training Loss: 0.87909239, Training R2: 0.272529
Validation Loss: 1.04076278, Validation R2: 0.069657

Epoch 125/1000
Training Loss: 0.87766796, Training R2: 0.274858
Validation Loss: 1.04282534, Validation R2: 0.070079

Epoch 126/1000
Training Loss: 0.87646898, Training R2: 0.278827
Validation Loss: 1.04566753, Validation R2: 0.071542

Epoch 127/1000
Training Loss: 0.87588207, Training R2: 0.281920
Validation Loss: 1.04305601, Validation R2: 0.076870

Epoch 128/1000
Training Loss: 0.87473214, Training R2: 0.283878
Validation Loss: 1.04002380, Validation R2: 0.080440

Epoch 129/1000
Training Loss: 0.87533838, Training R2: 0.284334
Validation Loss: 1.03992486, Validation R2: 0.081616

Epoch 130/1000
Training Loss: 0.87464160, Training R2: 0.284977
Validation Loss: 1.04379976, Validation R2: 0.075759

Epoch 131/1000
Training Loss: 0.87435384, Training R2: 0.283062
Validation Loss: 1.04374647, Validation R2: 0.071352

Epoch 132/1000
Training Loss: 0.87440252, Training R2: 0.279940
Validation Loss: 1.04326737, Validation R2: 0.069885

Epoch 133/1000
Training Loss: 0.87404409, Training R2: 0.279899
Validation Loss: 1.04643619, Validation R2: 0.072160

Epoch 134/1000
Training Loss: 0.87676971, Training R2: 0.284720
Validation Loss: 1.04996824, Validation R2: 0.072443

Epoch 135/1000
Training Loss: 0.87433360, Training R2: 0.283127
Validation Loss: 1.03931475, Validation R2: 0.074352

Epoch 136/1000
Training Loss: 0.87868049, Training R2: 0.274334
Validation Loss: 1.03861034, Validation R2: 0.076844

Epoch 137/1000
Epoch 00137: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.87666114, Training R2: 0.277292
Validation Loss: 1.04152048, Validation R2: 0.079347

Epoch 138/1000
学习率已减少 5 次
Training Loss: 0.87309377, Training R2: 0.286034
Validation Loss: 1.04540312, Validation R2: 0.077923

Epoch 139/1000
Training Loss: 0.87493347, Training R2: 0.287039
Validation Loss: 1.04746032, Validation R2: 0.076645

Epoch 140/1000
Training Loss: 0.87555181, Training R2: 0.287253
Validation Loss: 1.04351234, Validation R2: 0.079925

Epoch 141/1000
Training Loss: 0.87418662, Training R2: 0.285594
Validation Loss: 1.03752971, Validation R2: 0.081151

Epoch 142/1000
Training Loss: 0.87510986, Training R2: 0.279617
Validation Loss: 1.03732407, Validation R2: 0.080719

Epoch 143/1000
Training Loss: 0.87316248, Training R2: 0.282086
Validation Loss: 1.03936493, Validation R2: 0.082442

Epoch 144/1000
Training Loss: 0.87331902, Training R2: 0.287407
Validation Loss: 1.04691553, Validation R2: 0.079879

Epoch 145/1000
Training Loss: 0.87583408, Training R2: 0.288662
Validation Loss: 1.04852808, Validation R2: 0.077602

Epoch 146/1000
Training Loss: 0.87551179, Training R2: 0.286680
Validation Loss: 1.04284203, Validation R2: 0.078087

Epoch 147/1000
Training Loss: 0.87194930, Training R2: 0.285977
Validation Loss: 1.04092145, Validation R2: 0.078284

Epoch 148/1000
Training Loss: 0.87159136, Training R2: 0.284685
Validation Loss: 1.03935754, Validation R2: 0.079779

Epoch 149/1000
Training Loss: 0.87190484, Training R2: 0.283681
Validation Loss: 1.03936362, Validation R2: 0.079817

Epoch 150/1000
Training Loss: 0.87174228, Training R2: 0.284562
Validation Loss: 1.04133236, Validation R2: 0.079770

Epoch 151/1000
Training Loss: 0.87138779, Training R2: 0.284779
Validation Loss: 1.04199922, Validation R2: 0.078681

Epoch 152/1000
Training Loss: 0.87155121, Training R2: 0.283532
Validation Loss: 1.04015803, Validation R2: 0.078866

Epoch 153/1000
Training Loss: 0.87262064, Training R2: 0.281278
Validation Loss: 1.03880274, Validation R2: 0.079776

Epoch 154/1000
Training Loss: 0.87118204, Training R2: 0.283553
Validation Loss: 1.04127765, Validation R2: 0.081123

Epoch 155/1000
Training Loss: 0.87159837, Training R2: 0.287902
Validation Loss: 1.04570603, Validation R2: 0.079573

Epoch 156/1000
Training Loss: 0.87419818, Training R2: 0.289237
Validation Loss: 1.04407966, Validation R2: 0.080399

Epoch 157/1000
Training Loss: 0.87161375, Training R2: 0.288397
Validation Loss: 1.03848982, Validation R2: 0.081465

Epoch 158/1000
Epoch 00158: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.87080801, Training R2: 0.285699
Validation Loss: 1.03798783, Validation R2: 0.079331

Epoch 159/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
