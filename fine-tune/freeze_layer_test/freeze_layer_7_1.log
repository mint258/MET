Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 2.27785444, Training R2: -3.117946
Validation Loss: 1.54043579, Validation R2: -0.278581
Saved best model with validation R2 -0.278581 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.32454976, Training R2: -0.291932
Validation Loss: 1.19305027, Validation R2: 0.017175
Saved best model with validation R2 0.017175 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.10036313, Training R2: -0.060095
Validation Loss: 1.28015494, Validation R2: -0.187261

Epoch 4/1000
Training Loss: 1.12215843, Training R2: -0.123548
Validation Loss: 1.19341242, Validation R2: 0.039517
Saved best model with validation R2 0.039517 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.09647656, Training R2: 0.063946
Validation Loss: 1.22337556, Validation R2: 0.052910
Saved best model with validation R2 0.052910 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.07398146, Training R2: 0.086539
Validation Loss: 1.15942574, Validation R2: 0.019695

Epoch 7/1000
Training Loss: 1.04405145, Training R2: 0.047221
Validation Loss: 1.14767146, Validation R2: 0.049527

Epoch 8/1000
Training Loss: 1.02666900, Training R2: 0.100684
Validation Loss: 1.14894104, Validation R2: 0.087632
Saved best model with validation R2 0.087632 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.02517915, Training R2: 0.145247
Validation Loss: 1.15256608, Validation R2: 0.091576
Saved best model with validation R2 0.091576 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 1.01078437, Training R2: 0.149602
Validation Loss: 1.14016271, Validation R2: 0.073918

Epoch 11/1000
Training Loss: 1.00585628, Training R2: 0.133547
Validation Loss: 1.14149582, Validation R2: 0.081019

Epoch 12/1000
Training Loss: 0.99831800, Training R2: 0.162751
Validation Loss: 1.15530562, Validation R2: 0.076631

Epoch 13/1000
Training Loss: 0.99657849, Training R2: 0.159937
Validation Loss: 1.16011941, Validation R2: 0.102686
Saved best model with validation R2 0.102686 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 0.98871199, Training R2: 0.190443
Validation Loss: 1.13602781, Validation R2: 0.099260

Epoch 15/1000
Training Loss: 0.97735150, Training R2: 0.163869
Validation Loss: 1.12901545, Validation R2: 0.108267
Saved best model with validation R2 0.108267 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 0.97145730, Training R2: 0.197922
Validation Loss: 1.14360011, Validation R2: 0.112901
Saved best model with validation R2 0.112901 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.97477236, Training R2: 0.213716
Validation Loss: 1.13024211, Validation R2: 0.092727

Epoch 18/1000
Training Loss: 0.96455724, Training R2: 0.168609
Validation Loss: 1.15451777, Validation R2: 0.113810
Saved best model with validation R2 0.113810 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.98658152, Training R2: 0.198919
Validation Loss: 1.15017605, Validation R2: 0.061481

Epoch 20/1000
Training Loss: 0.97046824, Training R2: 0.158243
Validation Loss: 1.15617549, Validation R2: 0.121770
Saved best model with validation R2 0.121770 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.95663363, Training R2: 0.208978
Validation Loss: 1.12451851, Validation R2: 0.116636

Epoch 22/1000
Training Loss: 0.94944838, Training R2: 0.228455
Validation Loss: 1.13375974, Validation R2: 0.131490
Saved best model with validation R2 0.131490 to best_finetuned_model.pth

Epoch 23/1000
Training Loss: 0.92687571, Training R2: 0.247069
Validation Loss: 1.11830699, Validation R2: 0.095592

Epoch 24/1000
Training Loss: 0.93152493, Training R2: 0.235272
Validation Loss: 1.10367668, Validation R2: 0.126841

Epoch 25/1000
Training Loss: 0.93173742, Training R2: 0.209392
Validation Loss: 1.11317873, Validation R2: 0.112470

Epoch 26/1000
Training Loss: 0.91680828, Training R2: 0.227520
Validation Loss: 1.18490624, Validation R2: 0.101271

Epoch 27/1000
Training Loss: 0.96241043, Training R2: 0.216073
Validation Loss: 1.15495944, Validation R2: 0.031107

Epoch 28/1000
Training Loss: 0.97290723, Training R2: 0.138511
Validation Loss: 1.13056862, Validation R2: 0.151166
Saved best model with validation R2 0.151166 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 0.90760523, Training R2: 0.278980
Validation Loss: 1.11011612, Validation R2: 0.154453
Saved best model with validation R2 0.154453 to best_finetuned_model.pth

Epoch 30/1000
Training Loss: 0.91534804, Training R2: 0.261007
Validation Loss: 1.09667099, Validation R2: 0.153164

Epoch 31/1000
Training Loss: 0.91162910, Training R2: 0.234728
Validation Loss: 1.10381019, Validation R2: 0.164103
Saved best model with validation R2 0.164103 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 0.89103049, Training R2: 0.293768
Validation Loss: 1.09655178, Validation R2: 0.163293

Epoch 33/1000
Training Loss: 0.88699848, Training R2: 0.291629
Validation Loss: 1.08652961, Validation R2: 0.167051
Saved best model with validation R2 0.167051 to best_finetuned_model.pth

Epoch 34/1000
Training Loss: 0.88308762, Training R2: 0.283991
Validation Loss: 1.10391629, Validation R2: 0.175107
Saved best model with validation R2 0.175107 to best_finetuned_model.pth

Epoch 35/1000
Training Loss: 0.89401489, Training R2: 0.306165
Validation Loss: 1.06299067, Validation R2: 0.181081
Saved best model with validation R2 0.181081 to best_finetuned_model.pth

Epoch 36/1000
Training Loss: 0.87001112, Training R2: 0.316674
Validation Loss: 1.08232391, Validation R2: 0.160086

Epoch 37/1000
Training Loss: 0.88677481, Training R2: 0.274620
Validation Loss: 1.15882266, Validation R2: 0.130071

Epoch 38/1000
Training Loss: 0.89539455, Training R2: 0.304861
Validation Loss: 1.15569818, Validation R2: 0.039650

Epoch 39/1000
Training Loss: 0.95593638, Training R2: 0.167795
Validation Loss: 1.12835765, Validation R2: 0.155275

Epoch 40/1000
Training Loss: 0.91977548, Training R2: 0.282178
Validation Loss: 1.07000887, Validation R2: 0.181227
Saved best model with validation R2 0.181227 to best_finetuned_model.pth

Epoch 41/1000
Training Loss: 0.87255340, Training R2: 0.308971
Validation Loss: 1.09413087, Validation R2: 0.180436

Epoch 42/1000
Training Loss: 0.87621663, Training R2: 0.313278
Validation Loss: 1.09173059, Validation R2: 0.126743

Epoch 43/1000
Training Loss: 0.88187300, Training R2: 0.298800
Validation Loss: 1.11116612, Validation R2: 0.162083

Epoch 44/1000
Training Loss: 0.85365932, Training R2: 0.343244
Validation Loss: 1.09544325, Validation R2: 0.153211

Epoch 45/1000
Training Loss: 0.89674641, Training R2: 0.282403
Validation Loss: 1.13344586, Validation R2: 0.147975

Epoch 46/1000
Training Loss: 0.90878457, Training R2: 0.279090
Validation Loss: 1.08085859, Validation R2: 0.140787

Epoch 47/1000
Training Loss: 0.88933193, Training R2: 0.280812
Validation Loss: 1.07801187, Validation R2: 0.204589
Saved best model with validation R2 0.204589 to best_finetuned_model.pth

Epoch 48/1000
Training Loss: 0.86913948, Training R2: 0.325274
Validation Loss: 1.06158018, Validation R2: 0.174627

Epoch 49/1000
Training Loss: 0.87734071, Training R2: 0.308860
Validation Loss: 1.06877124, Validation R2: 0.207165
Saved best model with validation R2 0.207165 to best_finetuned_model.pth

Epoch 50/1000
Training Loss: 0.82712373, Training R2: 0.367146
Validation Loss: 1.05767608, Validation R2: 0.193692

Epoch 51/1000
Training Loss: 0.83198978, Training R2: 0.365316
Validation Loss: 1.05039704, Validation R2: 0.210845
Saved best model with validation R2 0.210845 to best_finetuned_model.pth

Epoch 52/1000
Training Loss: 0.83606003, Training R2: 0.355309
Validation Loss: 1.08702970, Validation R2: 0.197092

Epoch 53/1000
Training Loss: 0.83317436, Training R2: 0.371633
Validation Loss: 1.07126462, Validation R2: 0.168300

Epoch 54/1000
Training Loss: 0.86699383, Training R2: 0.318748
Validation Loss: 1.10143650, Validation R2: 0.186448

Epoch 55/1000
Training Loss: 0.83606785, Training R2: 0.358149
Validation Loss: 1.04671907, Validation R2: 0.193754

Epoch 56/1000
Training Loss: 0.82569787, Training R2: 0.376262
Validation Loss: 1.07175601, Validation R2: 0.175880

Epoch 57/1000
Training Loss: 0.88556787, Training R2: 0.298242
Validation Loss: 1.11760938, Validation R2: 0.170845

Epoch 58/1000
Training Loss: 0.83839849, Training R2: 0.361263
Validation Loss: 1.01850426, Validation R2: 0.257176
Saved best model with validation R2 0.257176 to best_finetuned_model.pth

Epoch 59/1000
Training Loss: 0.80706435, Training R2: 0.398005
Validation Loss: 1.01583540, Validation R2: 0.255178

Epoch 60/1000
Training Loss: 0.81359017, Training R2: 0.387699
Validation Loss: 1.02133060, Validation R2: 0.242490

Epoch 61/1000
Training Loss: 0.81986361, Training R2: 0.387161
Validation Loss: 1.04506695, Validation R2: 0.238927

Epoch 62/1000
Training Loss: 0.83128385, Training R2: 0.369601
Validation Loss: 1.03435087, Validation R2: 0.242876

Epoch 63/1000
Training Loss: 0.82937672, Training R2: 0.378814
Validation Loss: 1.02601755, Validation R2: 0.250527

Epoch 64/1000
Training Loss: 0.80730439, Training R2: 0.405536
Validation Loss: 1.00760651, Validation R2: 0.257030

Epoch 65/1000
Training Loss: 0.80789148, Training R2: 0.393014
Validation Loss: 1.01080680, Validation R2: 0.263023
Saved best model with validation R2 0.263023 to best_finetuned_model.pth

Epoch 66/1000
Training Loss: 0.81099300, Training R2: 0.392325
Validation Loss: 1.00419331, Validation R2: 0.271040
Saved best model with validation R2 0.271040 to best_finetuned_model.pth

Epoch 67/1000
Training Loss: 0.79219831, Training R2: 0.410536
Validation Loss: 1.00531757, Validation R2: 0.269818

Epoch 68/1000
Training Loss: 0.80986226, Training R2: 0.392736
Validation Loss: 0.96444523, Validation R2: 0.301676
Saved best model with validation R2 0.301676 to best_finetuned_model.pth

Epoch 69/1000
Training Loss: 0.79071223, Training R2: 0.404409
Validation Loss: 0.93786740, Validation R2: 0.313247
Saved best model with validation R2 0.313247 to best_finetuned_model.pth

Epoch 70/1000
Training Loss: 0.75927203, Training R2: 0.437556
Validation Loss: 0.96183646, Validation R2: 0.300674

Epoch 71/1000
Training Loss: 0.73907886, Training R2: 0.463685
Validation Loss: 0.95131820, Validation R2: 0.318158
Saved best model with validation R2 0.318158 to best_finetuned_model.pth

Epoch 72/1000
Training Loss: 0.73506510, Training R2: 0.474040
Validation Loss: 0.96967822, Validation R2: 0.300898

Epoch 73/1000
Training Loss: 0.75080284, Training R2: 0.461648
Validation Loss: 0.93587345, Validation R2: 0.326537
Saved best model with validation R2 0.326537 to best_finetuned_model.pth

Epoch 74/1000
Training Loss: 0.71988081, Training R2: 0.490839
Validation Loss: 0.93808639, Validation R2: 0.334863
Saved best model with validation R2 0.334863 to best_finetuned_model.pth

Epoch 75/1000
Training Loss: 0.71778584, Training R2: 0.492354
Validation Loss: 0.92934698, Validation R2: 0.344744
Saved best model with validation R2 0.344744 to best_finetuned_model.pth

Epoch 76/1000
Training Loss: 0.71157944, Training R2: 0.498394
Validation Loss: 1.03510845, Validation R2: 0.261790

Epoch 77/1000
Training Loss: 0.76363415, Training R2: 0.441270
Validation Loss: 0.90760297, Validation R2: 0.368562
Saved best model with validation R2 0.368562 to best_finetuned_model.pth

Epoch 78/1000
Training Loss: 0.72817824, Training R2: 0.486561
Validation Loss: 0.93956119, Validation R2: 0.326884

Epoch 79/1000
Training Loss: 0.73940212, Training R2: 0.473553
Validation Loss: 0.98688179, Validation R2: 0.301586

Epoch 80/1000
Training Loss: 0.77941969, Training R2: 0.441945
Validation Loss: 0.93765455, Validation R2: 0.316590

Epoch 81/1000
Training Loss: 0.76966155, Training R2: 0.451182
Validation Loss: 0.93777257, Validation R2: 0.325416

Epoch 82/1000
Training Loss: 0.78501869, Training R2: 0.436571
Validation Loss: 0.99418044, Validation R2: 0.284210

Epoch 83/1000
Training Loss: 0.73825885, Training R2: 0.474105
Validation Loss: 0.92350185, Validation R2: 0.352448

Epoch 84/1000
Training Loss: 0.72442801, Training R2: 0.481826
Validation Loss: 0.98618942, Validation R2: 0.310352

Epoch 85/1000
Training Loss: 0.75233649, Training R2: 0.455367
Validation Loss: 0.89351660, Validation R2: 0.378617
Saved best model with validation R2 0.378617 to best_finetuned_model.pth

Epoch 86/1000
Training Loss: 0.70735853, Training R2: 0.504385
Validation Loss: 0.89875340, Validation R2: 0.382620
Saved best model with validation R2 0.382620 to best_finetuned_model.pth

Epoch 87/1000
Training Loss: 0.73647630, Training R2: 0.494203
Validation Loss: 0.90398800, Validation R2: 0.364024

Epoch 88/1000
Training Loss: 0.69610327, Training R2: 0.524238
Validation Loss: 0.88773918, Validation R2: 0.370818

Epoch 89/1000
Training Loss: 0.71036661, Training R2: 0.506583
Validation Loss: 0.89427167, Validation R2: 0.376595

Epoch 90/1000
Training Loss: 0.68528525, Training R2: 0.537989
Validation Loss: 0.89919508, Validation R2: 0.374794

Epoch 91/1000
Training Loss: 0.67373982, Training R2: 0.541517
Validation Loss: 0.89000273, Validation R2: 0.383459
Saved best model with validation R2 0.383459 to best_finetuned_model.pth

Epoch 92/1000
Training Loss: 0.66552805, Training R2: 0.545992
Validation Loss: 0.94436616, Validation R2: 0.348688

Epoch 93/1000
Training Loss: 0.69696281, Training R2: 0.517848
Validation Loss: 0.90049285, Validation R2: 0.382976

Epoch 94/1000
Training Loss: 0.68734003, Training R2: 0.529369
Validation Loss: 0.86132038, Validation R2: 0.410295
Saved best model with validation R2 0.410295 to best_finetuned_model.pth

Epoch 95/1000
Training Loss: 0.67546545, Training R2: 0.563774
Validation Loss: 0.87054241, Validation R2: 0.406792

Epoch 96/1000
Training Loss: 0.66391443, Training R2: 0.561230
Validation Loss: 0.86464018, Validation R2: 0.409121

Epoch 97/1000
Training Loss: 0.65374587, Training R2: 0.572697
Validation Loss: 0.85618186, Validation R2: 0.414707
Saved best model with validation R2 0.414707 to best_finetuned_model.pth

Epoch 98/1000
Training Loss: 0.65417189, Training R2: 0.577973
Validation Loss: 0.84503371, Validation R2: 0.421145
Saved best model with validation R2 0.421145 to best_finetuned_model.pth

Epoch 99/1000
Training Loss: 0.62920055, Training R2: 0.600609
Validation Loss: 0.86704087, Validation R2: 0.396713

Epoch 100/1000
Training Loss: 0.63606204, Training R2: 0.582540
Validation Loss: 0.87816375, Validation R2: 0.396073

Epoch 101/1000
Training Loss: 0.62412818, Training R2: 0.596920
Validation Loss: 0.91340071, Validation R2: 0.381311

Epoch 102/1000
Training Loss: 0.66619660, Training R2: 0.571758
Validation Loss: 0.90792191, Validation R2: 0.379775

Epoch 103/1000
Training Loss: 0.70296127, Training R2: 0.535972
Validation Loss: 0.92984813, Validation R2: 0.372480

Epoch 104/1000
Training Loss: 0.67006847, Training R2: 0.569090
Validation Loss: 0.90640068, Validation R2: 0.372267

Epoch 105/1000
Training Loss: 0.65910976, Training R2: 0.576570
Validation Loss: 0.95322627, Validation R2: 0.330573

Epoch 106/1000
Training Loss: 0.70807184, Training R2: 0.520213
Validation Loss: 0.91198993, Validation R2: 0.349155

Epoch 107/1000
Training Loss: 0.67050052, Training R2: 0.562165
Validation Loss: 0.88470882, Validation R2: 0.383276

Epoch 108/1000
Training Loss: 0.62658671, Training R2: 0.597036
Validation Loss: 0.87390196, Validation R2: 0.378963

Epoch 109/1000
Training Loss: 0.61786484, Training R2: 0.614934
Validation Loss: 0.87952697, Validation R2: 0.377946

Epoch 110/1000
Training Loss: 0.60288229, Training R2: 0.619493
Validation Loss: 0.85581678, Validation R2: 0.399998

Epoch 111/1000
Training Loss: 0.60768892, Training R2: 0.620322
Validation Loss: 0.92412490, Validation R2: 0.360979

Epoch 112/1000
Training Loss: 0.64028851, Training R2: 0.593272
Validation Loss: 0.89803213, Validation R2: 0.362517

Epoch 113/1000
Training Loss: 0.65006369, Training R2: 0.591711
Validation Loss: 0.85341024, Validation R2: 0.397082

Epoch 114/1000
Training Loss: 0.63417635, Training R2: 0.601112
Validation Loss: 0.92291021, Validation R2: 0.352586

Epoch 115/1000
Training Loss: 0.62172792, Training R2: 0.604743
Validation Loss: 0.87195885, Validation R2: 0.394658

Epoch 116/1000
Training Loss: 0.60691781, Training R2: 0.625292
Validation Loss: 0.86667967, Validation R2: 0.397974

Epoch 117/1000
Training Loss: 0.61425251, Training R2: 0.629540
Validation Loss: 0.86519283, Validation R2: 0.396676

Epoch 118/1000
Training Loss: 0.60426022, Training R2: 0.638899
Validation Loss: 0.84712136, Validation R2: 0.406804

Epoch 119/1000
Epoch 00119: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.57934144, Training R2: 0.657635
Validation Loss: 0.89215606, Validation R2: 0.371927

Epoch 120/1000
学习率已减少 1 次
Training Loss: 0.61618519, Training R2: 0.614215
Validation Loss: 0.88510495, Validation R2: 0.380106

Epoch 121/1000
Training Loss: 0.59851709, Training R2: 0.635554
Validation Loss: 0.88502783, Validation R2: 0.384736

Epoch 122/1000
Training Loss: 0.57887883, Training R2: 0.651533
Validation Loss: 0.85773551, Validation R2: 0.402160

Epoch 123/1000
Training Loss: 0.60449256, Training R2: 0.641490
Validation Loss: 0.84853578, Validation R2: 0.399510

Epoch 124/1000
Training Loss: 0.61108541, Training R2: 0.629685
Validation Loss: 0.84297895, Validation R2: 0.400667

Epoch 125/1000
Training Loss: 0.58266736, Training R2: 0.660750
Validation Loss: 0.83313650, Validation R2: 0.406824

Epoch 126/1000
Training Loss: 0.56059926, Training R2: 0.668278
Validation Loss: 0.85062963, Validation R2: 0.396676

Epoch 127/1000
Training Loss: 0.56331048, Training R2: 0.663572
Validation Loss: 0.86626613, Validation R2: 0.394259

Epoch 128/1000
Training Loss: 0.56436087, Training R2: 0.665829
Validation Loss: 0.84846479, Validation R2: 0.401631

Epoch 129/1000
Training Loss: 0.55790789, Training R2: 0.671723
Validation Loss: 0.84235215, Validation R2: 0.402782

Epoch 130/1000
Training Loss: 0.57272918, Training R2: 0.666619
Validation Loss: 0.85550803, Validation R2: 0.399083

Epoch 131/1000
Training Loss: 0.56791902, Training R2: 0.669543
Validation Loss: 0.84177232, Validation R2: 0.407923

Epoch 132/1000
Training Loss: 0.54215800, Training R2: 0.686267
Validation Loss: 0.85536790, Validation R2: 0.404805

Epoch 133/1000
Training Loss: 0.55155555, Training R2: 0.669517
Validation Loss: 0.85732621, Validation R2: 0.406647

Epoch 134/1000
Training Loss: 0.55489011, Training R2: 0.672796
Validation Loss: 0.84247625, Validation R2: 0.412278

Epoch 135/1000
Training Loss: 0.54430546, Training R2: 0.681179
Validation Loss: 0.83167738, Validation R2: 0.415510

Epoch 136/1000
Training Loss: 0.53295231, Training R2: 0.687971
Validation Loss: 0.83569175, Validation R2: 0.408922

Epoch 137/1000
Training Loss: 0.53487015, Training R2: 0.693288
Validation Loss: 0.83119351, Validation R2: 0.414129

Epoch 138/1000
Training Loss: 0.53737032, Training R2: 0.692909
Validation Loss: 0.82943159, Validation R2: 0.419106

Epoch 139/1000
Training Loss: 0.52971980, Training R2: 0.693565
Validation Loss: 0.82833219, Validation R2: 0.424648
Saved best model with validation R2 0.424648 to best_finetuned_model.pth

Epoch 140/1000
Training Loss: 0.54367750, Training R2: 0.689906
Validation Loss: 0.84090865, Validation R2: 0.411741

Epoch 141/1000
Training Loss: 0.53128098, Training R2: 0.690760
Validation Loss: 0.83858854, Validation R2: 0.401511

Epoch 142/1000
Training Loss: 0.53923025, Training R2: 0.684996
Validation Loss: 0.83924419, Validation R2: 0.396808

Epoch 143/1000
Training Loss: 0.55626076, Training R2: 0.677426
Validation Loss: 0.87458885, Validation R2: 0.383354

Epoch 144/1000
Training Loss: 0.57711172, Training R2: 0.655603
Validation Loss: 0.84772396, Validation R2: 0.397813

Epoch 145/1000
Training Loss: 0.55962822, Training R2: 0.677611
Validation Loss: 0.85970420, Validation R2: 0.394289

Epoch 146/1000
Training Loss: 0.52260917, Training R2: 0.694330
Validation Loss: 0.83226532, Validation R2: 0.416604

Epoch 147/1000
Training Loss: 0.52027734, Training R2: 0.697246
Validation Loss: 0.82702559, Validation R2: 0.415964

Epoch 148/1000
Training Loss: 0.51558471, Training R2: 0.705031
Validation Loss: 0.83179998, Validation R2: 0.411679

Epoch 149/1000
Training Loss: 0.51898484, Training R2: 0.701060
Validation Loss: 0.86124265, Validation R2: 0.390582

Epoch 150/1000
Training Loss: 0.58023481, Training R2: 0.661256
Validation Loss: 0.85982203, Validation R2: 0.399976

Epoch 151/1000
Training Loss: 0.52457987, Training R2: 0.698229
Validation Loss: 0.87355477, Validation R2: 0.394711

Epoch 152/1000
Training Loss: 0.53331476, Training R2: 0.693464
Validation Loss: 0.86802864, Validation R2: 0.391563

Epoch 153/1000
Training Loss: 0.52785877, Training R2: 0.690819
Validation Loss: 0.82319385, Validation R2: 0.415125

Epoch 154/1000
Training Loss: 0.52505851, Training R2: 0.697727
Validation Loss: 0.82771027, Validation R2: 0.419560

Epoch 155/1000
Training Loss: 0.53585984, Training R2: 0.696092
Validation Loss: 0.86802137, Validation R2: 0.404208

Epoch 156/1000
Training Loss: 0.55899344, Training R2: 0.673065
Validation Loss: 0.86404389, Validation R2: 0.399978

Epoch 157/1000
Training Loss: 0.54121542, Training R2: 0.684102
Validation Loss: 0.85197079, Validation R2: 0.411369

Epoch 158/1000
Training Loss: 0.51690572, Training R2: 0.704036
Validation Loss: 0.83040786, Validation R2: 0.415399

Epoch 159/1000
Training Loss: 0.51407259, Training R2: 0.706515
Validation Loss: 0.83296067, Validation R2: 0.414669

Epoch 160/1000
Epoch 00160: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.50500392, Training R2: 0.709980
Validation Loss: 0.82813263, Validation R2: 0.414502

Epoch 161/1000
学习率已减少 2 次
Training Loss: 0.49700094, Training R2: 0.717168
Validation Loss: 0.83509159, Validation R2: 0.411260

Epoch 162/1000
Training Loss: 0.49052148, Training R2: 0.719587
Validation Loss: 0.83561230, Validation R2: 0.414957

Epoch 163/1000
Training Loss: 0.49634101, Training R2: 0.721345
Validation Loss: 0.84226269, Validation R2: 0.413899

Epoch 164/1000
Training Loss: 0.49314119, Training R2: 0.720432
Validation Loss: 0.84114265, Validation R2: 0.412493

Epoch 165/1000
Training Loss: 0.48998110, Training R2: 0.721783
Validation Loss: 0.83591706, Validation R2: 0.415171

Epoch 166/1000
Training Loss: 0.48954019, Training R2: 0.726490
Validation Loss: 0.85406506, Validation R2: 0.398283

Epoch 167/1000
Training Loss: 0.51725479, Training R2: 0.704759
Validation Loss: 0.84457821, Validation R2: 0.406802

Epoch 168/1000
Training Loss: 0.53187624, Training R2: 0.705047
Validation Loss: 0.85319990, Validation R2: 0.402263

Epoch 169/1000
Training Loss: 0.51418001, Training R2: 0.705711
Validation Loss: 0.85891175, Validation R2: 0.398511

Epoch 170/1000
Training Loss: 0.48894902, Training R2: 0.726333
Validation Loss: 0.85122663, Validation R2: 0.397839

Epoch 171/1000
Training Loss: 0.48897562, Training R2: 0.724237
Validation Loss: 0.84418279, Validation R2: 0.396080

Epoch 172/1000
Training Loss: 0.48328433, Training R2: 0.729589
Validation Loss: 0.84243119, Validation R2: 0.396210

Epoch 173/1000
Training Loss: 0.48766113, Training R2: 0.727828
Validation Loss: 0.86781508, Validation R2: 0.382618

Epoch 174/1000
Training Loss: 0.51472277, Training R2: 0.706452
Validation Loss: 0.85406780, Validation R2: 0.398596

Epoch 175/1000
Training Loss: 0.50829860, Training R2: 0.714644
Validation Loss: 0.85608035, Validation R2: 0.401370

Epoch 176/1000
Training Loss: 0.49877993, Training R2: 0.716075
Validation Loss: 0.83933669, Validation R2: 0.407911

Epoch 177/1000
Training Loss: 0.50487468, Training R2: 0.720295
Validation Loss: 0.83316833, Validation R2: 0.408760

Epoch 178/1000
Training Loss: 0.48626279, Training R2: 0.724972
Validation Loss: 0.84635800, Validation R2: 0.398659

Epoch 179/1000
Training Loss: 0.47439525, Training R2: 0.731467
Validation Loss: 0.84214962, Validation R2: 0.403311

Epoch 180/1000
Training Loss: 0.47468919, Training R2: 0.734077
Validation Loss: 0.84544647, Validation R2: 0.399788

Epoch 181/1000
Epoch 00181: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.47897147, Training R2: 0.733634
Validation Loss: 0.83721983, Validation R2: 0.399848

Epoch 182/1000
学习率已减少 3 次
Training Loss: 0.46939537, Training R2: 0.737589
Validation Loss: 0.83643615, Validation R2: 0.398404

Epoch 183/1000
Training Loss: 0.47027314, Training R2: 0.737051
Validation Loss: 0.83516204, Validation R2: 0.399032

Epoch 184/1000
Training Loss: 0.46766062, Training R2: 0.738141
Validation Loss: 0.84209687, Validation R2: 0.397518

Epoch 185/1000
Training Loss: 0.47102936, Training R2: 0.734959
Validation Loss: 0.85266292, Validation R2: 0.392928

Epoch 186/1000
Training Loss: 0.47102094, Training R2: 0.734400
Validation Loss: 0.85146552, Validation R2: 0.394705

Epoch 187/1000
Training Loss: 0.47074416, Training R2: 0.737234
Validation Loss: 0.84626263, Validation R2: 0.397999

Epoch 188/1000
Training Loss: 0.46794464, Training R2: 0.736316
Validation Loss: 0.84108794, Validation R2: 0.399885

Epoch 189/1000
Training Loss: 0.46503430, Training R2: 0.737370
Validation Loss: 0.83981538, Validation R2: 0.400620

Epoch 190/1000
Training Loss: 0.46576286, Training R2: 0.740457
Validation Loss: 0.85094160, Validation R2: 0.398585

Epoch 191/1000
Training Loss: 0.46666096, Training R2: 0.738243
Validation Loss: 0.85237241, Validation R2: 0.396813

Epoch 192/1000
Training Loss: 0.46758699, Training R2: 0.738743
Validation Loss: 0.84353530, Validation R2: 0.402511

Epoch 193/1000
Training Loss: 0.46051743, Training R2: 0.741223
Validation Loss: 0.83879620, Validation R2: 0.404438

Epoch 194/1000
Training Loss: 0.46054561, Training R2: 0.741519
Validation Loss: 0.84398901, Validation R2: 0.402982

Epoch 195/1000
Training Loss: 0.45885666, Training R2: 0.741732
Validation Loss: 0.84604126, Validation R2: 0.402172

Epoch 196/1000
Training Loss: 0.46491137, Training R2: 0.741406
Validation Loss: 0.85035729, Validation R2: 0.401658

Epoch 197/1000
Training Loss: 0.46373557, Training R2: 0.739712
Validation Loss: 0.84798551, Validation R2: 0.404205

Epoch 198/1000
Training Loss: 0.46379253, Training R2: 0.741119
Validation Loss: 0.84191495, Validation R2: 0.407459

Epoch 199/1000
Training Loss: 0.46649171, Training R2: 0.736905
Validation Loss: 0.84566569, Validation R2: 0.402953

Epoch 200/1000
Training Loss: 0.46051903, Training R2: 0.742517
Validation Loss: 0.83815688, Validation R2: 0.403113

Epoch 201/1000
Training Loss: 0.46765007, Training R2: 0.741154
Validation Loss: 0.83963728, Validation R2: 0.403664

Epoch 202/1000
Epoch 00202: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.45996900, Training R2: 0.742545
Validation Loss: 0.84593624, Validation R2: 0.402041

Epoch 203/1000
学习率已减少 4 次
Training Loss: 0.45555530, Training R2: 0.744197
Validation Loss: 0.84512454, Validation R2: 0.403659

Epoch 204/1000
Training Loss: 0.45920502, Training R2: 0.744009
Validation Loss: 0.84509575, Validation R2: 0.404357

Epoch 205/1000
Training Loss: 0.45547052, Training R2: 0.745737
Validation Loss: 0.84591889, Validation R2: 0.404395

Epoch 206/1000
Training Loss: 0.45555026, Training R2: 0.744127
Validation Loss: 0.84237099, Validation R2: 0.407142

Epoch 207/1000
Training Loss: 0.45395707, Training R2: 0.745562
Validation Loss: 0.84038144, Validation R2: 0.408031

Epoch 208/1000
Training Loss: 0.45463148, Training R2: 0.744517
Validation Loss: 0.84284008, Validation R2: 0.406865

Epoch 209/1000
Training Loss: 0.45418264, Training R2: 0.744401
Validation Loss: 0.84414738, Validation R2: 0.406078

Epoch 210/1000
Training Loss: 0.45438559, Training R2: 0.744377
Validation Loss: 0.84345686, Validation R2: 0.405607

Epoch 211/1000
Training Loss: 0.45356615, Training R2: 0.745228
Validation Loss: 0.84261686, Validation R2: 0.404448

Epoch 212/1000
Training Loss: 0.45291624, Training R2: 0.746628
Validation Loss: 0.84456402, Validation R2: 0.402753

Epoch 213/1000
Training Loss: 0.45294271, Training R2: 0.745258
Validation Loss: 0.84437025, Validation R2: 0.403352

Epoch 214/1000
Training Loss: 0.45232828, Training R2: 0.745713
Validation Loss: 0.84299994, Validation R2: 0.404435

Epoch 215/1000
Training Loss: 0.45133086, Training R2: 0.746100
Validation Loss: 0.84383464, Validation R2: 0.404607

Epoch 216/1000
Training Loss: 0.45133462, Training R2: 0.746436
Validation Loss: 0.84183830, Validation R2: 0.406241

Epoch 217/1000
Training Loss: 0.44953271, Training R2: 0.747351
Validation Loss: 0.84116483, Validation R2: 0.406138

Epoch 218/1000
Training Loss: 0.45164112, Training R2: 0.746322
Validation Loss: 0.83951241, Validation R2: 0.406548

Epoch 219/1000
Training Loss: 0.45300872, Training R2: 0.747256
Validation Loss: 0.84149498, Validation R2: 0.403407

Epoch 220/1000
Training Loss: 0.45521267, Training R2: 0.745983
Validation Loss: 0.84439558, Validation R2: 0.400848

Epoch 221/1000
Training Loss: 0.45262922, Training R2: 0.746654
Validation Loss: 0.84257758, Validation R2: 0.402175

Epoch 222/1000
Training Loss: 0.45061512, Training R2: 0.747384
Validation Loss: 0.83958828, Validation R2: 0.403706

Epoch 223/1000
Epoch 00223: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.45227186, Training R2: 0.746231
Validation Loss: 0.83792222, Validation R2: 0.403761

Epoch 224/1000
学习率已减少 5 次
Training Loss: 0.45154892, Training R2: 0.746833
Validation Loss: 0.83659154, Validation R2: 0.404130

Epoch 225/1000
Training Loss: 0.45105242, Training R2: 0.747372
Validation Loss: 0.83842635, Validation R2: 0.404070

Epoch 226/1000
Training Loss: 0.44899200, Training R2: 0.748475
Validation Loss: 0.84088010, Validation R2: 0.403365

Epoch 227/1000
Training Loss: 0.44940378, Training R2: 0.748058
Validation Loss: 0.84354198, Validation R2: 0.402265

Epoch 228/1000
Training Loss: 0.44874159, Training R2: 0.748316
Validation Loss: 0.84447080, Validation R2: 0.402306

Epoch 229/1000
Training Loss: 0.44786080, Training R2: 0.748891
Validation Loss: 0.84379441, Validation R2: 0.402464

Epoch 230/1000
Training Loss: 0.44744586, Training R2: 0.748998
Validation Loss: 0.84382033, Validation R2: 0.402398

Epoch 231/1000
Training Loss: 0.44785337, Training R2: 0.748749
Validation Loss: 0.84437978, Validation R2: 0.402130

Epoch 232/1000
Training Loss: 0.44800478, Training R2: 0.748801
Validation Loss: 0.84562308, Validation R2: 0.400864

Epoch 233/1000
Training Loss: 0.44891875, Training R2: 0.748842
Validation Loss: 0.84564543, Validation R2: 0.400294

Epoch 234/1000
Training Loss: 0.44782785, Training R2: 0.748827
Validation Loss: 0.84592670, Validation R2: 0.400103

Epoch 235/1000
Training Loss: 0.45075048, Training R2: 0.747055
Validation Loss: 0.84829777, Validation R2: 0.399078

Epoch 236/1000
Training Loss: 0.44983530, Training R2: 0.747087
Validation Loss: 0.84445637, Validation R2: 0.401672

Epoch 237/1000
Training Loss: 0.44836640, Training R2: 0.748540
Validation Loss: 0.84343338, Validation R2: 0.402490

Epoch 238/1000
Training Loss: 0.44784974, Training R2: 0.748877
Validation Loss: 0.84259170, Validation R2: 0.403063

Epoch 239/1000
Training Loss: 0.44666527, Training R2: 0.749367
Validation Loss: 0.84181470, Validation R2: 0.403701

Epoch 240/1000
Training Loss: 0.44776147, Training R2: 0.749320
Validation Loss: 0.84025937, Validation R2: 0.404594

Epoch 241/1000
Training Loss: 0.44769199, Training R2: 0.749338
Validation Loss: 0.84041905, Validation R2: 0.405452

Epoch 242/1000
Training Loss: 0.44675616, Training R2: 0.749555
Validation Loss: 0.84091735, Validation R2: 0.405894

Epoch 243/1000
Training Loss: 0.44655012, Training R2: 0.749264
Validation Loss: 0.84419930, Validation R2: 0.404562

Epoch 244/1000
Epoch 00244: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.44964477, Training R2: 0.747546
Validation Loss: 0.84455365, Validation R2: 0.404060

Epoch 245/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
