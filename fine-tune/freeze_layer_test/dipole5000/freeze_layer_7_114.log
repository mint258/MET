Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.34805281, Training R2: -0.370472
Validation Loss: 1.21241482, Validation R2: 0.025466
Saved best model with validation R2 0.025466 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.14454383, Training R2: 0.038463
Validation Loss: 1.13164929, Validation R2: 0.083316
Saved best model with validation R2 0.083316 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.05658547, Training R2: 0.161521
Validation Loss: 1.13981206, Validation R2: 0.137833
Saved best model with validation R2 0.137833 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.03160436, Training R2: 0.199072
Validation Loss: 1.02887895, Validation R2: 0.232762
Saved best model with validation R2 0.232762 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 0.98261767, Training R2: 0.256687
Validation Loss: 1.00603688, Validation R2: 0.240498
Saved best model with validation R2 0.240498 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 0.96818542, Training R2: 0.273409
Validation Loss: 0.95903850, Validation R2: 0.316044
Saved best model with validation R2 0.316044 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 0.94202076, Training R2: 0.314304
Validation Loss: 0.94508293, Validation R2: 0.334487
Saved best model with validation R2 0.334487 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 0.91481952, Training R2: 0.333954
Validation Loss: 0.93956829, Validation R2: 0.329445

Epoch 9/1000
Training Loss: 0.93548415, Training R2: 0.310134
Validation Loss: 0.92359314, Validation R2: 0.350759
Saved best model with validation R2 0.350759 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.88604113, Training R2: 0.369525
Validation Loss: 0.89452113, Validation R2: 0.392008
Saved best model with validation R2 0.392008 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 0.86914292, Training R2: 0.386283
Validation Loss: 0.88016551, Validation R2: 0.390492

Epoch 12/1000
Training Loss: 0.86688623, Training R2: 0.384989
Validation Loss: 0.90495676, Validation R2: 0.394823
Saved best model with validation R2 0.394823 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 0.87375875, Training R2: 0.386038
Validation Loss: 0.88139456, Validation R2: 0.385057

Epoch 14/1000
Training Loss: 0.84261764, Training R2: 0.416032
Validation Loss: 0.90510759, Validation R2: 0.366870

Epoch 15/1000
Training Loss: 0.84369720, Training R2: 0.412061
Validation Loss: 0.85231734, Validation R2: 0.429208
Saved best model with validation R2 0.429208 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 0.82101730, Training R2: 0.436863
Validation Loss: 0.84514748, Validation R2: 0.439824
Saved best model with validation R2 0.439824 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.80859100, Training R2: 0.457617
Validation Loss: 0.85821424, Validation R2: 0.424157

Epoch 18/1000
Training Loss: 0.80189173, Training R2: 0.459065
Validation Loss: 0.84619399, Validation R2: 0.441120
Saved best model with validation R2 0.441120 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.80434575, Training R2: 0.457868
Validation Loss: 0.87616279, Validation R2: 0.390074

Epoch 20/1000
Training Loss: 0.84799925, Training R2: 0.419469
Validation Loss: 0.85076040, Validation R2: 0.431684

Epoch 21/1000
Training Loss: 0.80769818, Training R2: 0.449572
Validation Loss: 0.82849164, Validation R2: 0.458393
Saved best model with validation R2 0.458393 to best_finetuned_model.pth

Epoch 22/1000
Training Loss: 0.80269493, Training R2: 0.462414
Validation Loss: 0.83327177, Validation R2: 0.455688

Epoch 23/1000
Training Loss: 0.80954407, Training R2: 0.450810
Validation Loss: 0.82378684, Validation R2: 0.455483

Epoch 24/1000
Training Loss: 0.79342988, Training R2: 0.470386
Validation Loss: 0.80721600, Validation R2: 0.474126
Saved best model with validation R2 0.474126 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 0.77973322, Training R2: 0.480677
Validation Loss: 0.83687162, Validation R2: 0.459521

Epoch 26/1000
Training Loss: 0.79471886, Training R2: 0.471769
Validation Loss: 0.80848539, Validation R2: 0.481126
Saved best model with validation R2 0.481126 to best_finetuned_model.pth

Epoch 27/1000
Training Loss: 0.77920527, Training R2: 0.483472
Validation Loss: 0.79253555, Validation R2: 0.491735
Saved best model with validation R2 0.491735 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 0.77070072, Training R2: 0.487289
Validation Loss: 0.80994903, Validation R2: 0.489488

Epoch 29/1000
Training Loss: 0.75459031, Training R2: 0.506684
Validation Loss: 0.78785935, Validation R2: 0.497824
Saved best model with validation R2 0.497824 to best_finetuned_model.pth

Epoch 30/1000
Training Loss: 0.73844925, Training R2: 0.520681
Validation Loss: 0.79354281, Validation R2: 0.496455

Epoch 31/1000
Training Loss: 0.75904698, Training R2: 0.499786
Validation Loss: 0.79336737, Validation R2: 0.486453

Epoch 32/1000
Training Loss: 0.73351889, Training R2: 0.522910
Validation Loss: 0.77330746, Validation R2: 0.514073
Saved best model with validation R2 0.514073 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 0.71992928, Training R2: 0.533991
Validation Loss: 0.75239465, Validation R2: 0.529900
Saved best model with validation R2 0.529900 to best_finetuned_model.pth

Epoch 34/1000
Training Loss: 0.71940924, Training R2: 0.539851
Validation Loss: 0.77385945, Validation R2: 0.505255

Epoch 35/1000
Training Loss: 0.71219711, Training R2: 0.543761
Validation Loss: 0.75000232, Validation R2: 0.531404
Saved best model with validation R2 0.531404 to best_finetuned_model.pth

Epoch 36/1000
Training Loss: 0.70544193, Training R2: 0.549454
Validation Loss: 0.74741582, Validation R2: 0.530883

Epoch 37/1000
Training Loss: 0.72475336, Training R2: 0.529485
Validation Loss: 0.75699468, Validation R2: 0.522319

Epoch 38/1000
Training Loss: 0.72003382, Training R2: 0.535075
Validation Loss: 0.74005643, Validation R2: 0.531477
Saved best model with validation R2 0.531477 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.69277313, Training R2: 0.562297
Validation Loss: 0.74139302, Validation R2: 0.530788

Epoch 40/1000
Training Loss: 0.68938613, Training R2: 0.563518
Validation Loss: 0.75440198, Validation R2: 0.530065

Epoch 41/1000
Training Loss: 0.70287838, Training R2: 0.549831
Validation Loss: 0.77515016, Validation R2: 0.508330

Epoch 42/1000
Training Loss: 0.68890974, Training R2: 0.565708
Validation Loss: 0.73011636, Validation R2: 0.549606
Saved best model with validation R2 0.549606 to best_finetuned_model.pth

Epoch 43/1000
Training Loss: 0.69454602, Training R2: 0.560915
Validation Loss: 0.71081612, Validation R2: 0.556708
Saved best model with validation R2 0.556708 to best_finetuned_model.pth

Epoch 44/1000
Training Loss: 0.69100452, Training R2: 0.560521
Validation Loss: 0.71991698, Validation R2: 0.548630

Epoch 45/1000
Training Loss: 0.67953780, Training R2: 0.575041
Validation Loss: 0.74754040, Validation R2: 0.536809

Epoch 46/1000
Training Loss: 0.66837839, Training R2: 0.583508
Validation Loss: 0.70397076, Validation R2: 0.570145
Saved best model with validation R2 0.570145 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.66448422, Training R2: 0.589370
Validation Loss: 0.72555785, Validation R2: 0.551330

Epoch 48/1000
Training Loss: 0.65864696, Training R2: 0.589847
Validation Loss: 0.70195352, Validation R2: 0.575442
Saved best model with validation R2 0.575442 to best_finetuned_model.pth

Epoch 49/1000
Training Loss: 0.66646110, Training R2: 0.590355
Validation Loss: 0.71316328, Validation R2: 0.557354

Epoch 50/1000
Training Loss: 0.67304230, Training R2: 0.583236
Validation Loss: 0.71563421, Validation R2: 0.563342

Epoch 51/1000
Training Loss: 0.66642908, Training R2: 0.587021
Validation Loss: 0.76382267, Validation R2: 0.519321

Epoch 52/1000
Training Loss: 0.65488130, Training R2: 0.597260
Validation Loss: 0.68181529, Validation R2: 0.586695
Saved best model with validation R2 0.586695 to best_finetuned_model.pth

Epoch 53/1000
Training Loss: 0.64107442, Training R2: 0.607480
Validation Loss: 0.70733537, Validation R2: 0.565555

Epoch 54/1000
Training Loss: 0.65305024, Training R2: 0.596306
Validation Loss: 0.67988734, Validation R2: 0.580590

Epoch 55/1000
Training Loss: 0.63121316, Training R2: 0.615825
Validation Loss: 0.77666417, Validation R2: 0.514347

Epoch 56/1000
Training Loss: 0.65516981, Training R2: 0.600313
Validation Loss: 0.79175489, Validation R2: 0.474038

Epoch 57/1000
Training Loss: 0.64507156, Training R2: 0.602544
Validation Loss: 0.67641862, Validation R2: 0.596485
Saved best model with validation R2 0.596485 to best_finetuned_model.pth

Epoch 58/1000
Training Loss: 0.64350338, Training R2: 0.607197
Validation Loss: 0.67051116, Validation R2: 0.600825
Saved best model with validation R2 0.600825 to best_finetuned_model.pth

Epoch 59/1000
Training Loss: 0.63478011, Training R2: 0.613481
Validation Loss: 0.68700939, Validation R2: 0.592253

Epoch 60/1000
Training Loss: 0.65853455, Training R2: 0.594923
Validation Loss: 0.69465646, Validation R2: 0.577664

Epoch 61/1000
Training Loss: 0.63787689, Training R2: 0.614291
Validation Loss: 0.73340573, Validation R2: 0.548310

Epoch 62/1000
Training Loss: 0.64554199, Training R2: 0.606423
Validation Loss: 0.68192637, Validation R2: 0.591400

Epoch 63/1000
Training Loss: 0.61535173, Training R2: 0.632595
Validation Loss: 0.66878711, Validation R2: 0.604822
Saved best model with validation R2 0.604822 to best_finetuned_model.pth

Epoch 64/1000
Training Loss: 0.61029965, Training R2: 0.640268
Validation Loss: 0.67765322, Validation R2: 0.594915

Epoch 65/1000
Training Loss: 0.62318059, Training R2: 0.627996
Validation Loss: 0.69340612, Validation R2: 0.584292

Epoch 66/1000
Training Loss: 0.63641556, Training R2: 0.618668
Validation Loss: 0.68995236, Validation R2: 0.584380

Epoch 67/1000
Training Loss: 0.63190060, Training R2: 0.622711
Validation Loss: 0.69173030, Validation R2: 0.579248

Epoch 68/1000
Training Loss: 0.62877229, Training R2: 0.619422
Validation Loss: 0.74252961, Validation R2: 0.553362

Epoch 69/1000
Training Loss: 0.62865921, Training R2: 0.626779
Validation Loss: 0.65815562, Validation R2: 0.612269
Saved best model with validation R2 0.612269 to best_finetuned_model.pth

Epoch 70/1000
Training Loss: 0.60962878, Training R2: 0.638289
Validation Loss: 0.65046131, Validation R2: 0.619051
Saved best model with validation R2 0.619051 to best_finetuned_model.pth

Epoch 71/1000
Training Loss: 0.61134226, Training R2: 0.639809
Validation Loss: 0.66321603, Validation R2: 0.611055

Epoch 72/1000
Training Loss: 0.60355018, Training R2: 0.645296
Validation Loss: 0.65201091, Validation R2: 0.612595

Epoch 73/1000
Training Loss: 0.60183411, Training R2: 0.644267
Validation Loss: 0.65110236, Validation R2: 0.622617
Saved best model with validation R2 0.622617 to best_finetuned_model.pth

Epoch 74/1000
Training Loss: 0.60647969, Training R2: 0.645366
Validation Loss: 0.64933438, Validation R2: 0.616255

Epoch 75/1000
Training Loss: 0.59252531, Training R2: 0.656015
Validation Loss: 0.67427013, Validation R2: 0.606629

Epoch 76/1000
Training Loss: 0.61742942, Training R2: 0.636270
Validation Loss: 0.67388138, Validation R2: 0.599673

Epoch 77/1000
Training Loss: 0.61143865, Training R2: 0.642631
Validation Loss: 0.71635533, Validation R2: 0.557281

Epoch 78/1000
Training Loss: 0.59626131, Training R2: 0.656292
Validation Loss: 0.64716525, Validation R2: 0.625011
Saved best model with validation R2 0.625011 to best_finetuned_model.pth

Epoch 79/1000
Training Loss: 0.58441472, Training R2: 0.662215
Validation Loss: 0.65300880, Validation R2: 0.615554

Epoch 80/1000
Training Loss: 0.58775135, Training R2: 0.656406
Validation Loss: 0.64848454, Validation R2: 0.617364

Epoch 81/1000
Training Loss: 0.59570430, Training R2: 0.658117
Validation Loss: 0.66246099, Validation R2: 0.623182

Epoch 82/1000
Training Loss: 0.59616532, Training R2: 0.655530
Validation Loss: 0.70624682, Validation R2: 0.544858

Epoch 83/1000
Training Loss: 0.63020776, Training R2: 0.628391
Validation Loss: 0.66356874, Validation R2: 0.619618

Epoch 84/1000
Training Loss: 0.58526807, Training R2: 0.664084
Validation Loss: 0.66717957, Validation R2: 0.613823

Epoch 85/1000
Training Loss: 0.59791987, Training R2: 0.654260
Validation Loss: 0.66287938, Validation R2: 0.607010

Epoch 86/1000
Training Loss: 0.58183218, Training R2: 0.668720
Validation Loss: 0.69957926, Validation R2: 0.584687

Epoch 87/1000
Training Loss: 0.58384089, Training R2: 0.667172
Validation Loss: 0.63651865, Validation R2: 0.639831
Saved best model with validation R2 0.639831 to best_finetuned_model.pth

Epoch 88/1000
Training Loss: 0.56819493, Training R2: 0.678884
Validation Loss: 0.66616784, Validation R2: 0.630197

Epoch 89/1000
Training Loss: 0.57200980, Training R2: 0.675294
Validation Loss: 0.71813229, Validation R2: 0.588297

Epoch 90/1000
Training Loss: 0.60215421, Training R2: 0.655088
Validation Loss: 0.63084271, Validation R2: 0.642088
Saved best model with validation R2 0.642088 to best_finetuned_model.pth

Epoch 91/1000
Training Loss: 0.55707245, Training R2: 0.683558
Validation Loss: 0.63355031, Validation R2: 0.646700
Saved best model with validation R2 0.646700 to best_finetuned_model.pth

Epoch 92/1000
Training Loss: 0.55351846, Training R2: 0.689234
Validation Loss: 0.62968007, Validation R2: 0.645789

Epoch 93/1000
Training Loss: 0.55506463, Training R2: 0.690065
Validation Loss: 0.64452371, Validation R2: 0.631693

Epoch 94/1000
Training Loss: 0.55639373, Training R2: 0.689035
Validation Loss: 0.64081955, Validation R2: 0.638895

Epoch 95/1000
Training Loss: 0.56631891, Training R2: 0.682218
Validation Loss: 0.63832284, Validation R2: 0.646070

Epoch 96/1000
Training Loss: 0.56411620, Training R2: 0.684814
Validation Loss: 0.64187834, Validation R2: 0.640592

Epoch 97/1000
Training Loss: 0.59361051, Training R2: 0.661189
Validation Loss: 0.70901666, Validation R2: 0.572825

Epoch 98/1000
Training Loss: 0.57419294, Training R2: 0.683448
Validation Loss: 0.62426585, Validation R2: 0.655639
Saved best model with validation R2 0.655639 to best_finetuned_model.pth

Epoch 99/1000
Training Loss: 0.55229300, Training R2: 0.697300
Validation Loss: 0.65345528, Validation R2: 0.641831

Epoch 100/1000
Training Loss: 0.54681830, Training R2: 0.701022
Validation Loss: 0.61915782, Validation R2: 0.657352
Saved best model with validation R2 0.657352 to best_finetuned_model.pth

Epoch 101/1000
Training Loss: 0.54058693, Training R2: 0.704624
Validation Loss: 0.61775042, Validation R2: 0.663636
Saved best model with validation R2 0.663636 to best_finetuned_model.pth

Epoch 102/1000
Training Loss: 0.53432570, Training R2: 0.710983
Validation Loss: 0.65640068, Validation R2: 0.642233

Epoch 103/1000
Training Loss: 0.56528426, Training R2: 0.685671
Validation Loss: 0.64068957, Validation R2: 0.647356

Epoch 104/1000
Training Loss: 0.56555470, Training R2: 0.686213
Validation Loss: 0.64140931, Validation R2: 0.628268

Epoch 105/1000
Training Loss: 0.54131250, Training R2: 0.705674
Validation Loss: 0.61657788, Validation R2: 0.664558
Saved best model with validation R2 0.664558 to best_finetuned_model.pth

Epoch 106/1000
Training Loss: 0.53889174, Training R2: 0.708927
Validation Loss: 0.64374392, Validation R2: 0.641319

Epoch 107/1000
Training Loss: 0.53000837, Training R2: 0.714339
Validation Loss: 0.62097566, Validation R2: 0.659426

Epoch 108/1000
Training Loss: 0.52864737, Training R2: 0.714004
Validation Loss: 0.61601446, Validation R2: 0.670616
Saved best model with validation R2 0.670616 to best_finetuned_model.pth

Epoch 109/1000
Training Loss: 0.53354907, Training R2: 0.710851
Validation Loss: 0.66822063, Validation R2: 0.615693

Epoch 110/1000
Training Loss: 0.55062127, Training R2: 0.699684
Validation Loss: 0.64386504, Validation R2: 0.639351

Epoch 111/1000
Training Loss: 0.53935800, Training R2: 0.709491
Validation Loss: 0.59979694, Validation R2: 0.673055
Saved best model with validation R2 0.673055 to best_finetuned_model.pth

Epoch 112/1000
Training Loss: 0.53267172, Training R2: 0.714818
Validation Loss: 0.63163071, Validation R2: 0.649742

Epoch 113/1000
Training Loss: 0.54506598, Training R2: 0.705670
Validation Loss: 0.63006266, Validation R2: 0.653882

Epoch 114/1000
Training Loss: 0.52904106, Training R2: 0.717674
Validation Loss: 0.60596513, Validation R2: 0.674131
Saved best model with validation R2 0.674131 to best_finetuned_model.pth

Epoch 115/1000
Training Loss: 0.51680165, Training R2: 0.724351
Validation Loss: 0.64716236, Validation R2: 0.644892

Epoch 116/1000
Training Loss: 0.52421182, Training R2: 0.721060
Validation Loss: 0.61669677, Validation R2: 0.669160

Epoch 117/1000
Training Loss: 0.51628522, Training R2: 0.727003
Validation Loss: 0.62063236, Validation R2: 0.669191

Epoch 118/1000
Training Loss: 0.52575806, Training R2: 0.720184
Validation Loss: 0.60277816, Validation R2: 0.683296
Saved best model with validation R2 0.683296 to best_finetuned_model.pth

Epoch 119/1000
Training Loss: 0.51543172, Training R2: 0.730557
Validation Loss: 0.67587216, Validation R2: 0.610174

Epoch 120/1000
Training Loss: 0.54264333, Training R2: 0.713950
Validation Loss: 0.60984721, Validation R2: 0.668783

Epoch 121/1000
Training Loss: 0.52488202, Training R2: 0.723578
Validation Loss: 0.60017293, Validation R2: 0.682781

Epoch 122/1000
Training Loss: 0.51360623, Training R2: 0.736018
Validation Loss: 0.59386047, Validation R2: 0.690191
Saved best model with validation R2 0.690191 to best_finetuned_model.pth

Epoch 123/1000
Training Loss: 0.50520716, Training R2: 0.738339
Validation Loss: 0.61069861, Validation R2: 0.677853

Epoch 124/1000
Training Loss: 0.50157379, Training R2: 0.738723
Validation Loss: 0.61208482, Validation R2: 0.674322

Epoch 125/1000
Training Loss: 0.53206380, Training R2: 0.721105
Validation Loss: 0.64867113, Validation R2: 0.642545

Epoch 126/1000
Training Loss: 0.51642098, Training R2: 0.729515
Validation Loss: 0.59724470, Validation R2: 0.679366

Epoch 127/1000
Training Loss: 0.50793396, Training R2: 0.733676
Validation Loss: 0.61880538, Validation R2: 0.658526

Epoch 128/1000
Training Loss: 0.50685995, Training R2: 0.734034
Validation Loss: 0.60576232, Validation R2: 0.672620

Epoch 129/1000
Training Loss: 0.50759004, Training R2: 0.739991
Validation Loss: 0.62060112, Validation R2: 0.654195

Epoch 130/1000
Training Loss: 0.49159730, Training R2: 0.746790
Validation Loss: 0.60321157, Validation R2: 0.690038

Epoch 131/1000
Training Loss: 0.51070575, Training R2: 0.738588
Validation Loss: 0.60457376, Validation R2: 0.681227

Epoch 132/1000
Training Loss: 0.53098437, Training R2: 0.723387
Validation Loss: 0.64662034, Validation R2: 0.632458

Epoch 133/1000
Training Loss: 0.52421140, Training R2: 0.726662
Validation Loss: 0.61452616, Validation R2: 0.670225

Epoch 134/1000
Training Loss: 0.52185892, Training R2: 0.729237
Validation Loss: 0.58494103, Validation R2: 0.691619
Saved best model with validation R2 0.691619 to best_finetuned_model.pth

Epoch 135/1000
Training Loss: 0.50728464, Training R2: 0.740955
Validation Loss: 0.61267636, Validation R2: 0.671892

Epoch 136/1000
Training Loss: 0.49532889, Training R2: 0.749218
Validation Loss: 0.58936747, Validation R2: 0.686777

Epoch 137/1000
Training Loss: 0.48520399, Training R2: 0.752948
Validation Loss: 0.59113883, Validation R2: 0.684754

Epoch 138/1000
Training Loss: 0.47854740, Training R2: 0.758771
Validation Loss: 0.57697809, Validation R2: 0.699698
Saved best model with validation R2 0.699698 to best_finetuned_model.pth

Epoch 139/1000
Training Loss: 0.49423822, Training R2: 0.749779
Validation Loss: 0.61128630, Validation R2: 0.660552

Epoch 140/1000
Training Loss: 0.47613961, Training R2: 0.763825
Validation Loss: 0.62365818, Validation R2: 0.643048

Epoch 141/1000
Training Loss: 0.47856616, Training R2: 0.760865
Validation Loss: 0.60598360, Validation R2: 0.676919

Epoch 142/1000
Training Loss: 0.48541225, Training R2: 0.757520
Validation Loss: 0.67260527, Validation R2: 0.593836

Epoch 143/1000
Training Loss: 0.47987012, Training R2: 0.761369
Validation Loss: 0.59536102, Validation R2: 0.682525

Epoch 144/1000
Training Loss: 0.48621825, Training R2: 0.756237
Validation Loss: 0.58300345, Validation R2: 0.693357

Epoch 145/1000
Training Loss: 0.48816583, Training R2: 0.759049
Validation Loss: 0.59576611, Validation R2: 0.673260

Epoch 146/1000
Training Loss: 0.48168000, Training R2: 0.759534
Validation Loss: 0.63628671, Validation R2: 0.658553

Epoch 147/1000
Training Loss: 0.46583147, Training R2: 0.772298
Validation Loss: 0.59651746, Validation R2: 0.685072

Epoch 148/1000
Training Loss: 0.47356621, Training R2: 0.768404
Validation Loss: 0.59010332, Validation R2: 0.696182

Epoch 149/1000
Training Loss: 0.45065202, Training R2: 0.786154
Validation Loss: 0.59647770, Validation R2: 0.683724

Epoch 150/1000
Training Loss: 0.45230100, Training R2: 0.782740
Validation Loss: 0.62457970, Validation R2: 0.642257

Epoch 151/1000
Training Loss: 0.44809198, Training R2: 0.785606
Validation Loss: 0.59809382, Validation R2: 0.687903

Epoch 152/1000
Training Loss: 0.44727201, Training R2: 0.785573
Validation Loss: 0.58547620, Validation R2: 0.693037

Epoch 153/1000
Training Loss: 0.44809059, Training R2: 0.784204
Validation Loss: 0.58415678, Validation R2: 0.697798

Epoch 154/1000
Training Loss: 0.48447910, Training R2: 0.761204
Validation Loss: 0.61516020, Validation R2: 0.670628

Epoch 155/1000
Training Loss: 0.48283563, Training R2: 0.768366
Validation Loss: 0.59211855, Validation R2: 0.696968

Epoch 156/1000
Training Loss: 0.45245326, Training R2: 0.782995
Validation Loss: 0.59611601, Validation R2: 0.678169

Epoch 157/1000
Training Loss: 0.45086301, Training R2: 0.787804
Validation Loss: 0.60251494, Validation R2: 0.677128

Epoch 158/1000
Training Loss: 0.45833480, Training R2: 0.780383
Validation Loss: 0.66908700, Validation R2: 0.609695

Epoch 159/1000
Epoch 00159: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.47452634, Training R2: 0.769455
Validation Loss: 0.64280727, Validation R2: 0.663085

Epoch 160/1000
学习率已减少 1 次
Training Loss: 0.45366875, Training R2: 0.784344
Validation Loss: 0.58499458, Validation R2: 0.693261

Epoch 161/1000
Training Loss: 0.41605690, Training R2: 0.805681
Validation Loss: 0.60259781, Validation R2: 0.666486

Epoch 162/1000
Training Loss: 0.42400471, Training R2: 0.802334
Validation Loss: 0.60885719, Validation R2: 0.675534

Epoch 163/1000
Training Loss: 0.41414106, Training R2: 0.807089
Validation Loss: 0.58435661, Validation R2: 0.688824

Epoch 164/1000
Training Loss: 0.40771311, Training R2: 0.812321
Validation Loss: 0.58166844, Validation R2: 0.687487

Epoch 165/1000
Training Loss: 0.40954220, Training R2: 0.813314
Validation Loss: 0.60615441, Validation R2: 0.681249

Epoch 166/1000
Training Loss: 0.41458882, Training R2: 0.807497
Validation Loss: 0.59313480, Validation R2: 0.681381

Epoch 167/1000
Training Loss: 0.41667975, Training R2: 0.805479
Validation Loss: 0.58796664, Validation R2: 0.679038

Epoch 168/1000
Training Loss: 0.41108188, Training R2: 0.810254
Validation Loss: 0.59273356, Validation R2: 0.678766

Epoch 169/1000
Training Loss: 0.40227309, Training R2: 0.815296
Validation Loss: 0.59286380, Validation R2: 0.681839

Epoch 170/1000
Training Loss: 0.40009792, Training R2: 0.816253
Validation Loss: 0.59283874, Validation R2: 0.683559

Epoch 171/1000
Training Loss: 0.39927518, Training R2: 0.817583
Validation Loss: 0.59471739, Validation R2: 0.678677

Epoch 172/1000
Training Loss: 0.40351602, Training R2: 0.815192
Validation Loss: 0.58986433, Validation R2: 0.683984

Epoch 173/1000
Training Loss: 0.39939172, Training R2: 0.816553
Validation Loss: 0.58686018, Validation R2: 0.688941

Epoch 174/1000
Training Loss: 0.39681208, Training R2: 0.819034
Validation Loss: 0.60173745, Validation R2: 0.669544

Epoch 175/1000
Training Loss: 0.38832766, Training R2: 0.823856
Validation Loss: 0.59075363, Validation R2: 0.679604

Epoch 176/1000
Training Loss: 0.38783864, Training R2: 0.823102
Validation Loss: 0.59123464, Validation R2: 0.683286

Epoch 177/1000
Training Loss: 0.39115906, Training R2: 0.822546
Validation Loss: 0.58112238, Validation R2: 0.694070

Epoch 178/1000
Training Loss: 0.38984482, Training R2: 0.824431
Validation Loss: 0.58867323, Validation R2: 0.680988

Epoch 179/1000
Training Loss: 0.38589350, Training R2: 0.828680
Validation Loss: 0.59505148, Validation R2: 0.674297

Epoch 180/1000
Epoch 00180: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.38642068, Training R2: 0.824137
Validation Loss: 0.59313330, Validation R2: 0.678902

Epoch 181/1000
学习率已减少 2 次
Training Loss: 0.37435833, Training R2: 0.830903
Validation Loss: 0.58327279, Validation R2: 0.696132

Epoch 182/1000
Training Loss: 0.37754459, Training R2: 0.829698
Validation Loss: 0.57575484, Validation R2: 0.696688

Epoch 183/1000
Training Loss: 0.36899002, Training R2: 0.834189
Validation Loss: 0.58345664, Validation R2: 0.691846

Epoch 184/1000
Training Loss: 0.36842768, Training R2: 0.835284
Validation Loss: 0.58426977, Validation R2: 0.689439

Epoch 185/1000
Training Loss: 0.36847243, Training R2: 0.834373
Validation Loss: 0.59013761, Validation R2: 0.688568

Epoch 186/1000
Training Loss: 0.36953029, Training R2: 0.835543
Validation Loss: 0.59028238, Validation R2: 0.686944

Epoch 187/1000
Training Loss: 0.36761028, Training R2: 0.834412
Validation Loss: 0.58486170, Validation R2: 0.689349

Epoch 188/1000
Training Loss: 0.36385514, Training R2: 0.837948
Validation Loss: 0.59283417, Validation R2: 0.686238

Epoch 189/1000
Training Loss: 0.36188094, Training R2: 0.839269
Validation Loss: 0.58067021, Validation R2: 0.696387

Epoch 190/1000
Training Loss: 0.35911140, Training R2: 0.840101
Validation Loss: 0.57233687, Validation R2: 0.707315
Saved best model with validation R2 0.707315 to best_finetuned_model.pth

Epoch 191/1000
Training Loss: 0.35630867, Training R2: 0.840339
Validation Loss: 0.58722534, Validation R2: 0.686652

Epoch 192/1000
Training Loss: 0.35868511, Training R2: 0.840507
Validation Loss: 0.58445577, Validation R2: 0.690648

Epoch 193/1000
Training Loss: 0.35861226, Training R2: 0.840327
Validation Loss: 0.58845920, Validation R2: 0.691628

Epoch 194/1000
Training Loss: 0.35700490, Training R2: 0.841656
Validation Loss: 0.58433708, Validation R2: 0.692422

Epoch 195/1000
Training Loss: 0.35862238, Training R2: 0.841740
Validation Loss: 0.58149227, Validation R2: 0.694790

Epoch 196/1000
Training Loss: 0.35824165, Training R2: 0.841244
Validation Loss: 0.58638676, Validation R2: 0.691484

Epoch 197/1000
Training Loss: 0.35009673, Training R2: 0.845101
Validation Loss: 0.59175239, Validation R2: 0.686862

Epoch 198/1000
Training Loss: 0.35037102, Training R2: 0.845072
Validation Loss: 0.58305837, Validation R2: 0.695347

Epoch 199/1000
Training Loss: 0.35067663, Training R2: 0.845543
Validation Loss: 0.58406331, Validation R2: 0.693392

Epoch 200/1000
Training Loss: 0.35262555, Training R2: 0.844514
Validation Loss: 0.59055404, Validation R2: 0.685784

Epoch 201/1000
Training Loss: 0.35061619, Training R2: 0.844725
Validation Loss: 0.58844855, Validation R2: 0.690098

Epoch 202/1000
Training Loss: 0.35279448, Training R2: 0.845945
Validation Loss: 0.60153651, Validation R2: 0.678625

Epoch 203/1000
Training Loss: 0.35944995, Training R2: 0.843362
Validation Loss: 0.57749270, Validation R2: 0.699161

Epoch 204/1000
Training Loss: 0.34737570, Training R2: 0.847779
Validation Loss: 0.59084009, Validation R2: 0.686152

Epoch 205/1000
Training Loss: 0.34866916, Training R2: 0.847813
Validation Loss: 0.58311210, Validation R2: 0.696281

Epoch 206/1000
Training Loss: 0.34355090, Training R2: 0.850434
Validation Loss: 0.58754996, Validation R2: 0.691469

Epoch 207/1000
Training Loss: 0.34518041, Training R2: 0.849071
Validation Loss: 0.59074061, Validation R2: 0.688280

Epoch 208/1000
Training Loss: 0.34067642, Training R2: 0.851775
Validation Loss: 0.59082872, Validation R2: 0.682231

Epoch 209/1000
Training Loss: 0.34153932, Training R2: 0.851616
Validation Loss: 0.59495075, Validation R2: 0.687126

Epoch 210/1000
Training Loss: 0.34435933, Training R2: 0.849992
Validation Loss: 0.59494325, Validation R2: 0.683126

Epoch 211/1000
Epoch 00211: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.34674675, Training R2: 0.850617
Validation Loss: 0.59270511, Validation R2: 0.686319

Epoch 212/1000
学习率已减少 3 次
Training Loss: 0.33402478, Training R2: 0.855312
Validation Loss: 0.59117540, Validation R2: 0.687308

Epoch 213/1000
Training Loss: 0.33146884, Training R2: 0.854895
Validation Loss: 0.59647972, Validation R2: 0.681752

Epoch 214/1000
Training Loss: 0.33059537, Training R2: 0.855947
Validation Loss: 0.58869898, Validation R2: 0.690060

Epoch 215/1000
Training Loss: 0.32896383, Training R2: 0.856359
Validation Loss: 0.58956447, Validation R2: 0.690476

Epoch 216/1000
Training Loss: 0.32671235, Training R2: 0.857805
Validation Loss: 0.59105085, Validation R2: 0.688916

Epoch 217/1000
Training Loss: 0.32942388, Training R2: 0.856929
Validation Loss: 0.59069983, Validation R2: 0.687857

Epoch 218/1000
Training Loss: 0.32535096, Training R2: 0.858320
Validation Loss: 0.58978833, Validation R2: 0.687066

Epoch 219/1000
Training Loss: 0.32261674, Training R2: 0.859743
Validation Loss: 0.58952016, Validation R2: 0.688686

Epoch 220/1000
Training Loss: 0.32470012, Training R2: 0.857884
Validation Loss: 0.59302526, Validation R2: 0.684940

Epoch 221/1000
Training Loss: 0.32270457, Training R2: 0.859024
Validation Loss: 0.59239241, Validation R2: 0.685369

Epoch 222/1000
Training Loss: 0.32129782, Training R2: 0.859669
Validation Loss: 0.59005034, Validation R2: 0.689329

Epoch 223/1000
Training Loss: 0.32403616, Training R2: 0.859493
Validation Loss: 0.59133893, Validation R2: 0.686889

Epoch 224/1000
Training Loss: 0.31992287, Training R2: 0.860820
Validation Loss: 0.58984657, Validation R2: 0.689515

Epoch 225/1000
Training Loss: 0.32343613, Training R2: 0.859982
Validation Loss: 0.59455068, Validation R2: 0.684657

Epoch 226/1000
Training Loss: 0.32652202, Training R2: 0.859612
Validation Loss: 0.59300635, Validation R2: 0.686452

Epoch 227/1000
Training Loss: 0.32410895, Training R2: 0.860493
Validation Loss: 0.59231386, Validation R2: 0.684599

Epoch 228/1000
Training Loss: 0.32398856, Training R2: 0.860775
Validation Loss: 0.59143923, Validation R2: 0.685873

Epoch 229/1000
Training Loss: 0.32019481, Training R2: 0.862225
Validation Loss: 0.59532210, Validation R2: 0.682979

Epoch 230/1000
Training Loss: 0.31739062, Training R2: 0.862781
Validation Loss: 0.59128485, Validation R2: 0.685537

Epoch 231/1000
Training Loss: 0.31705413, Training R2: 0.863642
Validation Loss: 0.59312397, Validation R2: 0.686097

Epoch 232/1000
Epoch 00232: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.31898228, Training R2: 0.861951
Validation Loss: 0.58978056, Validation R2: 0.689667

Epoch 233/1000
学习率已减少 4 次
Training Loss: 0.31382771, Training R2: 0.863819
Validation Loss: 0.59285472, Validation R2: 0.685658

Epoch 234/1000
Training Loss: 0.31161874, Training R2: 0.864910
Validation Loss: 0.58845655, Validation R2: 0.689006

Epoch 235/1000
Training Loss: 0.31170267, Training R2: 0.865201
Validation Loss: 0.59657380, Validation R2: 0.682403

Epoch 236/1000
Training Loss: 0.30934577, Training R2: 0.865429
Validation Loss: 0.58990540, Validation R2: 0.688271

Epoch 237/1000
Training Loss: 0.30974687, Training R2: 0.865305
Validation Loss: 0.59402874, Validation R2: 0.685212

Epoch 238/1000
Training Loss: 0.31337442, Training R2: 0.865192
Validation Loss: 0.59397649, Validation R2: 0.685049

Epoch 239/1000
Training Loss: 0.30825630, Training R2: 0.865487
Validation Loss: 0.59092544, Validation R2: 0.687646

Epoch 240/1000
Training Loss: 0.30803933, Training R2: 0.866459
Validation Loss: 0.59027603, Validation R2: 0.687097

Epoch 241/1000
Training Loss: 0.30926339, Training R2: 0.865712
Validation Loss: 0.59345104, Validation R2: 0.684727

Epoch 242/1000
Training Loss: 0.30827309, Training R2: 0.866619
Validation Loss: 0.59403248, Validation R2: 0.684259

Epoch 243/1000
Training Loss: 0.30847937, Training R2: 0.866601
Validation Loss: 0.58946727, Validation R2: 0.687988

Epoch 244/1000
Training Loss: 0.30902203, Training R2: 0.866479
Validation Loss: 0.59219613, Validation R2: 0.685865

Epoch 245/1000
Training Loss: 0.30791477, Training R2: 0.866435
Validation Loss: 0.59122247, Validation R2: 0.687439

Epoch 246/1000
Training Loss: 0.30745455, Training R2: 0.866964
Validation Loss: 0.59190177, Validation R2: 0.688432

Epoch 247/1000
Training Loss: 0.30736361, Training R2: 0.866980
Validation Loss: 0.59529395, Validation R2: 0.683146

Epoch 248/1000
Training Loss: 0.30589950, Training R2: 0.867520
Validation Loss: 0.59237673, Validation R2: 0.685340

Epoch 249/1000
Training Loss: 0.30440561, Training R2: 0.868157
Validation Loss: 0.59276113, Validation R2: 0.685657

Epoch 250/1000
Training Loss: 0.30579324, Training R2: 0.867378
Validation Loss: 0.59341923, Validation R2: 0.684873

Epoch 251/1000
Training Loss: 0.30400979, Training R2: 0.868447
Validation Loss: 0.59078081, Validation R2: 0.688315

Epoch 252/1000
Training Loss: 0.30268376, Training R2: 0.868365
Validation Loss: 0.59010391, Validation R2: 0.688055

Epoch 253/1000
Epoch 00253: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.30234260, Training R2: 0.868684
Validation Loss: 0.59130089, Validation R2: 0.687727

Epoch 254/1000
学习率已减少 5 次
Training Loss: 0.30052115, Training R2: 0.869022
Validation Loss: 0.59237935, Validation R2: 0.687213

Epoch 255/1000
Training Loss: 0.29992193, Training R2: 0.869325
Validation Loss: 0.59248502, Validation R2: 0.686933

Epoch 256/1000
Training Loss: 0.30042004, Training R2: 0.869114
Validation Loss: 0.59335136, Validation R2: 0.685565

Epoch 257/1000
Training Loss: 0.30002602, Training R2: 0.869271
Validation Loss: 0.59305043, Validation R2: 0.686070

Epoch 258/1000
Training Loss: 0.30004527, Training R2: 0.869338
Validation Loss: 0.59106812, Validation R2: 0.687984

Epoch 259/1000
Training Loss: 0.29891298, Training R2: 0.869617
Validation Loss: 0.59209482, Validation R2: 0.686800

Epoch 260/1000
Training Loss: 0.29939783, Training R2: 0.869710
Validation Loss: 0.59264683, Validation R2: 0.685759

Epoch 261/1000
Training Loss: 0.29879359, Training R2: 0.869775
Validation Loss: 0.59356919, Validation R2: 0.685206

Epoch 262/1000
Training Loss: 0.29881204, Training R2: 0.869686
Validation Loss: 0.59181974, Validation R2: 0.686924

Epoch 263/1000
Training Loss: 0.29870651, Training R2: 0.870222
Validation Loss: 0.59398504, Validation R2: 0.685343

Epoch 264/1000
Training Loss: 0.29937744, Training R2: 0.869889
Validation Loss: 0.59349127, Validation R2: 0.684694

Epoch 265/1000
Training Loss: 0.29974797, Training R2: 0.870109
Validation Loss: 0.59101331, Validation R2: 0.687580

Epoch 266/1000
Training Loss: 0.29977974, Training R2: 0.869881
Validation Loss: 0.59324371, Validation R2: 0.685741

Epoch 267/1000
Training Loss: 0.29808216, Training R2: 0.870213
Validation Loss: 0.59354748, Validation R2: 0.685691

Epoch 268/1000
Training Loss: 0.29775145, Training R2: 0.870265
Validation Loss: 0.59472458, Validation R2: 0.685220

Epoch 269/1000
Training Loss: 0.29768858, Training R2: 0.870244
Validation Loss: 0.59332047, Validation R2: 0.686004

Epoch 270/1000
Training Loss: 0.29828348, Training R2: 0.870374
Validation Loss: 0.59423494, Validation R2: 0.685282

Epoch 271/1000
Training Loss: 0.29714764, Training R2: 0.870406
Validation Loss: 0.59372325, Validation R2: 0.685471

Epoch 272/1000
Training Loss: 0.29799158, Training R2: 0.870544
Validation Loss: 0.59372504, Validation R2: 0.684130

Epoch 273/1000
Training Loss: 0.29611997, Training R2: 0.870915
Validation Loss: 0.59389435, Validation R2: 0.684882

Epoch 274/1000
Epoch 00274: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.29632970, Training R2: 0.870776
Validation Loss: 0.59484096, Validation R2: 0.684027

Epoch 275/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
