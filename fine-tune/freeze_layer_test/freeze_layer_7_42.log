Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.27577079, Training R2: -0.256920
Validation Loss: 1.15183747, Validation R2: -0.040494
Saved best model with validation R2 -0.040494 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.17520630, Training R2: -0.162993
Validation Loss: 1.14551985, Validation R2: -0.055201

Epoch 3/1000
Training Loss: 1.12138838, Training R2: 0.005681
Validation Loss: 1.11831105, Validation R2: 0.032360
Saved best model with validation R2 0.032360 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.08982480, Training R2: 0.004455
Validation Loss: 1.09755003, Validation R2: 0.030698

Epoch 5/1000
Training Loss: 1.07317221, Training R2: 0.081407
Validation Loss: 1.07270527, Validation R2: 0.060379
Saved best model with validation R2 0.060379 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.04247145, Training R2: 0.059433
Validation Loss: 1.06024635, Validation R2: 0.128117
Saved best model with validation R2 0.128117 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 1.08012538, Training R2: 0.110993
Validation Loss: 1.08652878, Validation R2: 0.003423

Epoch 8/1000
Training Loss: 1.05111918, Training R2: 0.042887
Validation Loss: 1.05768454, Validation R2: 0.083578

Epoch 9/1000
Training Loss: 1.00888092, Training R2: 0.138317
Validation Loss: 1.04546213, Validation R2: 0.120098

Epoch 10/1000
Training Loss: 1.00038632, Training R2: 0.158413
Validation Loss: 1.03447342, Validation R2: 0.141580
Saved best model with validation R2 0.141580 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 0.99564610, Training R2: 0.185277
Validation Loss: 1.02516639, Validation R2: 0.127161

Epoch 12/1000
Training Loss: 0.98237192, Training R2: 0.191240
Validation Loss: 1.01858985, Validation R2: 0.122340

Epoch 13/1000
Training Loss: 0.98067255, Training R2: 0.184577
Validation Loss: 1.04960847, Validation R2: 0.143489
Saved best model with validation R2 0.143489 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 1.00452168, Training R2: 0.190382
Validation Loss: 1.00961089, Validation R2: 0.125508

Epoch 15/1000
Training Loss: 0.95178560, Training R2: 0.232823
Validation Loss: 0.99311805, Validation R2: 0.194455
Saved best model with validation R2 0.194455 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 0.95775076, Training R2: 0.220368
Validation Loss: 0.96805722, Validation R2: 0.226959
Saved best model with validation R2 0.226959 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.92345087, Training R2: 0.287028
Validation Loss: 1.12662828, Validation R2: -0.054613

Epoch 18/1000
Training Loss: 0.97627612, Training R2: 0.216789
Validation Loss: 0.95364994, Validation R2: 0.243053
Saved best model with validation R2 0.243053 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.87884916, Training R2: 0.316451
Validation Loss: 0.96569699, Validation R2: 0.226760

Epoch 20/1000
Training Loss: 0.90125671, Training R2: 0.317896
Validation Loss: 0.95448440, Validation R2: 0.201159

Epoch 21/1000
Training Loss: 0.88324749, Training R2: 0.314966
Validation Loss: 0.92773724, Validation R2: 0.241224

Epoch 22/1000
Training Loss: 0.90660205, Training R2: 0.289485
Validation Loss: 1.01798165, Validation R2: 0.171886

Epoch 23/1000
Training Loss: 0.91233562, Training R2: 0.296650
Validation Loss: 1.08073688, Validation R2: 0.027419

Epoch 24/1000
Training Loss: 0.92918838, Training R2: 0.231773
Validation Loss: 1.01941931, Validation R2: 0.173823

Epoch 25/1000
Training Loss: 0.91065415, Training R2: 0.300238
Validation Loss: 1.31851792, Validation R2: -0.319044

Epoch 26/1000
Training Loss: 1.18334857, Training R2: -0.074295
Validation Loss: 0.96522719, Validation R2: 0.236484

Epoch 27/1000
Training Loss: 0.98520521, Training R2: 0.231258
Validation Loss: 0.92688787, Validation R2: 0.265993
Saved best model with validation R2 0.265993 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 0.91642785, Training R2: 0.255288
Validation Loss: 0.99381942, Validation R2: 0.154942

Epoch 29/1000
Training Loss: 0.88866287, Training R2: 0.305320
Validation Loss: 0.95103824, Validation R2: 0.256353

Epoch 30/1000
Training Loss: 0.88567639, Training R2: 0.343947
Validation Loss: 0.86786419, Validation R2: 0.316638
Saved best model with validation R2 0.316638 to best_finetuned_model.pth

Epoch 31/1000
Training Loss: 0.80072909, Training R2: 0.424529
Validation Loss: 0.88944763, Validation R2: 0.274499

Epoch 32/1000
Training Loss: 0.79913329, Training R2: 0.416694
Validation Loss: 0.87719470, Validation R2: 0.278908

Epoch 33/1000
Training Loss: 0.77921670, Training R2: 0.436667
Validation Loss: 0.85673016, Validation R2: 0.309720

Epoch 34/1000
Training Loss: 0.76720760, Training R2: 0.443476
Validation Loss: 0.87095267, Validation R2: 0.297475

Epoch 35/1000
Training Loss: 0.77466796, Training R2: 0.437752
Validation Loss: 0.85605311, Validation R2: 0.310938

Epoch 36/1000
Training Loss: 0.75844804, Training R2: 0.455780
Validation Loss: 0.84071714, Validation R2: 0.320336
Saved best model with validation R2 0.320336 to best_finetuned_model.pth

Epoch 37/1000
Training Loss: 0.76242195, Training R2: 0.449628
Validation Loss: 0.85053831, Validation R2: 0.321652
Saved best model with validation R2 0.321652 to best_finetuned_model.pth

Epoch 38/1000
Training Loss: 0.75332878, Training R2: 0.455161
Validation Loss: 0.84519583, Validation R2: 0.337908
Saved best model with validation R2 0.337908 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.75894287, Training R2: 0.447021
Validation Loss: 0.87047875, Validation R2: 0.318470

Epoch 40/1000
Training Loss: 0.76131441, Training R2: 0.443653
Validation Loss: 0.89256805, Validation R2: 0.267516

Epoch 41/1000
Training Loss: 0.77099597, Training R2: 0.423199
Validation Loss: 0.86993527, Validation R2: 0.311838

Epoch 42/1000
Training Loss: 0.75907485, Training R2: 0.448672
Validation Loss: 0.84554005, Validation R2: 0.325876

Epoch 43/1000
Training Loss: 0.73756115, Training R2: 0.474552
Validation Loss: 0.84819889, Validation R2: 0.315968

Epoch 44/1000
Training Loss: 0.74220697, Training R2: 0.457995
Validation Loss: 0.88032317, Validation R2: 0.298105

Epoch 45/1000
Training Loss: 0.81119564, Training R2: 0.387611
Validation Loss: 0.84576404, Validation R2: 0.330192

Epoch 46/1000
Training Loss: 0.74675936, Training R2: 0.461139
Validation Loss: 0.81847835, Validation R2: 0.353457
Saved best model with validation R2 0.353457 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.74876555, Training R2: 0.453723
Validation Loss: 0.84658366, Validation R2: 0.354778
Saved best model with validation R2 0.354778 to best_finetuned_model.pth

Epoch 48/1000
Training Loss: 0.75533656, Training R2: 0.467502
Validation Loss: 0.85783088, Validation R2: 0.308202

Epoch 49/1000
Training Loss: 0.73061651, Training R2: 0.462476
Validation Loss: 0.86950547, Validation R2: 0.301946

Epoch 50/1000
Training Loss: 0.75074422, Training R2: 0.459030
Validation Loss: 0.90049809, Validation R2: 0.257519

Epoch 51/1000
Training Loss: 0.73880209, Training R2: 0.464801
Validation Loss: 0.85362625, Validation R2: 0.316131

Epoch 52/1000
Training Loss: 0.73661583, Training R2: 0.461475
Validation Loss: 0.89055848, Validation R2: 0.260185

Epoch 53/1000
Training Loss: 0.77476902, Training R2: 0.415940
Validation Loss: 0.85057342, Validation R2: 0.334605

Epoch 54/1000
Training Loss: 0.73940798, Training R2: 0.464928
Validation Loss: 0.88660789, Validation R2: 0.274003

Epoch 55/1000
Training Loss: 0.72771158, Training R2: 0.465287
Validation Loss: 0.88665390, Validation R2: 0.291131

Epoch 56/1000
Training Loss: 0.73577132, Training R2: 0.470427
Validation Loss: 0.91155660, Validation R2: 0.233416

Epoch 57/1000
Training Loss: 0.74286045, Training R2: 0.453687
Validation Loss: 0.84629637, Validation R2: 0.327944

Epoch 58/1000
Training Loss: 0.72019519, Training R2: 0.478930
Validation Loss: 0.83019191, Validation R2: 0.330408

Epoch 59/1000
Training Loss: 0.72417142, Training R2: 0.483529
Validation Loss: 0.88108867, Validation R2: 0.281093

Epoch 60/1000
Training Loss: 0.73946951, Training R2: 0.468414
Validation Loss: 0.81820542, Validation R2: 0.356443
Saved best model with validation R2 0.356443 to best_finetuned_model.pth

Epoch 61/1000
Training Loss: 0.70545953, Training R2: 0.504870
Validation Loss: 0.86015546, Validation R2: 0.319224

Epoch 62/1000
Training Loss: 0.72641396, Training R2: 0.486186
Validation Loss: 0.84717739, Validation R2: 0.328711

Epoch 63/1000
Training Loss: 0.72542216, Training R2: 0.492824
Validation Loss: 0.85907948, Validation R2: 0.296522

Epoch 64/1000
Training Loss: 0.69892906, Training R2: 0.501167
Validation Loss: 0.84972769, Validation R2: 0.325172

Epoch 65/1000
Training Loss: 0.69938603, Training R2: 0.500186
Validation Loss: 0.83745354, Validation R2: 0.342038

Epoch 66/1000
Training Loss: 0.68718493, Training R2: 0.516275
Validation Loss: 0.87073243, Validation R2: 0.289111

Epoch 67/1000
Training Loss: 0.69566829, Training R2: 0.499761
Validation Loss: 0.84671795, Validation R2: 0.321927

Epoch 68/1000
Training Loss: 0.69503528, Training R2: 0.502020
Validation Loss: 0.84440398, Validation R2: 0.325555

Epoch 69/1000
Training Loss: 0.66892601, Training R2: 0.525741
Validation Loss: 0.83714765, Validation R2: 0.342090

Epoch 70/1000
Training Loss: 0.66870792, Training R2: 0.528712
Validation Loss: 0.82810348, Validation R2: 0.343271

Epoch 71/1000
Training Loss: 0.67933762, Training R2: 0.522304
Validation Loss: 0.82893157, Validation R2: 0.343196

Epoch 72/1000
Training Loss: 0.69317068, Training R2: 0.512254
Validation Loss: 0.84445775, Validation R2: 0.343866

Epoch 73/1000
Training Loss: 0.72004056, Training R2: 0.496288
Validation Loss: 0.84856641, Validation R2: 0.314985

Epoch 74/1000
Training Loss: 0.68819607, Training R2: 0.517100
Validation Loss: 0.82117140, Validation R2: 0.337387

Epoch 75/1000
Training Loss: 0.66712702, Training R2: 0.527276
Validation Loss: 0.84722328, Validation R2: 0.316429

Epoch 76/1000
Training Loss: 0.68011649, Training R2: 0.516181
Validation Loss: 0.81897748, Validation R2: 0.361108
Saved best model with validation R2 0.361108 to best_finetuned_model.pth

Epoch 77/1000
Training Loss: 0.67212722, Training R2: 0.527211
Validation Loss: 0.82220715, Validation R2: 0.362082
Saved best model with validation R2 0.362082 to best_finetuned_model.pth

Epoch 78/1000
Training Loss: 0.69344240, Training R2: 0.520567
Validation Loss: 0.87425190, Validation R2: 0.280028

Epoch 79/1000
Training Loss: 0.71512125, Training R2: 0.484755
Validation Loss: 0.83634824, Validation R2: 0.354454

Epoch 80/1000
Training Loss: 0.70144400, Training R2: 0.505297
Validation Loss: 0.85499531, Validation R2: 0.330153

Epoch 81/1000
Training Loss: 0.67944840, Training R2: 0.530736
Validation Loss: 0.86649281, Validation R2: 0.295691

Epoch 82/1000
Training Loss: 0.71821647, Training R2: 0.488492
Validation Loss: 0.83789802, Validation R2: 0.314075

Epoch 83/1000
Training Loss: 0.69242506, Training R2: 0.520868
Validation Loss: 0.86558259, Validation R2: 0.300850

Epoch 84/1000
Training Loss: 0.67001710, Training R2: 0.528964
Validation Loss: 0.81939918, Validation R2: 0.352083

Epoch 85/1000
Training Loss: 0.67320716, Training R2: 0.528326
Validation Loss: 0.79417706, Validation R2: 0.375872
Saved best model with validation R2 0.375872 to best_finetuned_model.pth

Epoch 86/1000
Training Loss: 0.67740662, Training R2: 0.529101
Validation Loss: 0.81281185, Validation R2: 0.364127

Epoch 87/1000
Training Loss: 0.67994131, Training R2: 0.522350
Validation Loss: 0.83450156, Validation R2: 0.350218

Epoch 88/1000
Training Loss: 0.67719063, Training R2: 0.529908
Validation Loss: 0.82937771, Validation R2: 0.340623

Epoch 89/1000
Training Loss: 0.67832025, Training R2: 0.519192
Validation Loss: 0.80444270, Validation R2: 0.374635

Epoch 90/1000
Training Loss: 0.67904379, Training R2: 0.524406
Validation Loss: 0.78825349, Validation R2: 0.397247
Saved best model with validation R2 0.397247 to best_finetuned_model.pth

Epoch 91/1000
Training Loss: 0.65530676, Training R2: 0.541091
Validation Loss: 0.80883223, Validation R2: 0.367696

Epoch 92/1000
Training Loss: 0.65214402, Training R2: 0.536514
Validation Loss: 0.80783081, Validation R2: 0.352230

Epoch 93/1000
Training Loss: 0.66235753, Training R2: 0.530713
Validation Loss: 0.79002178, Validation R2: 0.384291

Epoch 94/1000
Training Loss: 0.64639433, Training R2: 0.550635
Validation Loss: 0.81311041, Validation R2: 0.375514

Epoch 95/1000
Training Loss: 0.66341671, Training R2: 0.540036
Validation Loss: 0.85267287, Validation R2: 0.359811

Epoch 96/1000
Training Loss: 0.74197247, Training R2: 0.489505
Validation Loss: 0.84626067, Validation R2: 0.346749

Epoch 97/1000
Training Loss: 0.68474010, Training R2: 0.520450
Validation Loss: 0.78390819, Validation R2: 0.389823

Epoch 98/1000
Training Loss: 0.64913263, Training R2: 0.545303
Validation Loss: 0.77463937, Validation R2: 0.380886

Epoch 99/1000
Training Loss: 0.64332947, Training R2: 0.551722
Validation Loss: 0.81205136, Validation R2: 0.365986

Epoch 100/1000
Training Loss: 0.65669518, Training R2: 0.546251
Validation Loss: 0.78834003, Validation R2: 0.383523

Epoch 101/1000
Training Loss: 0.64408980, Training R2: 0.553729
Validation Loss: 0.84916121, Validation R2: 0.330309

Epoch 102/1000
Training Loss: 0.66428399, Training R2: 0.541515
Validation Loss: 0.80829811, Validation R2: 0.361880

Epoch 103/1000
Training Loss: 0.64917364, Training R2: 0.546956
Validation Loss: 0.80978537, Validation R2: 0.364664

Epoch 104/1000
Training Loss: 0.64972440, Training R2: 0.544004
Validation Loss: 0.79822892, Validation R2: 0.378297

Epoch 105/1000
Training Loss: 0.66608642, Training R2: 0.536635
Validation Loss: 0.77609551, Validation R2: 0.398421
Saved best model with validation R2 0.398421 to best_finetuned_model.pth

Epoch 106/1000
Training Loss: 0.63540200, Training R2: 0.560695
Validation Loss: 0.79101896, Validation R2: 0.382851

Epoch 107/1000
Training Loss: 0.62830121, Training R2: 0.562812
Validation Loss: 0.80377400, Validation R2: 0.356628

Epoch 108/1000
Training Loss: 0.61698032, Training R2: 0.568605
Validation Loss: 0.79238141, Validation R2: 0.357702

Epoch 109/1000
Training Loss: 0.62342491, Training R2: 0.566246
Validation Loss: 0.78647792, Validation R2: 0.371208

Epoch 110/1000
Training Loss: 0.62339122, Training R2: 0.568796
Validation Loss: 0.77281982, Validation R2: 0.385833

Epoch 111/1000
Training Loss: 0.62477046, Training R2: 0.568986
Validation Loss: 0.84665513, Validation R2: 0.329400

Epoch 112/1000
Training Loss: 0.64535058, Training R2: 0.551687
Validation Loss: 0.78897619, Validation R2: 0.386999

Epoch 113/1000
Training Loss: 0.64749117, Training R2: 0.553092
Validation Loss: 0.79021102, Validation R2: 0.366034

Epoch 114/1000
Training Loss: 0.63643285, Training R2: 0.554073
Validation Loss: 0.81604981, Validation R2: 0.342740

Epoch 115/1000
Training Loss: 0.63826222, Training R2: 0.566905
Validation Loss: 0.77753216, Validation R2: 0.386322

Epoch 116/1000
Training Loss: 0.60129842, Training R2: 0.585423
Validation Loss: 0.77845383, Validation R2: 0.390140

Epoch 117/1000
Training Loss: 0.60720822, Training R2: 0.585595
Validation Loss: 0.80112958, Validation R2: 0.349926

Epoch 118/1000
Training Loss: 0.63007369, Training R2: 0.572407
Validation Loss: 0.78610569, Validation R2: 0.365164

Epoch 119/1000
Training Loss: 0.61082446, Training R2: 0.582107
Validation Loss: 0.79324692, Validation R2: 0.370414

Epoch 120/1000
Training Loss: 0.61285655, Training R2: 0.580680
Validation Loss: 0.77652234, Validation R2: 0.364964

Epoch 121/1000
Training Loss: 0.63768268, Training R2: 0.562134
Validation Loss: 0.82510024, Validation R2: 0.351805

Epoch 122/1000
Training Loss: 0.62832199, Training R2: 0.573789
Validation Loss: 0.76979381, Validation R2: 0.391693

Epoch 123/1000
Training Loss: 0.62132324, Training R2: 0.581659
Validation Loss: 0.77574295, Validation R2: 0.356910

Epoch 124/1000
Training Loss: 0.60492419, Training R2: 0.585706
Validation Loss: 0.84600234, Validation R2: 0.300838

Epoch 125/1000
Training Loss: 0.62630214, Training R2: 0.569033
Validation Loss: 0.79062921, Validation R2: 0.348491

Epoch 126/1000
Epoch 00126: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.61502195, Training R2: 0.581507
Validation Loss: 0.78313190, Validation R2: 0.371739

Epoch 127/1000
学习率已减少 1 次
Training Loss: 0.60055754, Training R2: 0.591386
Validation Loss: 0.78736335, Validation R2: 0.359353

Epoch 128/1000
Training Loss: 0.61798181, Training R2: 0.575986
Validation Loss: 0.77701527, Validation R2: 0.355131

Epoch 129/1000
Training Loss: 0.61250398, Training R2: 0.587010
Validation Loss: 0.76346612, Validation R2: 0.374217

Epoch 130/1000
Training Loss: 0.58509462, Training R2: 0.601666
Validation Loss: 0.76694214, Validation R2: 0.372496

Epoch 131/1000
Training Loss: 0.57794366, Training R2: 0.606981
Validation Loss: 0.77159196, Validation R2: 0.351364

Epoch 132/1000
Training Loss: 0.57589914, Training R2: 0.613097
Validation Loss: 0.78179008, Validation R2: 0.350967

Epoch 133/1000
Training Loss: 0.57572110, Training R2: 0.605943
Validation Loss: 0.78976285, Validation R2: 0.342447

Epoch 134/1000
Training Loss: 0.58424649, Training R2: 0.605308
Validation Loss: 0.78445172, Validation R2: 0.346909

Epoch 135/1000
Training Loss: 0.57614338, Training R2: 0.612819
Validation Loss: 0.77906555, Validation R2: 0.345332

Epoch 136/1000
Training Loss: 0.58413041, Training R2: 0.606419
Validation Loss: 0.79403728, Validation R2: 0.350843

Epoch 137/1000
Training Loss: 0.58608558, Training R2: 0.601954
Validation Loss: 0.78850186, Validation R2: 0.346234

Epoch 138/1000
Training Loss: 0.60124782, Training R2: 0.598238
Validation Loss: 0.79557538, Validation R2: 0.340508

Epoch 139/1000
Training Loss: 0.57817987, Training R2: 0.609934
Validation Loss: 0.79656667, Validation R2: 0.316171

Epoch 140/1000
Training Loss: 0.58195747, Training R2: 0.612065
Validation Loss: 0.80000234, Validation R2: 0.341944

Epoch 141/1000
Training Loss: 0.58921389, Training R2: 0.603076
Validation Loss: 0.77504528, Validation R2: 0.367844

Epoch 142/1000
Training Loss: 0.57542330, Training R2: 0.613632
Validation Loss: 0.76834631, Validation R2: 0.361892

Epoch 143/1000
Training Loss: 0.56155057, Training R2: 0.620404
Validation Loss: 0.78875679, Validation R2: 0.331202

Epoch 144/1000
Training Loss: 0.57795131, Training R2: 0.611424
Validation Loss: 0.82495457, Validation R2: 0.319546

Epoch 145/1000
Training Loss: 0.59315683, Training R2: 0.599231
Validation Loss: 0.77927893, Validation R2: 0.360889

Epoch 146/1000
Training Loss: 0.56993731, Training R2: 0.616262
Validation Loss: 0.76744241, Validation R2: 0.353940

Epoch 147/1000
Epoch 00147: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.57724311, Training R2: 0.607031
Validation Loss: 0.77856827, Validation R2: 0.343001

Epoch 148/1000
学习率已减少 2 次
Training Loss: 0.55798466, Training R2: 0.622597
Validation Loss: 0.77641279, Validation R2: 0.353536

Epoch 149/1000
Training Loss: 0.54876492, Training R2: 0.629899
Validation Loss: 0.78161865, Validation R2: 0.340925

Epoch 150/1000
Training Loss: 0.55067951, Training R2: 0.630073
Validation Loss: 0.78798598, Validation R2: 0.325065

Epoch 151/1000
Training Loss: 0.54722921, Training R2: 0.630135
Validation Loss: 0.79216915, Validation R2: 0.314850

Epoch 152/1000
Training Loss: 0.55008024, Training R2: 0.630140
Validation Loss: 0.78988081, Validation R2: 0.321755

Epoch 153/1000
Training Loss: 0.54617604, Training R2: 0.633482
Validation Loss: 0.78436506, Validation R2: 0.341446

Epoch 154/1000
Training Loss: 0.54730927, Training R2: 0.635995
Validation Loss: 0.77160996, Validation R2: 0.354772

Epoch 155/1000
Training Loss: 0.55287940, Training R2: 0.633442
Validation Loss: 0.76254827, Validation R2: 0.366690

Epoch 156/1000
Training Loss: 0.54641020, Training R2: 0.632369
Validation Loss: 0.76096046, Validation R2: 0.366124

Epoch 157/1000
Training Loss: 0.54781044, Training R2: 0.632482
Validation Loss: 0.76829505, Validation R2: 0.359183

Epoch 158/1000
Training Loss: 0.54443151, Training R2: 0.635403
Validation Loss: 0.78127533, Validation R2: 0.335138

Epoch 159/1000
Training Loss: 0.54607201, Training R2: 0.631023
Validation Loss: 0.77550441, Validation R2: 0.332125

Epoch 160/1000
Training Loss: 0.55516067, Training R2: 0.629255
Validation Loss: 0.77706152, Validation R2: 0.348751

Epoch 161/1000
Training Loss: 0.54677179, Training R2: 0.632314
Validation Loss: 0.77752346, Validation R2: 0.362807

Epoch 162/1000
Training Loss: 0.55311018, Training R2: 0.632286
Validation Loss: 0.76470572, Validation R2: 0.365996

Epoch 163/1000
Training Loss: 0.54290405, Training R2: 0.637257
Validation Loss: 0.76472676, Validation R2: 0.361278

Epoch 164/1000
Training Loss: 0.54057715, Training R2: 0.638555
Validation Loss: 0.77786171, Validation R2: 0.346715

Epoch 165/1000
Training Loss: 0.54030599, Training R2: 0.637059
Validation Loss: 0.77975249, Validation R2: 0.346084

Epoch 166/1000
Training Loss: 0.53847310, Training R2: 0.641996
Validation Loss: 0.77812737, Validation R2: 0.342315

Epoch 167/1000
Training Loss: 0.54379828, Training R2: 0.642229
Validation Loss: 0.78371954, Validation R2: 0.330888

Epoch 168/1000
Epoch 00168: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.53826389, Training R2: 0.642545
Validation Loss: 0.78102583, Validation R2: 0.335266

Epoch 169/1000
学习率已减少 3 次
Training Loss: 0.53381573, Training R2: 0.643841
Validation Loss: 0.77850628, Validation R2: 0.344894

Epoch 170/1000
Training Loss: 0.52838958, Training R2: 0.646685
Validation Loss: 0.77783072, Validation R2: 0.344687

Epoch 171/1000
Training Loss: 0.52727159, Training R2: 0.648211
Validation Loss: 0.77734894, Validation R2: 0.348350

Epoch 172/1000
Training Loss: 0.52703138, Training R2: 0.647766
Validation Loss: 0.77681702, Validation R2: 0.351492

Epoch 173/1000
Training Loss: 0.52735997, Training R2: 0.648197
Validation Loss: 0.77746588, Validation R2: 0.346314

Epoch 174/1000
Training Loss: 0.52622431, Training R2: 0.647523
Validation Loss: 0.78554970, Validation R2: 0.336659

Epoch 175/1000
Training Loss: 0.53158403, Training R2: 0.645031
Validation Loss: 0.78201783, Validation R2: 0.331261

Epoch 176/1000
Training Loss: 0.52835464, Training R2: 0.647836
Validation Loss: 0.78124452, Validation R2: 0.324000

Epoch 177/1000
Training Loss: 0.52708476, Training R2: 0.650446
Validation Loss: 0.78711927, Validation R2: 0.323907

Epoch 178/1000
Training Loss: 0.52713504, Training R2: 0.647919
Validation Loss: 0.78115821, Validation R2: 0.334745

Epoch 179/1000
Training Loss: 0.52194208, Training R2: 0.650772
Validation Loss: 0.77715689, Validation R2: 0.347789

Epoch 180/1000
Training Loss: 0.52049819, Training R2: 0.651604
Validation Loss: 0.77652282, Validation R2: 0.349964

Epoch 181/1000
Training Loss: 0.51966766, Training R2: 0.651178
Validation Loss: 0.77642012, Validation R2: 0.348794

Epoch 182/1000
Training Loss: 0.51915715, Training R2: 0.651913
Validation Loss: 0.77533996, Validation R2: 0.350849

Epoch 183/1000
Training Loss: 0.52049379, Training R2: 0.652981
Validation Loss: 0.77740157, Validation R2: 0.349985

Epoch 184/1000
Training Loss: 0.51890193, Training R2: 0.652781
Validation Loss: 0.78089690, Validation R2: 0.339297

Epoch 185/1000
Training Loss: 0.51742795, Training R2: 0.653831
Validation Loss: 0.78111088, Validation R2: 0.333857

Epoch 186/1000
Training Loss: 0.52016216, Training R2: 0.652189
Validation Loss: 0.78242415, Validation R2: 0.336067

Epoch 187/1000
Training Loss: 0.51962957, Training R2: 0.652803
Validation Loss: 0.78347868, Validation R2: 0.337195

Epoch 188/1000
Training Loss: 0.51849715, Training R2: 0.656184
Validation Loss: 0.78810012, Validation R2: 0.333854

Epoch 189/1000
Epoch 00189: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.51906969, Training R2: 0.654900
Validation Loss: 0.79256791, Validation R2: 0.328409

Epoch 190/1000
学习率已减少 4 次
Training Loss: 0.51787631, Training R2: 0.655799
Validation Loss: 0.78921372, Validation R2: 0.328177

Epoch 191/1000
Training Loss: 0.51618894, Training R2: 0.656840
Validation Loss: 0.78918320, Validation R2: 0.323707

Epoch 192/1000
Training Loss: 0.51340285, Training R2: 0.657663
Validation Loss: 0.79260147, Validation R2: 0.325763

Epoch 193/1000
Training Loss: 0.51761192, Training R2: 0.654338
Validation Loss: 0.78917426, Validation R2: 0.328786

Epoch 194/1000
Training Loss: 0.51302769, Training R2: 0.657873
Validation Loss: 0.78663647, Validation R2: 0.327471

Epoch 195/1000
Training Loss: 0.51398626, Training R2: 0.658261
Validation Loss: 0.78694022, Validation R2: 0.330771

Epoch 196/1000
Training Loss: 0.51233459, Training R2: 0.658876
Validation Loss: 0.78842038, Validation R2: 0.329688

Epoch 197/1000
Training Loss: 0.51300491, Training R2: 0.658561
Validation Loss: 0.78573668, Validation R2: 0.329672

Epoch 198/1000
Training Loss: 0.51489882, Training R2: 0.658370
Validation Loss: 0.78275806, Validation R2: 0.335904

Epoch 199/1000
Training Loss: 0.51153394, Training R2: 0.659617
Validation Loss: 0.78351879, Validation R2: 0.338862

Epoch 200/1000
Training Loss: 0.51717882, Training R2: 0.655587
Validation Loss: 0.78326732, Validation R2: 0.337604

Epoch 201/1000
Training Loss: 0.51456408, Training R2: 0.656954
Validation Loss: 0.78249782, Validation R2: 0.337813

Epoch 202/1000
Training Loss: 0.51244727, Training R2: 0.659024
Validation Loss: 0.78430653, Validation R2: 0.337384

Epoch 203/1000
Training Loss: 0.51138531, Training R2: 0.659620
Validation Loss: 0.78696561, Validation R2: 0.331984

Epoch 204/1000
Training Loss: 0.51185652, Training R2: 0.660852
Validation Loss: 0.78827155, Validation R2: 0.325633

Epoch 205/1000
Training Loss: 0.51558481, Training R2: 0.659660
Validation Loss: 0.78657562, Validation R2: 0.331452

Epoch 206/1000
Training Loss: 0.50935721, Training R2: 0.660899
Validation Loss: 0.78803360, Validation R2: 0.331573

Epoch 207/1000
Training Loss: 0.51008843, Training R2: 0.659787
Validation Loss: 0.78807437, Validation R2: 0.329720

Epoch 208/1000
Training Loss: 0.51061274, Training R2: 0.660489
Validation Loss: 0.78762710, Validation R2: 0.330124

Epoch 209/1000
Training Loss: 0.50892874, Training R2: 0.660261
Validation Loss: 0.79205352, Validation R2: 0.330046

Epoch 210/1000
Epoch 00210: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.51427562, Training R2: 0.657885
Validation Loss: 0.79125118, Validation R2: 0.327223

Epoch 211/1000
学习率已减少 5 次
Training Loss: 0.50761315, Training R2: 0.661338
Validation Loss: 0.79031485, Validation R2: 0.325685

Epoch 212/1000
Training Loss: 0.50766762, Training R2: 0.661431
Validation Loss: 0.78946120, Validation R2: 0.325247

Epoch 213/1000
Training Loss: 0.50694782, Training R2: 0.661740
Validation Loss: 0.78845596, Validation R2: 0.324639

Epoch 214/1000
Training Loss: 0.50688364, Training R2: 0.662111
Validation Loss: 0.78811580, Validation R2: 0.325729

Epoch 215/1000
Training Loss: 0.50654051, Training R2: 0.662297
Validation Loss: 0.78821015, Validation R2: 0.325946

Epoch 216/1000
Training Loss: 0.50586840, Training R2: 0.662107
Validation Loss: 0.78686374, Validation R2: 0.327894

Epoch 217/1000
Training Loss: 0.50582595, Training R2: 0.661958
Validation Loss: 0.78614902, Validation R2: 0.330939

Epoch 218/1000
Training Loss: 0.50654636, Training R2: 0.661857
Validation Loss: 0.78529346, Validation R2: 0.332851

Epoch 219/1000
Training Loss: 0.50584230, Training R2: 0.662177
Validation Loss: 0.78402358, Validation R2: 0.333604

Epoch 220/1000
Training Loss: 0.50579488, Training R2: 0.662734
Validation Loss: 0.78393263, Validation R2: 0.333054

Epoch 221/1000
Training Loss: 0.50621304, Training R2: 0.662578
Validation Loss: 0.78449064, Validation R2: 0.332218

Epoch 222/1000
Training Loss: 0.50576283, Training R2: 0.663263
Validation Loss: 0.78405315, Validation R2: 0.332800

Epoch 223/1000
Training Loss: 0.50605715, Training R2: 0.663282
Validation Loss: 0.78538132, Validation R2: 0.332298

Epoch 224/1000
Training Loss: 0.50581771, Training R2: 0.662936
Validation Loss: 0.78787726, Validation R2: 0.331043

Epoch 225/1000
Training Loss: 0.50604788, Training R2: 0.662666
Validation Loss: 0.78848064, Validation R2: 0.329232

Epoch 226/1000
Training Loss: 0.50440651, Training R2: 0.663500
Validation Loss: 0.78899175, Validation R2: 0.327829

Epoch 227/1000
Training Loss: 0.50444611, Training R2: 0.663947
Validation Loss: 0.78985608, Validation R2: 0.327556

Epoch 228/1000
Training Loss: 0.50427682, Training R2: 0.663885
Validation Loss: 0.79002607, Validation R2: 0.327863

Epoch 229/1000
Training Loss: 0.50405043, Training R2: 0.663836
Validation Loss: 0.78975827, Validation R2: 0.328199

Epoch 230/1000
Training Loss: 0.50393483, Training R2: 0.663867
Validation Loss: 0.78964889, Validation R2: 0.327311

Epoch 231/1000
Epoch 00231: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.50314050, Training R2: 0.663932
Validation Loss: 0.78963310, Validation R2: 0.326660

Epoch 232/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
