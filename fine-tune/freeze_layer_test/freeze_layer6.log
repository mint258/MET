Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Trainable
lins.0.bias: Trainable
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1091331

Epoch 1/1000
Training Loss: 2.45127172, Training R2: -3.356415
Validation Loss: 1.23816860, Validation R2: -0.071454
Saved best model with validation R2 -0.071454 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.18785943, Training R2: -0.115178
Validation Loss: 1.23316360, Validation R2: -0.054126
Saved best model with validation R2 -0.054126 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.18050839, Training R2: -0.236650
Validation Loss: 1.23067248, Validation R2: -0.027717
Saved best model with validation R2 -0.027717 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.16836056, Training R2: -0.055559
Validation Loss: 1.28008401, Validation R2: -0.009393
Saved best model with validation R2 -0.009393 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.12766516, Training R2: -0.008873
Validation Loss: 1.25785458, Validation R2: -0.112259

Epoch 6/1000
Training Loss: 1.13173445, Training R2: -0.091597
Validation Loss: 1.23149776, Validation R2: -0.023003

Epoch 7/1000
Training Loss: 1.12035753, Training R2: -0.059115
Validation Loss: 1.23747218, Validation R2: -0.061936

Epoch 8/1000
Training Loss: 1.11769541, Training R2: -0.036931
Validation Loss: 1.23215818, Validation R2: -0.016814

Epoch 9/1000
Training Loss: 1.11732123, Training R2: -0.042853
Validation Loss: 1.24465013, Validation R2: -0.082286

Epoch 10/1000
Training Loss: 1.11996544, Training R2: -0.077872
Validation Loss: 1.23456502, Validation R2: -0.009705

Epoch 11/1000
Training Loss: 1.13651319, Training R2: -0.013305
Validation Loss: 1.25065112, Validation R2: 0.000597
Saved best model with validation R2 0.000597 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.12658577, Training R2: -0.009532
Validation Loss: 1.23537707, Validation R2: -0.056145

Epoch 13/1000
Training Loss: 1.11894116, Training R2: -0.075921
Validation Loss: 1.23103905, Validation R2: -0.025976

Epoch 14/1000
Training Loss: 1.12020003, Training R2: -0.008240
Validation Loss: 1.23784208, Validation R2: -0.004032

Epoch 15/1000
Training Loss: 1.12264733, Training R2: -0.035241
Validation Loss: 1.23153436, Validation R2: -0.041210

Epoch 16/1000
Training Loss: 1.11648376, Training R2: -0.016878
Validation Loss: 1.25437379, Validation R2: 0.000786
Saved best model with validation R2 0.000786 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 1.13355805, Training R2: -0.001410
Validation Loss: 1.23062229, Validation R2: -0.028319

Epoch 18/1000
Training Loss: 1.11457166, Training R2: -0.051019
Validation Loss: 1.25821304, Validation R2: -0.114029

Epoch 19/1000
Training Loss: 1.13538656, Training R2: -0.136694
Validation Loss: 1.23588932, Validation R2: -0.004828

Epoch 20/1000
Training Loss: 1.15428895, Training R2: -0.024068
Validation Loss: 1.23773003, Validation R2: -0.002801

Epoch 21/1000
Training Loss: 1.12325031, Training R2: -0.055275
Validation Loss: 1.24708176, Validation R2: -0.089687

Epoch 22/1000
Training Loss: 1.12173679, Training R2: -0.048784
Validation Loss: 1.26038301, Validation R2: 0.000222

Epoch 23/1000
Training Loss: 1.13704837, Training R2: 0.001132
Validation Loss: 1.23256636, Validation R2: -0.050486

Epoch 24/1000
Training Loss: 1.13238263, Training R2: -0.125680
Validation Loss: 1.23856342, Validation R2: -0.069175

Epoch 25/1000
Training Loss: 1.11123166, Training R2: -0.031686
Validation Loss: 1.26092029, Validation R2: 0.000455

Epoch 26/1000
Training Loss: 1.16259753, Training R2: -0.025174
Validation Loss: 1.24696624, Validation R2: 0.002687
Saved best model with validation R2 0.002687 to best_finetuned_model.pth

Epoch 27/1000
Training Loss: 1.12325748, Training R2: -0.014491
Validation Loss: 1.25411391, Validation R2: -0.107704

Epoch 28/1000
Training Loss: 1.13461622, Training R2: -0.138222
Validation Loss: 1.22862625, Validation R2: -0.013506

Epoch 29/1000
Training Loss: 1.12646303, Training R2: -0.004556
Validation Loss: 1.23613441, Validation R2: 0.001766

Epoch 30/1000
Training Loss: 1.11659590, Training R2: -0.039101
Validation Loss: 1.24584460, Validation R2: -0.091448

Epoch 31/1000
Training Loss: 1.11347866, Training R2: -0.070425
Validation Loss: 1.23262906, Validation R2: 0.002998
Saved best model with validation R2 0.002998 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 1.12091249, Training R2: 0.010612
Validation Loss: 1.23269165, Validation R2: 0.010261
Saved best model with validation R2 0.010261 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 1.11167516, Training R2: 0.014922
Validation Loss: 1.21650147, Validation R2: -0.029912

Epoch 34/1000
Training Loss: 1.09723444, Training R2: -0.023146
Validation Loss: 1.18931568, Validation R2: 0.030214
Saved best model with validation R2 0.030214 to best_finetuned_model.pth

Epoch 35/1000
Training Loss: 1.05902383, Training R2: 0.069215
Validation Loss: 1.14827788, Validation R2: 0.020233

Epoch 36/1000
Training Loss: 1.03185826, Training R2: 0.104982
Validation Loss: 1.22629189, Validation R2: -0.069452

Epoch 37/1000
Training Loss: 1.08540452, Training R2: 0.033357
Validation Loss: 1.16042757, Validation R2: 0.027094

Epoch 38/1000
Training Loss: 1.06950169, Training R2: 0.009198
Validation Loss: 1.27846992, Validation R2: 0.018194

Epoch 39/1000
Training Loss: 1.09037421, Training R2: 0.058767
Validation Loss: 1.13005328, Validation R2: 0.099192
Saved best model with validation R2 0.099192 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.99856165, Training R2: 0.160886
Validation Loss: 1.14987826, Validation R2: 0.088867

Epoch 41/1000
Training Loss: 1.05141761, Training R2: 0.056341
Validation Loss: 1.13195491, Validation R2: 0.133881
Saved best model with validation R2 0.133881 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 0.97043005, Training R2: 0.206142
Validation Loss: 1.10142899, Validation R2: 0.146874
Saved best model with validation R2 0.146874 to best_finetuned_model.pth

Epoch 43/1000
Training Loss: 0.96258359, Training R2: 0.217606
Validation Loss: 1.15127933, Validation R2: 0.128532

Epoch 44/1000
Training Loss: 0.95714753, Training R2: 0.223194
Validation Loss: 1.10147870, Validation R2: 0.158970
Saved best model with validation R2 0.158970 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.97250097, Training R2: 0.198086
Validation Loss: 1.09701550, Validation R2: 0.172538
Saved best model with validation R2 0.172538 to best_finetuned_model.pth

Epoch 46/1000
Training Loss: 0.96998948, Training R2: 0.215636
Validation Loss: 1.18426979, Validation R2: 0.102991

Epoch 47/1000
Training Loss: 0.98117176, Training R2: 0.196928
Validation Loss: 1.08047640, Validation R2: 0.173036
Saved best model with validation R2 0.173036 to best_finetuned_model.pth

Epoch 48/1000
Training Loss: 0.95136344, Training R2: 0.232550
Validation Loss: 1.09130538, Validation R2: 0.169496

Epoch 49/1000
Training Loss: 0.93853971, Training R2: 0.253440
Validation Loss: 1.07408166, Validation R2: 0.180728
Saved best model with validation R2 0.180728 to best_finetuned_model.pth

Epoch 50/1000
Training Loss: 0.89947644, Training R2: 0.287008
Validation Loss: 1.05704010, Validation R2: 0.194473
Saved best model with validation R2 0.194473 to best_finetuned_model.pth

Epoch 51/1000
Training Loss: 0.89561166, Training R2: 0.280518
Validation Loss: 1.26439834, Validation R2: 0.021531

Epoch 52/1000
Training Loss: 0.96453222, Training R2: 0.179132
Validation Loss: 1.08539593, Validation R2: 0.128062

Epoch 53/1000
Training Loss: 0.88913801, Training R2: 0.279131
Validation Loss: 1.10330117, Validation R2: 0.161345

Epoch 54/1000
Training Loss: 0.87400117, Training R2: 0.315086
Validation Loss: 1.09412253, Validation R2: 0.171368

Epoch 55/1000
Training Loss: 0.94526858, Training R2: 0.250116
Validation Loss: 1.10852456, Validation R2: 0.148910

Epoch 56/1000
Training Loss: 0.94371464, Training R2: 0.240012
Validation Loss: 1.15054178, Validation R2: 0.133945

Epoch 57/1000
Training Loss: 0.95101562, Training R2: 0.222005
Validation Loss: 1.15211296, Validation R2: 0.142669

Epoch 58/1000
Training Loss: 0.95351331, Training R2: 0.248724
Validation Loss: 1.08549404, Validation R2: 0.146667

Epoch 59/1000
Training Loss: 0.89679185, Training R2: 0.262425
Validation Loss: 1.08792007, Validation R2: 0.179892

Epoch 60/1000
Training Loss: 0.88253989, Training R2: 0.288817
Validation Loss: 0.98142081, Validation R2: 0.242300
Saved best model with validation R2 0.242300 to best_finetuned_model.pth

Epoch 61/1000
Training Loss: 0.80663177, Training R2: 0.375076
Validation Loss: 0.97464198, Validation R2: 0.280004
Saved best model with validation R2 0.280004 to best_finetuned_model.pth

Epoch 62/1000
Training Loss: 0.81083422, Training R2: 0.394062
Validation Loss: 0.92773235, Validation R2: 0.311630
Saved best model with validation R2 0.311630 to best_finetuned_model.pth

Epoch 63/1000
Training Loss: 0.76400533, Training R2: 0.430078
Validation Loss: 0.91330504, Validation R2: 0.304839

Epoch 64/1000
Training Loss: 0.77745379, Training R2: 0.427391
Validation Loss: 0.90311801, Validation R2: 0.300856

Epoch 65/1000
Training Loss: 0.79073996, Training R2: 0.426589
Validation Loss: 0.91338527, Validation R2: 0.274653

Epoch 66/1000
Training Loss: 0.75576379, Training R2: 0.435222
Validation Loss: 0.97286224, Validation R2: 0.189610

Epoch 67/1000
Training Loss: 0.75418100, Training R2: 0.419449
Validation Loss: 1.13521278, Validation R2: 0.133167

Epoch 68/1000
Training Loss: 0.88465914, Training R2: 0.287394
Validation Loss: 0.95560604, Validation R2: 0.312091
Saved best model with validation R2 0.312091 to best_finetuned_model.pth

Epoch 69/1000
Training Loss: 0.80673293, Training R2: 0.411059
Validation Loss: 0.93177575, Validation R2: 0.321355
Saved best model with validation R2 0.321355 to best_finetuned_model.pth

Epoch 70/1000
Training Loss: 0.77034332, Training R2: 0.426269
Validation Loss: 1.09908581, Validation R2: 0.195329

Epoch 71/1000
Training Loss: 0.85431036, Training R2: 0.335907
Validation Loss: 0.94111937, Validation R2: 0.305511

Epoch 72/1000
Training Loss: 0.77537545, Training R2: 0.418085
Validation Loss: 0.94213486, Validation R2: 0.327074
Saved best model with validation R2 0.327074 to best_finetuned_model.pth

Epoch 73/1000
Training Loss: 0.76894554, Training R2: 0.434010
Validation Loss: 0.89452159, Validation R2: 0.342637
Saved best model with validation R2 0.342637 to best_finetuned_model.pth

Epoch 74/1000
Training Loss: 0.71178406, Training R2: 0.487908
Validation Loss: 0.87375462, Validation R2: 0.361157
Saved best model with validation R2 0.361157 to best_finetuned_model.pth

Epoch 75/1000
Training Loss: 0.71961155, Training R2: 0.477442
Validation Loss: 0.87939703, Validation R2: 0.351633

Epoch 76/1000
Training Loss: 0.74183879, Training R2: 0.467548
Validation Loss: 0.84509176, Validation R2: 0.380208
Saved best model with validation R2 0.380208 to best_finetuned_model.pth

Epoch 77/1000
Training Loss: 0.73988334, Training R2: 0.464278
Validation Loss: 0.84912217, Validation R2: 0.378837

Epoch 78/1000
Training Loss: 0.71276513, Training R2: 0.471476
Validation Loss: 0.87540370, Validation R2: 0.372294

Epoch 79/1000
Training Loss: 0.70218374, Training R2: 0.503261
Validation Loss: 0.84560692, Validation R2: 0.390137
Saved best model with validation R2 0.390137 to best_finetuned_model.pth

Epoch 80/1000
Training Loss: 0.71180803, Training R2: 0.495709
Validation Loss: 0.88030255, Validation R2: 0.310460

Epoch 81/1000
Training Loss: 0.68917300, Training R2: 0.493760
Validation Loss: 0.87593460, Validation R2: 0.362393

Epoch 82/1000
Training Loss: 0.69748326, Training R2: 0.497806
Validation Loss: 0.81738913, Validation R2: 0.396070
Saved best model with validation R2 0.396070 to best_finetuned_model.pth

Epoch 83/1000
Training Loss: 0.67698266, Training R2: 0.527454
Validation Loss: 0.78832740, Validation R2: 0.405143
Saved best model with validation R2 0.405143 to best_finetuned_model.pth

Epoch 84/1000
Training Loss: 0.64393189, Training R2: 0.553238
Validation Loss: 0.79164296, Validation R2: 0.411462
Saved best model with validation R2 0.411462 to best_finetuned_model.pth

Epoch 85/1000
Training Loss: 0.64527273, Training R2: 0.544806
Validation Loss: 0.79287505, Validation R2: 0.410998

Epoch 86/1000
Training Loss: 0.63910951, Training R2: 0.562402
Validation Loss: 0.79687297, Validation R2: 0.411091

Epoch 87/1000
Training Loss: 0.63795834, Training R2: 0.571815
Validation Loss: 0.80842388, Validation R2: 0.415288
Saved best model with validation R2 0.415288 to best_finetuned_model.pth

Epoch 88/1000
Training Loss: 0.63760871, Training R2: 0.568925
Validation Loss: 0.86002129, Validation R2: 0.377786

Epoch 89/1000
Training Loss: 0.65466685, Training R2: 0.554588
Validation Loss: 0.80887347, Validation R2: 0.404419

Epoch 90/1000
Training Loss: 0.64434916, Training R2: 0.565849
Validation Loss: 0.78755081, Validation R2: 0.443253
Saved best model with validation R2 0.443253 to best_finetuned_model.pth

Epoch 91/1000
Training Loss: 0.64767956, Training R2: 0.569890
Validation Loss: 0.79733860, Validation R2: 0.426364

Epoch 92/1000
Training Loss: 0.63419390, Training R2: 0.566976
Validation Loss: 0.82837093, Validation R2: 0.387596

Epoch 93/1000
Training Loss: 0.65806033, Training R2: 0.533936
Validation Loss: 0.79382473, Validation R2: 0.394719

Epoch 94/1000
Training Loss: 0.66372681, Training R2: 0.556000
Validation Loss: 0.80825859, Validation R2: 0.388873

Epoch 95/1000
Training Loss: 0.67201328, Training R2: 0.542178
Validation Loss: 0.81467754, Validation R2: 0.378048

Epoch 96/1000
Training Loss: 0.66769268, Training R2: 0.535282
Validation Loss: 0.82435912, Validation R2: 0.401682

Epoch 97/1000
Training Loss: 0.64089679, Training R2: 0.575762
Validation Loss: 0.77518159, Validation R2: 0.437051

Epoch 98/1000
Training Loss: 0.61418578, Training R2: 0.598762
Validation Loss: 0.77925611, Validation R2: 0.402820

Epoch 99/1000
Training Loss: 0.62908866, Training R2: 0.581670
Validation Loss: 0.82877320, Validation R2: 0.348526

Epoch 100/1000
Training Loss: 0.67508684, Training R2: 0.539627
Validation Loss: 0.81203610, Validation R2: 0.375520

Epoch 101/1000
Training Loss: 0.72913947, Training R2: 0.467952
Validation Loss: 0.97594404, Validation R2: 0.303652

Epoch 102/1000
Training Loss: 0.71949161, Training R2: 0.500382
Validation Loss: 0.80165571, Validation R2: 0.415944

Epoch 103/1000
Training Loss: 0.64876876, Training R2: 0.570870
Validation Loss: 0.79019397, Validation R2: 0.427054

Epoch 104/1000
Training Loss: 0.63624170, Training R2: 0.565947
Validation Loss: 0.90849656, Validation R2: 0.332297

Epoch 105/1000
Training Loss: 0.64708347, Training R2: 0.557203
Validation Loss: 0.79303068, Validation R2: 0.433156

Epoch 106/1000
Training Loss: 0.67762266, Training R2: 0.556798
Validation Loss: 0.80768216, Validation R2: 0.415555

Epoch 107/1000
Training Loss: 0.62550129, Training R2: 0.579440
Validation Loss: 0.81457168, Validation R2: 0.424824

Epoch 108/1000
Training Loss: 0.61353774, Training R2: 0.603785
Validation Loss: 0.79358208, Validation R2: 0.447997
Saved best model with validation R2 0.447997 to best_finetuned_model.pth

Epoch 109/1000
Training Loss: 0.60879506, Training R2: 0.594544
Validation Loss: 0.82020682, Validation R2: 0.402769

Epoch 110/1000
Training Loss: 0.62885875, Training R2: 0.592373
Validation Loss: 0.83821273, Validation R2: 0.405067

Epoch 111/1000
Training Loss: 0.63371890, Training R2: 0.587329
Validation Loss: 0.82851982, Validation R2: 0.403040

Epoch 112/1000
Training Loss: 0.67958620, Training R2: 0.535173
Validation Loss: 0.96446228, Validation R2: 0.268526

Epoch 113/1000
Training Loss: 0.67928212, Training R2: 0.525453
Validation Loss: 0.95534134, Validation R2: 0.211288

Epoch 114/1000
Training Loss: 0.70179150, Training R2: 0.507094
Validation Loss: 0.92058402, Validation R2: 0.325468

Epoch 115/1000
Training Loss: 0.71834943, Training R2: 0.506359
Validation Loss: 0.82969314, Validation R2: 0.423137

Epoch 116/1000
Training Loss: 0.73506878, Training R2: 0.510622
Validation Loss: 0.84810263, Validation R2: 0.390711

Epoch 117/1000
Training Loss: 0.66925339, Training R2: 0.555292
Validation Loss: 0.84280109, Validation R2: 0.394586

Epoch 118/1000
Training Loss: 0.66204150, Training R2: 0.549551
Validation Loss: 0.99383342, Validation R2: 0.289385

Epoch 119/1000
Training Loss: 0.73667081, Training R2: 0.501454
Validation Loss: 0.79757446, Validation R2: 0.413497

Epoch 120/1000
Training Loss: 0.63818588, Training R2: 0.576475
Validation Loss: 0.78432399, Validation R2: 0.436097

Epoch 121/1000
Training Loss: 0.61698222, Training R2: 0.593521
Validation Loss: 0.80449629, Validation R2: 0.433895

Epoch 122/1000
Training Loss: 0.61016129, Training R2: 0.614886
Validation Loss: 0.86110836, Validation R2: 0.375232

Epoch 123/1000
Training Loss: 0.62914523, Training R2: 0.603712
Validation Loss: 0.78994995, Validation R2: 0.429647

Epoch 124/1000
Training Loss: 0.61059127, Training R2: 0.606431
Validation Loss: 0.83591259, Validation R2: 0.390437

Epoch 125/1000
Training Loss: 0.59290112, Training R2: 0.621746
Validation Loss: 0.83493710, Validation R2: 0.409469

Epoch 126/1000
Training Loss: 0.58760062, Training R2: 0.627691
Validation Loss: 0.84092206, Validation R2: 0.387579

Epoch 127/1000
Training Loss: 0.60797409, Training R2: 0.615821
Validation Loss: 0.78099561, Validation R2: 0.440995

Epoch 128/1000
Training Loss: 0.61920895, Training R2: 0.610256
Validation Loss: 0.81573558, Validation R2: 0.424299

Epoch 129/1000
Epoch 00129: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 0.61833065, Training R2: 0.621366
Validation Loss: 0.81484085, Validation R2: 0.413232

Epoch 130/1000
学习率已减少 1 次
Training Loss: 0.59255708, Training R2: 0.629264
Validation Loss: 0.79171872, Validation R2: 0.420643

Epoch 131/1000
Training Loss: 0.59192093, Training R2: 0.634005
Validation Loss: 0.79049653, Validation R2: 0.420565

Epoch 132/1000
Training Loss: 0.58872942, Training R2: 0.634476
Validation Loss: 0.80190581, Validation R2: 0.410743

Epoch 133/1000
Training Loss: 0.59370368, Training R2: 0.619298
Validation Loss: 0.84216011, Validation R2: 0.401596

Epoch 134/1000
Training Loss: 0.58778821, Training R2: 0.623446
Validation Loss: 0.80639225, Validation R2: 0.429277

Epoch 135/1000
Training Loss: 0.58583814, Training R2: 0.635622
Validation Loss: 0.79880673, Validation R2: 0.431215

Epoch 136/1000
Training Loss: 0.58179110, Training R2: 0.642054
Validation Loss: 0.78382087, Validation R2: 0.439834

Epoch 137/1000
Training Loss: 0.56991401, Training R2: 0.646881
Validation Loss: 0.85276318, Validation R2: 0.397220

Epoch 138/1000
Training Loss: 0.60265615, Training R2: 0.609746
Validation Loss: 0.79676437, Validation R2: 0.422800

Epoch 139/1000
Training Loss: 0.61607822, Training R2: 0.612099
Validation Loss: 0.86375380, Validation R2: 0.390672

Epoch 140/1000
Training Loss: 0.59900812, Training R2: 0.625793
Validation Loss: 0.84460628, Validation R2: 0.400825

Epoch 141/1000
Training Loss: 0.58406404, Training R2: 0.631089
Validation Loss: 0.77594364, Validation R2: 0.443047

Epoch 142/1000
Training Loss: 0.58337312, Training R2: 0.633327
Validation Loss: 0.87711555, Validation R2: 0.390289

Epoch 143/1000
Training Loss: 0.64166082, Training R2: 0.591591
Validation Loss: 0.78695267, Validation R2: 0.424739

Epoch 144/1000
Training Loss: 0.60640121, Training R2: 0.620011
Validation Loss: 0.82569748, Validation R2: 0.421978

Epoch 145/1000
Training Loss: 0.59345264, Training R2: 0.628546
Validation Loss: 0.82186109, Validation R2: 0.425148

Epoch 146/1000
Training Loss: 0.58665114, Training R2: 0.643184
Validation Loss: 0.78707820, Validation R2: 0.437284

Epoch 147/1000
Training Loss: 0.56402092, Training R2: 0.658717
Validation Loss: 0.79942107, Validation R2: 0.434160

Epoch 148/1000
Training Loss: 0.54633224, Training R2: 0.670602
Validation Loss: 0.76992422, Validation R2: 0.444646

Epoch 149/1000
Training Loss: 0.54994074, Training R2: 0.669896
Validation Loss: 0.77656013, Validation R2: 0.442126

Epoch 150/1000
Epoch 00150: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 0.55014939, Training R2: 0.668693
Validation Loss: 0.86628890, Validation R2: 0.378371

Epoch 151/1000
学习率已减少 2 次
Training Loss: 0.57143554, Training R2: 0.653220
Validation Loss: 0.77336591, Validation R2: 0.438652

Epoch 152/1000
Training Loss: 0.54653347, Training R2: 0.672608
Validation Loss: 0.76077461, Validation R2: 0.445572

Epoch 153/1000
Training Loss: 0.54526992, Training R2: 0.671268
Validation Loss: 0.75654495, Validation R2: 0.425922

Epoch 154/1000
Training Loss: 0.55523049, Training R2: 0.663315
Validation Loss: 0.74951440, Validation R2: 0.426257

Epoch 155/1000
Training Loss: 0.54589132, Training R2: 0.668456
Validation Loss: 0.77099365, Validation R2: 0.432424

Epoch 156/1000
Training Loss: 0.53701837, Training R2: 0.673059
Validation Loss: 0.76734948, Validation R2: 0.443065

Epoch 157/1000
Training Loss: 0.54223785, Training R2: 0.670188
Validation Loss: 0.77456146, Validation R2: 0.449262
Saved best model with validation R2 0.449262 to best_finetuned_model.pth

Epoch 158/1000
Training Loss: 0.53206829, Training R2: 0.682403
Validation Loss: 0.77740383, Validation R2: 0.446693

Epoch 159/1000
Training Loss: 0.52611736, Training R2: 0.689259
Validation Loss: 0.77574730, Validation R2: 0.438741

Epoch 160/1000
Training Loss: 0.53211383, Training R2: 0.685673
Validation Loss: 0.79496163, Validation R2: 0.420160

Epoch 161/1000
Training Loss: 0.54673172, Training R2: 0.676266
Validation Loss: 0.76095998, Validation R2: 0.429710

Epoch 162/1000
Training Loss: 0.55117108, Training R2: 0.667816
Validation Loss: 0.84732145, Validation R2: 0.399722

Epoch 163/1000
Training Loss: 0.62817567, Training R2: 0.620467
Validation Loss: 0.77118438, Validation R2: 0.442386

Epoch 164/1000
Training Loss: 0.57789608, Training R2: 0.638685
Validation Loss: 0.80994594, Validation R2: 0.420783

Epoch 165/1000
Training Loss: 0.58013650, Training R2: 0.652259
Validation Loss: 0.80586284, Validation R2: 0.417018

Epoch 166/1000
Training Loss: 0.55009198, Training R2: 0.666364
Validation Loss: 0.78129333, Validation R2: 0.432978

Epoch 167/1000
Training Loss: 0.56401086, Training R2: 0.664688
Validation Loss: 0.82097501, Validation R2: 0.418947

Epoch 168/1000
Training Loss: 0.54235050, Training R2: 0.673969
Validation Loss: 0.78814071, Validation R2: 0.411482

Epoch 169/1000
Training Loss: 0.53520684, Training R2: 0.679070
Validation Loss: 0.81412274, Validation R2: 0.406276

Epoch 170/1000
Training Loss: 0.52860386, Training R2: 0.686264
Validation Loss: 0.78065419, Validation R2: 0.433096

Epoch 171/1000
Training Loss: 0.53932167, Training R2: 0.680438
Validation Loss: 0.82932293, Validation R2: 0.408700

Epoch 172/1000
Training Loss: 0.54349750, Training R2: 0.685115
Validation Loss: 0.76438034, Validation R2: 0.438201

Epoch 173/1000
Training Loss: 0.53113793, Training R2: 0.684567
Validation Loss: 0.80118805, Validation R2: 0.420903

Epoch 174/1000
Training Loss: 0.52909957, Training R2: 0.685994
Validation Loss: 0.73967648, Validation R2: 0.445045

Epoch 175/1000
Training Loss: 0.54341136, Training R2: 0.666966
Validation Loss: 0.79503232, Validation R2: 0.432085

Epoch 176/1000
Training Loss: 0.56266732, Training R2: 0.648253
Validation Loss: 0.78571862, Validation R2: 0.430879

Epoch 177/1000
Training Loss: 0.56186231, Training R2: 0.646488
Validation Loss: 0.75386429, Validation R2: 0.445403

Epoch 178/1000
Epoch 00178: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 0.54199382, Training R2: 0.677097
Validation Loss: 0.75927496, Validation R2: 0.444649

Epoch 179/1000
学习率已减少 3 次
Training Loss: 0.52867810, Training R2: 0.685752
Validation Loss: 0.75815719, Validation R2: 0.434973

Epoch 180/1000
Training Loss: 0.51899969, Training R2: 0.689665
Validation Loss: 0.77012122, Validation R2: 0.439293

Epoch 181/1000
Training Loss: 0.51386526, Training R2: 0.689361
Validation Loss: 0.76653165, Validation R2: 0.433975

Epoch 182/1000
Training Loss: 0.51497854, Training R2: 0.689254
Validation Loss: 0.76766324, Validation R2: 0.441230

Epoch 183/1000
Training Loss: 0.51882520, Training R2: 0.691848
Validation Loss: 0.78599125, Validation R2: 0.428687

Epoch 184/1000
Training Loss: 0.52833839, Training R2: 0.685979
Validation Loss: 0.76151830, Validation R2: 0.439869

Epoch 185/1000
Training Loss: 0.51602125, Training R2: 0.690511
Validation Loss: 0.75758314, Validation R2: 0.444188

Epoch 186/1000
Training Loss: 0.51536938, Training R2: 0.694202
Validation Loss: 0.76781362, Validation R2: 0.445487

Epoch 187/1000
Training Loss: 0.51192182, Training R2: 0.694991
Validation Loss: 0.76496410, Validation R2: 0.437884

Epoch 188/1000
Training Loss: 0.50933729, Training R2: 0.697844
Validation Loss: 0.77400631, Validation R2: 0.435331

Epoch 189/1000
Training Loss: 0.49945333, Training R2: 0.704566
Validation Loss: 0.75954145, Validation R2: 0.441184

Epoch 190/1000
Training Loss: 0.50038350, Training R2: 0.704514
Validation Loss: 0.76538986, Validation R2: 0.443562

Epoch 191/1000
Training Loss: 0.49681232, Training R2: 0.709227
Validation Loss: 0.76811641, Validation R2: 0.436702

Epoch 192/1000
Training Loss: 0.49281855, Training R2: 0.711789
Validation Loss: 0.78075272, Validation R2: 0.420102

Epoch 193/1000
Training Loss: 0.49296265, Training R2: 0.714919
Validation Loss: 0.78921384, Validation R2: 0.419108

Epoch 194/1000
Training Loss: 0.48919011, Training R2: 0.716986
Validation Loss: 0.78674895, Validation R2: 0.419726

Epoch 195/1000
Training Loss: 0.48915242, Training R2: 0.719601
Validation Loss: 0.79502517, Validation R2: 0.418138

Epoch 196/1000
Training Loss: 0.49489870, Training R2: 0.714915
Validation Loss: 0.77549398, Validation R2: 0.424932

Epoch 197/1000
Training Loss: 0.51048412, Training R2: 0.700866
Validation Loss: 0.79543531, Validation R2: 0.416091

Epoch 198/1000
Training Loss: 0.49734720, Training R2: 0.715645
Validation Loss: 0.79950482, Validation R2: 0.416330

Epoch 199/1000
Epoch 00199: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 0.51123619, Training R2: 0.702307
Validation Loss: 0.81525540, Validation R2: 0.399735

Epoch 200/1000
学习率已减少 4 次
Training Loss: 0.51681980, Training R2: 0.693111
Validation Loss: 0.83077598, Validation R2: 0.392831

Epoch 201/1000
Training Loss: 0.51485843, Training R2: 0.696889
Validation Loss: 0.80835682, Validation R2: 0.406721

Epoch 202/1000
Training Loss: 0.51400235, Training R2: 0.697144
Validation Loss: 0.80700970, Validation R2: 0.402018

Epoch 203/1000
Training Loss: 0.51313010, Training R2: 0.697180
Validation Loss: 0.79793632, Validation R2: 0.409521

Epoch 204/1000
Training Loss: 0.49695305, Training R2: 0.710552
Validation Loss: 0.80594420, Validation R2: 0.397015

Epoch 205/1000
Training Loss: 0.49208490, Training R2: 0.715678
Validation Loss: 0.79524326, Validation R2: 0.414202

Epoch 206/1000
Training Loss: 0.48812245, Training R2: 0.720965
Validation Loss: 0.78887349, Validation R2: 0.417047

Epoch 207/1000
Training Loss: 0.49514552, Training R2: 0.717777
Validation Loss: 0.78356040, Validation R2: 0.420586

Epoch 208/1000
Training Loss: 0.49369197, Training R2: 0.718032
Validation Loss: 0.78171998, Validation R2: 0.414813

Epoch 209/1000
Training Loss: 0.49075155, Training R2: 0.719001
Validation Loss: 0.77923125, Validation R2: 0.412639

Epoch 210/1000
Training Loss: 0.50120937, Training R2: 0.711335
Validation Loss: 0.78906167, Validation R2: 0.430229

Epoch 211/1000
Training Loss: 0.49995078, Training R2: 0.716321
Validation Loss: 0.80719441, Validation R2: 0.415186

Epoch 212/1000
Training Loss: 0.49563667, Training R2: 0.724489
Validation Loss: 0.79190344, Validation R2: 0.421359

Epoch 213/1000
Training Loss: 0.49198573, Training R2: 0.725413
Validation Loss: 0.80469066, Validation R2: 0.407194

Epoch 214/1000
Training Loss: 0.48507800, Training R2: 0.729120
Validation Loss: 0.78336740, Validation R2: 0.423772

Epoch 215/1000
Training Loss: 0.49154013, Training R2: 0.721807
Validation Loss: 0.75302535, Validation R2: 0.431749

Epoch 216/1000
Training Loss: 0.50589648, Training R2: 0.711543
Validation Loss: 0.74543840, Validation R2: 0.436895

Epoch 217/1000
Training Loss: 0.49551304, Training R2: 0.717057
Validation Loss: 0.76913875, Validation R2: 0.432553

Epoch 218/1000
Training Loss: 0.49633256, Training R2: 0.719930
Validation Loss: 0.75978798, Validation R2: 0.437902

Epoch 219/1000
Training Loss: 0.49314490, Training R2: 0.721132
Validation Loss: 0.76165152, Validation R2: 0.429817

Epoch 220/1000
Epoch 00220: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 0.48824583, Training R2: 0.724574
Validation Loss: 0.76875645, Validation R2: 0.433554

Epoch 221/1000
学习率已减少 5 次
Training Loss: 0.48636024, Training R2: 0.725836
Validation Loss: 0.76402432, Validation R2: 0.435407

Epoch 222/1000
Training Loss: 0.48230315, Training R2: 0.727596
Validation Loss: 0.75264055, Validation R2: 0.437376

Epoch 223/1000
Training Loss: 0.48155670, Training R2: 0.726919
Validation Loss: 0.75192106, Validation R2: 0.436698

Epoch 224/1000
Training Loss: 0.47890681, Training R2: 0.728637
Validation Loss: 0.76050568, Validation R2: 0.434792

Epoch 225/1000
Training Loss: 0.47898920, Training R2: 0.728795
Validation Loss: 0.77245116, Validation R2: 0.427941

Epoch 226/1000
Training Loss: 0.48231287, Training R2: 0.726504
Validation Loss: 0.76741207, Validation R2: 0.428854

Epoch 227/1000
Training Loss: 0.47518945, Training R2: 0.731017
Validation Loss: 0.76028550, Validation R2: 0.428179

Epoch 228/1000
Training Loss: 0.47580555, Training R2: 0.731257
Validation Loss: 0.76135498, Validation R2: 0.428665

Epoch 229/1000
Training Loss: 0.47069469, Training R2: 0.734383
Validation Loss: 0.76813233, Validation R2: 0.428290

Epoch 230/1000
Training Loss: 0.46914779, Training R2: 0.735357
Validation Loss: 0.77101552, Validation R2: 0.425962

Epoch 231/1000
Training Loss: 0.46855366, Training R2: 0.735293
Validation Loss: 0.77157730, Validation R2: 0.424465

Epoch 232/1000
Training Loss: 0.46800593, Training R2: 0.735669
Validation Loss: 0.77107221, Validation R2: 0.423987

Epoch 233/1000
Training Loss: 0.46875299, Training R2: 0.735573
Validation Loss: 0.77791417, Validation R2: 0.422214

Epoch 234/1000
Training Loss: 0.46696853, Training R2: 0.736638
Validation Loss: 0.78028572, Validation R2: 0.420592

Epoch 235/1000
Training Loss: 0.46752585, Training R2: 0.737154
Validation Loss: 0.77822918, Validation R2: 0.419210

Epoch 236/1000
Training Loss: 0.46454066, Training R2: 0.739065
Validation Loss: 0.76952070, Validation R2: 0.420927

Epoch 237/1000
Training Loss: 0.46440972, Training R2: 0.738020
Validation Loss: 0.77018768, Validation R2: 0.421201

Epoch 238/1000
Training Loss: 0.46207569, Training R2: 0.739732
Validation Loss: 0.76907790, Validation R2: 0.423359

Epoch 239/1000
Training Loss: 0.46446682, Training R2: 0.738356
Validation Loss: 0.76476431, Validation R2: 0.425964

Epoch 240/1000
Training Loss: 0.46221131, Training R2: 0.739461
Validation Loss: 0.76152635, Validation R2: 0.424928

Epoch 241/1000
Epoch 00241: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 0.46310166, Training R2: 0.739216
Validation Loss: 0.76387548, Validation R2: 0.425619

Epoch 242/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/r2_curve_dipole.png
