Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Trainable
lins.0.bias: Trainable
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1223811

Epoch 1/1000
Training Loss: 2.27192532, Training R2: -3.103174
Validation Loss: 1.53519070, Validation R2: -0.271926
Saved best model with validation R2 -0.271926 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.31605089, Training R2: -0.275435
Validation Loss: 1.18968093, Validation R2: 0.013106
Saved best model with validation R2 0.013106 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.10383623, Training R2: -0.074161
Validation Loss: 1.27741408, Validation R2: -0.182530

Epoch 4/1000
Training Loss: 1.11571774, Training R2: -0.105246
Validation Loss: 1.19641757, Validation R2: 0.044944
Saved best model with validation R2 0.044944 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.09904173, Training R2: 0.067019
Validation Loss: 1.22381830, Validation R2: 0.052608
Saved best model with validation R2 0.052608 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.06857839, Training R2: 0.091388
Validation Loss: 1.16579509, Validation R2: -0.001610

Epoch 7/1000
Training Loss: 1.04981408, Training R2: 0.026246
Validation Loss: 1.15269816, Validation R2: 0.030937

Epoch 8/1000
Training Loss: 1.02249041, Training R2: 0.106956
Validation Loss: 1.16022742, Validation R2: 0.087905
Saved best model with validation R2 0.087905 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.02295010, Training R2: 0.153409
Validation Loss: 1.15089715, Validation R2: 0.090190
Saved best model with validation R2 0.090190 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 1.00662890, Training R2: 0.150533
Validation Loss: 1.14815974, Validation R2: 0.075359

Epoch 11/1000
Training Loss: 1.00283820, Training R2: 0.137726
Validation Loss: 1.14735961, Validation R2: 0.090896
Saved best model with validation R2 0.090896 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 0.98824348, Training R2: 0.178281
Validation Loss: 1.14307523, Validation R2: 0.106765
Saved best model with validation R2 0.106765 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 0.98038847, Training R2: 0.201904
Validation Loss: 1.13537216, Validation R2: 0.120325
Saved best model with validation R2 0.120325 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 0.96895022, Training R2: 0.208973
Validation Loss: 1.13982725, Validation R2: 0.083275

Epoch 15/1000
Training Loss: 0.96091785, Training R2: 0.190019
Validation Loss: 1.13662612, Validation R2: 0.129874
Saved best model with validation R2 0.129874 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 0.95477663, Training R2: 0.224915
Validation Loss: 1.12495434, Validation R2: 0.139063
Saved best model with validation R2 0.139063 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.94870319, Training R2: 0.244435
Validation Loss: 1.11260355, Validation R2: 0.139036

Epoch 18/1000
Training Loss: 0.92630826, Training R2: 0.233429
Validation Loss: 1.11078227, Validation R2: 0.150661
Saved best model with validation R2 0.150661 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.92310974, Training R2: 0.267258
Validation Loss: 1.07920444, Validation R2: 0.159246
Saved best model with validation R2 0.159246 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 0.90835427, Training R2: 0.263901
Validation Loss: 1.07884562, Validation R2: 0.189544
Saved best model with validation R2 0.189544 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.89486753, Training R2: 0.284373
Validation Loss: 1.04646719, Validation R2: 0.195658
Saved best model with validation R2 0.195658 to best_finetuned_model.pth

Epoch 22/1000
Training Loss: 0.89850923, Training R2: 0.295594
Validation Loss: 1.07980227, Validation R2: 0.197695
Saved best model with validation R2 0.197695 to best_finetuned_model.pth

Epoch 23/1000
Training Loss: 0.86671127, Training R2: 0.334878
Validation Loss: 1.02437198, Validation R2: 0.231063
Saved best model with validation R2 0.231063 to best_finetuned_model.pth

Epoch 24/1000
Training Loss: 0.83999702, Training R2: 0.363629
Validation Loss: 1.00908566, Validation R2: 0.239784
Saved best model with validation R2 0.239784 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 0.83007971, Training R2: 0.366087
Validation Loss: 1.01126182, Validation R2: 0.234838

Epoch 26/1000
Training Loss: 0.86746670, Training R2: 0.314067
Validation Loss: 1.19662356, Validation R2: 0.101044

Epoch 27/1000
Training Loss: 0.92611315, Training R2: 0.260273
Validation Loss: 1.12521791, Validation R2: 0.086120

Epoch 28/1000
Training Loss: 0.92390416, Training R2: 0.234529
Validation Loss: 1.08951569, Validation R2: 0.194035

Epoch 29/1000
Training Loss: 0.84337661, Training R2: 0.376573
Validation Loss: 1.02609956, Validation R2: 0.187339

Epoch 30/1000
Training Loss: 0.83075609, Training R2: 0.359644
Validation Loss: 0.97426862, Validation R2: 0.285409
Saved best model with validation R2 0.285409 to best_finetuned_model.pth

Epoch 31/1000
Training Loss: 0.78404239, Training R2: 0.429636
Validation Loss: 0.94869274, Validation R2: 0.333240
Saved best model with validation R2 0.333240 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 0.75379455, Training R2: 0.464379
Validation Loss: 0.98693103, Validation R2: 0.287005

Epoch 33/1000
Training Loss: 0.75610306, Training R2: 0.451517
Validation Loss: 0.95502180, Validation R2: 0.255847

Epoch 34/1000
Training Loss: 0.75203042, Training R2: 0.436957
Validation Loss: 0.96093625, Validation R2: 0.324046

Epoch 35/1000
Training Loss: 0.73842265, Training R2: 0.467188
Validation Loss: 0.90781766, Validation R2: 0.357160
Saved best model with validation R2 0.357160 to best_finetuned_model.pth

Epoch 36/1000
Training Loss: 0.76507915, Training R2: 0.466641
Validation Loss: 0.90786332, Validation R2: 0.355711

Epoch 37/1000
Training Loss: 0.74804497, Training R2: 0.480439
Validation Loss: 0.90069515, Validation R2: 0.365869
Saved best model with validation R2 0.365869 to best_finetuned_model.pth

Epoch 38/1000
Training Loss: 0.73578433, Training R2: 0.476238
Validation Loss: 0.91116345, Validation R2: 0.356765

Epoch 39/1000
Training Loss: 0.79280356, Training R2: 0.411813
Validation Loss: 0.92721862, Validation R2: 0.340074

Epoch 40/1000
Training Loss: 0.78139314, Training R2: 0.439720
Validation Loss: 0.87576813, Validation R2: 0.370548
Saved best model with validation R2 0.370548 to best_finetuned_model.pth

Epoch 41/1000
Training Loss: 0.71531835, Training R2: 0.503840
Validation Loss: 0.90712643, Validation R2: 0.348575

Epoch 42/1000
Training Loss: 0.71338380, Training R2: 0.507900
Validation Loss: 0.88442272, Validation R2: 0.333093

Epoch 43/1000
Training Loss: 0.71490779, Training R2: 0.499486
Validation Loss: 0.89474177, Validation R2: 0.348794

Epoch 44/1000
Training Loss: 0.70115503, Training R2: 0.507436
Validation Loss: 0.87266415, Validation R2: 0.384628
Saved best model with validation R2 0.384628 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.69105338, Training R2: 0.531520
Validation Loss: 0.91507316, Validation R2: 0.348862

Epoch 46/1000
Training Loss: 0.71346315, Training R2: 0.507681
Validation Loss: 0.86149114, Validation R2: 0.385608
Saved best model with validation R2 0.385608 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.68846078, Training R2: 0.541030
Validation Loss: 0.88108402, Validation R2: 0.384587

Epoch 48/1000
Training Loss: 0.69441019, Training R2: 0.537935
Validation Loss: 0.86598074, Validation R2: 0.391746
Saved best model with validation R2 0.391746 to best_finetuned_model.pth

Epoch 49/1000
Training Loss: 0.67545656, Training R2: 0.540851
Validation Loss: 0.84778470, Validation R2: 0.396961
Saved best model with validation R2 0.396961 to best_finetuned_model.pth

Epoch 50/1000
Training Loss: 0.68170766, Training R2: 0.540473
Validation Loss: 0.86736035, Validation R2: 0.385250

Epoch 51/1000
Training Loss: 0.66014015, Training R2: 0.557888
Validation Loss: 0.86486363, Validation R2: 0.392497

Epoch 52/1000
Training Loss: 0.66104795, Training R2: 0.561535
Validation Loss: 0.88531631, Validation R2: 0.368599

Epoch 53/1000
Training Loss: 0.66368763, Training R2: 0.564768
Validation Loss: 0.86393750, Validation R2: 0.378327

Epoch 54/1000
Training Loss: 0.64379764, Training R2: 0.586040
Validation Loss: 0.88829106, Validation R2: 0.357835

Epoch 55/1000
Training Loss: 0.64159851, Training R2: 0.574726
Validation Loss: 0.87619901, Validation R2: 0.375813

Epoch 56/1000
Training Loss: 0.66079236, Training R2: 0.565392
Validation Loss: 0.87247342, Validation R2: 0.370994

Epoch 57/1000
Training Loss: 0.65439599, Training R2: 0.574183
Validation Loss: 0.87361157, Validation R2: 0.326477

Epoch 58/1000
Training Loss: 0.66580189, Training R2: 0.568865
Validation Loss: 0.89478099, Validation R2: 0.348518

Epoch 59/1000
Training Loss: 0.63457048, Training R2: 0.592211
Validation Loss: 0.85266173, Validation R2: 0.381185

Epoch 60/1000
Training Loss: 0.64704102, Training R2: 0.581575
Validation Loss: 0.88700759, Validation R2: 0.373134

Epoch 61/1000
Training Loss: 0.67266500, Training R2: 0.579662
Validation Loss: 0.92093176, Validation R2: 0.332372

Epoch 62/1000
Training Loss: 0.65620862, Training R2: 0.585973
Validation Loss: 0.83260846, Validation R2: 0.388589

Epoch 63/1000
Training Loss: 0.62300183, Training R2: 0.596991
Validation Loss: 0.84752655, Validation R2: 0.388643

Epoch 64/1000
Training Loss: 0.60563376, Training R2: 0.618567
Validation Loss: 0.88029790, Validation R2: 0.361912

Epoch 65/1000
Training Loss: 0.59330526, Training R2: 0.628180
Validation Loss: 0.84349865, Validation R2: 0.384114

Epoch 66/1000
Training Loss: 0.59921159, Training R2: 0.625728
Validation Loss: 0.86539924, Validation R2: 0.351977

Epoch 67/1000
Training Loss: 0.60375448, Training R2: 0.621776
Validation Loss: 0.86567825, Validation R2: 0.354415

Epoch 68/1000
Training Loss: 0.60326669, Training R2: 0.621159
Validation Loss: 0.96532744, Validation R2: 0.300055

Epoch 69/1000
Training Loss: 0.64780435, Training R2: 0.583394
Validation Loss: 0.84395552, Validation R2: 0.345955

Epoch 70/1000
Epoch 00070: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.61304758, Training R2: 0.617977
Validation Loss: 0.84702170, Validation R2: 0.361782

Epoch 71/1000
学习率已减少 1 次
Training Loss: 0.60539859, Training R2: 0.620906
Validation Loss: 0.85998428, Validation R2: 0.361524

Epoch 72/1000
Training Loss: 0.59133343, Training R2: 0.625884
Validation Loss: 0.83873057, Validation R2: 0.382978

Epoch 73/1000
Training Loss: 0.57816975, Training R2: 0.648797
Validation Loss: 0.84066123, Validation R2: 0.379801

Epoch 74/1000
Training Loss: 0.56858276, Training R2: 0.654185
Validation Loss: 0.85537201, Validation R2: 0.371681

Epoch 75/1000
Training Loss: 0.56810778, Training R2: 0.655477
Validation Loss: 0.86511838, Validation R2: 0.371362

Epoch 76/1000
Training Loss: 0.55606226, Training R2: 0.655913
Validation Loss: 0.88300186, Validation R2: 0.362035

Epoch 77/1000
Training Loss: 0.57159770, Training R2: 0.651458
Validation Loss: 0.84488130, Validation R2: 0.379567

Epoch 78/1000
Training Loss: 0.55343255, Training R2: 0.664522
Validation Loss: 0.84483761, Validation R2: 0.377666

Epoch 79/1000
Training Loss: 0.54758674, Training R2: 0.662481
Validation Loss: 0.86047393, Validation R2: 0.337519

Epoch 80/1000
Training Loss: 0.55768731, Training R2: 0.656020
Validation Loss: 0.86552405, Validation R2: 0.352322

Epoch 81/1000
Training Loss: 0.55490998, Training R2: 0.659703
Validation Loss: 0.83323234, Validation R2: 0.381720

Epoch 82/1000
Training Loss: 0.55251088, Training R2: 0.666995
Validation Loss: 0.84696156, Validation R2: 0.379509

Epoch 83/1000
Training Loss: 0.53796268, Training R2: 0.672378
Validation Loss: 0.83844376, Validation R2: 0.383565

Epoch 84/1000
Training Loss: 0.53682456, Training R2: 0.668871
Validation Loss: 0.83357358, Validation R2: 0.379695

Epoch 85/1000
Training Loss: 0.53986444, Training R2: 0.665124
Validation Loss: 0.84063745, Validation R2: 0.370062

Epoch 86/1000
Training Loss: 0.54229773, Training R2: 0.666878
Validation Loss: 0.82151729, Validation R2: 0.389129

Epoch 87/1000
Training Loss: 0.54669561, Training R2: 0.666711
Validation Loss: 0.85575432, Validation R2: 0.359463

Epoch 88/1000
Training Loss: 0.54674687, Training R2: 0.663698
Validation Loss: 0.87439263, Validation R2: 0.344829

Epoch 89/1000
Training Loss: 0.55022328, Training R2: 0.652533
Validation Loss: 0.84449863, Validation R2: 0.351504

Epoch 90/1000
Training Loss: 0.53700942, Training R2: 0.677627
Validation Loss: 0.86274868, Validation R2: 0.347348

Epoch 91/1000
Epoch 00091: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.53480423, Training R2: 0.670782
Validation Loss: 0.82948864, Validation R2: 0.372143

Epoch 92/1000
学习率已减少 2 次
Training Loss: 0.52769530, Training R2: 0.683862
Validation Loss: 0.82989383, Validation R2: 0.374536

Epoch 93/1000
Training Loss: 0.52502603, Training R2: 0.679398
Validation Loss: 0.82187474, Validation R2: 0.375325

Epoch 94/1000
Training Loss: 0.52866134, Training R2: 0.683711
Validation Loss: 0.83045089, Validation R2: 0.369410

Epoch 95/1000
Training Loss: 0.51922893, Training R2: 0.681948
Validation Loss: 0.82630473, Validation R2: 0.372724

Epoch 96/1000
Training Loss: 0.51463621, Training R2: 0.688905
Validation Loss: 0.82588422, Validation R2: 0.375138

Epoch 97/1000
Training Loss: 0.51869053, Training R2: 0.686008
Validation Loss: 0.82892132, Validation R2: 0.372059

Epoch 98/1000
Training Loss: 0.51863729, Training R2: 0.689067
Validation Loss: 0.83181775, Validation R2: 0.371121

Epoch 99/1000
Training Loss: 0.51765687, Training R2: 0.686947
Validation Loss: 0.83583426, Validation R2: 0.364306

Epoch 100/1000
Training Loss: 0.50719637, Training R2: 0.691579
Validation Loss: 0.83550137, Validation R2: 0.363068

Epoch 101/1000
Training Loss: 0.50965860, Training R2: 0.692751
Validation Loss: 0.83723235, Validation R2: 0.367990

Epoch 102/1000
Training Loss: 0.51142654, Training R2: 0.688248
Validation Loss: 0.83147764, Validation R2: 0.366182

Epoch 103/1000
Training Loss: 0.51714633, Training R2: 0.691645
Validation Loss: 0.83898872, Validation R2: 0.364787

Epoch 104/1000
Training Loss: 0.51308099, Training R2: 0.687137
Validation Loss: 0.82939368, Validation R2: 0.367311

Epoch 105/1000
Training Loss: 0.50771865, Training R2: 0.696550
Validation Loss: 0.82801634, Validation R2: 0.370626

Epoch 106/1000
Training Loss: 0.50487722, Training R2: 0.693578
Validation Loss: 0.82552862, Validation R2: 0.372151

Epoch 107/1000
Training Loss: 0.50231729, Training R2: 0.696689
Validation Loss: 0.82521850, Validation R2: 0.372013

Epoch 108/1000
Training Loss: 0.49993580, Training R2: 0.697773
Validation Loss: 0.82584548, Validation R2: 0.371410

Epoch 109/1000
Training Loss: 0.49674221, Training R2: 0.699553
Validation Loss: 0.82787395, Validation R2: 0.368470

Epoch 110/1000
Training Loss: 0.50064805, Training R2: 0.696399
Validation Loss: 0.82302946, Validation R2: 0.369306

Epoch 111/1000
Training Loss: 0.51275482, Training R2: 0.697032
Validation Loss: 0.83284086, Validation R2: 0.366977

Epoch 112/1000
Epoch 00112: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.51081600, Training R2: 0.694123
Validation Loss: 0.82730007, Validation R2: 0.366461

Epoch 113/1000
学习率已减少 3 次
Training Loss: 0.50871358, Training R2: 0.698472
Validation Loss: 0.82145107, Validation R2: 0.375512

Epoch 114/1000
Training Loss: 0.49559510, Training R2: 0.702935
Validation Loss: 0.82723987, Validation R2: 0.372957

Epoch 115/1000
Training Loss: 0.50384554, Training R2: 0.694962
Validation Loss: 0.82512021, Validation R2: 0.370814

Epoch 116/1000
Training Loss: 0.50343934, Training R2: 0.699106
Validation Loss: 0.82894802, Validation R2: 0.365874

Epoch 117/1000
Training Loss: 0.50072758, Training R2: 0.697363
Validation Loss: 0.83638853, Validation R2: 0.365999

Epoch 118/1000
Training Loss: 0.49407792, Training R2: 0.701353
Validation Loss: 0.82154304, Validation R2: 0.374776

Epoch 119/1000
Training Loss: 0.49859538, Training R2: 0.701768
Validation Loss: 0.82093263, Validation R2: 0.378447

Epoch 120/1000
Training Loss: 0.49468508, Training R2: 0.701063
Validation Loss: 0.82315016, Validation R2: 0.374852

Epoch 121/1000
Training Loss: 0.49202226, Training R2: 0.703458
Validation Loss: 0.82368904, Validation R2: 0.371375

Epoch 122/1000
Training Loss: 0.48940706, Training R2: 0.703557
Validation Loss: 0.82470745, Validation R2: 0.370541

Epoch 123/1000
Training Loss: 0.49328258, Training R2: 0.699425
Validation Loss: 0.82032925, Validation R2: 0.372538

Epoch 124/1000
Training Loss: 0.49264972, Training R2: 0.704839
Validation Loss: 0.82225353, Validation R2: 0.371851

Epoch 125/1000
Training Loss: 0.49216350, Training R2: 0.701946
Validation Loss: 0.81812298, Validation R2: 0.376368

Epoch 126/1000
Training Loss: 0.49378228, Training R2: 0.705112
Validation Loss: 0.81802952, Validation R2: 0.377723

Epoch 127/1000
Training Loss: 0.48966399, Training R2: 0.704374
Validation Loss: 0.82834530, Validation R2: 0.369287

Epoch 128/1000
Training Loss: 0.49223286, Training R2: 0.700420
Validation Loss: 0.81982046, Validation R2: 0.372394

Epoch 129/1000
Training Loss: 0.48739193, Training R2: 0.706610
Validation Loss: 0.81674826, Validation R2: 0.375908

Epoch 130/1000
Training Loss: 0.48657027, Training R2: 0.704422
Validation Loss: 0.82028908, Validation R2: 0.374206

Epoch 131/1000
Training Loss: 0.48854847, Training R2: 0.703102
Validation Loss: 0.82528031, Validation R2: 0.371375

Epoch 132/1000
Training Loss: 0.48778044, Training R2: 0.708033
Validation Loss: 0.82885194, Validation R2: 0.365709

Epoch 133/1000
Epoch 00133: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.48596168, Training R2: 0.705192
Validation Loss: 0.82508713, Validation R2: 0.368027

Epoch 134/1000
学习率已减少 4 次
Training Loss: 0.48713449, Training R2: 0.705536
Validation Loss: 0.82165563, Validation R2: 0.371562

Epoch 135/1000
Training Loss: 0.48500950, Training R2: 0.708452
Validation Loss: 0.82242125, Validation R2: 0.371342

Epoch 136/1000
Training Loss: 0.48324408, Training R2: 0.709521
Validation Loss: 0.82796013, Validation R2: 0.368638

Epoch 137/1000
Training Loss: 0.48573742, Training R2: 0.708194
Validation Loss: 0.82762092, Validation R2: 0.368061

Epoch 138/1000
Training Loss: 0.48387464, Training R2: 0.709755
Validation Loss: 0.82487309, Validation R2: 0.367750

Epoch 139/1000
Training Loss: 0.48602466, Training R2: 0.709001
Validation Loss: 0.82196498, Validation R2: 0.370257

Epoch 140/1000
Training Loss: 0.48220009, Training R2: 0.708725
Validation Loss: 0.82117969, Validation R2: 0.371927

Epoch 141/1000
Training Loss: 0.48267209, Training R2: 0.707718
Validation Loss: 0.81986928, Validation R2: 0.373576

Epoch 142/1000
Training Loss: 0.48138581, Training R2: 0.709822
Validation Loss: 0.81945378, Validation R2: 0.373834

Epoch 143/1000
Training Loss: 0.48459336, Training R2: 0.710090
Validation Loss: 0.81904340, Validation R2: 0.374138

Epoch 144/1000
Training Loss: 0.48078912, Training R2: 0.709927
Validation Loss: 0.82147622, Validation R2: 0.372311

Epoch 145/1000
Training Loss: 0.48330106, Training R2: 0.708025
Validation Loss: 0.82072997, Validation R2: 0.371189

Epoch 146/1000
Training Loss: 0.48115451, Training R2: 0.710988
Validation Loss: 0.82227772, Validation R2: 0.368291

Epoch 147/1000
Training Loss: 0.48585776, Training R2: 0.709391
Validation Loss: 0.82222706, Validation R2: 0.368411

Epoch 148/1000
Training Loss: 0.48193047, Training R2: 0.708283
Validation Loss: 0.82315934, Validation R2: 0.368785

Epoch 149/1000
Training Loss: 0.47951612, Training R2: 0.709933
Validation Loss: 0.82160306, Validation R2: 0.370129

Epoch 150/1000
Training Loss: 0.48252017, Training R2: 0.711070
Validation Loss: 0.82416332, Validation R2: 0.367888

Epoch 151/1000
Training Loss: 0.48187002, Training R2: 0.711366
Validation Loss: 0.82675916, Validation R2: 0.367484

Epoch 152/1000
Training Loss: 0.48055179, Training R2: 0.710634
Validation Loss: 0.82261014, Validation R2: 0.370569

Epoch 153/1000
Training Loss: 0.47986956, Training R2: 0.711084
Validation Loss: 0.82034492, Validation R2: 0.372404

Epoch 154/1000
Epoch 00154: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.48262252, Training R2: 0.710602
Validation Loss: 0.82251906, Validation R2: 0.369884

Epoch 155/1000
学习率已减少 5 次
Training Loss: 0.47914263, Training R2: 0.710650
Validation Loss: 0.82555264, Validation R2: 0.367313

Epoch 156/1000
Training Loss: 0.47994585, Training R2: 0.709698
Validation Loss: 0.82651418, Validation R2: 0.366719

Epoch 157/1000
Training Loss: 0.47853037, Training R2: 0.711255
Validation Loss: 0.82607985, Validation R2: 0.366997

Epoch 158/1000
Training Loss: 0.47831758, Training R2: 0.712023
Validation Loss: 0.82490689, Validation R2: 0.367924

Epoch 159/1000
Training Loss: 0.47780346, Training R2: 0.711525
Validation Loss: 0.82274956, Validation R2: 0.368932

Epoch 160/1000
Training Loss: 0.47740375, Training R2: 0.711763
Validation Loss: 0.82196188, Validation R2: 0.368949

Epoch 161/1000
Training Loss: 0.47808803, Training R2: 0.711408
Validation Loss: 0.82230365, Validation R2: 0.369054

Epoch 162/1000
Training Loss: 0.47727844, Training R2: 0.711265
Validation Loss: 0.82309598, Validation R2: 0.368583

Epoch 163/1000
Training Loss: 0.47685107, Training R2: 0.711770
Validation Loss: 0.82263130, Validation R2: 0.368634

Epoch 164/1000
Training Loss: 0.47672636, Training R2: 0.711897
Validation Loss: 0.82213140, Validation R2: 0.369355

Epoch 165/1000
Training Loss: 0.47679905, Training R2: 0.711587
Validation Loss: 0.82256818, Validation R2: 0.369431

Epoch 166/1000
Training Loss: 0.47642621, Training R2: 0.711722
Validation Loss: 0.82357711, Validation R2: 0.369219

Epoch 167/1000
Training Loss: 0.47721205, Training R2: 0.710903
Validation Loss: 0.82366842, Validation R2: 0.368636

Epoch 168/1000
Training Loss: 0.47672744, Training R2: 0.711257
Validation Loss: 0.82136059, Validation R2: 0.369691

Epoch 169/1000
Training Loss: 0.47658994, Training R2: 0.712724
Validation Loss: 0.82104343, Validation R2: 0.370647

Epoch 170/1000
Training Loss: 0.47635736, Training R2: 0.712319
Validation Loss: 0.82189125, Validation R2: 0.370755

Epoch 171/1000
Training Loss: 0.47599540, Training R2: 0.712193
Validation Loss: 0.82329130, Validation R2: 0.369471

Epoch 172/1000
Training Loss: 0.47674976, Training R2: 0.711486
Validation Loss: 0.82269478, Validation R2: 0.369334

Epoch 173/1000
Training Loss: 0.47652658, Training R2: 0.712172
Validation Loss: 0.82193309, Validation R2: 0.369046

Epoch 174/1000
Training Loss: 0.47567053, Training R2: 0.712955
Validation Loss: 0.82161903, Validation R2: 0.369443

Epoch 175/1000
Epoch 00175: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.47570407, Training R2: 0.712283
Validation Loss: 0.82229102, Validation R2: 0.369072

Epoch 176/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
