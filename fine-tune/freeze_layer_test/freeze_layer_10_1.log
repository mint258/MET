Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)
冻结层 9: lins.2 (Linear)
冻结层 10: encoder (Sequential)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Frozen
lins.2.bias: Frozen
encoder.0.weight: Frozen
encoder.0.bias: Frozen
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 993539

Epoch 1/1000
Training Loss: 2.29465580, Training R2: -3.162445
Validation Loss: 1.54454541, Validation R2: -0.283833
Saved best model with validation R2 -0.283833 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.34012542, Training R2: -0.320863
Validation Loss: 1.20448661, Validation R2: 0.023703
Saved best model with validation R2 0.023703 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.09623358, Training R2: -0.037313
Validation Loss: 1.28097820, Validation R2: -0.188843

Epoch 4/1000
Training Loss: 1.12870945, Training R2: -0.143519
Validation Loss: 1.19183552, Validation R2: 0.037009
Saved best model with validation R2 0.037009 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.09606975, Training R2: 0.059669
Validation Loss: 1.23152161, Validation R2: 0.050928
Saved best model with validation R2 0.050928 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.08297167, Training R2: 0.078989
Validation Loss: 1.16288972, Validation R2: 0.032841

Epoch 7/1000
Training Loss: 1.04998072, Training R2: 0.040388
Validation Loss: 1.15422738, Validation R2: 0.028572

Epoch 8/1000
Training Loss: 1.03892414, Training R2: 0.068272
Validation Loss: 1.16197884, Validation R2: 0.083921
Saved best model with validation R2 0.083921 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.04442989, Training R2: 0.126847
Validation Loss: 1.16806376, Validation R2: 0.088839
Saved best model with validation R2 0.088839 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 1.03415519, Training R2: 0.129322
Validation Loss: 1.15022302, Validation R2: 0.067622

Epoch 11/1000
Training Loss: 1.03854112, Training R2: 0.074506
Validation Loss: 1.14639962, Validation R2: 0.068884

Epoch 12/1000
Training Loss: 1.02046566, Training R2: 0.131092
Validation Loss: 1.16768038, Validation R2: 0.089896
Saved best model with validation R2 0.089896 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 1.02370390, Training R2: 0.155380
Validation Loss: 1.14999306, Validation R2: 0.091874
Saved best model with validation R2 0.091874 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 1.00677167, Training R2: 0.150503
Validation Loss: 1.13723004, Validation R2: 0.072203

Epoch 15/1000
Training Loss: 1.00285074, Training R2: 0.134108
Validation Loss: 1.13667643, Validation R2: 0.082247

Epoch 16/1000
Training Loss: 0.99799942, Training R2: 0.143639
Validation Loss: 1.14523900, Validation R2: 0.093967
Saved best model with validation R2 0.093967 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.99848483, Training R2: 0.176983
Validation Loss: 1.13659966, Validation R2: 0.095490
Saved best model with validation R2 0.095490 to best_finetuned_model.pth

Epoch 18/1000
Training Loss: 0.99009619, Training R2: 0.152487
Validation Loss: 1.15187609, Validation R2: 0.097515
Saved best model with validation R2 0.097515 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.99508399, Training R2: 0.181417
Validation Loss: 1.13446736, Validation R2: 0.057120

Epoch 20/1000
Training Loss: 0.99278094, Training R2: 0.121807
Validation Loss: 1.18762970, Validation R2: 0.086030

Epoch 21/1000
Training Loss: 1.01170482, Training R2: 0.172772
Validation Loss: 1.12564826, Validation R2: 0.087105

Epoch 22/1000
Training Loss: 0.97597043, Training R2: 0.178275
Validation Loss: 1.17184031, Validation R2: 0.095401

Epoch 23/1000
Training Loss: 1.00482455, Training R2: 0.185410
Validation Loss: 1.12920654, Validation R2: 0.059681

Epoch 24/1000
Training Loss: 0.98997508, Training R2: 0.123955
Validation Loss: 1.14806318, Validation R2: 0.106589
Saved best model with validation R2 0.106589 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 0.98486124, Training R2: 0.195121
Validation Loss: 1.17023683, Validation R2: -0.003810

Epoch 26/1000
Training Loss: 1.04523620, Training R2: 0.028372
Validation Loss: 1.20923078, Validation R2: 0.082023

Epoch 27/1000
Training Loss: 1.03003664, Training R2: 0.162052
Validation Loss: 1.12477374, Validation R2: 0.086683

Epoch 28/1000
Training Loss: 1.04204812, Training R2: 0.021289
Validation Loss: 1.12831199, Validation R2: 0.063202

Epoch 29/1000
Training Loss: 1.00207572, Training R2: 0.142110
Validation Loss: 1.17188036, Validation R2: 0.110094
Saved best model with validation R2 0.110094 to best_finetuned_model.pth

Epoch 30/1000
Training Loss: 0.99153523, Training R2: 0.194010
Validation Loss: 1.14215195, Validation R2: 0.063317

Epoch 31/1000
Training Loss: 1.02763334, Training R2: 0.066126
Validation Loss: 1.13207614, Validation R2: 0.122237
Saved best model with validation R2 0.122237 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 0.97765937, Training R2: 0.205637
Validation Loss: 1.14563143, Validation R2: 0.116954

Epoch 33/1000
Training Loss: 0.97227234, Training R2: 0.199605
Validation Loss: 1.12435377, Validation R2: 0.077522

Epoch 34/1000
Training Loss: 0.97957365, Training R2: 0.144833
Validation Loss: 1.12113309, Validation R2: 0.101195

Epoch 35/1000
Training Loss: 0.97145697, Training R2: 0.193552
Validation Loss: 1.12451982, Validation R2: 0.107186

Epoch 36/1000
Training Loss: 0.96361099, Training R2: 0.203398
Validation Loss: 1.12447250, Validation R2: 0.076280

Epoch 37/1000
Training Loss: 0.98644824, Training R2: 0.135648
Validation Loss: 1.13381708, Validation R2: 0.118231

Epoch 38/1000
Training Loss: 0.98040765, Training R2: 0.211301
Validation Loss: 1.11213970, Validation R2: 0.083700

Epoch 39/1000
Training Loss: 1.01189183, Training R2: 0.074466
Validation Loss: 1.11544573, Validation R2: 0.127022
Saved best model with validation R2 0.127022 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.97270360, Training R2: 0.217670
Validation Loss: 1.12575102, Validation R2: 0.133407
Saved best model with validation R2 0.133407 to best_finetuned_model.pth

Epoch 41/1000
Training Loss: 0.97710584, Training R2: 0.176538
Validation Loss: 1.10341251, Validation R2: 0.087119

Epoch 42/1000
Training Loss: 0.98359071, Training R2: 0.175208
Validation Loss: 1.14958155, Validation R2: 0.116396

Epoch 43/1000
Training Loss: 0.98405199, Training R2: 0.202404
Validation Loss: 1.11603451, Validation R2: 0.111415

Epoch 44/1000
Training Loss: 0.98545012, Training R2: 0.165059
Validation Loss: 1.11602497, Validation R2: 0.123867

Epoch 45/1000
Training Loss: 0.97279808, Training R2: 0.183066
Validation Loss: 1.10907733, Validation R2: 0.135459
Saved best model with validation R2 0.135459 to best_finetuned_model.pth

Epoch 46/1000
Training Loss: 0.95806274, Training R2: 0.206550
Validation Loss: 1.11212945, Validation R2: 0.139239
Saved best model with validation R2 0.139239 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.95904865, Training R2: 0.217449
Validation Loss: 1.09510708, Validation R2: 0.131369

Epoch 48/1000
Training Loss: 0.95087860, Training R2: 0.201864
Validation Loss: 1.11191642, Validation R2: 0.139979
Saved best model with validation R2 0.139979 to best_finetuned_model.pth

Epoch 49/1000
Training Loss: 0.94568874, Training R2: 0.232780
Validation Loss: 1.10413694, Validation R2: 0.145247
Saved best model with validation R2 0.145247 to best_finetuned_model.pth

Epoch 50/1000
Training Loss: 0.93567996, Training R2: 0.238918
Validation Loss: 1.10606492, Validation R2: 0.132852

Epoch 51/1000
Training Loss: 0.95799201, Training R2: 0.208797
Validation Loss: 1.12129641, Validation R2: 0.100571

Epoch 52/1000
Training Loss: 0.97838110, Training R2: 0.149670
Validation Loss: 1.17471719, Validation R2: 0.118329

Epoch 53/1000
Training Loss: 0.97973367, Training R2: 0.213559
Validation Loss: 1.11616647, Validation R2: 0.084112

Epoch 54/1000
Training Loss: 0.96389626, Training R2: 0.162593
Validation Loss: 1.19145358, Validation R2: 0.100526

Epoch 55/1000
Training Loss: 0.97747188, Training R2: 0.206086
Validation Loss: 1.12074578, Validation R2: 0.074136

Epoch 56/1000
Training Loss: 0.96018608, Training R2: 0.187815
Validation Loss: 1.12709725, Validation R2: 0.147141
Saved best model with validation R2 0.147141 to best_finetuned_model.pth

Epoch 57/1000
Training Loss: 0.94768692, Training R2: 0.218913
Validation Loss: 1.12713361, Validation R2: 0.147787
Saved best model with validation R2 0.147787 to best_finetuned_model.pth

Epoch 58/1000
Training Loss: 0.94962755, Training R2: 0.224388
Validation Loss: 1.11251724, Validation R2: 0.121164

Epoch 59/1000
Training Loss: 0.99093014, Training R2: 0.116208
Validation Loss: 1.13466370, Validation R2: 0.146345

Epoch 60/1000
Training Loss: 1.00997633, Training R2: 0.185011
Validation Loss: 1.12511194, Validation R2: 0.151103
Saved best model with validation R2 0.151103 to best_finetuned_model.pth

Epoch 61/1000
Training Loss: 0.96399988, Training R2: 0.190598
Validation Loss: 1.10021257, Validation R2: 0.099804

Epoch 62/1000
Training Loss: 0.96473859, Training R2: 0.187060
Validation Loss: 1.13143003, Validation R2: 0.144896

Epoch 63/1000
Training Loss: 0.95699906, Training R2: 0.234463
Validation Loss: 1.10077250, Validation R2: 0.097419

Epoch 64/1000
Training Loss: 0.96928099, Training R2: 0.154356
Validation Loss: 1.11688042, Validation R2: 0.148920

Epoch 65/1000
Training Loss: 0.95345191, Training R2: 0.234928
Validation Loss: 1.12202251, Validation R2: 0.145842

Epoch 66/1000
Training Loss: 0.94475362, Training R2: 0.218804
Validation Loss: 1.13325393, Validation R2: 0.149271

Epoch 67/1000
Training Loss: 0.95629149, Training R2: 0.242525
Validation Loss: 1.10013413, Validation R2: 0.128298

Epoch 68/1000
Training Loss: 0.93470708, Training R2: 0.215966
Validation Loss: 1.11028099, Validation R2: 0.159970
Saved best model with validation R2 0.159970 to best_finetuned_model.pth

Epoch 69/1000
Training Loss: 0.91786539, Training R2: 0.271741
Validation Loss: 1.09645665, Validation R2: 0.156830

Epoch 70/1000
Training Loss: 0.90886148, Training R2: 0.265868
Validation Loss: 1.12268901, Validation R2: 0.153275

Epoch 71/1000
Training Loss: 0.91128070, Training R2: 0.261279
Validation Loss: 1.13374269, Validation R2: 0.145601

Epoch 72/1000
Training Loss: 0.92469485, Training R2: 0.259724
Validation Loss: 1.08478177, Validation R2: 0.139104

Epoch 73/1000
Training Loss: 0.92063366, Training R2: 0.243845
Validation Loss: 1.12781799, Validation R2: 0.156850

Epoch 74/1000
Training Loss: 0.91473807, Training R2: 0.281519
Validation Loss: 1.09151852, Validation R2: 0.165975
Saved best model with validation R2 0.165975 to best_finetuned_model.pth

Epoch 75/1000
Training Loss: 0.91038442, Training R2: 0.278381
Validation Loss: 1.10342848, Validation R2: 0.174418
Saved best model with validation R2 0.174418 to best_finetuned_model.pth

Epoch 76/1000
Training Loss: 0.91108896, Training R2: 0.273649
Validation Loss: 1.13237214, Validation R2: 0.156908

Epoch 77/1000
Training Loss: 0.89872644, Training R2: 0.289952
Validation Loss: 1.09659851, Validation R2: 0.141401

Epoch 78/1000
Training Loss: 0.89734801, Training R2: 0.289136
Validation Loss: 1.10100174, Validation R2: 0.128361

Epoch 79/1000
Training Loss: 0.91676212, Training R2: 0.248068
Validation Loss: 1.16211617, Validation R2: 0.131826

Epoch 80/1000
Training Loss: 0.92679753, Training R2: 0.255540
Validation Loss: 1.10496867, Validation R2: 0.129856

Epoch 81/1000
Training Loss: 0.93472599, Training R2: 0.241940
Validation Loss: 1.12665057, Validation R2: 0.165572

Epoch 82/1000
Training Loss: 0.91878664, Training R2: 0.265243
Validation Loss: 1.10236382, Validation R2: 0.156286

Epoch 83/1000
Training Loss: 0.91373707, Training R2: 0.270868
Validation Loss: 1.12991631, Validation R2: 0.161652

Epoch 84/1000
Training Loss: 0.91756550, Training R2: 0.253291
Validation Loss: 1.16703939, Validation R2: 0.129009

Epoch 85/1000
Training Loss: 0.94610353, Training R2: 0.243266
Validation Loss: 1.10054040, Validation R2: 0.157149

Epoch 86/1000
Training Loss: 0.89270713, Training R2: 0.295943
Validation Loss: 1.12469387, Validation R2: 0.153654

Epoch 87/1000
Training Loss: 0.89140641, Training R2: 0.297900
Validation Loss: 1.10426211, Validation R2: 0.131289

Epoch 88/1000
Training Loss: 0.91786335, Training R2: 0.235071
Validation Loss: 1.24064195, Validation R2: 0.069329

Epoch 89/1000
Training Loss: 1.07140574, Training R2: 0.107158
Validation Loss: 1.08854735, Validation R2: 0.133255

Epoch 90/1000
Training Loss: 0.97758355, Training R2: 0.137035
Validation Loss: 1.09066796, Validation R2: 0.129378

Epoch 91/1000
Training Loss: 0.93035901, Training R2: 0.261123
Validation Loss: 1.11281574, Validation R2: 0.168328

Epoch 92/1000
Training Loss: 0.92779937, Training R2: 0.252693
Validation Loss: 1.12354457, Validation R2: 0.171847

Epoch 93/1000
Training Loss: 0.93282841, Training R2: 0.263194
Validation Loss: 1.10372889, Validation R2: 0.153309

Epoch 94/1000
Training Loss: 0.94363785, Training R2: 0.196596
Validation Loss: 1.16491282, Validation R2: 0.125215

Epoch 95/1000
Training Loss: 0.92009142, Training R2: 0.278115
Validation Loss: 1.10200655, Validation R2: 0.153414

Epoch 96/1000
Training Loss: 0.88675484, Training R2: 0.302491
Validation Loss: 1.09307444, Validation R2: 0.186046
Saved best model with validation R2 0.186046 to best_finetuned_model.pth

Epoch 97/1000
Training Loss: 0.88305233, Training R2: 0.304668
Validation Loss: 1.11301863, Validation R2: 0.183032

Epoch 98/1000
Training Loss: 0.88356862, Training R2: 0.314126
Validation Loss: 1.08659410, Validation R2: 0.174373

Epoch 99/1000
Training Loss: 0.88900135, Training R2: 0.300437
Validation Loss: 1.11282754, Validation R2: 0.168858

Epoch 100/1000
Training Loss: 0.87985916, Training R2: 0.321645
Validation Loss: 1.08463836, Validation R2: 0.178878

Epoch 101/1000
Training Loss: 0.87229320, Training R2: 0.321769
Validation Loss: 1.07919180, Validation R2: 0.195676
Saved best model with validation R2 0.195676 to best_finetuned_model.pth

Epoch 102/1000
Training Loss: 0.89451013, Training R2: 0.278667
Validation Loss: 1.07470334, Validation R2: 0.179475

Epoch 103/1000
Training Loss: 0.88868340, Training R2: 0.291238
Validation Loss: 1.07371986, Validation R2: 0.196673
Saved best model with validation R2 0.196673 to best_finetuned_model.pth

Epoch 104/1000
Training Loss: 0.87116837, Training R2: 0.321678
Validation Loss: 1.08954704, Validation R2: 0.189361

Epoch 105/1000
Training Loss: 0.87303957, Training R2: 0.321455
Validation Loss: 1.08508420, Validation R2: 0.172641

Epoch 106/1000
Training Loss: 0.89506772, Training R2: 0.273479
Validation Loss: 1.12308300, Validation R2: 0.165170

Epoch 107/1000
Training Loss: 0.89213189, Training R2: 0.292493
Validation Loss: 1.08121049, Validation R2: 0.188399

Epoch 108/1000
Training Loss: 0.86281748, Training R2: 0.332183
Validation Loss: 1.11857760, Validation R2: 0.181238

Epoch 109/1000
Training Loss: 0.87092321, Training R2: 0.331495
Validation Loss: 1.11771512, Validation R2: 0.184910

Epoch 110/1000
Training Loss: 0.87669469, Training R2: 0.324958
Validation Loss: 1.09056056, Validation R2: 0.189193

Epoch 111/1000
Training Loss: 0.86416232, Training R2: 0.323666
Validation Loss: 1.12801766, Validation R2: 0.162714

Epoch 112/1000
Training Loss: 0.85658534, Training R2: 0.346927
Validation Loss: 1.07286203, Validation R2: 0.157223

Epoch 113/1000
Training Loss: 0.90576950, Training R2: 0.262058
Validation Loss: 1.09255850, Validation R2: 0.183374

Epoch 114/1000
Training Loss: 0.88461832, Training R2: 0.309234
Validation Loss: 1.15705669, Validation R2: 0.136416

Epoch 115/1000
Training Loss: 0.92043629, Training R2: 0.287804
Validation Loss: 1.12153053, Validation R2: 0.094091

Epoch 116/1000
Training Loss: 0.96968803, Training R2: 0.148638
Validation Loss: 1.12242711, Validation R2: 0.171510

Epoch 117/1000
Training Loss: 0.91614426, Training R2: 0.298874
Validation Loss: 1.12703311, Validation R2: 0.111034

Epoch 118/1000
Training Loss: 0.95335911, Training R2: 0.170001
Validation Loss: 1.12876153, Validation R2: 0.164077

Epoch 119/1000
Training Loss: 0.89526198, Training R2: 0.316294
Validation Loss: 1.10264933, Validation R2: 0.134361

Epoch 120/1000
Training Loss: 0.93460648, Training R2: 0.202169
Validation Loss: 1.08611238, Validation R2: 0.150614

Epoch 121/1000
Training Loss: 0.91094898, Training R2: 0.305019
Validation Loss: 1.09970558, Validation R2: 0.172788

Epoch 122/1000
Training Loss: 0.90257776, Training R2: 0.276228
Validation Loss: 1.08600771, Validation R2: 0.176815

Epoch 123/1000
Training Loss: 0.87699817, Training R2: 0.311403
Validation Loss: 1.16186666, Validation R2: 0.138565

Epoch 124/1000
Epoch 00124: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.89542997, Training R2: 0.299471
Validation Loss: 1.12690353, Validation R2: 0.173847

Epoch 125/1000
学习率已减少 1 次
Training Loss: 0.87407162, Training R2: 0.324014
Validation Loss: 1.12044322, Validation R2: 0.181853

Epoch 126/1000
Training Loss: 0.85751090, Training R2: 0.341135
Validation Loss: 1.09788096, Validation R2: 0.190641

Epoch 127/1000
Training Loss: 0.85624216, Training R2: 0.340349
Validation Loss: 1.10168993, Validation R2: 0.189948

Epoch 128/1000
Training Loss: 0.86176050, Training R2: 0.342345
Validation Loss: 1.10155368, Validation R2: 0.185682

Epoch 129/1000
Training Loss: 0.85650304, Training R2: 0.340157
Validation Loss: 1.08725512, Validation R2: 0.180639

Epoch 130/1000
Training Loss: 0.86394413, Training R2: 0.324004
Validation Loss: 1.11401081, Validation R2: 0.184664

Epoch 131/1000
Training Loss: 0.87949867, Training R2: 0.321598
Validation Loss: 1.10578537, Validation R2: 0.189216

Epoch 132/1000
Training Loss: 0.86222586, Training R2: 0.325690
Validation Loss: 1.07158577, Validation R2: 0.152196

Epoch 133/1000
Training Loss: 0.87037703, Training R2: 0.312292
Validation Loss: 1.12206674, Validation R2: 0.181102

Epoch 134/1000
Training Loss: 0.86222804, Training R2: 0.350140
Validation Loss: 1.06314814, Validation R2: 0.197317
Saved best model with validation R2 0.197317 to best_finetuned_model.pth

Epoch 135/1000
Training Loss: 0.85415791, Training R2: 0.336469
Validation Loss: 1.06624365, Validation R2: 0.195124

Epoch 136/1000
Training Loss: 0.84423080, Training R2: 0.355318
Validation Loss: 1.10811973, Validation R2: 0.178812

Epoch 137/1000
Training Loss: 0.85181767, Training R2: 0.358869
Validation Loss: 1.08548403, Validation R2: 0.178775

Epoch 138/1000
Training Loss: 0.84062726, Training R2: 0.356843
Validation Loss: 1.08185840, Validation R2: 0.175572

Epoch 139/1000
Training Loss: 0.85731523, Training R2: 0.323623
Validation Loss: 1.09526932, Validation R2: 0.185741

Epoch 140/1000
Training Loss: 0.83333972, Training R2: 0.366523
Validation Loss: 1.14430773, Validation R2: 0.158559

Epoch 141/1000
Training Loss: 0.86401604, Training R2: 0.342241
Validation Loss: 1.08052170, Validation R2: 0.176901

Epoch 142/1000
Training Loss: 0.88966109, Training R2: 0.281385
Validation Loss: 1.05990374, Validation R2: 0.188309

Epoch 143/1000
Training Loss: 0.85265044, Training R2: 0.353590
Validation Loss: 1.12668073, Validation R2: 0.180326

Epoch 144/1000
Training Loss: 0.86099906, Training R2: 0.348646
Validation Loss: 1.06341445, Validation R2: 0.184045

Epoch 145/1000
Training Loss: 0.84465661, Training R2: 0.350341
Validation Loss: 1.10174203, Validation R2: 0.190694

Epoch 146/1000
Training Loss: 0.83951347, Training R2: 0.367809
Validation Loss: 1.08241320, Validation R2: 0.193409

Epoch 147/1000
Training Loss: 0.83437170, Training R2: 0.358527
Validation Loss: 1.08722413, Validation R2: 0.196944

Epoch 148/1000
Training Loss: 0.85535264, Training R2: 0.350901
Validation Loss: 1.10476530, Validation R2: 0.187399

Epoch 149/1000
Training Loss: 0.83391822, Training R2: 0.361441
Validation Loss: 1.07640183, Validation R2: 0.147213

Epoch 150/1000
Training Loss: 0.86278615, Training R2: 0.316419
Validation Loss: 1.11485660, Validation R2: 0.176594

Epoch 151/1000
Training Loss: 0.86841444, Training R2: 0.341527
Validation Loss: 1.09603214, Validation R2: 0.188160

Epoch 152/1000
Training Loss: 0.83838958, Training R2: 0.354097
Validation Loss: 1.08669233, Validation R2: 0.188456

Epoch 153/1000
Training Loss: 0.83143416, Training R2: 0.361985
Validation Loss: 1.11770141, Validation R2: 0.177056

Epoch 154/1000
Training Loss: 0.83671272, Training R2: 0.365144
Validation Loss: 1.07716632, Validation R2: 0.186247

Epoch 155/1000
Epoch 00155: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.83391705, Training R2: 0.365867
Validation Loss: 1.12069261, Validation R2: 0.177031

Epoch 156/1000
学习率已减少 2 次
Training Loss: 0.84808186, Training R2: 0.359763
Validation Loss: 1.09602952, Validation R2: 0.191369

Epoch 157/1000
Training Loss: 0.81696465, Training R2: 0.383514
Validation Loss: 1.07243562, Validation R2: 0.196987

Epoch 158/1000
Training Loss: 0.82321400, Training R2: 0.370676
Validation Loss: 1.09706712, Validation R2: 0.195427

Epoch 159/1000
Training Loss: 0.82564216, Training R2: 0.370770
Validation Loss: 1.09354782, Validation R2: 0.195607

Epoch 160/1000
Training Loss: 0.81603170, Training R2: 0.381700
Validation Loss: 1.08247495, Validation R2: 0.200015
Saved best model with validation R2 0.200015 to best_finetuned_model.pth

Epoch 161/1000
Training Loss: 0.82149225, Training R2: 0.377587
Validation Loss: 1.08655393, Validation R2: 0.190603

Epoch 162/1000
Training Loss: 0.82891878, Training R2: 0.369764
Validation Loss: 1.07597792, Validation R2: 0.191039

Epoch 163/1000
Training Loss: 0.82472606, Training R2: 0.368947
Validation Loss: 1.07995331, Validation R2: 0.196421

Epoch 164/1000
Training Loss: 0.81508988, Training R2: 0.383771
Validation Loss: 1.12386262, Validation R2: 0.176306

Epoch 165/1000
Training Loss: 0.83961722, Training R2: 0.360907
Validation Loss: 1.09243321, Validation R2: 0.192412

Epoch 166/1000
Training Loss: 0.82004270, Training R2: 0.373848
Validation Loss: 1.08347940, Validation R2: 0.189862

Epoch 167/1000
Training Loss: 0.81953189, Training R2: 0.373575
Validation Loss: 1.09491205, Validation R2: 0.177184

Epoch 168/1000
Training Loss: 0.82243592, Training R2: 0.375238
Validation Loss: 1.09143031, Validation R2: 0.179346

Epoch 169/1000
Training Loss: 0.81638132, Training R2: 0.380324
Validation Loss: 1.08729839, Validation R2: 0.187991

Epoch 170/1000
Training Loss: 0.81036515, Training R2: 0.386259
Validation Loss: 1.09268045, Validation R2: 0.193334

Epoch 171/1000
Training Loss: 0.80964410, Training R2: 0.388386
Validation Loss: 1.08721912, Validation R2: 0.197855

Epoch 172/1000
Training Loss: 0.81049841, Training R2: 0.388130
Validation Loss: 1.08464754, Validation R2: 0.197130

Epoch 173/1000
Training Loss: 0.81226919, Training R2: 0.386823
Validation Loss: 1.08431792, Validation R2: 0.195047

Epoch 174/1000
Training Loss: 0.80934128, Training R2: 0.390609
Validation Loss: 1.07867169, Validation R2: 0.194431

Epoch 175/1000
Training Loss: 0.81034621, Training R2: 0.385881
Validation Loss: 1.08440399, Validation R2: 0.193540

Epoch 176/1000
Training Loss: 0.80666313, Training R2: 0.391290
Validation Loss: 1.10782194, Validation R2: 0.182686

Epoch 177/1000
Training Loss: 0.81256215, Training R2: 0.387821
Validation Loss: 1.09191310, Validation R2: 0.186766

Epoch 178/1000
Training Loss: 0.81614532, Training R2: 0.382517
Validation Loss: 1.07777727, Validation R2: 0.182979

Epoch 179/1000
Training Loss: 0.81613672, Training R2: 0.383700
Validation Loss: 1.10866153, Validation R2: 0.181225

Epoch 180/1000
Training Loss: 0.81656628, Training R2: 0.389408
Validation Loss: 1.08849978, Validation R2: 0.196357

Epoch 181/1000
Epoch 00181: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.80398369, Training R2: 0.396031
Validation Loss: 1.07200456, Validation R2: 0.199080

Epoch 182/1000
学习率已减少 3 次
Training Loss: 0.81243904, Training R2: 0.384549
Validation Loss: 1.07521081, Validation R2: 0.200215
Saved best model with validation R2 0.200215 to best_finetuned_model.pth

Epoch 183/1000
Training Loss: 0.80280911, Training R2: 0.395337
Validation Loss: 1.10423625, Validation R2: 0.189365

Epoch 184/1000
Training Loss: 0.81383104, Training R2: 0.391087
Validation Loss: 1.08706737, Validation R2: 0.200540
Saved best model with validation R2 0.200540 to best_finetuned_model.pth

Epoch 185/1000
Training Loss: 0.80341153, Training R2: 0.399431
Validation Loss: 1.07005012, Validation R2: 0.204726
Saved best model with validation R2 0.204726 to best_finetuned_model.pth

Epoch 186/1000
Training Loss: 0.80378750, Training R2: 0.396413
Validation Loss: 1.07081795, Validation R2: 0.202436

Epoch 187/1000
Training Loss: 0.80234146, Training R2: 0.395850
Validation Loss: 1.07532978, Validation R2: 0.200829

Epoch 188/1000
Training Loss: 0.80047654, Training R2: 0.396961
Validation Loss: 1.08146667, Validation R2: 0.197800

Epoch 189/1000
Training Loss: 0.79994806, Training R2: 0.396129
Validation Loss: 1.08563149, Validation R2: 0.195984

Epoch 190/1000
Training Loss: 0.80158439, Training R2: 0.395604
Validation Loss: 1.09244323, Validation R2: 0.193876

Epoch 191/1000
Training Loss: 0.79843549, Training R2: 0.394880
Validation Loss: 1.07245266, Validation R2: 0.196884

Epoch 192/1000
Training Loss: 0.80760077, Training R2: 0.385089
Validation Loss: 1.07567573, Validation R2: 0.197486

Epoch 193/1000
Training Loss: 0.79938553, Training R2: 0.395737
Validation Loss: 1.08930790, Validation R2: 0.196724

Epoch 194/1000
Training Loss: 0.79865543, Training R2: 0.398958
Validation Loss: 1.08315516, Validation R2: 0.201265

Epoch 195/1000
Training Loss: 0.79689067, Training R2: 0.398838
Validation Loss: 1.07155931, Validation R2: 0.206084
Saved best model with validation R2 0.206084 to best_finetuned_model.pth

Epoch 196/1000
Training Loss: 0.79979446, Training R2: 0.398080
Validation Loss: 1.07568324, Validation R2: 0.207111
Saved best model with validation R2 0.207111 to best_finetuned_model.pth

Epoch 197/1000
Training Loss: 0.79711595, Training R2: 0.400011
Validation Loss: 1.07265973, Validation R2: 0.206415

Epoch 198/1000
Training Loss: 0.79857803, Training R2: 0.398048
Validation Loss: 1.06836212, Validation R2: 0.203092

Epoch 199/1000
Training Loss: 0.79936552, Training R2: 0.395952
Validation Loss: 1.07654762, Validation R2: 0.198808

Epoch 200/1000
Training Loss: 0.80066289, Training R2: 0.393996
Validation Loss: 1.07266629, Validation R2: 0.197978

Epoch 201/1000
Training Loss: 0.79671276, Training R2: 0.396302
Validation Loss: 1.08557689, Validation R2: 0.196279

Epoch 202/1000
Training Loss: 0.80198554, Training R2: 0.397492
Validation Loss: 1.09325886, Validation R2: 0.194517

Epoch 203/1000
Training Loss: 0.79433603, Training R2: 0.402902
Validation Loss: 1.07188404, Validation R2: 0.198776

Epoch 204/1000
Training Loss: 0.80524329, Training R2: 0.386276
Validation Loss: 1.06972587, Validation R2: 0.197807

Epoch 205/1000
Training Loss: 0.79977466, Training R2: 0.393489
Validation Loss: 1.08992326, Validation R2: 0.196519

Epoch 206/1000
Training Loss: 0.79591212, Training R2: 0.401202
Validation Loss: 1.08001947, Validation R2: 0.197948

Epoch 207/1000
Training Loss: 0.79229190, Training R2: 0.402785
Validation Loss: 1.07108831, Validation R2: 0.196614

Epoch 208/1000
Training Loss: 0.79846217, Training R2: 0.397810
Validation Loss: 1.08038175, Validation R2: 0.196700

Epoch 209/1000
Training Loss: 0.79748549, Training R2: 0.402247
Validation Loss: 1.09978950, Validation R2: 0.189850

Epoch 210/1000
Training Loss: 0.79984091, Training R2: 0.399850
Validation Loss: 1.08984494, Validation R2: 0.195513

Epoch 211/1000
Training Loss: 0.79400136, Training R2: 0.401909
Validation Loss: 1.08306253, Validation R2: 0.198502

Epoch 212/1000
Training Loss: 0.79276240, Training R2: 0.402951
Validation Loss: 1.09490466, Validation R2: 0.193922

Epoch 213/1000
Training Loss: 0.79712254, Training R2: 0.399743
Validation Loss: 1.08435929, Validation R2: 0.199441

Epoch 214/1000
Training Loss: 0.79344883, Training R2: 0.402338
Validation Loss: 1.07513845, Validation R2: 0.201095

Epoch 215/1000
Training Loss: 0.78933430, Training R2: 0.404432
Validation Loss: 1.09966850, Validation R2: 0.190489

Epoch 216/1000
Training Loss: 0.80457997, Training R2: 0.393115
Validation Loss: 1.09236062, Validation R2: 0.192865

Epoch 217/1000
Epoch 00217: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.79341975, Training R2: 0.401168
Validation Loss: 1.07362521, Validation R2: 0.197822

Epoch 218/1000
学习率已减少 4 次
Training Loss: 0.79138627, Training R2: 0.401813
Validation Loss: 1.08278334, Validation R2: 0.196461

Epoch 219/1000
Training Loss: 0.78896336, Training R2: 0.405375
Validation Loss: 1.08108985, Validation R2: 0.197379

Epoch 220/1000
Training Loss: 0.78817820, Training R2: 0.405277
Validation Loss: 1.07644844, Validation R2: 0.198494

Epoch 221/1000
Training Loss: 0.79063795, Training R2: 0.402179
Validation Loss: 1.07204318, Validation R2: 0.198622

Epoch 222/1000
Training Loss: 0.79121379, Training R2: 0.401406
Validation Loss: 1.08134830, Validation R2: 0.198747

Epoch 223/1000
Training Loss: 0.78750504, Training R2: 0.406687
Validation Loss: 1.09103763, Validation R2: 0.194291

Epoch 224/1000
Training Loss: 0.78868269, Training R2: 0.405707
Validation Loss: 1.07877684, Validation R2: 0.199285

Epoch 225/1000
Training Loss: 0.78861979, Training R2: 0.404468
Validation Loss: 1.07381439, Validation R2: 0.200757

Epoch 226/1000
Training Loss: 0.78759691, Training R2: 0.405080
Validation Loss: 1.07906926, Validation R2: 0.200688

Epoch 227/1000
Training Loss: 0.78586200, Training R2: 0.407781
Validation Loss: 1.08766472, Validation R2: 0.197883

Epoch 228/1000
Training Loss: 0.78792656, Training R2: 0.406215
Validation Loss: 1.08621955, Validation R2: 0.198519

Epoch 229/1000
Training Loss: 0.78526715, Training R2: 0.407178
Validation Loss: 1.07563531, Validation R2: 0.201894

Epoch 230/1000
Training Loss: 0.78788624, Training R2: 0.405181
Validation Loss: 1.07485366, Validation R2: 0.202266

Epoch 231/1000
Training Loss: 0.78604307, Training R2: 0.406351
Validation Loss: 1.08683288, Validation R2: 0.198112

Epoch 232/1000
Training Loss: 0.78856928, Training R2: 0.405603
Validation Loss: 1.08852291, Validation R2: 0.197036

Epoch 233/1000
Training Loss: 0.78715322, Training R2: 0.405974
Validation Loss: 1.08082354, Validation R2: 0.200373

Epoch 234/1000
Training Loss: 0.78472095, Training R2: 0.407200
Validation Loss: 1.07505441, Validation R2: 0.202339

Epoch 235/1000
Training Loss: 0.78447370, Training R2: 0.408220
Validation Loss: 1.08269989, Validation R2: 0.200213

Epoch 236/1000
Training Loss: 0.78593424, Training R2: 0.408022
Validation Loss: 1.08463514, Validation R2: 0.198953

Epoch 237/1000
Training Loss: 0.78520617, Training R2: 0.408464
Validation Loss: 1.07167935, Validation R2: 0.203056

Epoch 238/1000
Epoch 00238: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.78519896, Training R2: 0.407590
Validation Loss: 1.07158875, Validation R2: 0.203017

Epoch 239/1000
学习率已减少 5 次
Training Loss: 0.78438734, Training R2: 0.408969
Validation Loss: 1.07490718, Validation R2: 0.202974

Epoch 240/1000
Training Loss: 0.78264285, Training R2: 0.409780
Validation Loss: 1.07719874, Validation R2: 0.202578

Epoch 241/1000
Training Loss: 0.78299501, Training R2: 0.409916
Validation Loss: 1.08061349, Validation R2: 0.201396

Epoch 242/1000
Training Loss: 0.78475981, Training R2: 0.408787
Validation Loss: 1.07816446, Validation R2: 0.202259

Epoch 243/1000
Training Loss: 0.78387185, Training R2: 0.408339
Validation Loss: 1.07282114, Validation R2: 0.203533

Epoch 244/1000
Training Loss: 0.78523325, Training R2: 0.406217
Validation Loss: 1.06969738, Validation R2: 0.203739

Epoch 245/1000
Training Loss: 0.78441941, Training R2: 0.407420
Validation Loss: 1.07135558, Validation R2: 0.203546

Epoch 246/1000
Training Loss: 0.78323311, Training R2: 0.408326
Validation Loss: 1.07523203, Validation R2: 0.202263

Epoch 247/1000
Training Loss: 0.78238323, Training R2: 0.409395
Validation Loss: 1.07533109, Validation R2: 0.201829

Epoch 248/1000
Training Loss: 0.78194928, Training R2: 0.409375
Validation Loss: 1.07772255, Validation R2: 0.200848

Epoch 249/1000
Training Loss: 0.78193606, Training R2: 0.409642
Validation Loss: 1.08166313, Validation R2: 0.199099

Epoch 250/1000
Training Loss: 0.78316793, Training R2: 0.408973
Validation Loss: 1.08482158, Validation R2: 0.197984

Epoch 251/1000
Training Loss: 0.78265147, Training R2: 0.408690
Validation Loss: 1.08146775, Validation R2: 0.199554

Epoch 252/1000
Training Loss: 0.78158326, Training R2: 0.408832
Validation Loss: 1.07835722, Validation R2: 0.200876

Epoch 253/1000
Training Loss: 0.78177603, Training R2: 0.408003
Validation Loss: 1.07205844, Validation R2: 0.201822

Epoch 254/1000
Training Loss: 0.78420252, Training R2: 0.405831
Validation Loss: 1.06985795, Validation R2: 0.202964

Epoch 255/1000
Training Loss: 0.78405490, Training R2: 0.405662
Validation Loss: 1.07142687, Validation R2: 0.204132

Epoch 256/1000
Training Loss: 0.78253550, Training R2: 0.408111
Validation Loss: 1.07213056, Validation R2: 0.204544

Epoch 257/1000
Training Loss: 0.78184289, Training R2: 0.408459
Validation Loss: 1.07408655, Validation R2: 0.204432

Epoch 258/1000
Training Loss: 0.78135882, Training R2: 0.409674
Validation Loss: 1.08142960, Validation R2: 0.202376

Epoch 259/1000
Epoch 00259: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.78179317, Training R2: 0.410203
Validation Loss: 1.08487117, Validation R2: 0.200920

Epoch 260/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
