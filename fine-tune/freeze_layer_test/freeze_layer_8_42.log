Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1092227

Epoch 1/1000
Training Loss: 1.27668638, Training R2: -0.258434
Validation Loss: 1.14993942, Validation R2: -0.030070
Saved best model with validation R2 -0.030070 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.17524974, Training R2: -0.162196
Validation Loss: 1.14897370, Validation R2: -0.072962

Epoch 3/1000
Training Loss: 1.11756057, Training R2: 0.000718
Validation Loss: 1.12280631, Validation R2: 0.016567
Saved best model with validation R2 0.016567 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.08692969, Training R2: 0.001097
Validation Loss: 1.09098077, Validation R2: 0.055506
Saved best model with validation R2 0.055506 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.07052443, Training R2: 0.090582
Validation Loss: 1.07737923, Validation R2: 0.038829

Epoch 6/1000
Training Loss: 1.04474137, Training R2: 0.065999
Validation Loss: 1.05480278, Validation R2: 0.136340
Saved best model with validation R2 0.136340 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 1.05200658, Training R2: 0.130039
Validation Loss: 1.12168038, Validation R2: -0.056835

Epoch 8/1000
Training Loss: 1.06835043, Training R2: 0.029409
Validation Loss: 1.07409775, Validation R2: 0.086300

Epoch 9/1000
Training Loss: 1.02671027, Training R2: 0.109835
Validation Loss: 1.06220865, Validation R2: 0.093878

Epoch 10/1000
Training Loss: 1.02612481, Training R2: 0.138799
Validation Loss: 1.03828990, Validation R2: 0.120522

Epoch 11/1000
Training Loss: 1.01539391, Training R2: 0.142260
Validation Loss: 1.03175616, Validation R2: 0.140750
Saved best model with validation R2 0.140750 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.02385226, Training R2: 0.154860
Validation Loss: 1.09520638, Validation R2: -0.000087

Epoch 13/1000
Training Loss: 1.03934891, Training R2: 0.077464
Validation Loss: 1.10866690, Validation R2: 0.084391

Epoch 14/1000
Training Loss: 1.07781027, Training R2: 0.116159
Validation Loss: 1.10232639, Validation R2: -0.022615

Epoch 15/1000
Training Loss: 1.03084239, Training R2: 0.081406
Validation Loss: 1.06909561, Validation R2: 0.125278

Epoch 16/1000
Training Loss: 1.05202777, Training R2: 0.143809
Validation Loss: 1.04551172, Validation R2: 0.097046

Epoch 17/1000
Training Loss: 0.99814636, Training R2: 0.151365
Validation Loss: 1.04017830, Validation R2: 0.101369

Epoch 18/1000
Training Loss: 0.99295200, Training R2: 0.153670
Validation Loss: 1.02221489, Validation R2: 0.152816
Saved best model with validation R2 0.152816 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 1.00146425, Training R2: 0.197873
Validation Loss: 1.00972807, Validation R2: 0.155840
Saved best model with validation R2 0.155840 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 0.96775096, Training R2: 0.210820
Validation Loss: 1.02055645, Validation R2: 0.154208

Epoch 21/1000
Training Loss: 0.95382675, Training R2: 0.208727
Validation Loss: 1.02663386, Validation R2: 0.120383

Epoch 22/1000
Training Loss: 0.93924933, Training R2: 0.240226
Validation Loss: 1.03745973, Validation R2: 0.149015

Epoch 23/1000
Training Loss: 0.95535940, Training R2: 0.235620
Validation Loss: 1.01745117, Validation R2: 0.133112

Epoch 24/1000
Training Loss: 0.94274550, Training R2: 0.246013
Validation Loss: 1.09236979, Validation R2: -0.014705

Epoch 25/1000
Training Loss: 0.99072343, Training R2: 0.144540
Validation Loss: 0.98583782, Validation R2: 0.162604
Saved best model with validation R2 0.162604 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 0.99010611, Training R2: 0.136474
Validation Loss: 0.99899352, Validation R2: 0.190369
Saved best model with validation R2 0.190369 to best_finetuned_model.pth

Epoch 27/1000
Training Loss: 0.95943167, Training R2: 0.247352
Validation Loss: 0.98640060, Validation R2: 0.168959

Epoch 28/1000
Training Loss: 0.91343044, Training R2: 0.271920
Validation Loss: 0.97099942, Validation R2: 0.221047
Saved best model with validation R2 0.221047 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 0.91740303, Training R2: 0.276886
Validation Loss: 1.03360379, Validation R2: 0.159735

Epoch 30/1000
Training Loss: 0.95481020, Training R2: 0.249498
Validation Loss: 0.95129454, Validation R2: 0.219255

Epoch 31/1000
Training Loss: 0.89107542, Training R2: 0.300374
Validation Loss: 0.94777852, Validation R2: 0.228555
Saved best model with validation R2 0.228555 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 0.90122809, Training R2: 0.275341
Validation Loss: 0.93500471, Validation R2: 0.256730
Saved best model with validation R2 0.256730 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 0.88293777, Training R2: 0.313085
Validation Loss: 0.99805886, Validation R2: 0.121236

Epoch 34/1000
Training Loss: 0.90534935, Training R2: 0.282939
Validation Loss: 0.92705262, Validation R2: 0.219619

Epoch 35/1000
Training Loss: 0.91744412, Training R2: 0.243639
Validation Loss: 0.96055150, Validation R2: 0.232220

Epoch 36/1000
Training Loss: 0.88273635, Training R2: 0.312406
Validation Loss: 0.96825469, Validation R2: 0.176950

Epoch 37/1000
Training Loss: 0.87089468, Training R2: 0.302212
Validation Loss: 0.91143352, Validation R2: 0.267696
Saved best model with validation R2 0.267696 to best_finetuned_model.pth

Epoch 38/1000
Training Loss: 0.86137136, Training R2: 0.326376
Validation Loss: 0.90605205, Validation R2: 0.270563
Saved best model with validation R2 0.270563 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.83357723, Training R2: 0.362266
Validation Loss: 0.91722089, Validation R2: 0.259126

Epoch 40/1000
Training Loss: 0.84851019, Training R2: 0.341282
Validation Loss: 0.90029758, Validation R2: 0.286210
Saved best model with validation R2 0.286210 to best_finetuned_model.pth

Epoch 41/1000
Training Loss: 0.82586114, Training R2: 0.361182
Validation Loss: 0.88804013, Validation R2: 0.300736
Saved best model with validation R2 0.300736 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 0.82949563, Training R2: 0.366089
Validation Loss: 0.87340188, Validation R2: 0.305963
Saved best model with validation R2 0.305963 to best_finetuned_model.pth

Epoch 43/1000
Training Loss: 0.81026473, Training R2: 0.376479
Validation Loss: 0.91165525, Validation R2: 0.238757

Epoch 44/1000
Training Loss: 0.82984360, Training R2: 0.333453
Validation Loss: 0.90282124, Validation R2: 0.277640

Epoch 45/1000
Training Loss: 0.81508576, Training R2: 0.372280
Validation Loss: 0.88267463, Validation R2: 0.301333

Epoch 46/1000
Training Loss: 0.81944088, Training R2: 0.371240
Validation Loss: 0.94809890, Validation R2: 0.198945

Epoch 47/1000
Training Loss: 0.84705091, Training R2: 0.332079
Validation Loss: 0.85996217, Validation R2: 0.326023
Saved best model with validation R2 0.326023 to best_finetuned_model.pth

Epoch 48/1000
Training Loss: 0.85203000, Training R2: 0.314789
Validation Loss: 0.88454318, Validation R2: 0.305073

Epoch 49/1000
Training Loss: 0.86322716, Training R2: 0.345498
Validation Loss: 0.90785825, Validation R2: 0.268966

Epoch 50/1000
Training Loss: 0.81351853, Training R2: 0.368821
Validation Loss: 0.91626525, Validation R2: 0.279016

Epoch 51/1000
Training Loss: 0.82361562, Training R2: 0.354716
Validation Loss: 0.83948147, Validation R2: 0.352723
Saved best model with validation R2 0.352723 to best_finetuned_model.pth

Epoch 52/1000
Training Loss: 0.83027430, Training R2: 0.368211
Validation Loss: 0.92872447, Validation R2: 0.235976

Epoch 53/1000
Training Loss: 0.91864369, Training R2: 0.242001
Validation Loss: 0.88412023, Validation R2: 0.319131

Epoch 54/1000
Training Loss: 0.83605522, Training R2: 0.378883
Validation Loss: 0.96159881, Validation R2: 0.167369

Epoch 55/1000
Training Loss: 0.87038149, Training R2: 0.295576
Validation Loss: 1.00989902, Validation R2: 0.177878

Epoch 56/1000
Training Loss: 0.90180202, Training R2: 0.289212
Validation Loss: 1.02646685, Validation R2: 0.090913

Epoch 57/1000
Training Loss: 0.87097187, Training R2: 0.295772
Validation Loss: 0.90739995, Validation R2: 0.264823

Epoch 58/1000
Training Loss: 0.80907156, Training R2: 0.374583
Validation Loss: 0.89800614, Validation R2: 0.246387

Epoch 59/1000
Training Loss: 0.82360889, Training R2: 0.379759
Validation Loss: 0.87507701, Validation R2: 0.278246

Epoch 60/1000
Training Loss: 0.84710658, Training R2: 0.347287
Validation Loss: 0.95753044, Validation R2: 0.226609

Epoch 61/1000
Training Loss: 0.93554440, Training R2: 0.278000
Validation Loss: 0.90639234, Validation R2: 0.245492

Epoch 62/1000
Training Loss: 0.88295063, Training R2: 0.277545
Validation Loss: 0.84580928, Validation R2: 0.328124

Epoch 63/1000
Training Loss: 0.83393107, Training R2: 0.359814
Validation Loss: 0.84342849, Validation R2: 0.321597

Epoch 64/1000
Training Loss: 0.81488458, Training R2: 0.385312
Validation Loss: 0.85691100, Validation R2: 0.328645

Epoch 65/1000
Training Loss: 0.81901283, Training R2: 0.386676
Validation Loss: 0.88441592, Validation R2: 0.285028

Epoch 66/1000
Training Loss: 0.79199576, Training R2: 0.391570
Validation Loss: 0.89040065, Validation R2: 0.278834

Epoch 67/1000
Training Loss: 0.76935532, Training R2: 0.422047
Validation Loss: 0.87960738, Validation R2: 0.275117

Epoch 68/1000
Training Loss: 0.77412451, Training R2: 0.411752
Validation Loss: 0.86575377, Validation R2: 0.301029

Epoch 69/1000
Training Loss: 0.75389031, Training R2: 0.442025
Validation Loss: 0.85997641, Validation R2: 0.315688

Epoch 70/1000
Training Loss: 0.75083884, Training R2: 0.451513
Validation Loss: 0.86832136, Validation R2: 0.292028

Epoch 71/1000
Training Loss: 0.74178801, Training R2: 0.451131
Validation Loss: 0.87304699, Validation R2: 0.283482

Epoch 72/1000
Epoch 00072: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.74813937, Training R2: 0.445844
Validation Loss: 0.88989180, Validation R2: 0.284179

Epoch 73/1000
学习率已减少 1 次
Training Loss: 0.76620705, Training R2: 0.434052
Validation Loss: 0.86619174, Validation R2: 0.290340

Epoch 74/1000
Training Loss: 0.75508584, Training R2: 0.434953
Validation Loss: 0.86644471, Validation R2: 0.307056

Epoch 75/1000
Training Loss: 0.76614076, Training R2: 0.437105
Validation Loss: 0.87738842, Validation R2: 0.298381

Epoch 76/1000
Training Loss: 0.75022926, Training R2: 0.443101
Validation Loss: 0.90519691, Validation R2: 0.242022

Epoch 77/1000
Training Loss: 0.74908705, Training R2: 0.440974
Validation Loss: 0.85656846, Validation R2: 0.315322

Epoch 78/1000
Training Loss: 0.73342822, Training R2: 0.465314
Validation Loss: 0.85206473, Validation R2: 0.309785

Epoch 79/1000
Training Loss: 0.76854919, Training R2: 0.430234
Validation Loss: 0.84364879, Validation R2: 0.336784

Epoch 80/1000
Training Loss: 0.74222655, Training R2: 0.463762
Validation Loss: 0.86950314, Validation R2: 0.323831

Epoch 81/1000
Training Loss: 0.74551985, Training R2: 0.462120
Validation Loss: 0.85966474, Validation R2: 0.298956

Epoch 82/1000
Training Loss: 0.74637520, Training R2: 0.457733
Validation Loss: 0.86767226, Validation R2: 0.288167

Epoch 83/1000
Training Loss: 0.73179245, Training R2: 0.466991
Validation Loss: 0.86655837, Validation R2: 0.299310

Epoch 84/1000
Training Loss: 0.71720171, Training R2: 0.480167
Validation Loss: 0.86706960, Validation R2: 0.295376

Epoch 85/1000
Training Loss: 0.72384826, Training R2: 0.474067
Validation Loss: 0.85191107, Validation R2: 0.322288

Epoch 86/1000
Training Loss: 0.71500839, Training R2: 0.485255
Validation Loss: 0.84750980, Validation R2: 0.327253

Epoch 87/1000
Training Loss: 0.71681079, Training R2: 0.482360
Validation Loss: 0.86680394, Validation R2: 0.304573

Epoch 88/1000
Training Loss: 0.71314820, Training R2: 0.481466
Validation Loss: 0.86446738, Validation R2: 0.317451

Epoch 89/1000
Training Loss: 0.71770764, Training R2: 0.476044
Validation Loss: 0.86147422, Validation R2: 0.309849

Epoch 90/1000
Training Loss: 0.71203198, Training R2: 0.482930
Validation Loss: 0.85232353, Validation R2: 0.319037

Epoch 91/1000
Training Loss: 0.70722780, Training R2: 0.484083
Validation Loss: 0.85931516, Validation R2: 0.313959

Epoch 92/1000
Training Loss: 0.71222747, Training R2: 0.475084
Validation Loss: 0.84347302, Validation R2: 0.329960

Epoch 93/1000
Epoch 00093: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.70905703, Training R2: 0.480710
Validation Loss: 0.84617597, Validation R2: 0.330704

Epoch 94/1000
学习率已减少 2 次
Training Loss: 0.70588734, Training R2: 0.486595
Validation Loss: 0.84666729, Validation R2: 0.332750

Epoch 95/1000
Training Loss: 0.69594858, Training R2: 0.493514
Validation Loss: 0.84517151, Validation R2: 0.340203

Epoch 96/1000
Training Loss: 0.70332742, Training R2: 0.493055
Validation Loss: 0.84482849, Validation R2: 0.343575

Epoch 97/1000
Training Loss: 0.69819812, Training R2: 0.493527
Validation Loss: 0.84924251, Validation R2: 0.335229

Epoch 98/1000
Training Loss: 0.69923235, Training R2: 0.495964
Validation Loss: 0.84673953, Validation R2: 0.337916

Epoch 99/1000
Training Loss: 0.70595760, Training R2: 0.490971
Validation Loss: 0.84973782, Validation R2: 0.327588

Epoch 100/1000
Training Loss: 0.68963213, Training R2: 0.501347
Validation Loss: 0.84697539, Validation R2: 0.325467

Epoch 101/1000
Training Loss: 0.69193136, Training R2: 0.500848
Validation Loss: 0.84624141, Validation R2: 0.327831

Epoch 102/1000
Training Loss: 0.69586865, Training R2: 0.497432
Validation Loss: 0.84801894, Validation R2: 0.323328

Epoch 103/1000
Training Loss: 0.69253916, Training R2: 0.500478
Validation Loss: 0.85403413, Validation R2: 0.314863

Epoch 104/1000
Training Loss: 0.68701230, Training R2: 0.503616
Validation Loss: 0.84740508, Validation R2: 0.330074

Epoch 105/1000
Training Loss: 0.68957259, Training R2: 0.504090
Validation Loss: 0.83421063, Validation R2: 0.338469

Epoch 106/1000
Training Loss: 0.68829052, Training R2: 0.508781
Validation Loss: 0.83200043, Validation R2: 0.346855

Epoch 107/1000
Training Loss: 0.68497818, Training R2: 0.511412
Validation Loss: 0.83647060, Validation R2: 0.342113

Epoch 108/1000
Training Loss: 0.68166681, Training R2: 0.512918
Validation Loss: 0.84754252, Validation R2: 0.324288

Epoch 109/1000
Training Loss: 0.68436581, Training R2: 0.509617
Validation Loss: 0.85553432, Validation R2: 0.319648

Epoch 110/1000
Training Loss: 0.68532049, Training R2: 0.506495
Validation Loss: 0.86195654, Validation R2: 0.314340

Epoch 111/1000
Training Loss: 0.68160983, Training R2: 0.510587
Validation Loss: 0.85566390, Validation R2: 0.319004

Epoch 112/1000
Training Loss: 0.69006118, Training R2: 0.508945
Validation Loss: 0.84515303, Validation R2: 0.329552

Epoch 113/1000
Training Loss: 0.67654004, Training R2: 0.516900
Validation Loss: 0.83842891, Validation R2: 0.344047

Epoch 114/1000
Epoch 00114: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.68274956, Training R2: 0.512607
Validation Loss: 0.83413833, Validation R2: 0.339890

Epoch 115/1000
学习率已减少 3 次
Training Loss: 0.67597708, Training R2: 0.517099
Validation Loss: 0.83782285, Validation R2: 0.342189

Epoch 116/1000
Training Loss: 0.67701779, Training R2: 0.516447
Validation Loss: 0.84159541, Validation R2: 0.338999

Epoch 117/1000
Training Loss: 0.67433901, Training R2: 0.518725
Validation Loss: 0.84612995, Validation R2: 0.332921

Epoch 118/1000
Training Loss: 0.67346925, Training R2: 0.520071
Validation Loss: 0.84277344, Validation R2: 0.339295

Epoch 119/1000
Training Loss: 0.67772068, Training R2: 0.516989
Validation Loss: 0.84019345, Validation R2: 0.340406

Epoch 120/1000
Training Loss: 0.67123946, Training R2: 0.521487
Validation Loss: 0.84327602, Validation R2: 0.329640

Epoch 121/1000
Training Loss: 0.67192697, Training R2: 0.519870
Validation Loss: 0.84615219, Validation R2: 0.326034

Epoch 122/1000
Training Loss: 0.67112259, Training R2: 0.519532
Validation Loss: 0.84765881, Validation R2: 0.324215

Epoch 123/1000
Training Loss: 0.66874175, Training R2: 0.520952
Validation Loss: 0.84565043, Validation R2: 0.329065

Epoch 124/1000
Training Loss: 0.66929056, Training R2: 0.522791
Validation Loss: 0.84147698, Validation R2: 0.334116

Epoch 125/1000
Training Loss: 0.66810952, Training R2: 0.524948
Validation Loss: 0.83744019, Validation R2: 0.335005

Epoch 126/1000
Training Loss: 0.67041668, Training R2: 0.524475
Validation Loss: 0.84199214, Validation R2: 0.332318

Epoch 127/1000
Training Loss: 0.66627626, Training R2: 0.523938
Validation Loss: 0.85043854, Validation R2: 0.323617

Epoch 128/1000
Training Loss: 0.66745049, Training R2: 0.521095
Validation Loss: 0.84928191, Validation R2: 0.323170

Epoch 129/1000
Training Loss: 0.66454650, Training R2: 0.524466
Validation Loss: 0.84587628, Validation R2: 0.330531

Epoch 130/1000
Training Loss: 0.66395339, Training R2: 0.526964
Validation Loss: 0.84167427, Validation R2: 0.335761

Epoch 131/1000
Training Loss: 0.66529193, Training R2: 0.526099
Validation Loss: 0.84200627, Validation R2: 0.334449

Epoch 132/1000
Training Loss: 0.66396529, Training R2: 0.526207
Validation Loss: 0.84019119, Validation R2: 0.334437

Epoch 133/1000
Training Loss: 0.66332583, Training R2: 0.525097
Validation Loss: 0.84288388, Validation R2: 0.330106

Epoch 134/1000
Training Loss: 0.66109611, Training R2: 0.526422
Validation Loss: 0.84308314, Validation R2: 0.330775

Epoch 135/1000
Epoch 00135: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.66157006, Training R2: 0.525552
Validation Loss: 0.84276235, Validation R2: 0.328101

Epoch 136/1000
学习率已减少 4 次
Training Loss: 0.66604537, Training R2: 0.525352
Validation Loss: 0.84307069, Validation R2: 0.327628

Epoch 137/1000
Training Loss: 0.66104085, Training R2: 0.527040
Validation Loss: 0.84264380, Validation R2: 0.331273

Epoch 138/1000
Training Loss: 0.66209028, Training R2: 0.526196
Validation Loss: 0.84476250, Validation R2: 0.329711

Epoch 139/1000
Training Loss: 0.66114017, Training R2: 0.526077
Validation Loss: 0.84718192, Validation R2: 0.325461

Epoch 140/1000
Training Loss: 0.66203792, Training R2: 0.526236
Validation Loss: 0.84634572, Validation R2: 0.328227

Epoch 141/1000
Training Loss: 0.66037559, Training R2: 0.528220
Validation Loss: 0.84630859, Validation R2: 0.330875

Epoch 142/1000
Training Loss: 0.65865577, Training R2: 0.528672
Validation Loss: 0.84450591, Validation R2: 0.331104

Epoch 143/1000
Training Loss: 0.65709761, Training R2: 0.528779
Validation Loss: 0.84474975, Validation R2: 0.329943

Epoch 144/1000
Training Loss: 0.65797552, Training R2: 0.528865
Validation Loss: 0.84493053, Validation R2: 0.330332

Epoch 145/1000
Training Loss: 0.65667092, Training R2: 0.529782
Validation Loss: 0.84349757, Validation R2: 0.330392

Epoch 146/1000
Training Loss: 0.65973059, Training R2: 0.529087
Validation Loss: 0.84276760, Validation R2: 0.330285

Epoch 147/1000
Training Loss: 0.65763700, Training R2: 0.528590
Validation Loss: 0.84133041, Validation R2: 0.333116

Epoch 148/1000
Training Loss: 0.65886382, Training R2: 0.529195
Validation Loss: 0.83966368, Validation R2: 0.332997

Epoch 149/1000
Training Loss: 0.65777183, Training R2: 0.530173
Validation Loss: 0.84209883, Validation R2: 0.329295

Epoch 150/1000
Training Loss: 0.65654327, Training R2: 0.530444
Validation Loss: 0.84526914, Validation R2: 0.330342

Epoch 151/1000
Training Loss: 0.65582314, Training R2: 0.530723
Validation Loss: 0.84611934, Validation R2: 0.327846

Epoch 152/1000
Training Loss: 0.65691239, Training R2: 0.531423
Validation Loss: 0.84564579, Validation R2: 0.328756

Epoch 153/1000
Training Loss: 0.65578765, Training R2: 0.531649
Validation Loss: 0.84630966, Validation R2: 0.330743

Epoch 154/1000
Training Loss: 0.65507894, Training R2: 0.531020
Validation Loss: 0.84373420, Validation R2: 0.332148

Epoch 155/1000
Training Loss: 0.65400245, Training R2: 0.531902
Validation Loss: 0.84103018, Validation R2: 0.333557

Epoch 156/1000
Epoch 00156: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.65410368, Training R2: 0.531810
Validation Loss: 0.84275353, Validation R2: 0.331777

Epoch 157/1000
学习率已减少 5 次
Training Loss: 0.65325585, Training R2: 0.532705
Validation Loss: 0.84168547, Validation R2: 0.333300

Epoch 158/1000
Training Loss: 0.65295967, Training R2: 0.533173
Validation Loss: 0.83970547, Validation R2: 0.335696

Epoch 159/1000
Training Loss: 0.65346207, Training R2: 0.532983
Validation Loss: 0.83795220, Validation R2: 0.337754

Epoch 160/1000
Training Loss: 0.65345845, Training R2: 0.533043
Validation Loss: 0.83733922, Validation R2: 0.338423

Epoch 161/1000
Training Loss: 0.65265775, Training R2: 0.533580
Validation Loss: 0.83766347, Validation R2: 0.338413

Epoch 162/1000
Training Loss: 0.65228817, Training R2: 0.534036
Validation Loss: 0.83800870, Validation R2: 0.339251

Epoch 163/1000
Training Loss: 0.65225951, Training R2: 0.533832
Validation Loss: 0.83993590, Validation R2: 0.339094

Epoch 164/1000
Training Loss: 0.65390490, Training R2: 0.532575
Validation Loss: 0.84218138, Validation R2: 0.336275

Epoch 165/1000
Training Loss: 0.65238450, Training R2: 0.533416
Validation Loss: 0.84318721, Validation R2: 0.333254

Epoch 166/1000
Training Loss: 0.65208057, Training R2: 0.533855
Validation Loss: 0.84411001, Validation R2: 0.331778

Epoch 167/1000
Training Loss: 0.65156775, Training R2: 0.534159
Validation Loss: 0.84358394, Validation R2: 0.332938

Epoch 168/1000
Training Loss: 0.65102635, Training R2: 0.534576
Validation Loss: 0.84296185, Validation R2: 0.333040

Epoch 169/1000
Training Loss: 0.65110412, Training R2: 0.534315
Validation Loss: 0.84206665, Validation R2: 0.333569

Epoch 170/1000
Training Loss: 0.65062669, Training R2: 0.534555
Validation Loss: 0.84153473, Validation R2: 0.335647

Epoch 171/1000
Training Loss: 0.65146081, Training R2: 0.534291
Validation Loss: 0.84235615, Validation R2: 0.334658

Epoch 172/1000
Training Loss: 0.65094681, Training R2: 0.534337
Validation Loss: 0.84226638, Validation R2: 0.333231

Epoch 173/1000
Training Loss: 0.65041370, Training R2: 0.534689
Validation Loss: 0.84230971, Validation R2: 0.331953

Epoch 174/1000
Training Loss: 0.65155855, Training R2: 0.534268
Validation Loss: 0.84249151, Validation R2: 0.331836

Epoch 175/1000
Training Loss: 0.65077739, Training R2: 0.534956
Validation Loss: 0.84157407, Validation R2: 0.333594

Epoch 176/1000
Training Loss: 0.64986066, Training R2: 0.535404
Validation Loss: 0.84009391, Validation R2: 0.337284

Epoch 177/1000
Epoch 00177: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.65009252, Training R2: 0.536146
Validation Loss: 0.83837414, Validation R2: 0.337955

Epoch 178/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
