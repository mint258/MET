Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Trainable
interaction_blocks.2.conv1.lin_rel.bias: Trainable
interaction_blocks.2.conv1.lin_root.weight: Trainable
interaction_blocks.2.conv2.lin_rel.weight: Trainable
interaction_blocks.2.conv2.lin_rel.bias: Trainable
interaction_blocks.2.conv2.lin_root.weight: Trainable
interaction_blocks.2.lin1.weight: Trainable
interaction_blocks.2.lin1.bias: Trainable
interaction_blocks.2.lin2.weight: Trainable
interaction_blocks.2.lin2.bias: Trainable
interaction_blocks.2.lin_cat.weight: Trainable
interaction_blocks.2.lin_cat.bias: Trainable
interaction_blocks.2.norm.weight: Trainable
interaction_blocks.2.norm.bias: Trainable
interaction_blocks.2.norm.mean_scale: Trainable
interaction_blocks.2.lin_feature1.lin1.weight: Trainable
interaction_blocks.2.lin_feature1.lin2.weight: Trainable
interaction_blocks.2.lin_feature2.lin1.weight: Trainable
interaction_blocks.2.lin_feature2.lin2.weight: Trainable
interaction_blocks.2.lin.weight: Trainable
interaction_blocks.2.lin.bias: Trainable
interaction_blocks.2.lins.0.weight: Trainable
interaction_blocks.2.lins.0.bias: Trainable
interaction_blocks.2.lins.1.weight: Trainable
interaction_blocks.2.lins.1.bias: Trainable
interaction_blocks.2.lins.2.weight: Trainable
interaction_blocks.2.lins.2.bias: Trainable
interaction_blocks.2.lins.3.weight: Trainable
interaction_blocks.2.lins.3.bias: Trainable
interaction_blocks.2.final.weight: Trainable
interaction_blocks.2.final.bias: Trainable
interaction_blocks.3.conv1.lin_rel.weight: Trainable
interaction_blocks.3.conv1.lin_rel.bias: Trainable
interaction_blocks.3.conv1.lin_root.weight: Trainable
interaction_blocks.3.conv2.lin_rel.weight: Trainable
interaction_blocks.3.conv2.lin_rel.bias: Trainable
interaction_blocks.3.conv2.lin_root.weight: Trainable
interaction_blocks.3.lin1.weight: Trainable
interaction_blocks.3.lin1.bias: Trainable
interaction_blocks.3.lin2.weight: Trainable
interaction_blocks.3.lin2.bias: Trainable
interaction_blocks.3.lin_cat.weight: Trainable
interaction_blocks.3.lin_cat.bias: Trainable
interaction_blocks.3.norm.weight: Trainable
interaction_blocks.3.norm.bias: Trainable
interaction_blocks.3.norm.mean_scale: Trainable
interaction_blocks.3.lin_feature1.lin1.weight: Trainable
interaction_blocks.3.lin_feature1.lin2.weight: Trainable
interaction_blocks.3.lin_feature2.lin1.weight: Trainable
interaction_blocks.3.lin_feature2.lin2.weight: Trainable
interaction_blocks.3.lin.weight: Trainable
interaction_blocks.3.lin.bias: Trainable
interaction_blocks.3.lins.0.weight: Trainable
interaction_blocks.3.lins.0.bias: Trainable
interaction_blocks.3.lins.1.weight: Trainable
interaction_blocks.3.lins.1.bias: Trainable
interaction_blocks.3.lins.2.weight: Trainable
interaction_blocks.3.lins.2.bias: Trainable
interaction_blocks.3.lins.3.weight: Trainable
interaction_blocks.3.lins.3.bias: Trainable
interaction_blocks.3.final.weight: Trainable
interaction_blocks.3.final.bias: Trainable
lins.0.weight: Trainable
lins.0.bias: Trainable
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 3126019

Epoch 1/1000
Training Loss: 2.45670632, Training R2: -3.368996
Validation Loss: 1.27228546, Validation R2: -0.144448
Saved best model with validation R2 -0.144448 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.23657168, Training R2: -0.214452
Validation Loss: 1.23241019, Validation R2: -0.016643
Saved best model with validation R2 -0.016643 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.16699356, Training R2: -0.190502
Validation Loss: 1.24078870, Validation R2: -0.071759

Epoch 4/1000
Training Loss: 1.15456758, Training R2: -0.057800
Validation Loss: 1.26836753, Validation R2: -0.003623
Saved best model with validation R2 -0.003623 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.12446660, Training R2: -0.004224
Validation Loss: 1.24971199, Validation R2: -0.093633

Epoch 6/1000
Training Loss: 1.12690159, Training R2: -0.083846
Validation Loss: 1.23240304, Validation R2: -0.041492

Epoch 7/1000
Training Loss: 1.12265193, Training R2: -0.084743
Validation Loss: 1.23784757, Validation R2: -0.062167

Epoch 8/1000
Training Loss: 1.11868146, Training R2: -0.032677
Validation Loss: 1.23582304, Validation R2: -0.008692

Epoch 9/1000
Training Loss: 1.11833383, Training R2: -0.027336
Validation Loss: 1.24849057, Validation R2: -0.090659

Epoch 10/1000
Training Loss: 1.12363213, Training R2: -0.098477
Validation Loss: 1.23319042, Validation R2: -0.015054

Epoch 11/1000
Training Loss: 1.13874686, Training R2: -0.018529
Validation Loss: 1.26151133, Validation R2: -0.001333
Saved best model with validation R2 -0.001333 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.13372216, Training R2: -0.006185
Validation Loss: 1.23311079, Validation R2: -0.046638

Epoch 13/1000
Training Loss: 1.12067614, Training R2: -0.079080
Validation Loss: 1.23271406, Validation R2: -0.045211

Epoch 14/1000
Training Loss: 1.11791968, Training R2: -0.023084
Validation Loss: 1.23838496, Validation R2: -0.004284

Epoch 15/1000
Training Loss: 1.12236294, Training R2: -0.023216
Validation Loss: 1.23144877, Validation R2: -0.036171

Epoch 16/1000
Training Loss: 1.11525063, Training R2: -0.020972
Validation Loss: 1.24005067, Validation R2: -0.002776

Epoch 17/1000
Training Loss: 1.12592513, Training R2: -0.000148
Validation Loss: 1.23156250, Validation R2: -0.018691

Epoch 18/1000
Training Loss: 1.11422110, Training R2: -0.033153
Validation Loss: 1.25353992, Validation R2: -0.102867

Epoch 19/1000
Training Loss: 1.13446872, Training R2: -0.133798
Validation Loss: 1.23210716, Validation R2: -0.014586

Epoch 20/1000
Training Loss: 1.14127620, Training R2: -0.017508
Validation Loss: 1.23452520, Validation R2: -0.006224

Epoch 21/1000
Training Loss: 1.11832613, Training R2: -0.045866
Validation Loss: 1.24202204, Validation R2: -0.077078

Epoch 22/1000
Training Loss: 1.11679367, Training R2: -0.041261
Validation Loss: 1.24639153, Validation R2: 0.003279
Saved best model with validation R2 0.003279 to best_finetuned_model.pth

Epoch 23/1000
Training Loss: 1.12590878, Training R2: 0.008894
Validation Loss: 1.23095345, Validation R2: -0.041716

Epoch 24/1000
Training Loss: 1.12224066, Training R2: -0.098628
Validation Loss: 1.23229432, Validation R2: -0.055353

Epoch 25/1000
Training Loss: 1.10366918, Training R2: -0.017787
Validation Loss: 1.24104881, Validation R2: 0.015843
Saved best model with validation R2 0.015843 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 1.14060364, Training R2: 0.005192
Validation Loss: 1.22827470, Validation R2: 0.001136

Epoch 27/1000
Training Loss: 1.11942643, Training R2: -0.039520
Validation Loss: 1.24618363, Validation R2: -0.089439

Epoch 28/1000
Training Loss: 1.11523597, Training R2: -0.072348
Validation Loss: 1.23684859, Validation R2: 0.013723

Epoch 29/1000
Training Loss: 1.10941366, Training R2: 0.035326
Validation Loss: 1.24499285, Validation R2: -0.094581

Epoch 30/1000
Training Loss: 1.14868662, Training R2: -0.173962
Validation Loss: 1.22587109, Validation R2: 0.023464
Saved best model with validation R2 0.023464 to best_finetuned_model.pth

Epoch 31/1000
Training Loss: 1.08801936, Training R2: 0.066863
Validation Loss: 1.19005597, Validation R2: 0.024821
Saved best model with validation R2 0.024821 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 1.06303092, Training R2: 0.052707
Validation Loss: 1.19642210, Validation R2: 0.009086

Epoch 33/1000
Training Loss: 1.08703460, Training R2: 0.029688
Validation Loss: 1.24017000, Validation R2: -0.063528

Epoch 34/1000
Training Loss: 1.27626254, Training R2: -0.344569
Validation Loss: 1.25485623, Validation R2: -0.021372

Epoch 35/1000
Training Loss: 1.14316579, Training R2: -0.126374
Validation Loss: 1.27652502, Validation R2: -0.148684

Epoch 36/1000
Training Loss: 1.13017299, Training R2: -0.114636
Validation Loss: 1.24900734, Validation R2: -0.000178

Epoch 37/1000
Training Loss: 1.14106759, Training R2: -0.008452
Validation Loss: 1.23401368, Validation R2: -0.012883

Epoch 38/1000
Training Loss: 1.12697655, Training R2: -0.077267
Validation Loss: 1.28476822, Validation R2: -0.165207

Epoch 39/1000
Training Loss: 1.13915054, Training R2: -0.132502
Validation Loss: 1.26058745, Validation R2: -0.001255

Epoch 40/1000
Training Loss: 1.17346938, Training R2: -0.044549
Validation Loss: 1.28763938, Validation R2: -0.014586

Epoch 41/1000
Training Loss: 1.14210981, Training R2: -0.019682
Validation Loss: 1.25795960, Validation R2: -0.111672

Epoch 42/1000
Training Loss: 1.15249106, Training R2: -0.179790
Validation Loss: 1.23391962, Validation R2: -0.049157

Epoch 43/1000
Training Loss: 1.12147111, Training R2: -0.022000
Validation Loss: 1.25375903, Validation R2: -0.000068

Epoch 44/1000
Training Loss: 1.13173660, Training R2: -0.002376
Validation Loss: 1.23193133, Validation R2: -0.024238

Epoch 45/1000
Training Loss: 1.11631970, Training R2: -0.039495
Validation Loss: 1.23408079, Validation R2: -0.049946

Epoch 46/1000
Training Loss: 1.11611977, Training R2: -0.040380
Validation Loss: 1.23305345, Validation R2: -0.015901

Epoch 47/1000
Training Loss: 1.11735423, Training R2: -0.019420
Validation Loss: 1.23188913, Validation R2: -0.036022

Epoch 48/1000
Training Loss: 1.11616856, Training R2: -0.046548
Validation Loss: 1.23444223, Validation R2: -0.051350

Epoch 49/1000
Training Loss: 1.11731761, Training R2: -0.053512
Validation Loss: 1.23326814, Validation R2: -0.046402

Epoch 50/1000
Training Loss: 1.11711474, Training R2: -0.057920
Validation Loss: 1.23277223, Validation R2: -0.043920

Epoch 51/1000
Training Loss: 1.11530889, Training R2: -0.036924
Validation Loss: 1.23498428, Validation R2: -0.010654

Epoch 52/1000
Epoch 00052: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 1.12153667, Training R2: -0.003901
Validation Loss: 1.23311508, Validation R2: -0.015676

Epoch 53/1000
学习率已减少 1 次
Training Loss: 1.12069633, Training R2: -0.034575
Validation Loss: 1.23418367, Validation R2: -0.050359

Epoch 54/1000
Training Loss: 1.11771929, Training R2: -0.059803
Validation Loss: 1.23428464, Validation R2: -0.050741

Epoch 55/1000
Training Loss: 1.11716183, Training R2: -0.056139
Validation Loss: 1.23203135, Validation R2: -0.039382

Epoch 56/1000
Training Loss: 1.11610777, Training R2: -0.034823
Validation Loss: 1.23194575, Validation R2: -0.023719

Epoch 57/1000
Training Loss: 1.11636079, Training R2: -0.025533
Validation Loss: 1.23191381, Validation R2: -0.024333

Epoch 58/1000
Training Loss: 1.11804046, Training R2: -0.020805
Validation Loss: 1.23343158, Validation R2: -0.014759

Epoch 59/1000
Training Loss: 1.11918867, Training R2: -0.011286
Validation Loss: 1.23214805, Validation R2: -0.020202

Epoch 60/1000
Training Loss: 1.11846192, Training R2: -0.040503
Validation Loss: 1.23705900, Validation R2: -0.059740

Epoch 61/1000
Training Loss: 1.11842457, Training R2: -0.070716
Validation Loss: 1.23376763, Validation R2: -0.048532

Epoch 62/1000
Training Loss: 1.11693263, Training R2: -0.044525
Validation Loss: 1.23186278, Validation R2: -0.025579

Epoch 63/1000
Training Loss: 1.11685378, Training R2: -0.024674
Validation Loss: 1.23181546, Validation R2: -0.026623

Epoch 64/1000
Training Loss: 1.11596444, Training R2: -0.029506
Validation Loss: 1.23191607, Validation R2: -0.036716

Epoch 65/1000
Training Loss: 1.11717501, Training R2: -0.049622
Validation Loss: 1.23422444, Validation R2: -0.050526

Epoch 66/1000
Training Loss: 1.11696882, Training R2: -0.053673
Validation Loss: 1.23200011, Validation R2: -0.038714

Epoch 67/1000
Training Loss: 1.11644599, Training R2: -0.043958
Validation Loss: 1.23201787, Validation R2: -0.022467

Epoch 68/1000
Training Loss: 1.11943130, Training R2: -0.010080
Validation Loss: 1.24499106, Validation R2: -0.001121

Epoch 69/1000
Training Loss: 1.12934234, Training R2: -0.001134
Validation Loss: 1.23870456, Validation R2: -0.004719

Epoch 70/1000
Training Loss: 1.12205350, Training R2: -0.003730
Validation Loss: 1.23379517, Validation R2: -0.013745

Epoch 71/1000
Training Loss: 1.11880920, Training R2: -0.011029
Validation Loss: 1.23321629, Validation R2: -0.015348

Epoch 72/1000
Training Loss: 1.11733314, Training R2: -0.017370
Validation Loss: 1.23179317, Validation R2: -0.026690

Epoch 73/1000
Epoch 00073: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 1.11597801, Training R2: -0.029505
Validation Loss: 1.23176455, Validation R2: -0.028152

Epoch 74/1000
学习率已减少 2 次
Training Loss: 1.11588198, Training R2: -0.027878
Validation Loss: 1.23191416, Validation R2: -0.024451

Epoch 75/1000
Training Loss: 1.11646149, Training R2: -0.022901
Validation Loss: 1.23204613, Validation R2: -0.021977

Epoch 76/1000
Training Loss: 1.11636295, Training R2: -0.021588
Validation Loss: 1.23173821, Validation R2: -0.027701

Epoch 77/1000
Training Loss: 1.11587820, Training R2: -0.035145
Validation Loss: 1.23262537, Validation R2: -0.043166

Epoch 78/1000
Training Loss: 1.11642320, Training R2: -0.048599
Validation Loss: 1.23242068, Validation R2: -0.042157

Epoch 79/1000
Training Loss: 1.11610305, Training R2: -0.045133
Validation Loss: 1.23176980, Validation R2: -0.030505

Epoch 80/1000
Training Loss: 1.11578509, Training R2: -0.026227
Validation Loss: 1.23258567, Validation R2: -0.017393

Epoch 81/1000
Training Loss: 1.11731387, Training R2: -0.016143
Validation Loss: 1.23208404, Validation R2: -0.021307

Epoch 82/1000
Training Loss: 1.11667130, Training R2: -0.025706
Validation Loss: 1.23174644, Validation R2: -0.032996

Epoch 83/1000
Training Loss: 1.11605609, Training R2: -0.039013
Validation Loss: 1.23242545, Validation R2: -0.042173

Epoch 84/1000
Training Loss: 1.11684459, Training R2: -0.052228
Validation Loss: 1.23318803, Validation R2: -0.045946

Epoch 85/1000
Training Loss: 1.11649703, Training R2: -0.046877
Validation Loss: 1.23187423, Validation R2: -0.036789

Epoch 86/1000
Training Loss: 1.11597548, Training R2: -0.039105
Validation Loss: 1.23189354, Validation R2: -0.037328

Epoch 87/1000
Training Loss: 1.11607288, Training R2: -0.041319
Validation Loss: 1.23194122, Validation R2: -0.038456

Epoch 88/1000
Training Loss: 1.11617238, Training R2: -0.042483
Validation Loss: 1.23322725, Validation R2: -0.046196

Epoch 89/1000
Training Loss: 1.11687839, Training R2: -0.061204
Validation Loss: 1.24020052, Validation R2: -0.069234

Epoch 90/1000
Training Loss: 1.12200359, Training R2: -0.089393
Validation Loss: 1.23496103, Validation R2: -0.053220

Epoch 91/1000
Training Loss: 1.11597340, Training R2: -0.040597
Validation Loss: 1.23265421, Validation R2: -0.016940

Epoch 92/1000
Training Loss: 1.11779733, Training R2: -0.020491
Validation Loss: 1.23181677, Validation R2: -0.025326

Epoch 93/1000
Training Loss: 1.11638979, Training R2: -0.024283
Validation Loss: 1.23175430, Validation R2: -0.026503

Epoch 94/1000
Epoch 00094: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 1.11608363, Training R2: -0.030757
Validation Loss: 1.23169422, Validation R2: -0.033051

Epoch 95/1000
学习率已减少 3 次
Training Loss: 1.11572384, Training R2: -0.035487
Validation Loss: 1.23183298, Validation R2: -0.035872

Epoch 96/1000
Training Loss: 1.11566020, Training R2: -0.039181
Validation Loss: 1.23223162, Validation R2: -0.040819

Epoch 97/1000
Training Loss: 1.11650178, Training R2: -0.048892
Validation Loss: 1.23434365, Validation R2: -0.050818

Epoch 98/1000
Training Loss: 1.11697127, Training R2: -0.061251
Validation Loss: 1.23619831, Validation R2: -0.056929

Epoch 99/1000
Training Loss: 1.11779506, Training R2: -0.066665
Validation Loss: 1.23520803, Validation R2: -0.053946

Epoch 100/1000
Training Loss: 1.11706292, Training R2: -0.060699
Validation Loss: 1.23414588, Validation R2: -0.050139

Epoch 101/1000
Training Loss: 1.11719768, Training R2: -0.059681
Validation Loss: 1.23429275, Validation R2: -0.050965

Epoch 102/1000
Training Loss: 1.11674163, Training R2: -0.057737
Validation Loss: 1.23196602, Validation R2: -0.038672

Epoch 103/1000
Training Loss: 1.11578612, Training R2: -0.031448
Validation Loss: 1.23280466, Validation R2: -0.016420

Epoch 104/1000
Training Loss: 1.11798095, Training R2: -0.012579
Validation Loss: 1.23418105, Validation R2: -0.012562

Epoch 105/1000
Training Loss: 1.11803298, Training R2: -0.011026
Validation Loss: 1.23249650, Validation R2: -0.017519

Epoch 106/1000
Training Loss: 1.11776054, Training R2: -0.021255
Validation Loss: 1.23177505, Validation R2: -0.025730

Epoch 107/1000
Training Loss: 1.11613180, Training R2: -0.026932
Validation Loss: 1.23180962, Validation R2: -0.025368

Epoch 108/1000
Training Loss: 1.11642786, Training R2: -0.023340
Validation Loss: 1.23201728, Validation R2: -0.021230

Epoch 109/1000
Training Loss: 1.11682497, Training R2: -0.023546
Validation Loss: 1.23165691, Validation R2: -0.028507

Epoch 110/1000
Training Loss: 1.11530018, Training R2: -0.030826
Validation Loss: 1.23167694, Validation R2: -0.036432

Epoch 111/1000
Training Loss: 1.11631957, Training R2: -0.043964
Validation Loss: 1.23272598, Validation R2: -0.044883

Epoch 112/1000
Training Loss: 1.11644409, Training R2: -0.051381
Validation Loss: 1.23198795, Validation R2: -0.041200

Epoch 113/1000
Training Loss: 1.11613193, Training R2: -0.040569
Validation Loss: 1.23154688, Validation R2: -0.027569

Epoch 114/1000
Training Loss: 1.11650205, Training R2: -0.025608
Validation Loss: 1.23177409, Validation R2: -0.021000

Epoch 115/1000
Epoch 00115: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 1.11672860, Training R2: -0.019163
Validation Loss: 1.23207796, Validation R2: -0.018245

Epoch 116/1000
学习率已减少 4 次
Training Loss: 1.11674637, Training R2: -0.016910
Validation Loss: 1.23203278, Validation R2: -0.018921

Epoch 117/1000
Training Loss: 1.11661421, Training R2: -0.017570
Validation Loss: 1.23189950, Validation R2: -0.020980

Epoch 118/1000
Training Loss: 1.11585290, Training R2: -0.022435
Validation Loss: 1.23159671, Validation R2: -0.027252

Epoch 119/1000
Training Loss: 1.11553235, Training R2: -0.029413
Validation Loss: 1.23165345, Validation R2: -0.031095

Epoch 120/1000
Training Loss: 1.11555074, Training R2: -0.033378
Validation Loss: 1.23164320, Validation R2: -0.033696

Epoch 121/1000
Training Loss: 1.11545252, Training R2: -0.036708
Validation Loss: 1.23178422, Validation R2: -0.037261

Epoch 122/1000
Training Loss: 1.11540227, Training R2: -0.041046
Validation Loss: 1.23220456, Validation R2: -0.041968

Epoch 123/1000
Training Loss: 1.11568627, Training R2: -0.048790
Validation Loss: 1.23341382, Validation R2: -0.047706

Epoch 124/1000
Training Loss: 1.11623027, Training R2: -0.053689
Validation Loss: 1.23286605, Validation R2: -0.045339

Epoch 125/1000
Training Loss: 1.11587014, Training R2: -0.048157
Validation Loss: 1.23168290, Validation R2: -0.037793

Epoch 126/1000
Training Loss: 1.11515731, Training R2: -0.039519
Validation Loss: 1.23145926, Validation R2: -0.030944

Epoch 127/1000
Training Loss: 1.11549547, Training R2: -0.028511
Validation Loss: 1.23177052, Validation R2: -0.021574

Epoch 128/1000
Training Loss: 1.11568630, Training R2: -0.019734
Validation Loss: 1.23189521, Validation R2: -0.019866

Epoch 129/1000
Training Loss: 1.11589455, Training R2: -0.019194
Validation Loss: 1.23175311, Validation R2: -0.022826

Epoch 130/1000
Training Loss: 1.11539747, Training R2: -0.023310
Validation Loss: 1.23150134, Validation R2: -0.026964

Epoch 131/1000
Training Loss: 1.11495058, Training R2: -0.028104
Validation Loss: 1.23152435, Validation R2: -0.032425

Epoch 132/1000
Training Loss: 1.11481679, Training R2: -0.036126
Validation Loss: 1.23241091, Validation R2: -0.043454

Epoch 133/1000
Training Loss: 1.11589741, Training R2: -0.054767
Validation Loss: 1.23644876, Validation R2: -0.058519

Epoch 134/1000
Training Loss: 1.11760376, Training R2: -0.069908
Validation Loss: 1.23768508, Validation R2: -0.062325

Epoch 135/1000
Training Loss: 1.11822150, Training R2: -0.073579
Validation Loss: 1.23710334, Validation R2: -0.060613

Epoch 136/1000
Epoch 00136: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 1.11751932, Training R2: -0.067659
Validation Loss: 1.23414230, Validation R2: -0.050683

Epoch 137/1000
学习率已减少 5 次
Training Loss: 1.11600426, Training R2: -0.054970
Validation Loss: 1.23241019, Validation R2: -0.043085

Epoch 138/1000
Training Loss: 1.11528502, Training R2: -0.044570
Validation Loss: 1.23162174, Validation R2: -0.035488

Epoch 139/1000
Training Loss: 1.11518150, Training R2: -0.035860
Validation Loss: 1.23140812, Validation R2: -0.030637

Epoch 140/1000
Training Loss: 1.11491610, Training R2: -0.031003
Validation Loss: 1.23139453, Validation R2: -0.028818

Epoch 141/1000
Training Loss: 1.11496356, Training R2: -0.028842
Validation Loss: 1.23136103, Validation R2: -0.027674

Epoch 142/1000
Training Loss: 1.11490283, Training R2: -0.028279
Validation Loss: 1.23145831, Validation R2: -0.027211

Epoch 143/1000
Training Loss: 1.11497621, Training R2: -0.025774
Validation Loss: 1.23167217, Validation R2: -0.023911

Epoch 144/1000
Training Loss: 1.11512627, Training R2: -0.023098
Validation Loss: 1.23167253, Validation R2: -0.023764

Epoch 145/1000
Training Loss: 1.11507658, Training R2: -0.022902
Validation Loss: 1.23142886, Validation R2: -0.023827

Epoch 146/1000
Training Loss: 1.11500365, Training R2: -0.023275
Validation Loss: 1.23132610, Validation R2: -0.025041

Epoch 147/1000
Training Loss: 1.11504579, Training R2: -0.026327
Validation Loss: 1.23121297, Validation R2: -0.029594

Epoch 148/1000
Training Loss: 1.11488306, Training R2: -0.032083
Validation Loss: 1.23139191, Validation R2: -0.034914

Epoch 149/1000
Training Loss: 1.11517853, Training R2: -0.038904
Validation Loss: 1.23158693, Validation R2: -0.039418

Epoch 150/1000
Training Loss: 1.11504279, Training R2: -0.043819
Validation Loss: 1.23217773, Validation R2: -0.043062

Epoch 151/1000
Training Loss: 1.11559682, Training R2: -0.050003
Validation Loss: 1.23295391, Validation R2: -0.046867

Epoch 152/1000
Training Loss: 1.11589789, Training R2: -0.053931
Validation Loss: 1.23303628, Validation R2: -0.047204

Epoch 153/1000
Training Loss: 1.11555011, Training R2: -0.051887
Validation Loss: 1.23218644, Validation R2: -0.043285

Epoch 154/1000
Training Loss: 1.11533014, Training R2: -0.046537
Validation Loss: 1.23148310, Validation R2: -0.039238

Epoch 155/1000
Training Loss: 1.11500358, Training R2: -0.041676
Validation Loss: 1.23130107, Validation R2: -0.037180

Epoch 156/1000
Training Loss: 1.11479384, Training R2: -0.040074
Validation Loss: 1.23135996, Validation R2: -0.037763

Epoch 157/1000
Epoch 00157: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 1.11484487, Training R2: -0.041510
Validation Loss: 1.23146403, Validation R2: -0.039546

Epoch 158/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/r2_curve_dipole.png
