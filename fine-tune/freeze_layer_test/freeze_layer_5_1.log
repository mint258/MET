Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Trainable
interaction_blocks.3.conv1.lin_rel.bias: Trainable
interaction_blocks.3.conv1.lin_root.weight: Trainable
interaction_blocks.3.conv2.lin_rel.weight: Trainable
interaction_blocks.3.conv2.lin_rel.bias: Trainable
interaction_blocks.3.conv2.lin_root.weight: Trainable
interaction_blocks.3.lin1.weight: Trainable
interaction_blocks.3.lin1.bias: Trainable
interaction_blocks.3.lin2.weight: Trainable
interaction_blocks.3.lin2.bias: Trainable
interaction_blocks.3.lin_cat.weight: Trainable
interaction_blocks.3.lin_cat.bias: Trainable
interaction_blocks.3.norm.weight: Trainable
interaction_blocks.3.norm.bias: Trainable
interaction_blocks.3.norm.mean_scale: Trainable
interaction_blocks.3.lin_feature1.lin1.weight: Trainable
interaction_blocks.3.lin_feature1.lin2.weight: Trainable
interaction_blocks.3.lin_feature2.lin1.weight: Trainable
interaction_blocks.3.lin_feature2.lin2.weight: Trainable
interaction_blocks.3.lin.weight: Trainable
interaction_blocks.3.lin.bias: Trainable
interaction_blocks.3.lins.0.weight: Trainable
interaction_blocks.3.lins.0.bias: Trainable
interaction_blocks.3.lins.1.weight: Trainable
interaction_blocks.3.lins.1.bias: Trainable
interaction_blocks.3.lins.2.weight: Trainable
interaction_blocks.3.lins.2.bias: Trainable
interaction_blocks.3.lins.3.weight: Trainable
interaction_blocks.3.lins.3.bias: Trainable
interaction_blocks.3.final.weight: Trainable
interaction_blocks.3.final.bias: Trainable
lins.0.weight: Trainable
lins.0.bias: Trainable
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 2337411

Epoch 1/1000
Training Loss: 2.24465351, Training R2: -3.026961
Validation Loss: 1.53503430, Validation R2: -0.274854
Saved best model with validation R2 -0.274854 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.31129579, Training R2: -0.268057
Validation Loss: 1.20871210, Validation R2: -0.018140
Saved best model with validation R2 -0.018140 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.12146580, Training R2: -0.107510
Validation Loss: 1.28172266, Validation R2: -0.190737

Epoch 4/1000
Training Loss: 1.11944491, Training R2: -0.105309
Validation Loss: 1.21168292, Validation R2: 0.037929
Saved best model with validation R2 0.037929 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.10253838, Training R2: 0.065192
Validation Loss: 1.21114409, Validation R2: 0.062124
Saved best model with validation R2 0.062124 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.04879323, Training R2: 0.105530
Validation Loss: 1.15735078, Validation R2: 0.000045

Epoch 7/1000
Training Loss: 1.02145764, Training R2: 0.064253
Validation Loss: 1.10903311, Validation R2: 0.107896
Saved best model with validation R2 0.107896 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 0.95675343, Training R2: 0.216894
Validation Loss: 1.09690678, Validation R2: 0.155468
Saved best model with validation R2 0.155468 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 0.90903965, Training R2: 0.285838
Validation Loss: 1.04449701, Validation R2: 0.210284
Saved best model with validation R2 0.210284 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.85816079, Training R2: 0.347509
Validation Loss: 1.03830111, Validation R2: 0.215945
Saved best model with validation R2 0.215945 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 0.83269855, Training R2: 0.370311
Validation Loss: 0.99339491, Validation R2: 0.251420
Saved best model with validation R2 0.251420 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 0.79738726, Training R2: 0.396274
Validation Loss: 0.97196043, Validation R2: 0.258091
Saved best model with validation R2 0.258091 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 0.75337117, Training R2: 0.429189
Validation Loss: 0.96206874, Validation R2: 0.261448
Saved best model with validation R2 0.261448 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 0.72389666, Training R2: 0.468901
Validation Loss: 0.91625851, Validation R2: 0.286726
Saved best model with validation R2 0.286726 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 0.71336846, Training R2: 0.491652
Validation Loss: 0.92126262, Validation R2: 0.293764
Saved best model with validation R2 0.293764 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 0.70638555, Training R2: 0.494926
Validation Loss: 0.85456055, Validation R2: 0.360873
Saved best model with validation R2 0.360873 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.64829808, Training R2: 0.549849
Validation Loss: 0.88069892, Validation R2: 0.335063

Epoch 18/1000
Training Loss: 0.65225174, Training R2: 0.542640
Validation Loss: 0.83919126, Validation R2: 0.377993
Saved best model with validation R2 0.377993 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.61918467, Training R2: 0.592092
Validation Loss: 0.84017879, Validation R2: 0.383326
Saved best model with validation R2 0.383326 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 0.59859453, Training R2: 0.602066
Validation Loss: 0.87077469, Validation R2: 0.347863

Epoch 21/1000
Training Loss: 0.57360332, Training R2: 0.623799
Validation Loss: 0.92795318, Validation R2: 0.312295

Epoch 22/1000
Training Loss: 0.64891044, Training R2: 0.578803
Validation Loss: 0.86307263, Validation R2: 0.385135
Saved best model with validation R2 0.385135 to best_finetuned_model.pth

Epoch 23/1000
Training Loss: 0.58591300, Training R2: 0.626759
Validation Loss: 0.83476138, Validation R2: 0.392082
Saved best model with validation R2 0.392082 to best_finetuned_model.pth

Epoch 24/1000
Training Loss: 0.52650669, Training R2: 0.675137
Validation Loss: 0.82767576, Validation R2: 0.393501
Saved best model with validation R2 0.393501 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 0.51561102, Training R2: 0.679611
Validation Loss: 0.84777081, Validation R2: 0.388387

Epoch 26/1000
Training Loss: 0.52677983, Training R2: 0.684456
Validation Loss: 0.87103683, Validation R2: 0.362264

Epoch 27/1000
Training Loss: 0.52902519, Training R2: 0.683665
Validation Loss: 0.79567182, Validation R2: 0.431986
Saved best model with validation R2 0.431986 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 0.50452303, Training R2: 0.706649
Validation Loss: 0.80190551, Validation R2: 0.427968

Epoch 29/1000
Training Loss: 0.49333396, Training R2: 0.714735
Validation Loss: 0.83786070, Validation R2: 0.394090

Epoch 30/1000
Training Loss: 0.52313783, Training R2: 0.692021
Validation Loss: 0.79144895, Validation R2: 0.440864
Saved best model with validation R2 0.440864 to best_finetuned_model.pth

Epoch 31/1000
Training Loss: 0.46461560, Training R2: 0.744409
Validation Loss: 0.80211270, Validation R2: 0.424346

Epoch 32/1000
Training Loss: 0.45788237, Training R2: 0.744638
Validation Loss: 0.84093916, Validation R2: 0.398642

Epoch 33/1000
Training Loss: 0.49663044, Training R2: 0.714350
Validation Loss: 0.78162640, Validation R2: 0.457801
Saved best model with validation R2 0.457801 to best_finetuned_model.pth

Epoch 34/1000
Training Loss: 0.44970472, Training R2: 0.767453
Validation Loss: 0.86108077, Validation R2: 0.375470

Epoch 35/1000
Training Loss: 0.47771636, Training R2: 0.729101
Validation Loss: 0.79760265, Validation R2: 0.427373

Epoch 36/1000
Training Loss: 0.42802837, Training R2: 0.767768
Validation Loss: 0.81167483, Validation R2: 0.413283

Epoch 37/1000
Training Loss: 0.43632894, Training R2: 0.769046
Validation Loss: 0.81408089, Validation R2: 0.403333

Epoch 38/1000
Training Loss: 0.41480737, Training R2: 0.784970
Validation Loss: 0.76757169, Validation R2: 0.453266

Epoch 39/1000
Training Loss: 0.38146323, Training R2: 0.805721
Validation Loss: 0.74437803, Validation R2: 0.476151
Saved best model with validation R2 0.476151 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.36323579, Training R2: 0.812482
Validation Loss: 0.75866002, Validation R2: 0.475622

Epoch 41/1000
Training Loss: 0.35504485, Training R2: 0.822557
Validation Loss: 0.75259453, Validation R2: 0.481423
Saved best model with validation R2 0.481423 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 0.34124471, Training R2: 0.831284
Validation Loss: 0.75713146, Validation R2: 0.466552

Epoch 43/1000
Training Loss: 0.35785665, Training R2: 0.829681
Validation Loss: 0.76314551, Validation R2: 0.465325

Epoch 44/1000
Training Loss: 0.35684905, Training R2: 0.832745
Validation Loss: 0.76092476, Validation R2: 0.472192

Epoch 45/1000
Training Loss: 0.33121575, Training R2: 0.847262
Validation Loss: 0.72956777, Validation R2: 0.510383
Saved best model with validation R2 0.510383 to best_finetuned_model.pth

Epoch 46/1000
Training Loss: 0.34859743, Training R2: 0.845688
Validation Loss: 0.75981367, Validation R2: 0.485465

Epoch 47/1000
Training Loss: 0.36628783, Training R2: 0.836367
Validation Loss: 0.73781818, Validation R2: 0.501913

Epoch 48/1000
Training Loss: 0.30295052, Training R2: 0.866244
Validation Loss: 0.72282004, Validation R2: 0.515011
Saved best model with validation R2 0.515011 to best_finetuned_model.pth

Epoch 49/1000
Training Loss: 0.29357662, Training R2: 0.877942
Validation Loss: 0.74709862, Validation R2: 0.496841

Epoch 50/1000
Training Loss: 0.29494523, Training R2: 0.880356
Validation Loss: 0.72596037, Validation R2: 0.515500
Saved best model with validation R2 0.515500 to best_finetuned_model.pth

Epoch 51/1000
Training Loss: 0.27747423, Training R2: 0.895166
Validation Loss: 0.71167302, Validation R2: 0.531730
Saved best model with validation R2 0.531730 to best_finetuned_model.pth

Epoch 52/1000
Training Loss: 0.26402541, Training R2: 0.901389
Validation Loss: 0.70361555, Validation R2: 0.538690
Saved best model with validation R2 0.538690 to best_finetuned_model.pth

Epoch 53/1000
Training Loss: 0.25833565, Training R2: 0.903530
Validation Loss: 0.72566557, Validation R2: 0.523832

Epoch 54/1000
Training Loss: 0.27092792, Training R2: 0.906613
Validation Loss: 0.75719428, Validation R2: 0.492790

Epoch 55/1000
Training Loss: 0.27933666, Training R2: 0.898100
Validation Loss: 0.74556839, Validation R2: 0.511027

Epoch 56/1000
Training Loss: 0.28987179, Training R2: 0.887917
Validation Loss: 0.71767026, Validation R2: 0.524497

Epoch 57/1000
Training Loss: 0.27788721, Training R2: 0.899106
Validation Loss: 0.73168278, Validation R2: 0.518395

Epoch 58/1000
Training Loss: 0.28203919, Training R2: 0.906096
Validation Loss: 0.76287824, Validation R2: 0.495231

Epoch 59/1000
Training Loss: 0.27512370, Training R2: 0.895219
Validation Loss: 0.74492252, Validation R2: 0.522510

Epoch 60/1000
Training Loss: 0.24443857, Training R2: 0.915618
Validation Loss: 0.71890533, Validation R2: 0.528579

Epoch 61/1000
Training Loss: 0.24197292, Training R2: 0.914766
Validation Loss: 0.75735295, Validation R2: 0.539485
Saved best model with validation R2 0.539485 to best_finetuned_model.pth

Epoch 62/1000
Training Loss: 0.24852507, Training R2: 0.916999
Validation Loss: 0.76213849, Validation R2: 0.528795

Epoch 63/1000
Training Loss: 0.23755666, Training R2: 0.922228
Validation Loss: 0.75225234, Validation R2: 0.516522

Epoch 64/1000
Training Loss: 0.23206240, Training R2: 0.915477
Validation Loss: 0.72959006, Validation R2: 0.520089

Epoch 65/1000
Training Loss: 0.23346720, Training R2: 0.918197
Validation Loss: 0.71940672, Validation R2: 0.525362

Epoch 66/1000
Training Loss: 0.23136790, Training R2: 0.928121
Validation Loss: 0.72507977, Validation R2: 0.541893
Saved best model with validation R2 0.541893 to best_finetuned_model.pth

Epoch 67/1000
Training Loss: 0.20372941, Training R2: 0.936524
Validation Loss: 0.72565675, Validation R2: 0.514922

Epoch 68/1000
Training Loss: 0.21474335, Training R2: 0.930822
Validation Loss: 0.72498566, Validation R2: 0.525665

Epoch 69/1000
Training Loss: 0.20487662, Training R2: 0.938740
Validation Loss: 0.75268078, Validation R2: 0.496103

Epoch 70/1000
Training Loss: 0.22422124, Training R2: 0.934627
Validation Loss: 0.76862043, Validation R2: 0.498632

Epoch 71/1000
Training Loss: 0.21620458, Training R2: 0.936165
Validation Loss: 0.74976897, Validation R2: 0.509827

Epoch 72/1000
Training Loss: 0.21267165, Training R2: 0.938489
Validation Loss: 0.73918968, Validation R2: 0.523636

Epoch 73/1000
Training Loss: 0.20482665, Training R2: 0.942389
Validation Loss: 0.72403824, Validation R2: 0.520851

Epoch 74/1000
Training Loss: 0.18850567, Training R2: 0.946317
Validation Loss: 0.72352636, Validation R2: 0.523085

Epoch 75/1000
Training Loss: 0.19193171, Training R2: 0.946368
Validation Loss: 0.79535800, Validation R2: 0.495847

Epoch 76/1000
Training Loss: 0.24651219, Training R2: 0.929130
Validation Loss: 0.76073790, Validation R2: 0.522002

Epoch 77/1000
Training Loss: 0.24651258, Training R2: 0.932209
Validation Loss: 0.71924758, Validation R2: 0.554778
Saved best model with validation R2 0.554778 to best_finetuned_model.pth

Epoch 78/1000
Training Loss: 0.23060974, Training R2: 0.933614
Validation Loss: 0.73639476, Validation R2: 0.537098

Epoch 79/1000
Training Loss: 0.27473491, Training R2: 0.914123
Validation Loss: 0.72732067, Validation R2: 0.540210

Epoch 80/1000
Training Loss: 0.21921395, Training R2: 0.939774
Validation Loss: 0.76189262, Validation R2: 0.510622

Epoch 81/1000
Training Loss: 0.20522438, Training R2: 0.943073
Validation Loss: 0.75753701, Validation R2: 0.516918

Epoch 82/1000
Training Loss: 0.17904016, Training R2: 0.954091
Validation Loss: 0.73935741, Validation R2: 0.527048

Epoch 83/1000
Training Loss: 0.16174363, Training R2: 0.956881
Validation Loss: 0.70912933, Validation R2: 0.555945
Saved best model with validation R2 0.555945 to best_finetuned_model.pth

Epoch 84/1000
Training Loss: 0.18428206, Training R2: 0.952264
Validation Loss: 0.70226681, Validation R2: 0.558718
Saved best model with validation R2 0.558718 to best_finetuned_model.pth

Epoch 85/1000
Training Loss: 0.16214840, Training R2: 0.958297
Validation Loss: 0.70816922, Validation R2: 0.561043
Saved best model with validation R2 0.561043 to best_finetuned_model.pth

Epoch 86/1000
Training Loss: 0.17556980, Training R2: 0.956954
Validation Loss: 0.72019565, Validation R2: 0.552724

Epoch 87/1000
Training Loss: 0.19352769, Training R2: 0.950127
Validation Loss: 0.75106651, Validation R2: 0.534562

Epoch 88/1000
Training Loss: 0.17624302, Training R2: 0.955340
Validation Loss: 0.74513000, Validation R2: 0.534080

Epoch 89/1000
Training Loss: 0.16842076, Training R2: 0.957817
Validation Loss: 0.73847401, Validation R2: 0.531118

Epoch 90/1000
Training Loss: 0.17114931, Training R2: 0.953460
Validation Loss: 0.73594534, Validation R2: 0.522982

Epoch 91/1000
Training Loss: 0.15825637, Training R2: 0.959634
Validation Loss: 0.71999311, Validation R2: 0.547021

Epoch 92/1000
Training Loss: 0.14773001, Training R2: 0.963166
Validation Loss: 0.72917509, Validation R2: 0.544342

Epoch 93/1000
Training Loss: 0.16239854, Training R2: 0.961378
Validation Loss: 0.73270530, Validation R2: 0.538265

Epoch 94/1000
Training Loss: 0.15313041, Training R2: 0.965516
Validation Loss: 0.71310914, Validation R2: 0.550864

Epoch 95/1000
Training Loss: 0.17428550, Training R2: 0.961197
Validation Loss: 0.71791929, Validation R2: 0.545852

Epoch 96/1000
Training Loss: 0.17068461, Training R2: 0.961087
Validation Loss: 0.71378028, Validation R2: 0.545030

Epoch 97/1000
Training Loss: 0.17899937, Training R2: 0.957406
Validation Loss: 0.72330785, Validation R2: 0.540892

Epoch 98/1000
Training Loss: 0.14758884, Training R2: 0.964901
Validation Loss: 0.69706631, Validation R2: 0.567602
Saved best model with validation R2 0.567602 to best_finetuned_model.pth

Epoch 99/1000
Training Loss: 0.13797737, Training R2: 0.969197
Validation Loss: 0.73054534, Validation R2: 0.531789

Epoch 100/1000
Training Loss: 0.14673032, Training R2: 0.967731
Validation Loss: 0.75036436, Validation R2: 0.526699

Epoch 101/1000
Training Loss: 0.13558487, Training R2: 0.970172
Validation Loss: 0.74172765, Validation R2: 0.542044

Epoch 102/1000
Training Loss: 0.11766654, Training R2: 0.974126
Validation Loss: 0.73038197, Validation R2: 0.549747

Epoch 103/1000
Training Loss: 0.12869487, Training R2: 0.972038
Validation Loss: 0.72044516, Validation R2: 0.553695

Epoch 104/1000
Training Loss: 0.12008215, Training R2: 0.973931
Validation Loss: 0.71225554, Validation R2: 0.557455

Epoch 105/1000
Training Loss: 0.10969127, Training R2: 0.976179
Validation Loss: 0.71852738, Validation R2: 0.545773

Epoch 106/1000
Training Loss: 0.13034042, Training R2: 0.970103
Validation Loss: 0.72691178, Validation R2: 0.545609

Epoch 107/1000
Training Loss: 0.12591082, Training R2: 0.973823
Validation Loss: 0.72953719, Validation R2: 0.533006

Epoch 108/1000
Training Loss: 0.12640572, Training R2: 0.972175
Validation Loss: 0.74978054, Validation R2: 0.519308

Epoch 109/1000
Training Loss: 0.13707753, Training R2: 0.970459
Validation Loss: 0.75165939, Validation R2: 0.530647

Epoch 110/1000
Training Loss: 0.14870311, Training R2: 0.970725
Validation Loss: 0.73402929, Validation R2: 0.533987

Epoch 111/1000
Training Loss: 0.13072138, Training R2: 0.973262
Validation Loss: 0.73013413, Validation R2: 0.544819

Epoch 112/1000
Training Loss: 0.12144455, Training R2: 0.975354
Validation Loss: 0.72443420, Validation R2: 0.544847

Epoch 113/1000
Training Loss: 0.13783658, Training R2: 0.971808
Validation Loss: 0.74069989, Validation R2: 0.531025

Epoch 114/1000
Training Loss: 0.16304036, Training R2: 0.963907
Validation Loss: 0.75804818, Validation R2: 0.525067

Epoch 115/1000
Training Loss: 0.15545886, Training R2: 0.966021
Validation Loss: 0.73877412, Validation R2: 0.540174

Epoch 116/1000
Training Loss: 0.12222958, Training R2: 0.975931
Validation Loss: 0.73754865, Validation R2: 0.542950

Epoch 117/1000
Training Loss: 0.12289857, Training R2: 0.974239
Validation Loss: 0.72503227, Validation R2: 0.544655

Epoch 118/1000
Training Loss: 0.12710285, Training R2: 0.975246
Validation Loss: 0.71550596, Validation R2: 0.552417

Epoch 119/1000
Epoch 00119: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.13411855, Training R2: 0.970565
Validation Loss: 0.70863163, Validation R2: 0.557222

Epoch 120/1000
学习率已减少 1 次
Training Loss: 0.12423845, Training R2: 0.975142
Validation Loss: 0.71092129, Validation R2: 0.556653

Epoch 121/1000
Training Loss: 0.11094131, Training R2: 0.977965
Validation Loss: 0.72429806, Validation R2: 0.556679

Epoch 122/1000
Training Loss: 0.10713064, Training R2: 0.979245
Validation Loss: 0.72136623, Validation R2: 0.554836

Epoch 123/1000
Training Loss: 0.09174073, Training R2: 0.980953
Validation Loss: 0.71805340, Validation R2: 0.555828

Epoch 124/1000
Training Loss: 0.08668428, Training R2: 0.982103
Validation Loss: 0.72209942, Validation R2: 0.556471

Epoch 125/1000
Training Loss: 0.09138533, Training R2: 0.983116
Validation Loss: 0.71814489, Validation R2: 0.560493

Epoch 126/1000
Training Loss: 0.08275290, Training R2: 0.983955
Validation Loss: 0.70841259, Validation R2: 0.565181

Epoch 127/1000
Training Loss: 0.08021063, Training R2: 0.984953
Validation Loss: 0.70766622, Validation R2: 0.566355

Epoch 128/1000
Training Loss: 0.08273776, Training R2: 0.983820
Validation Loss: 0.71061409, Validation R2: 0.573326
Saved best model with validation R2 0.573326 to best_finetuned_model.pth

Epoch 129/1000
Training Loss: 0.08573963, Training R2: 0.984120
Validation Loss: 0.70348936, Validation R2: 0.574247
Saved best model with validation R2 0.574247 to best_finetuned_model.pth

Epoch 130/1000
Training Loss: 0.06976080, Training R2: 0.986245
Validation Loss: 0.70221394, Validation R2: 0.563612

Epoch 131/1000
Training Loss: 0.07392302, Training R2: 0.985389
Validation Loss: 0.70652509, Validation R2: 0.564432

Epoch 132/1000
Training Loss: 0.06516754, Training R2: 0.986565
Validation Loss: 0.70777702, Validation R2: 0.570778

Epoch 133/1000
Training Loss: 0.06366697, Training R2: 0.986621
Validation Loss: 0.70769483, Validation R2: 0.572068

Epoch 134/1000
Training Loss: 0.06925721, Training R2: 0.986415
Validation Loss: 0.71276993, Validation R2: 0.563563

Epoch 135/1000
Training Loss: 0.06140723, Training R2: 0.987344
Validation Loss: 0.72661811, Validation R2: 0.556212

Epoch 136/1000
Training Loss: 0.06716166, Training R2: 0.986295
Validation Loss: 0.72135550, Validation R2: 0.553794

Epoch 137/1000
Training Loss: 0.07450310, Training R2: 0.986512
Validation Loss: 0.71585274, Validation R2: 0.562614

Epoch 138/1000
Training Loss: 0.06777478, Training R2: 0.987428
Validation Loss: 0.70665908, Validation R2: 0.572396

Epoch 139/1000
Training Loss: 0.06747459, Training R2: 0.987878
Validation Loss: 0.72620529, Validation R2: 0.557245

Epoch 140/1000
Training Loss: 0.06496962, Training R2: 0.987477
Validation Loss: 0.71370041, Validation R2: 0.570788

Epoch 141/1000
Training Loss: 0.06163927, Training R2: 0.988226
Validation Loss: 0.69691223, Validation R2: 0.580105
Saved best model with validation R2 0.580105 to best_finetuned_model.pth

Epoch 142/1000
Training Loss: 0.10345638, Training R2: 0.983802
Validation Loss: 0.70507336, Validation R2: 0.569505

Epoch 143/1000
Training Loss: 0.09138963, Training R2: 0.984786
Validation Loss: 0.70846188, Validation R2: 0.569061

Epoch 144/1000
Training Loss: 0.08696543, Training R2: 0.986607
Validation Loss: 0.72265553, Validation R2: 0.554296

Epoch 145/1000
Training Loss: 0.08149960, Training R2: 0.986273
Validation Loss: 0.70786452, Validation R2: 0.571843

Epoch 146/1000
Training Loss: 0.06909077, Training R2: 0.988610
Validation Loss: 0.71024489, Validation R2: 0.570920

Epoch 147/1000
Training Loss: 0.06199208, Training R2: 0.989224
Validation Loss: 0.70162261, Validation R2: 0.576525

Epoch 148/1000
Training Loss: 0.06863303, Training R2: 0.988432
Validation Loss: 0.70039481, Validation R2: 0.574877

Epoch 149/1000
Training Loss: 0.07282664, Training R2: 0.987899
Validation Loss: 0.70245469, Validation R2: 0.572035

Epoch 150/1000
Training Loss: 0.06834858, Training R2: 0.988955
Validation Loss: 0.70582914, Validation R2: 0.576170

Epoch 151/1000
Training Loss: 0.06138888, Training R2: 0.989217
Validation Loss: 0.71106827, Validation R2: 0.574446

Epoch 152/1000
Training Loss: 0.06705177, Training R2: 0.989123
Validation Loss: 0.71274918, Validation R2: 0.574068

Epoch 153/1000
Training Loss: 0.07296079, Training R2: 0.988304
Validation Loss: 0.71696043, Validation R2: 0.571730

Epoch 154/1000
Training Loss: 0.06991892, Training R2: 0.988932
Validation Loss: 0.71929908, Validation R2: 0.572601

Epoch 155/1000
Training Loss: 0.08543693, Training R2: 0.987140
Validation Loss: 0.70727253, Validation R2: 0.581013
Saved best model with validation R2 0.581013 to best_finetuned_model.pth

Epoch 156/1000
Training Loss: 0.07558482, Training R2: 0.988097
Validation Loss: 0.69928235, Validation R2: 0.577752

Epoch 157/1000
Training Loss: 0.07409179, Training R2: 0.988335
Validation Loss: 0.70512313, Validation R2: 0.580933

Epoch 158/1000
Training Loss: 0.06573322, Training R2: 0.989905
Validation Loss: 0.70662731, Validation R2: 0.574095

Epoch 159/1000
Training Loss: 0.09557284, Training R2: 0.985393
Validation Loss: 0.70539290, Validation R2: 0.575204

Epoch 160/1000
Training Loss: 0.08251268, Training R2: 0.988081
Validation Loss: 0.69845837, Validation R2: 0.587264
Saved best model with validation R2 0.587264 to best_finetuned_model.pth

Epoch 161/1000
Training Loss: 0.08081866, Training R2: 0.988264
Validation Loss: 0.72267848, Validation R2: 0.566834

Epoch 162/1000
Training Loss: 0.09014692, Training R2: 0.987604
Validation Loss: 0.70364660, Validation R2: 0.579950

Epoch 163/1000
Training Loss: 0.06518244, Training R2: 0.989827
Validation Loss: 0.69935775, Validation R2: 0.582317

Epoch 164/1000
Training Loss: 0.05372981, Training R2: 0.991021
Validation Loss: 0.70369828, Validation R2: 0.581977

Epoch 165/1000
Training Loss: 0.05181768, Training R2: 0.991283
Validation Loss: 0.70115614, Validation R2: 0.583825

Epoch 166/1000
Training Loss: 0.05155571, Training R2: 0.991264
Validation Loss: 0.71290040, Validation R2: 0.579600

Epoch 167/1000
Training Loss: 0.05786065, Training R2: 0.990869
Validation Loss: 0.71208876, Validation R2: 0.579668

Epoch 168/1000
Training Loss: 0.05295648, Training R2: 0.991272
Validation Loss: 0.71205533, Validation R2: 0.576430

Epoch 169/1000
Training Loss: 0.06790214, Training R2: 0.990104
Validation Loss: 0.72008413, Validation R2: 0.563978

Epoch 170/1000
Training Loss: 0.09782947, Training R2: 0.986561
Validation Loss: 0.71432447, Validation R2: 0.572351

Epoch 171/1000
Training Loss: 0.08091757, Training R2: 0.988252
Validation Loss: 0.71454316, Validation R2: 0.570512

Epoch 172/1000
Training Loss: 0.08856442, Training R2: 0.987962
Validation Loss: 0.70962065, Validation R2: 0.576798

Epoch 173/1000
Training Loss: 0.07537963, Training R2: 0.989008
Validation Loss: 0.71251541, Validation R2: 0.575889

Epoch 174/1000
Training Loss: 0.06312938, Training R2: 0.990179
Validation Loss: 0.70545810, Validation R2: 0.584142

Epoch 175/1000
Training Loss: 0.05216091, Training R2: 0.991354
Validation Loss: 0.70187092, Validation R2: 0.585588

Epoch 176/1000
Training Loss: 0.05235601, Training R2: 0.991517
Validation Loss: 0.70469183, Validation R2: 0.579907

Epoch 177/1000
Training Loss: 0.06978728, Training R2: 0.989714
Validation Loss: 0.70521283, Validation R2: 0.579280

Epoch 178/1000
Training Loss: 0.04801227, Training R2: 0.991832
Validation Loss: 0.71075928, Validation R2: 0.568393

Epoch 179/1000
Training Loss: 0.05292496, Training R2: 0.991205
Validation Loss: 0.69873714, Validation R2: 0.585036

Epoch 180/1000
Training Loss: 0.05368636, Training R2: 0.991379
Validation Loss: 0.70906919, Validation R2: 0.571492

Epoch 181/1000
Epoch 00181: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.05653151, Training R2: 0.991086
Validation Loss: 0.71704215, Validation R2: 0.575574

Epoch 182/1000
学习率已减少 2 次
Training Loss: 0.05050446, Training R2: 0.991713
Validation Loss: 0.71163774, Validation R2: 0.579221

Epoch 183/1000
Training Loss: 0.04033624, Training R2: 0.992410
Validation Loss: 0.71031022, Validation R2: 0.577104

Epoch 184/1000
Training Loss: 0.04029745, Training R2: 0.992540
Validation Loss: 0.70727706, Validation R2: 0.579957

Epoch 185/1000
Training Loss: 0.03574224, Training R2: 0.992774
Validation Loss: 0.70339042, Validation R2: 0.579484

Epoch 186/1000
Training Loss: 0.04203366, Training R2: 0.992442
Validation Loss: 0.70776945, Validation R2: 0.574194

Epoch 187/1000
Training Loss: 0.03905032, Training R2: 0.992683
Validation Loss: 0.70667690, Validation R2: 0.580606

Epoch 188/1000
Training Loss: 0.03353974, Training R2: 0.993024
Validation Loss: 0.70780259, Validation R2: 0.576256

Epoch 189/1000
Training Loss: 0.03488032, Training R2: 0.992802
Validation Loss: 0.70409453, Validation R2: 0.579439

Epoch 190/1000
Training Loss: 0.04091922, Training R2: 0.992535
Validation Loss: 0.70696437, Validation R2: 0.579579

Epoch 191/1000
Training Loss: 0.03335897, Training R2: 0.992996
Validation Loss: 0.71686679, Validation R2: 0.567586

Epoch 192/1000
Training Loss: 0.04597313, Training R2: 0.992338
Validation Loss: 0.71581846, Validation R2: 0.569871

Epoch 193/1000
Training Loss: 0.05014538, Training R2: 0.992259
Validation Loss: 0.70562470, Validation R2: 0.576688

Epoch 194/1000
Training Loss: 0.04714210, Training R2: 0.992042
Validation Loss: 0.70385861, Validation R2: 0.573408

Epoch 195/1000
Training Loss: 0.04934980, Training R2: 0.991851
Validation Loss: 0.69972992, Validation R2: 0.584255

Epoch 196/1000
Training Loss: 0.04185240, Training R2: 0.992553
Validation Loss: 0.70937932, Validation R2: 0.573357

Epoch 197/1000
Training Loss: 0.04298292, Training R2: 0.992534
Validation Loss: 0.71024460, Validation R2: 0.570006

Epoch 198/1000
Training Loss: 0.03348335, Training R2: 0.992950
Validation Loss: 0.71110904, Validation R2: 0.577979

Epoch 199/1000
Training Loss: 0.03542435, Training R2: 0.992956
Validation Loss: 0.70916009, Validation R2: 0.572282

Epoch 200/1000
Training Loss: 0.03693676, Training R2: 0.992869
Validation Loss: 0.70446646, Validation R2: 0.575886

Epoch 201/1000
Training Loss: 0.03348804, Training R2: 0.993009
Validation Loss: 0.70264167, Validation R2: 0.581433

Epoch 202/1000
Epoch 00202: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.03282808, Training R2: 0.993176
Validation Loss: 0.70644802, Validation R2: 0.576072

Epoch 203/1000
学习率已减少 3 次
Training Loss: 0.02936495, Training R2: 0.993309
Validation Loss: 0.70574647, Validation R2: 0.579836

Epoch 204/1000
Training Loss: 0.03126401, Training R2: 0.993246
Validation Loss: 0.70875835, Validation R2: 0.577526

Epoch 205/1000
Training Loss: 0.02819587, Training R2: 0.993403
Validation Loss: 0.70615143, Validation R2: 0.577516

Epoch 206/1000
Training Loss: 0.02501077, Training R2: 0.993535
Validation Loss: 0.70201045, Validation R2: 0.581978

Epoch 207/1000
Training Loss: 0.02359643, Training R2: 0.993466
Validation Loss: 0.70016342, Validation R2: 0.582886

Epoch 208/1000
Training Loss: 0.03002877, Training R2: 0.993356
Validation Loss: 0.70371985, Validation R2: 0.580669

Epoch 209/1000
Training Loss: 0.02689097, Training R2: 0.993411
Validation Loss: 0.70611006, Validation R2: 0.580576

Epoch 210/1000
Training Loss: 0.02332698, Training R2: 0.993574
Validation Loss: 0.70624375, Validation R2: 0.578499

Epoch 211/1000
Training Loss: 0.02122415, Training R2: 0.993637
Validation Loss: 0.70854580, Validation R2: 0.575108

Epoch 212/1000
Training Loss: 0.02010556, Training R2: 0.993649
Validation Loss: 0.70671082, Validation R2: 0.578191

Epoch 213/1000
Training Loss: 0.01956675, Training R2: 0.993661
Validation Loss: 0.70852858, Validation R2: 0.574952

Epoch 214/1000
Training Loss: 0.02008174, Training R2: 0.993668
Validation Loss: 0.70480007, Validation R2: 0.580094

Epoch 215/1000
Training Loss: 0.01858771, Training R2: 0.993698
Validation Loss: 0.70675153, Validation R2: 0.578472

Epoch 216/1000
Training Loss: 0.01943927, Training R2: 0.993693
Validation Loss: 0.70644540, Validation R2: 0.579536

Epoch 217/1000
Training Loss: 0.01927210, Training R2: 0.993671
Validation Loss: 0.70743561, Validation R2: 0.579305

Epoch 218/1000
Training Loss: 0.01878444, Training R2: 0.993664
Validation Loss: 0.70643216, Validation R2: 0.579224

Epoch 219/1000
Training Loss: 0.01910763, Training R2: 0.993686
Validation Loss: 0.70579284, Validation R2: 0.578959

Epoch 220/1000
Training Loss: 0.01905638, Training R2: 0.993749
Validation Loss: 0.70673811, Validation R2: 0.580243

Epoch 221/1000
Training Loss: 0.02343668, Training R2: 0.993645
Validation Loss: 0.70662200, Validation R2: 0.579968

Epoch 222/1000
Training Loss: 0.02129779, Training R2: 0.993617
Validation Loss: 0.70798141, Validation R2: 0.576775

Epoch 223/1000
Epoch 00223: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.02084745, Training R2: 0.993655
Validation Loss: 0.70890594, Validation R2: 0.576747

Epoch 224/1000
学习率已减少 4 次
Training Loss: 0.02177476, Training R2: 0.993665
Validation Loss: 0.70614797, Validation R2: 0.579524

Epoch 225/1000
Training Loss: 0.02068208, Training R2: 0.993627
Validation Loss: 0.70465714, Validation R2: 0.580671

Epoch 226/1000
Training Loss: 0.02187747, Training R2: 0.993668
Validation Loss: 0.70886517, Validation R2: 0.576056

Epoch 227/1000
Training Loss: 0.02098396, Training R2: 0.993722
Validation Loss: 0.70782632, Validation R2: 0.577023

Epoch 228/1000
Training Loss: 0.01728874, Training R2: 0.993753
Validation Loss: 0.70645642, Validation R2: 0.578495

Epoch 229/1000
Training Loss: 0.01741288, Training R2: 0.993769
Validation Loss: 0.70756489, Validation R2: 0.577550

Epoch 230/1000
Training Loss: 0.01701731, Training R2: 0.993816
Validation Loss: 0.70786130, Validation R2: 0.578235

Epoch 231/1000
Training Loss: 0.01551185, Training R2: 0.993853
Validation Loss: 0.70775199, Validation R2: 0.577994

Epoch 232/1000
Training Loss: 0.01457939, Training R2: 0.993854
Validation Loss: 0.70513886, Validation R2: 0.580266

Epoch 233/1000
Training Loss: 0.01588489, Training R2: 0.993872
Validation Loss: 0.70604908, Validation R2: 0.579400

Epoch 234/1000
Training Loss: 0.01419684, Training R2: 0.993910
Validation Loss: 0.70717293, Validation R2: 0.577472

Epoch 235/1000
Training Loss: 0.01410729, Training R2: 0.993899
Validation Loss: 0.70787489, Validation R2: 0.577668

Epoch 236/1000
Training Loss: 0.01506128, Training R2: 0.993803
Validation Loss: 0.70628262, Validation R2: 0.579261

Epoch 237/1000
Training Loss: 0.01450430, Training R2: 0.993850
Validation Loss: 0.70630330, Validation R2: 0.578327

Epoch 238/1000
Training Loss: 0.01479501, Training R2: 0.993853
Validation Loss: 0.70500541, Validation R2: 0.580532

Epoch 239/1000
Training Loss: 0.01723091, Training R2: 0.993868
Validation Loss: 0.70548534, Validation R2: 0.580469

Epoch 240/1000
Training Loss: 0.01507716, Training R2: 0.993890
Validation Loss: 0.70682806, Validation R2: 0.578199

Epoch 241/1000
Training Loss: 0.01491227, Training R2: 0.993935
Validation Loss: 0.70685029, Validation R2: 0.578993

Epoch 242/1000
Training Loss: 0.01413705, Training R2: 0.993931
Validation Loss: 0.70626289, Validation R2: 0.579752

Epoch 243/1000
Training Loss: 0.01258657, Training R2: 0.993946
Validation Loss: 0.70580852, Validation R2: 0.579210

Epoch 244/1000
Epoch 00244: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.01307915, Training R2: 0.993881
Validation Loss: 0.70549011, Validation R2: 0.579995

Epoch 245/1000
学习率已减少 5 次
Training Loss: 0.01276365, Training R2: 0.993894
Validation Loss: 0.70539063, Validation R2: 0.580286

Epoch 246/1000
Training Loss: 0.01221886, Training R2: 0.993930
Validation Loss: 0.70614225, Validation R2: 0.579799

Epoch 247/1000
Training Loss: 0.01251284, Training R2: 0.993912
Validation Loss: 0.70553577, Validation R2: 0.579715

Epoch 248/1000
Training Loss: 0.01126541, Training R2: 0.993962
Validation Loss: 0.70573652, Validation R2: 0.579025

Epoch 249/1000
Training Loss: 0.01135790, Training R2: 0.993934
Validation Loss: 0.70615578, Validation R2: 0.579024

Epoch 250/1000
Training Loss: 0.01064442, Training R2: 0.993960
Validation Loss: 0.70626068, Validation R2: 0.578583

Epoch 251/1000
Training Loss: 0.01064139, Training R2: 0.993939
Validation Loss: 0.70574921, Validation R2: 0.579300

Epoch 252/1000
Training Loss: 0.01055473, Training R2: 0.993970
Validation Loss: 0.70603108, Validation R2: 0.579092

Epoch 253/1000
Training Loss: 0.01121683, Training R2: 0.993988
Validation Loss: 0.70592648, Validation R2: 0.579392

Epoch 254/1000
Training Loss: 0.01143937, Training R2: 0.993969
Validation Loss: 0.70558500, Validation R2: 0.579222

Epoch 255/1000
Training Loss: 0.01181630, Training R2: 0.993939
Validation Loss: 0.70589614, Validation R2: 0.579017

Epoch 256/1000
Training Loss: 0.01008334, Training R2: 0.993991
Validation Loss: 0.70611668, Validation R2: 0.578897

Epoch 257/1000
Training Loss: 0.01017885, Training R2: 0.993976
Validation Loss: 0.70632732, Validation R2: 0.578536

Epoch 258/1000
Training Loss: 0.01032247, Training R2: 0.993978
Validation Loss: 0.70556301, Validation R2: 0.579633

Epoch 259/1000
Training Loss: 0.00986487, Training R2: 0.993990
Validation Loss: 0.70552176, Validation R2: 0.579763

Epoch 260/1000
Training Loss: 0.01010449, Training R2: 0.994000
Validation Loss: 0.70563352, Validation R2: 0.579327

Epoch 261/1000
Training Loss: 0.00981005, Training R2: 0.993966
Validation Loss: 0.70639706, Validation R2: 0.578338

Epoch 262/1000
Training Loss: 0.01039301, Training R2: 0.993964
Validation Loss: 0.70624435, Validation R2: 0.579069

Epoch 263/1000
Training Loss: 0.00972132, Training R2: 0.994007
Validation Loss: 0.70655286, Validation R2: 0.578805

Epoch 264/1000
Training Loss: 0.00937282, Training R2: 0.994024
Validation Loss: 0.70616817, Validation R2: 0.578954

Epoch 265/1000
Epoch 00265: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.00969149, Training R2: 0.993995
Validation Loss: 0.70615250, Validation R2: 0.578727

Epoch 266/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
