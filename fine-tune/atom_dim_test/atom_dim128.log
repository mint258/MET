Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1025539

Epoch 1/1000
Training Loss: 2.10132705, Training R2: -1.986899
Validation Loss: 1.17457807, Validation R2: -0.160403
Saved best model with validation R2 -0.160403 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.21398208, Training R2: -0.056540
Validation Loss: 1.33816040, Validation R2: -0.618943

Epoch 3/1000
Training Loss: 1.26285468, Training R2: -0.272710
Validation Loss: 1.15264404, Validation R2: -0.121267
Saved best model with validation R2 -0.121267 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.22449106, Training R2: -0.044470
Validation Loss: 1.08594859, Validation R2: -0.067513
Saved best model with validation R2 -0.067513 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.19896433, Training R2: -0.193472
Validation Loss: 1.07346392, Validation R2: -0.013447
Saved best model with validation R2 -0.013447 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.18948592, Training R2: -0.019426
Validation Loss: 1.10454714, Validation R2: -0.026034

Epoch 7/1000
Training Loss: 1.17774762, Training R2: -0.043703
Validation Loss: 1.11477745, Validation R2: -0.142596

Epoch 8/1000
Training Loss: 1.16632480, Training R2: -0.108097
Validation Loss: 1.07373822, Validation R2: 0.003113
Saved best model with validation R2 0.003113 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.15609882, Training R2: -0.001526
Validation Loss: 1.07371521, Validation R2: 0.008245
Saved best model with validation R2 0.008245 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 1.15477524, Training R2: -0.002850
Validation Loss: 1.06960154, Validation R2: 0.005453

Epoch 11/1000
Training Loss: 1.15349102, Training R2: -0.000922
Validation Loss: 1.06581986, Validation R2: 0.002607

Epoch 12/1000
Training Loss: 1.14348989, Training R2: -0.023320
Validation Loss: 1.08700037, Validation R2: -0.087927

Epoch 13/1000
Training Loss: 1.15246167, Training R2: -0.092311
Validation Loss: 1.04995739, Validation R2: 0.027059
Saved best model with validation R2 0.027059 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 1.13689390, Training R2: 0.014549
Validation Loss: 1.03108752, Validation R2: 0.058825
Saved best model with validation R2 0.058825 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 1.11675027, Training R2: 0.011078
Validation Loss: 0.97060615, Validation R2: 0.154745
Saved best model with validation R2 0.154745 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 1.07442221, Training R2: 0.100527
Validation Loss: 0.90810025, Validation R2: 0.240122
Saved best model with validation R2 0.240122 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 1.02949960, Training R2: 0.133135
Validation Loss: 0.98762083, Validation R2: 0.156459

Epoch 18/1000
Training Loss: 1.19550983, Training R2: -0.070295
Validation Loss: 0.97801942, Validation R2: 0.152923

Epoch 19/1000
Training Loss: 1.07595331, Training R2: 0.116137
Validation Loss: 1.07142842, Validation R2: -0.065160

Epoch 20/1000
Training Loss: 1.12837724, Training R2: -0.060839
Validation Loss: 1.00858271, Validation R2: 0.113519

Epoch 21/1000
Training Loss: 1.10322888, Training R2: 0.094837
Validation Loss: 0.98132795, Validation R2: 0.151342

Epoch 22/1000
Training Loss: 1.07202414, Training R2: 0.073615
Validation Loss: 0.93155301, Validation R2: 0.227327

Epoch 23/1000
Training Loss: 1.03779482, Training R2: 0.164500
Validation Loss: 0.88305801, Validation R2: 0.274641
Saved best model with validation R2 0.274641 to best_finetuned_model.pth

Epoch 24/1000
Training Loss: 0.99949476, Training R2: 0.193488
Validation Loss: 1.03819096, Validation R2: 0.037828

Epoch 25/1000
Training Loss: 1.08398444, Training R2: 0.076434
Validation Loss: 0.89195633, Validation R2: 0.275705
Saved best model with validation R2 0.275705 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 1.03528879, Training R2: 0.123297
Validation Loss: 0.88817477, Validation R2: 0.285221
Saved best model with validation R2 0.285221 to best_finetuned_model.pth

Epoch 27/1000
Training Loss: 0.99267931, Training R2: 0.209656
Validation Loss: 0.92500913, Validation R2: 0.228465

Epoch 28/1000
Training Loss: 1.03408670, Training R2: 0.154300
Validation Loss: 0.88953757, Validation R2: 0.252520

Epoch 29/1000
Training Loss: 1.02648948, Training R2: 0.137764
Validation Loss: 1.02844894, Validation R2: 0.091881

Epoch 30/1000
Training Loss: 1.06676458, Training R2: 0.152427
Validation Loss: 1.05845261, Validation R2: 0.005770

Epoch 31/1000
Training Loss: 1.03324017, Training R2: 0.143604
Validation Loss: 0.90138561, Validation R2: 0.261745

Epoch 32/1000
Training Loss: 0.98441192, Training R2: 0.217046
Validation Loss: 0.84223819, Validation R2: 0.339907
Saved best model with validation R2 0.339907 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 0.97174558, Training R2: 0.243969
Validation Loss: 0.81759596, Validation R2: 0.368052
Saved best model with validation R2 0.368052 to best_finetuned_model.pth

Epoch 34/1000
Training Loss: 0.91285190, Training R2: 0.304371
Validation Loss: 0.82967335, Validation R2: 0.354173

Epoch 35/1000
Training Loss: 0.90278865, Training R2: 0.313422
Validation Loss: 0.81183243, Validation R2: 0.382173
Saved best model with validation R2 0.382173 to best_finetuned_model.pth

Epoch 36/1000
Training Loss: 0.90077901, Training R2: 0.312040
Validation Loss: 0.82589674, Validation R2: 0.353874

Epoch 37/1000
Training Loss: 0.88123488, Training R2: 0.326335
Validation Loss: 0.80819899, Validation R2: 0.381434

Epoch 38/1000
Training Loss: 0.86470032, Training R2: 0.341893
Validation Loss: 0.79816896, Validation R2: 0.387811
Saved best model with validation R2 0.387811 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.85077456, Training R2: 0.353928
Validation Loss: 0.94188637, Validation R2: 0.155408

Epoch 40/1000
Training Loss: 0.92737636, Training R2: 0.273416
Validation Loss: 0.88477749, Validation R2: 0.293838

Epoch 41/1000
Training Loss: 0.89225049, Training R2: 0.323667
Validation Loss: 0.89101356, Validation R2: 0.209310

Epoch 42/1000
Training Loss: 0.91282951, Training R2: 0.283072
Validation Loss: 0.83489639, Validation R2: 0.315121

Epoch 43/1000
Training Loss: 0.88280268, Training R2: 0.332551
Validation Loss: 0.84431213, Validation R2: 0.301661

Epoch 44/1000
Training Loss: 0.89205546, Training R2: 0.325789
Validation Loss: 0.79443520, Validation R2: 0.393518
Saved best model with validation R2 0.393518 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.80156965, Training R2: 0.414494
Validation Loss: 0.82975304, Validation R2: 0.311239

Epoch 46/1000
Training Loss: 0.80638225, Training R2: 0.395884
Validation Loss: 0.79325700, Validation R2: 0.384586

Epoch 47/1000
Training Loss: 0.86848137, Training R2: 0.343790
Validation Loss: 0.77298623, Validation R2: 0.421382
Saved best model with validation R2 0.421382 to best_finetuned_model.pth

Epoch 48/1000
Training Loss: 0.81313920, Training R2: 0.389219
Validation Loss: 0.89970672, Validation R2: 0.280767

Epoch 49/1000
Training Loss: 0.81237008, Training R2: 0.378660
Validation Loss: 0.87030762, Validation R2: 0.313980

Epoch 50/1000
Training Loss: 0.85646460, Training R2: 0.368781
Validation Loss: 1.23069239, Validation R2: -0.273509

Epoch 51/1000
Training Loss: 1.03978303, Training R2: 0.099055
Validation Loss: 1.01281869, Validation R2: 0.138324

Epoch 52/1000
Training Loss: 0.95256343, Training R2: 0.280669
Validation Loss: 0.93852371, Validation R2: 0.164243

Epoch 53/1000
Training Loss: 0.92123847, Training R2: 0.262970
Validation Loss: 0.91419828, Validation R2: 0.265454

Epoch 54/1000
Training Loss: 0.85762977, Training R2: 0.360400
Validation Loss: 0.77933943, Validation R2: 0.426247
Saved best model with validation R2 0.426247 to best_finetuned_model.pth

Epoch 55/1000
Training Loss: 0.84855690, Training R2: 0.364691
Validation Loss: 0.69758302, Validation R2: 0.507059
Saved best model with validation R2 0.507059 to best_finetuned_model.pth

Epoch 56/1000
Training Loss: 0.78349241, Training R2: 0.431715
Validation Loss: 0.72865897, Validation R2: 0.472537

Epoch 57/1000
Training Loss: 0.78053378, Training R2: 0.451373
Validation Loss: 0.89894193, Validation R2: 0.204738

Epoch 58/1000
Training Loss: 0.88582165, Training R2: 0.315431
Validation Loss: 0.88510954, Validation R2: 0.231430

Epoch 59/1000
Training Loss: 0.94648902, Training R2: 0.233672
Validation Loss: 0.77484280, Validation R2: 0.433331

Epoch 60/1000
Training Loss: 0.85091424, Training R2: 0.373811
Validation Loss: 0.81104779, Validation R2: 0.385029

Epoch 61/1000
Training Loss: 0.86225843, Training R2: 0.360232
Validation Loss: 0.78334379, Validation R2: 0.420517

Epoch 62/1000
Training Loss: 0.85182335, Training R2: 0.362477
Validation Loss: 0.76280576, Validation R2: 0.437566

Epoch 63/1000
Training Loss: 0.84618104, Training R2: 0.371381
Validation Loss: 0.77634621, Validation R2: 0.434954

Epoch 64/1000
Training Loss: 0.83517403, Training R2: 0.390700
Validation Loss: 0.77873981, Validation R2: 0.442378

Epoch 65/1000
Training Loss: 0.82115713, Training R2: 0.403786
Validation Loss: 0.75036281, Validation R2: 0.456565

Epoch 66/1000
Training Loss: 0.82693326, Training R2: 0.381353
Validation Loss: 0.78948009, Validation R2: 0.399517

Epoch 67/1000
Training Loss: 0.85424311, Training R2: 0.356290
Validation Loss: 0.96596539, Validation R2: 0.195040

Epoch 68/1000
Training Loss: 0.89706041, Training R2: 0.314549
Validation Loss: 0.84453368, Validation R2: 0.366706

Epoch 69/1000
Training Loss: 0.87743746, Training R2: 0.357969
Validation Loss: 0.76520920, Validation R2: 0.462667

Epoch 70/1000
Training Loss: 0.82945436, Training R2: 0.398160
Validation Loss: 0.75786650, Validation R2: 0.444127

Epoch 71/1000
Training Loss: 0.78552162, Training R2: 0.432977
Validation Loss: 0.75667816, Validation R2: 0.439297

Epoch 72/1000
Training Loss: 0.82966413, Training R2: 0.371622
Validation Loss: 0.73779893, Validation R2: 0.478483

Epoch 73/1000
Training Loss: 0.80674084, Training R2: 0.408321
Validation Loss: 0.77258956, Validation R2: 0.431592

Epoch 74/1000
Training Loss: 0.77645728, Training R2: 0.431927
Validation Loss: 0.74919903, Validation R2: 0.465024

Epoch 75/1000
Training Loss: 0.78181325, Training R2: 0.433213
Validation Loss: 0.73225456, Validation R2: 0.473683

Epoch 76/1000
Epoch 00076: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 0.77478027, Training R2: 0.437227
Validation Loss: 0.74031228, Validation R2: 0.477928

Epoch 77/1000
学习率已减少 1 次
Training Loss: 0.74956240, Training R2: 0.459569
Validation Loss: 0.71880233, Validation R2: 0.490640

Epoch 78/1000
Training Loss: 0.73126482, Training R2: 0.475715
Validation Loss: 0.71576178, Validation R2: 0.490551

Epoch 79/1000
Training Loss: 0.72851698, Training R2: 0.474707
Validation Loss: 0.72099823, Validation R2: 0.477709

Epoch 80/1000
Training Loss: 0.74239979, Training R2: 0.453762
Validation Loss: 0.71077114, Validation R2: 0.488880

Epoch 81/1000
Training Loss: 0.73393610, Training R2: 0.459001
Validation Loss: 0.72264969, Validation R2: 0.484605

Epoch 82/1000
Training Loss: 0.74245290, Training R2: 0.463425
Validation Loss: 0.70823514, Validation R2: 0.498913

Epoch 83/1000
Training Loss: 0.72451625, Training R2: 0.470088
Validation Loss: 0.71230757, Validation R2: 0.490114

Epoch 84/1000
Training Loss: 0.71509209, Training R2: 0.474824
Validation Loss: 0.70739561, Validation R2: 0.497849

Epoch 85/1000
Training Loss: 0.71951701, Training R2: 0.469319
Validation Loss: 0.70902938, Validation R2: 0.497139

Epoch 86/1000
Training Loss: 0.72255366, Training R2: 0.452895
Validation Loss: 0.71264690, Validation R2: 0.488772

Epoch 87/1000
Training Loss: 0.72428547, Training R2: 0.450001
Validation Loss: 0.70730007, Validation R2: 0.498080

Epoch 88/1000
Training Loss: 0.71576350, Training R2: 0.474484
Validation Loss: 0.70769960, Validation R2: 0.493420

Epoch 89/1000
Training Loss: 0.71702288, Training R2: 0.478586
Validation Loss: 0.70794266, Validation R2: 0.489034

Epoch 90/1000
Training Loss: 0.70759123, Training R2: 0.478102
Validation Loss: 0.70738775, Validation R2: 0.482588

Epoch 91/1000
Training Loss: 0.70418862, Training R2: 0.478311
Validation Loss: 0.71878612, Validation R2: 0.476236

Epoch 92/1000
Training Loss: 0.70395592, Training R2: 0.448585
Validation Loss: 0.71895629, Validation R2: 0.479116

Epoch 93/1000
Training Loss: 0.69704857, Training R2: 0.454063
Validation Loss: 0.70179945, Validation R2: 0.503408

Epoch 94/1000
Training Loss: 0.71068203, Training R2: 0.471500
Validation Loss: 0.69319379, Validation R2: 0.509628
Saved best model with validation R2 0.509628 to best_finetuned_model.pth

Epoch 95/1000
Training Loss: 0.68689258, Training R2: 0.492355
Validation Loss: 0.68506354, Validation R2: 0.519094
Saved best model with validation R2 0.519094 to best_finetuned_model.pth

Epoch 96/1000
Training Loss: 0.68986572, Training R2: 0.489369
Validation Loss: 0.69503814, Validation R2: 0.507600

Epoch 97/1000
Training Loss: 0.71718629, Training R2: 0.486660
Validation Loss: 0.68592650, Validation R2: 0.527108
Saved best model with validation R2 0.527108 to best_finetuned_model.pth

Epoch 98/1000
Training Loss: 0.68478787, Training R2: 0.508390
Validation Loss: 0.72880721, Validation R2: 0.466718

Epoch 99/1000
Training Loss: 0.71485772, Training R2: 0.477127
Validation Loss: 0.73370749, Validation R2: 0.474871

Epoch 100/1000
Training Loss: 0.74288451, Training R2: 0.452618
Validation Loss: 0.69220120, Validation R2: 0.527973
Saved best model with validation R2 0.527973 to best_finetuned_model.pth

Epoch 101/1000
Training Loss: 0.71333606, Training R2: 0.484434
Validation Loss: 0.66949403, Validation R2: 0.534029
Saved best model with validation R2 0.534029 to best_finetuned_model.pth

Epoch 102/1000
Training Loss: 0.69303190, Training R2: 0.492104
Validation Loss: 0.68580931, Validation R2: 0.509403

Epoch 103/1000
Training Loss: 0.69740588, Training R2: 0.469327
Validation Loss: 0.69067806, Validation R2: 0.504029

Epoch 104/1000
Training Loss: 0.67322978, Training R2: 0.501777
Validation Loss: 0.68790555, Validation R2: 0.511966

Epoch 105/1000
Training Loss: 0.67954030, Training R2: 0.506169
Validation Loss: 0.67073929, Validation R2: 0.526116

Epoch 106/1000
Training Loss: 0.68598278, Training R2: 0.496751
Validation Loss: 0.66161907, Validation R2: 0.537661
Saved best model with validation R2 0.537661 to best_finetuned_model.pth

Epoch 107/1000
Training Loss: 0.68090073, Training R2: 0.502453
Validation Loss: 0.66771162, Validation R2: 0.535428

Epoch 108/1000
Training Loss: 0.67348423, Training R2: 0.506530
Validation Loss: 0.67235595, Validation R2: 0.532275

Epoch 109/1000
Training Loss: 0.68218203, Training R2: 0.504598
Validation Loss: 0.66047001, Validation R2: 0.540012
Saved best model with validation R2 0.540012 to best_finetuned_model.pth

Epoch 110/1000
Training Loss: 0.66790086, Training R2: 0.510920
Validation Loss: 0.66281414, Validation R2: 0.535618

Epoch 111/1000
Training Loss: 0.66608449, Training R2: 0.510386
Validation Loss: 0.65695953, Validation R2: 0.549450
Saved best model with validation R2 0.549450 to best_finetuned_model.pth

Epoch 112/1000
Training Loss: 0.65958668, Training R2: 0.525394
Validation Loss: 0.69654679, Validation R2: 0.502759

Epoch 113/1000
Training Loss: 0.69371175, Training R2: 0.484776
Validation Loss: 0.67164242, Validation R2: 0.541981

Epoch 114/1000
Training Loss: 0.68821026, Training R2: 0.503882
Validation Loss: 0.67944169, Validation R2: 0.543999

Epoch 115/1000
Training Loss: 0.68619125, Training R2: 0.502418
Validation Loss: 0.67088109, Validation R2: 0.547211

Epoch 116/1000
Training Loss: 0.67559369, Training R2: 0.512129
Validation Loss: 0.66931438, Validation R2: 0.544295

Epoch 117/1000
Training Loss: 0.70596506, Training R2: 0.493481
Validation Loss: 0.67667568, Validation R2: 0.538181

Epoch 118/1000
Training Loss: 0.70619702, Training R2: 0.494115
Validation Loss: 0.70527244, Validation R2: 0.512380

Epoch 119/1000
Training Loss: 0.71582993, Training R2: 0.487775
Validation Loss: 0.69730866, Validation R2: 0.494839

Epoch 120/1000
Training Loss: 0.69526635, Training R2: 0.496030
Validation Loss: 0.64600885, Validation R2: 0.559822
Saved best model with validation R2 0.559822 to best_finetuned_model.pth

Epoch 121/1000
Training Loss: 0.65960845, Training R2: 0.534405
Validation Loss: 0.66135281, Validation R2: 0.548854

Epoch 122/1000
Training Loss: 0.67357017, Training R2: 0.524630
Validation Loss: 0.66091079, Validation R2: 0.553582

Epoch 123/1000
Training Loss: 0.66302591, Training R2: 0.531381
Validation Loss: 0.65874428, Validation R2: 0.531942

Epoch 124/1000
Training Loss: 0.66483995, Training R2: 0.533773
Validation Loss: 0.66125965, Validation R2: 0.526778

Epoch 125/1000
Training Loss: 0.67866363, Training R2: 0.520180
Validation Loss: 0.70167410, Validation R2: 0.482363

Epoch 126/1000
Training Loss: 0.69722467, Training R2: 0.495762
Validation Loss: 0.89286971, Validation R2: 0.062423

Epoch 127/1000
Training Loss: 0.82840605, Training R2: 0.267054
Validation Loss: 0.67816329, Validation R2: 0.516308

Epoch 128/1000
Training Loss: 0.70707026, Training R2: 0.482532
Validation Loss: 0.64212483, Validation R2: 0.551422

Epoch 129/1000
Training Loss: 0.69527067, Training R2: 0.485192
Validation Loss: 0.65063804, Validation R2: 0.517624

Epoch 130/1000
Training Loss: 0.68892987, Training R2: 0.482197
Validation Loss: 0.66724890, Validation R2: 0.520976

Epoch 131/1000
Training Loss: 0.68316792, Training R2: 0.489744
Validation Loss: 0.65210235, Validation R2: 0.527724

Epoch 132/1000
Training Loss: 0.67358578, Training R2: 0.499324
Validation Loss: 0.65077341, Validation R2: 0.536283

Epoch 133/1000
Training Loss: 0.69219818, Training R2: 0.488385
Validation Loss: 0.66697389, Validation R2: 0.523561

Epoch 134/1000
Training Loss: 0.67954571, Training R2: 0.501553
Validation Loss: 0.69484264, Validation R2: 0.491575

Epoch 135/1000
Training Loss: 0.68375188, Training R2: 0.500788
Validation Loss: 0.65038693, Validation R2: 0.516754

Epoch 136/1000
Training Loss: 0.65661340, Training R2: 0.509436
Validation Loss: 0.66498595, Validation R2: 0.518584

Epoch 137/1000
Training Loss: 0.66288872, Training R2: 0.514959
Validation Loss: 0.73698139, Validation R2: 0.459455

Epoch 138/1000
Training Loss: 0.70503437, Training R2: 0.496956
Validation Loss: 0.71463072, Validation R2: 0.454691

Epoch 139/1000
Training Loss: 0.70300255, Training R2: 0.498833
Validation Loss: 0.71048337, Validation R2: 0.492158

Epoch 140/1000
Training Loss: 0.70635720, Training R2: 0.506970
Validation Loss: 0.66702300, Validation R2: 0.528219

Epoch 141/1000
Epoch 00141: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 0.67425503, Training R2: 0.526447
Validation Loss: 0.75061840, Validation R2: 0.471021

Epoch 142/1000
学习率已减少 2 次
Training Loss: 0.69269306, Training R2: 0.517607
Validation Loss: 0.66745174, Validation R2: 0.520850

Epoch 143/1000
Training Loss: 0.68010938, Training R2: 0.524454
Validation Loss: 0.66311491, Validation R2: 0.524750

Epoch 144/1000
Training Loss: 0.70353869, Training R2: 0.482741
Validation Loss: 0.63903058, Validation R2: 0.547236

Epoch 145/1000
Training Loss: 0.66856825, Training R2: 0.523638
Validation Loss: 0.65428334, Validation R2: 0.527015

Epoch 146/1000
Training Loss: 0.65289625, Training R2: 0.538036
Validation Loss: 0.65221900, Validation R2: 0.548927

Epoch 147/1000
Training Loss: 0.64914835, Training R2: 0.542777
Validation Loss: 0.65280938, Validation R2: 0.540130

Epoch 148/1000
Training Loss: 0.64992637, Training R2: 0.548165
Validation Loss: 0.65410203, Validation R2: 0.551049

Epoch 149/1000
Training Loss: 0.65154058, Training R2: 0.548066
Validation Loss: 0.61987948, Validation R2: 0.564861
Saved best model with validation R2 0.564861 to best_finetuned_model.pth

Epoch 150/1000
Training Loss: 0.63654952, Training R2: 0.558571
Validation Loss: 0.60879570, Validation R2: 0.584385
Saved best model with validation R2 0.584385 to best_finetuned_model.pth

Epoch 151/1000
Training Loss: 0.63788693, Training R2: 0.553939
Validation Loss: 0.61679101, Validation R2: 0.582208

Epoch 152/1000
Training Loss: 0.61984519, Training R2: 0.568502
Validation Loss: 0.61370987, Validation R2: 0.584321

Epoch 153/1000
Training Loss: 0.61918680, Training R2: 0.564598
Validation Loss: 0.63314939, Validation R2: 0.580878

Epoch 154/1000
Training Loss: 0.63923999, Training R2: 0.557956
Validation Loss: 0.61175680, Validation R2: 0.589215
Saved best model with validation R2 0.589215 to best_finetuned_model.pth

Epoch 155/1000
Training Loss: 0.63487768, Training R2: 0.555452
Validation Loss: 0.60358471, Validation R2: 0.596245
Saved best model with validation R2 0.596245 to best_finetuned_model.pth

Epoch 156/1000
Training Loss: 0.63301158, Training R2: 0.562050
Validation Loss: 0.60373396, Validation R2: 0.588605

Epoch 157/1000
Training Loss: 0.61883184, Training R2: 0.567876
Validation Loss: 0.61534637, Validation R2: 0.571251

Epoch 158/1000
Training Loss: 0.61691007, Training R2: 0.572195
Validation Loss: 0.61015403, Validation R2: 0.594659

Epoch 159/1000
Training Loss: 0.60866630, Training R2: 0.586907
Validation Loss: 0.61159939, Validation R2: 0.588943

Epoch 160/1000
Training Loss: 0.60868626, Training R2: 0.583605
Validation Loss: 0.61049771, Validation R2: 0.589218

Epoch 161/1000
Training Loss: 0.60888772, Training R2: 0.583539
Validation Loss: 0.61278677, Validation R2: 0.593117

Epoch 162/1000
Training Loss: 0.60971165, Training R2: 0.579823
Validation Loss: 0.61652875, Validation R2: 0.600665
Saved best model with validation R2 0.600665 to best_finetuned_model.pth

Epoch 163/1000
Training Loss: 0.63572212, Training R2: 0.568244
Validation Loss: 0.59708166, Validation R2: 0.610137
Saved best model with validation R2 0.610137 to best_finetuned_model.pth

Epoch 164/1000
Training Loss: 0.63470006, Training R2: 0.563674
Validation Loss: 0.61430395, Validation R2: 0.598701

Epoch 165/1000
Training Loss: 0.64317650, Training R2: 0.558769
Validation Loss: 0.60739976, Validation R2: 0.597280

Epoch 166/1000
Training Loss: 0.62977188, Training R2: 0.566838
Validation Loss: 0.60351145, Validation R2: 0.601013

Epoch 167/1000
Training Loss: 0.64951872, Training R2: 0.517055
Validation Loss: 0.65966743, Validation R2: 0.547430

Epoch 168/1000
Training Loss: 0.65858146, Training R2: 0.511413
Validation Loss: 0.61472583, Validation R2: 0.589227

Epoch 169/1000
Training Loss: 0.62855098, Training R2: 0.548104
Validation Loss: 0.60894585, Validation R2: 0.601800

Epoch 170/1000
Training Loss: 0.63581799, Training R2: 0.540705
Validation Loss: 0.59412634, Validation R2: 0.612014
Saved best model with validation R2 0.612014 to best_finetuned_model.pth

Epoch 171/1000
Training Loss: 0.61540910, Training R2: 0.566503
Validation Loss: 0.58931583, Validation R2: 0.617742
Saved best model with validation R2 0.617742 to best_finetuned_model.pth

Epoch 172/1000
Training Loss: 0.61870711, Training R2: 0.572601
Validation Loss: 0.59388363, Validation R2: 0.612552

Epoch 173/1000
Training Loss: 0.60241110, Training R2: 0.589524
Validation Loss: 0.59482819, Validation R2: 0.607697

Epoch 174/1000
Training Loss: 0.59968835, Training R2: 0.590899
Validation Loss: 0.59958607, Validation R2: 0.601939

Epoch 175/1000
Training Loss: 0.58958083, Training R2: 0.597254
Validation Loss: 0.59702528, Validation R2: 0.619347
Saved best model with validation R2 0.619347 to best_finetuned_model.pth

Epoch 176/1000
Training Loss: 0.58484890, Training R2: 0.605269
Validation Loss: 0.61861652, Validation R2: 0.602317

Epoch 177/1000
Training Loss: 0.59773858, Training R2: 0.598604
Validation Loss: 0.61168569, Validation R2: 0.601936

Epoch 178/1000
Training Loss: 0.58652438, Training R2: 0.598964
Validation Loss: 0.61610657, Validation R2: 0.601196

Epoch 179/1000
Training Loss: 0.58912147, Training R2: 0.594714
Validation Loss: 0.62450731, Validation R2: 0.608256

Epoch 180/1000
Training Loss: 0.59918586, Training R2: 0.602475
Validation Loss: 0.63114971, Validation R2: 0.582311

Epoch 181/1000
Training Loss: 0.61705143, Training R2: 0.582933
Validation Loss: 0.62949824, Validation R2: 0.585147

Epoch 182/1000
Training Loss: 0.60335871, Training R2: 0.588737
Validation Loss: 0.63050765, Validation R2: 0.588243

Epoch 183/1000
Training Loss: 0.60670499, Training R2: 0.594253
Validation Loss: 0.62614715, Validation R2: 0.587499

Epoch 184/1000
Training Loss: 0.61363070, Training R2: 0.580196
Validation Loss: 0.69515991, Validation R2: 0.517911

Epoch 185/1000
Training Loss: 0.67688553, Training R2: 0.542772
Validation Loss: 0.64400983, Validation R2: 0.566954

Epoch 186/1000
Training Loss: 0.67967328, Training R2: 0.540448
Validation Loss: 0.61668867, Validation R2: 0.594526

Epoch 187/1000
Training Loss: 0.64776886, Training R2: 0.560897
Validation Loss: 0.62335855, Validation R2: 0.593269

Epoch 188/1000
Training Loss: 0.62566665, Training R2: 0.582375
Validation Loss: 0.63847911, Validation R2: 0.576874

Epoch 189/1000
Training Loss: 0.62595452, Training R2: 0.575113
Validation Loss: 0.64571327, Validation R2: 0.586022

Epoch 190/1000
Training Loss: 0.62488856, Training R2: 0.583960
Validation Loss: 0.62073195, Validation R2: 0.598116

Epoch 191/1000
Training Loss: 0.60909063, Training R2: 0.590836
Validation Loss: 0.60862660, Validation R2: 0.608800

Epoch 192/1000
Training Loss: 0.61242415, Training R2: 0.593091
Validation Loss: 0.59991825, Validation R2: 0.615137

Epoch 193/1000
Training Loss: 0.60200077, Training R2: 0.595580
Validation Loss: 0.62301445, Validation R2: 0.590513

Epoch 194/1000
Training Loss: 0.58395588, Training R2: 0.607261
Validation Loss: 0.61421400, Validation R2: 0.605064

Epoch 195/1000
Training Loss: 0.58054289, Training R2: 0.610522
Validation Loss: 0.63347673, Validation R2: 0.574266

Epoch 196/1000
Epoch 00196: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 0.58621474, Training R2: 0.600965
Validation Loss: 0.64353889, Validation R2: 0.575119

Epoch 197/1000
学习率已减少 3 次
Training Loss: 0.61771978, Training R2: 0.578467
Validation Loss: 0.60628051, Validation R2: 0.607745

Epoch 198/1000
Training Loss: 0.58360435, Training R2: 0.606065
Validation Loss: 0.64304471, Validation R2: 0.571172

Epoch 199/1000
Training Loss: 0.60314019, Training R2: 0.590627
Validation Loss: 0.61138272, Validation R2: 0.604483

Epoch 200/1000
Training Loss: 0.57946205, Training R2: 0.608255
Validation Loss: 0.60892582, Validation R2: 0.607947

Epoch 201/1000
Training Loss: 0.56458404, Training R2: 0.619386
Validation Loss: 0.61475170, Validation R2: 0.605593

Epoch 202/1000
Training Loss: 0.57538103, Training R2: 0.619224
Validation Loss: 0.60358852, Validation R2: 0.613959

Epoch 203/1000
Training Loss: 0.55392790, Training R2: 0.628618
Validation Loss: 0.62401372, Validation R2: 0.596563

Epoch 204/1000
Training Loss: 0.56045703, Training R2: 0.624623
Validation Loss: 0.61600971, Validation R2: 0.598814

Epoch 205/1000
Training Loss: 0.54725575, Training R2: 0.636382
Validation Loss: 0.60757518, Validation R2: 0.607126

Epoch 206/1000
Training Loss: 0.55341798, Training R2: 0.638022
Validation Loss: 0.61530358, Validation R2: 0.590671

Epoch 207/1000
Training Loss: 0.55202730, Training R2: 0.636187
Validation Loss: 0.63092124, Validation R2: 0.571695

Epoch 208/1000
Training Loss: 0.55253422, Training R2: 0.632132
Validation Loss: 0.62996185, Validation R2: 0.569637

Epoch 209/1000
Training Loss: 0.54579379, Training R2: 0.637179
Validation Loss: 0.61872327, Validation R2: 0.580679

Epoch 210/1000
Training Loss: 0.54021018, Training R2: 0.643511
Validation Loss: 0.61614305, Validation R2: 0.583249

Epoch 211/1000
Training Loss: 0.53850696, Training R2: 0.646629
Validation Loss: 0.61072499, Validation R2: 0.593313

Epoch 212/1000
Training Loss: 0.53248927, Training R2: 0.648489
Validation Loss: 0.61484104, Validation R2: 0.585008

Epoch 213/1000
Training Loss: 0.53394596, Training R2: 0.647673
Validation Loss: 0.60650456, Validation R2: 0.589363

Epoch 214/1000
Training Loss: 0.53432050, Training R2: 0.645797
Validation Loss: 0.60480797, Validation R2: 0.596154

Epoch 215/1000
Training Loss: 0.52975622, Training R2: 0.651200
Validation Loss: 0.60174596, Validation R2: 0.602718

Epoch 216/1000
Training Loss: 0.52715160, Training R2: 0.650978
Validation Loss: 0.60879201, Validation R2: 0.595474

Epoch 217/1000
Epoch 00217: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 0.52552871, Training R2: 0.651732
Validation Loss: 0.62026364, Validation R2: 0.586038

Epoch 218/1000
学习率已减少 4 次
Training Loss: 0.52578292, Training R2: 0.652049
Validation Loss: 0.61285615, Validation R2: 0.587757

Epoch 219/1000
Training Loss: 0.52231382, Training R2: 0.652653
Validation Loss: 0.61171585, Validation R2: 0.586335

Epoch 220/1000
Training Loss: 0.52214711, Training R2: 0.652993
Validation Loss: 0.60727787, Validation R2: 0.588548

Epoch 221/1000
Training Loss: 0.52022805, Training R2: 0.654444
Validation Loss: 0.60601181, Validation R2: 0.588417

Epoch 222/1000
Training Loss: 0.51808370, Training R2: 0.655765
Validation Loss: 0.61075461, Validation R2: 0.585460

Epoch 223/1000
Training Loss: 0.51431352, Training R2: 0.655670
Validation Loss: 0.60798252, Validation R2: 0.585101

Epoch 224/1000
Training Loss: 0.51684333, Training R2: 0.655607
Validation Loss: 0.60741562, Validation R2: 0.590128

Epoch 225/1000
Training Loss: 0.51701342, Training R2: 0.657611
Validation Loss: 0.61061746, Validation R2: 0.590793

Epoch 226/1000
Training Loss: 0.51277499, Training R2: 0.660314
Validation Loss: 0.60185128, Validation R2: 0.594841

Epoch 227/1000
Training Loss: 0.51249593, Training R2: 0.660526
Validation Loss: 0.61173183, Validation R2: 0.586920

Epoch 228/1000
Training Loss: 0.51454600, Training R2: 0.660558
Validation Loss: 0.61784226, Validation R2: 0.579551

Epoch 229/1000
Training Loss: 0.50763836, Training R2: 0.664731
Validation Loss: 0.60642809, Validation R2: 0.587585

Epoch 230/1000
Training Loss: 0.51049532, Training R2: 0.664778
Validation Loss: 0.60634571, Validation R2: 0.589030

Epoch 231/1000
Training Loss: 0.50566726, Training R2: 0.666178
Validation Loss: 0.60904807, Validation R2: 0.589358

Epoch 232/1000
Training Loss: 0.50340964, Training R2: 0.667194
Validation Loss: 0.61371297, Validation R2: 0.588623

Epoch 233/1000
Training Loss: 0.50143708, Training R2: 0.668285
Validation Loss: 0.60888851, Validation R2: 0.591804

Epoch 234/1000
Training Loss: 0.50179620, Training R2: 0.668562
Validation Loss: 0.60123694, Validation R2: 0.596645

Epoch 235/1000
Training Loss: 0.50229531, Training R2: 0.667400
Validation Loss: 0.60145044, Validation R2: 0.591801

Epoch 236/1000
Training Loss: 0.50183214, Training R2: 0.665235
Validation Loss: 0.60366899, Validation R2: 0.590516

Epoch 237/1000
Training Loss: 0.50233680, Training R2: 0.665063
Validation Loss: 0.60121596, Validation R2: 0.590871

Epoch 238/1000
Epoch 00238: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 0.50650337, Training R2: 0.663701
Validation Loss: 0.59994233, Validation R2: 0.594994

Epoch 239/1000
学习率已减少 5 次
Training Loss: 0.51067097, Training R2: 0.661663
Validation Loss: 0.60771024, Validation R2: 0.589239

Epoch 240/1000
Training Loss: 0.50895305, Training R2: 0.663422
Validation Loss: 0.60069305, Validation R2: 0.591790

Epoch 241/1000
Training Loss: 0.50199678, Training R2: 0.665500
Validation Loss: 0.60275143, Validation R2: 0.587864

Epoch 242/1000
Training Loss: 0.50476978, Training R2: 0.665086
Validation Loss: 0.60212916, Validation R2: 0.589275

Epoch 243/1000
Training Loss: 0.49597643, Training R2: 0.671356
Validation Loss: 0.60421324, Validation R2: 0.589884

Epoch 244/1000
Training Loss: 0.49711719, Training R2: 0.671592
Validation Loss: 0.60238713, Validation R2: 0.595395

Epoch 245/1000
Training Loss: 0.50187942, Training R2: 0.669995
Validation Loss: 0.60544056, Validation R2: 0.593383

Epoch 246/1000
Training Loss: 0.49640907, Training R2: 0.671913
Validation Loss: 0.60685539, Validation R2: 0.588067

Epoch 247/1000
Training Loss: 0.49692125, Training R2: 0.672317
Validation Loss: 0.60731697, Validation R2: 0.585477

Epoch 248/1000
Training Loss: 0.49356813, Training R2: 0.673227
Validation Loss: 0.60888082, Validation R2: 0.585721

Epoch 249/1000
Training Loss: 0.49395980, Training R2: 0.673369
Validation Loss: 0.61191148, Validation R2: 0.586927

Epoch 250/1000
Training Loss: 0.49183447, Training R2: 0.674397
Validation Loss: 0.60951048, Validation R2: 0.590173

Epoch 251/1000
Training Loss: 0.49334434, Training R2: 0.673987
Validation Loss: 0.60885781, Validation R2: 0.591150

Epoch 252/1000
Training Loss: 0.49190576, Training R2: 0.674636
Validation Loss: 0.61158359, Validation R2: 0.591664

Epoch 253/1000
Training Loss: 0.49263318, Training R2: 0.674742
Validation Loss: 0.61000711, Validation R2: 0.592503

Epoch 254/1000
Training Loss: 0.48955689, Training R2: 0.674958
Validation Loss: 0.60972393, Validation R2: 0.590545

Epoch 255/1000
Training Loss: 0.48814201, Training R2: 0.675844
Validation Loss: 0.61020774, Validation R2: 0.588229

Epoch 256/1000
Training Loss: 0.48810386, Training R2: 0.676420
Validation Loss: 0.60862523, Validation R2: 0.587539

Epoch 257/1000
Training Loss: 0.48731548, Training R2: 0.676775
Validation Loss: 0.60646474, Validation R2: 0.589156

Epoch 258/1000
Training Loss: 0.48742788, Training R2: 0.676363
Validation Loss: 0.60561448, Validation R2: 0.590196

Epoch 259/1000
Epoch 00259: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 0.48843608, Training R2: 0.676315
Validation Loss: 0.60273057, Validation R2: 0.590929

Epoch 260/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/r2_curve_dipole.png
