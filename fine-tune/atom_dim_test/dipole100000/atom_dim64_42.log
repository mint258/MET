Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 100000, Training: 80000, Validation: 20000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 424387

Epoch 1/1000
Training Loss: 0.94282649, Training R2: 0.259131
Validation Loss: 0.82290662, Validation R2: 0.400575
Saved best model with validation R2 0.400575 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 0.80810943, Training R2: 0.416930
Validation Loss: 0.77717777, Validation R2: 0.450863
Saved best model with validation R2 0.450863 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 0.76793502, Training R2: 0.461189
Validation Loss: 0.76462182, Validation R2: 0.475668
Saved best model with validation R2 0.475668 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 0.74079674, Training R2: 0.489298
Validation Loss: 0.78438130, Validation R2: 0.466238

Epoch 5/1000
Training Loss: 0.72744136, Training R2: 0.504457
Validation Loss: 0.72403468, Validation R2: 0.519611
Saved best model with validation R2 0.519611 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 0.71308088, Training R2: 0.521009
Validation Loss: 0.72628938, Validation R2: 0.510795

Epoch 7/1000
Training Loss: 0.70765127, Training R2: 0.527516
Validation Loss: 0.69280211, Validation R2: 0.548728
Saved best model with validation R2 0.548728 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 0.69510488, Training R2: 0.543765
Validation Loss: 0.69293255, Validation R2: 0.552460
Saved best model with validation R2 0.552460 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 0.68032912, Training R2: 0.563108
Validation Loss: 0.68172172, Validation R2: 0.569336
Saved best model with validation R2 0.569336 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.67394421, Training R2: 0.572667
Validation Loss: 0.66801808, Validation R2: 0.588263
Saved best model with validation R2 0.588263 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 0.66801208, Training R2: 0.582526
Validation Loss: 0.71486795, Validation R2: 0.543571

Epoch 12/1000
Training Loss: 0.66319342, Training R2: 0.590322
Validation Loss: 0.67085664, Validation R2: 0.597944
Saved best model with validation R2 0.597944 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 0.66217031, Training R2: 0.594917
Validation Loss: 0.66336879, Validation R2: 0.601918
Saved best model with validation R2 0.601918 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 0.65335033, Training R2: 0.610730
Validation Loss: 0.64733471, Validation R2: 0.627508
Saved best model with validation R2 0.627508 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 0.64608871, Training R2: 0.624939
Validation Loss: 0.65580377, Validation R2: 0.626174

Epoch 16/1000
Training Loss: 0.64096481, Training R2: 0.638887
Validation Loss: 0.64988514, Validation R2: 0.637308
Saved best model with validation R2 0.637308 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.64013309, Training R2: 0.642332
Validation Loss: 0.64086846, Validation R2: 0.644312
Saved best model with validation R2 0.644312 to best_finetuned_model.pth

Epoch 18/1000
Training Loss: 0.63105627, Training R2: 0.651566
Validation Loss: 0.66150737, Validation R2: 0.638556

Epoch 19/1000
Training Loss: 0.62647164, Training R2: 0.658811
Validation Loss: 0.62441572, Validation R2: 0.659627
Saved best model with validation R2 0.659627 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 0.62696204, Training R2: 0.657008
Validation Loss: 0.62199479, Validation R2: 0.662933
Saved best model with validation R2 0.662933 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.62189423, Training R2: 0.663760
Validation Loss: 0.64557988, Validation R2: 0.648606

Epoch 22/1000
Training Loss: 0.61766742, Training R2: 0.668037
Validation Loss: 0.63878775, Validation R2: 0.648787

Epoch 23/1000
Training Loss: 0.61509544, Training R2: 0.670119
Validation Loss: 0.65362779, Validation R2: 0.623815

Epoch 24/1000
Training Loss: 0.60977042, Training R2: 0.675037
Validation Loss: 0.62344944, Validation R2: 0.661958

Epoch 25/1000
Training Loss: 0.60342678, Training R2: 0.681950
Validation Loss: 0.61634166, Validation R2: 0.673378
Saved best model with validation R2 0.673378 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 0.60114939, Training R2: 0.685686
Validation Loss: 0.60671772, Validation R2: 0.683164
Saved best model with validation R2 0.683164 to best_finetuned_model.pth

Epoch 27/1000
Training Loss: 0.60263082, Training R2: 0.684897
Validation Loss: 0.63329233, Validation R2: 0.652575

Epoch 28/1000
Training Loss: 0.59591612, Training R2: 0.691093
Validation Loss: 0.59489200, Validation R2: 0.693122
Saved best model with validation R2 0.693122 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 0.59283741, Training R2: 0.694420
Validation Loss: 0.61271888, Validation R2: 0.675275

Epoch 30/1000
Training Loss: 0.58910794, Training R2: 0.697637
Validation Loss: 0.62884411, Validation R2: 0.661598

Epoch 31/1000
Training Loss: 0.58887261, Training R2: 0.698903
Validation Loss: 0.59494635, Validation R2: 0.696599
Saved best model with validation R2 0.696599 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 0.58650624, Training R2: 0.700552
Validation Loss: 0.59373621, Validation R2: 0.698122
Saved best model with validation R2 0.698122 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 0.58126348, Training R2: 0.706736
Validation Loss: 0.59386683, Validation R2: 0.693839

Epoch 34/1000
Training Loss: 0.58192144, Training R2: 0.705975
Validation Loss: 0.58273183, Validation R2: 0.706163
Saved best model with validation R2 0.706163 to best_finetuned_model.pth

Epoch 35/1000
Training Loss: 0.58108708, Training R2: 0.707932
Validation Loss: 0.59115154, Validation R2: 0.692836

Epoch 36/1000
Training Loss: 0.57396267, Training R2: 0.713693
Validation Loss: 0.60152831, Validation R2: 0.687220

Epoch 37/1000
Training Loss: 0.57306602, Training R2: 0.714775
Validation Loss: 0.57458810, Validation R2: 0.712764
Saved best model with validation R2 0.712764 to best_finetuned_model.pth

Epoch 38/1000
Training Loss: 0.56908528, Training R2: 0.718347
Validation Loss: 0.57977562, Validation R2: 0.710766

Epoch 39/1000
Training Loss: 0.56798085, Training R2: 0.719307
Validation Loss: 0.58208345, Validation R2: 0.708819

Epoch 40/1000
Training Loss: 0.55968969, Training R2: 0.727377
Validation Loss: 0.57274609, Validation R2: 0.714083
Saved best model with validation R2 0.714083 to best_finetuned_model.pth

Epoch 41/1000
Training Loss: 0.55871671, Training R2: 0.727265
Validation Loss: 0.57195155, Validation R2: 0.718909
Saved best model with validation R2 0.718909 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 0.56148934, Training R2: 0.725445
Validation Loss: 0.61961943, Validation R2: 0.682661

Epoch 43/1000
Training Loss: 0.55717555, Training R2: 0.729517
Validation Loss: 0.58107827, Validation R2: 0.709683

Epoch 44/1000
Training Loss: 0.55001213, Training R2: 0.735482
Validation Loss: 0.56186086, Validation R2: 0.723723
Saved best model with validation R2 0.723723 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.54657923, Training R2: 0.738738
Validation Loss: 0.55782163, Validation R2: 0.728531
Saved best model with validation R2 0.728531 to best_finetuned_model.pth

Epoch 46/1000
Training Loss: 0.55120430, Training R2: 0.734506
Validation Loss: 0.56287135, Validation R2: 0.725797

Epoch 47/1000
Training Loss: 0.54292242, Training R2: 0.740793
Validation Loss: 0.56104025, Validation R2: 0.723655

Epoch 48/1000
Training Loss: 0.54491588, Training R2: 0.739579
Validation Loss: 0.55495544, Validation R2: 0.731442
Saved best model with validation R2 0.731442 to best_finetuned_model.pth

Epoch 49/1000
Training Loss: 0.54230577, Training R2: 0.742165
Validation Loss: 0.56148261, Validation R2: 0.727116

Epoch 50/1000
Training Loss: 0.53912515, Training R2: 0.743986
Validation Loss: 0.56563249, Validation R2: 0.718470

Epoch 51/1000
Training Loss: 0.53695059, Training R2: 0.746690
Validation Loss: 0.55227238, Validation R2: 0.731278

Epoch 52/1000
Training Loss: 0.53418510, Training R2: 0.749442
Validation Loss: 0.56437397, Validation R2: 0.722831

Epoch 53/1000
Training Loss: 0.53143272, Training R2: 0.751437
Validation Loss: 0.55610116, Validation R2: 0.733230
Saved best model with validation R2 0.733230 to best_finetuned_model.pth

Epoch 54/1000
Training Loss: 0.53078000, Training R2: 0.751203
Validation Loss: 0.56136759, Validation R2: 0.724312

Epoch 55/1000
Training Loss: 0.52926961, Training R2: 0.753291
Validation Loss: 0.55198025, Validation R2: 0.728234

Epoch 56/1000
Training Loss: 0.52427631, Training R2: 0.757044
Validation Loss: 0.54581128, Validation R2: 0.736384
Saved best model with validation R2 0.736384 to best_finetuned_model.pth

Epoch 57/1000
Training Loss: 0.52645809, Training R2: 0.756018
Validation Loss: 0.54218814, Validation R2: 0.739468
Saved best model with validation R2 0.739468 to best_finetuned_model.pth

Epoch 58/1000
Training Loss: 0.51967045, Training R2: 0.760273
Validation Loss: 0.54362677, Validation R2: 0.738295

Epoch 59/1000
Training Loss: 0.51819041, Training R2: 0.762153
Validation Loss: 0.53960362, Validation R2: 0.744450
Saved best model with validation R2 0.744450 to best_finetuned_model.pth

Epoch 60/1000
Training Loss: 0.51704250, Training R2: 0.762778
Validation Loss: 0.54180950, Validation R2: 0.742435

Epoch 61/1000
Training Loss: 0.51692029, Training R2: 0.762871
Validation Loss: 0.54468529, Validation R2: 0.740142

Epoch 62/1000
Training Loss: 0.51049894, Training R2: 0.768637
Validation Loss: 0.53873503, Validation R2: 0.744748
Saved best model with validation R2 0.744748 to best_finetuned_model.pth

Epoch 63/1000
Training Loss: 0.51183554, Training R2: 0.767232
Validation Loss: 0.53624421, Validation R2: 0.744268

Epoch 64/1000
Training Loss: 0.50981762, Training R2: 0.769084
Validation Loss: 0.54244010, Validation R2: 0.741660

Epoch 65/1000
Training Loss: 0.51319476, Training R2: 0.767309
Validation Loss: 0.56014103, Validation R2: 0.729744

Epoch 66/1000
Training Loss: 0.50687159, Training R2: 0.770879
Validation Loss: 0.53267014, Validation R2: 0.745739
Saved best model with validation R2 0.745739 to best_finetuned_model.pth

Epoch 67/1000
Training Loss: 0.50222610, Training R2: 0.774530
Validation Loss: 0.53234303, Validation R2: 0.746542
Saved best model with validation R2 0.746542 to best_finetuned_model.pth

Epoch 68/1000
Training Loss: 0.49869553, Training R2: 0.776817
Validation Loss: 0.54492625, Validation R2: 0.734518

Epoch 69/1000
Training Loss: 0.50243779, Training R2: 0.774921
Validation Loss: 0.54079829, Validation R2: 0.742995

Epoch 70/1000
Training Loss: 0.50390077, Training R2: 0.773431
Validation Loss: 0.53775919, Validation R2: 0.742476

Epoch 71/1000
Training Loss: 0.49574695, Training R2: 0.779309
Validation Loss: 0.55146757, Validation R2: 0.731017

Epoch 72/1000
Training Loss: 0.49973770, Training R2: 0.776887
Validation Loss: 0.53948099, Validation R2: 0.737016

Epoch 73/1000
Training Loss: 0.49117322, Training R2: 0.782815
Validation Loss: 0.52628154, Validation R2: 0.752792
Saved best model with validation R2 0.752792 to best_finetuned_model.pth

Epoch 74/1000
Training Loss: 0.48956480, Training R2: 0.785217
Validation Loss: 0.54180548, Validation R2: 0.739997

Epoch 75/1000
Training Loss: 0.48858255, Training R2: 0.785400
Validation Loss: 0.52807639, Validation R2: 0.752822
Saved best model with validation R2 0.752822 to best_finetuned_model.pth

Epoch 76/1000
Training Loss: 0.48961784, Training R2: 0.784741
Validation Loss: 0.53919927, Validation R2: 0.740293

Epoch 77/1000
Training Loss: 0.48425109, Training R2: 0.788636
Validation Loss: 0.52544064, Validation R2: 0.751955

Epoch 78/1000
Training Loss: 0.48186444, Training R2: 0.790581
Validation Loss: 0.53234856, Validation R2: 0.741431

Epoch 79/1000
Training Loss: 0.48158133, Training R2: 0.790669
Validation Loss: 0.53140042, Validation R2: 0.749589

Epoch 80/1000
Training Loss: 0.47932858, Training R2: 0.792584
Validation Loss: 0.54668406, Validation R2: 0.728187

Epoch 81/1000
Training Loss: 0.47740542, Training R2: 0.794048
Validation Loss: 0.52259523, Validation R2: 0.752936
Saved best model with validation R2 0.752936 to best_finetuned_model.pth

Epoch 82/1000
Training Loss: 0.47493913, Training R2: 0.795620
Validation Loss: 0.52442758, Validation R2: 0.749858

Epoch 83/1000
Training Loss: 0.47313983, Training R2: 0.797167
Validation Loss: 0.52207542, Validation R2: 0.753097
Saved best model with validation R2 0.753097 to best_finetuned_model.pth

Epoch 84/1000
Training Loss: 0.47510946, Training R2: 0.796063
Validation Loss: 0.52211508, Validation R2: 0.754984
Saved best model with validation R2 0.754984 to best_finetuned_model.pth

Epoch 85/1000
Training Loss: 0.47081253, Training R2: 0.798943
Validation Loss: 0.52588457, Validation R2: 0.750843

Epoch 86/1000
Training Loss: 0.46911667, Training R2: 0.800348
Validation Loss: 0.53411521, Validation R2: 0.746758

Epoch 87/1000
Training Loss: 0.46949439, Training R2: 0.800272
Validation Loss: 0.53419313, Validation R2: 0.740795

Epoch 88/1000
Training Loss: 0.46640026, Training R2: 0.802292
Validation Loss: 0.51898544, Validation R2: 0.756458
Saved best model with validation R2 0.756458 to best_finetuned_model.pth

Epoch 89/1000
Training Loss: 0.46739630, Training R2: 0.801740
Validation Loss: 0.52971571, Validation R2: 0.749970

Epoch 90/1000
Training Loss: 0.46048104, Training R2: 0.806061
Validation Loss: 0.52701455, Validation R2: 0.749498

Epoch 91/1000
Training Loss: 0.46098305, Training R2: 0.806097
Validation Loss: 0.51404585, Validation R2: 0.761741
Saved best model with validation R2 0.761741 to best_finetuned_model.pth

Epoch 92/1000
Training Loss: 0.45811068, Training R2: 0.808517
Validation Loss: 0.52118934, Validation R2: 0.754110

Epoch 93/1000
Training Loss: 0.45679748, Training R2: 0.809659
Validation Loss: 0.52269807, Validation R2: 0.754865

Epoch 94/1000
Training Loss: 0.45739762, Training R2: 0.808819
Validation Loss: 0.52709770, Validation R2: 0.745381

Epoch 95/1000
Training Loss: 0.45360407, Training R2: 0.811608
Validation Loss: 0.51401935, Validation R2: 0.760583

Epoch 96/1000
Training Loss: 0.45052580, Training R2: 0.814096
Validation Loss: 0.51926538, Validation R2: 0.756808

Epoch 97/1000
Training Loss: 0.45237898, Training R2: 0.812737
Validation Loss: 0.53240486, Validation R2: 0.746884

Epoch 98/1000
Training Loss: 0.44729859, Training R2: 0.816192
Validation Loss: 0.53343069, Validation R2: 0.741340

Epoch 99/1000
Training Loss: 0.45179850, Training R2: 0.813478
Validation Loss: 0.52078218, Validation R2: 0.754845

Epoch 100/1000
Training Loss: 0.44399812, Training R2: 0.818446
Validation Loss: 0.51911665, Validation R2: 0.753521

Epoch 101/1000
Training Loss: 0.44422143, Training R2: 0.819192
Validation Loss: 0.51111433, Validation R2: 0.763779
Saved best model with validation R2 0.763779 to best_finetuned_model.pth

Epoch 102/1000
Training Loss: 0.44170343, Training R2: 0.820824
Validation Loss: 0.51974887, Validation R2: 0.752314

Epoch 103/1000
Training Loss: 0.44157244, Training R2: 0.820698
Validation Loss: 0.51387746, Validation R2: 0.763026

Epoch 104/1000
Training Loss: 0.44366050, Training R2: 0.819591
Validation Loss: 0.51539805, Validation R2: 0.760307

Epoch 105/1000
Training Loss: 0.43880630, Training R2: 0.822397
Validation Loss: 0.51688872, Validation R2: 0.757383

Epoch 106/1000
Training Loss: 0.43720681, Training R2: 0.823651
Validation Loss: 0.51490614, Validation R2: 0.761347

Epoch 107/1000
Training Loss: 0.43712081, Training R2: 0.824405
Validation Loss: 0.51521837, Validation R2: 0.758031

Epoch 108/1000
Training Loss: 0.43459316, Training R2: 0.825922
Validation Loss: 0.52267468, Validation R2: 0.753908

Epoch 109/1000
Training Loss: 0.43378450, Training R2: 0.826945
Validation Loss: 0.54324136, Validation R2: 0.733411

Epoch 110/1000
Training Loss: 0.43237390, Training R2: 0.827708
Validation Loss: 0.52157410, Validation R2: 0.756179

Epoch 111/1000
Training Loss: 0.42806626, Training R2: 0.830398
Validation Loss: 0.53358738, Validation R2: 0.744943

Epoch 112/1000
Training Loss: 0.42994805, Training R2: 0.829456
Validation Loss: 0.51737777, Validation R2: 0.757963

Epoch 113/1000
Training Loss: 0.42279111, Training R2: 0.833814
Validation Loss: 0.50964266, Validation R2: 0.764421
Saved best model with validation R2 0.764421 to best_finetuned_model.pth

Epoch 114/1000
Training Loss: 0.42406741, Training R2: 0.833889
Validation Loss: 0.51039969, Validation R2: 0.765544
Saved best model with validation R2 0.765544 to best_finetuned_model.pth

Epoch 115/1000
Training Loss: 0.42156892, Training R2: 0.835059
Validation Loss: 0.51201843, Validation R2: 0.758367

Epoch 116/1000
Training Loss: 0.41975193, Training R2: 0.836003
Validation Loss: 0.51442716, Validation R2: 0.756013

Epoch 117/1000
Training Loss: 0.42014959, Training R2: 0.836383
Validation Loss: 0.51669504, Validation R2: 0.759481

Epoch 118/1000
Training Loss: 0.41979381, Training R2: 0.836423
Validation Loss: 0.50796957, Validation R2: 0.763989

Epoch 119/1000
Training Loss: 0.41611308, Training R2: 0.838765
Validation Loss: 0.51261432, Validation R2: 0.759670

Epoch 120/1000
Training Loss: 0.41250046, Training R2: 0.841345
Validation Loss: 0.51633846, Validation R2: 0.757531

Epoch 121/1000
Training Loss: 0.41385489, Training R2: 0.840639
Validation Loss: 0.51249769, Validation R2: 0.762667

Epoch 122/1000
Training Loss: 0.41361525, Training R2: 0.840663
Validation Loss: 0.51472985, Validation R2: 0.759646

Epoch 123/1000
Training Loss: 0.40899437, Training R2: 0.844078
Validation Loss: 0.51298724, Validation R2: 0.763018

Epoch 124/1000
Training Loss: 0.40839197, Training R2: 0.844477
Validation Loss: 0.51302588, Validation R2: 0.759489

Epoch 125/1000
Training Loss: 0.40914154, Training R2: 0.843944
Validation Loss: 0.51138420, Validation R2: 0.762148

Epoch 126/1000
Training Loss: 0.40695651, Training R2: 0.845591
Validation Loss: 0.51055622, Validation R2: 0.763175

Epoch 127/1000
Training Loss: 0.40736589, Training R2: 0.845122
Validation Loss: 0.51170337, Validation R2: 0.762831

Epoch 128/1000
Training Loss: 0.40090710, Training R2: 0.849693
Validation Loss: 0.51136010, Validation R2: 0.759561

Epoch 129/1000
Training Loss: 0.39979816, Training R2: 0.850223
Validation Loss: 0.51565311, Validation R2: 0.762648

Epoch 130/1000
Training Loss: 0.39988078, Training R2: 0.849998
Validation Loss: 0.52853919, Validation R2: 0.742317

Epoch 131/1000
Training Loss: 0.39689405, Training R2: 0.852148
Validation Loss: 0.50649993, Validation R2: 0.765097

Epoch 132/1000
Training Loss: 0.39303280, Training R2: 0.854892
Validation Loss: 0.52954823, Validation R2: 0.750770

Epoch 133/1000
Training Loss: 0.39431022, Training R2: 0.854392
Validation Loss: 0.51732364, Validation R2: 0.758227

Epoch 134/1000
Training Loss: 0.39455287, Training R2: 0.854254
Validation Loss: 0.50740847, Validation R2: 0.764539

Epoch 135/1000
Epoch 00135: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.39498422, Training R2: 0.853768
Validation Loss: 0.50583077, Validation R2: 0.765055

Epoch 136/1000
学习率已减少 1 次
Training Loss: 0.36915354, Training R2: 0.868107
Validation Loss: 0.50293462, Validation R2: 0.766627
Saved best model with validation R2 0.766627 to best_finetuned_model.pth

Epoch 137/1000
Training Loss: 0.36480752, Training R2: 0.870284
Validation Loss: 0.50234355, Validation R2: 0.770248
Saved best model with validation R2 0.770248 to best_finetuned_model.pth

Epoch 138/1000
Training Loss: 0.36164192, Training R2: 0.871939
Validation Loss: 0.50418412, Validation R2: 0.766983

Epoch 139/1000
Training Loss: 0.36072701, Training R2: 0.872742
Validation Loss: 0.50343683, Validation R2: 0.767929

Epoch 140/1000
Training Loss: 0.35963513, Training R2: 0.873441
Validation Loss: 0.51005670, Validation R2: 0.766034

Epoch 141/1000
Training Loss: 0.35623160, Training R2: 0.875094
Validation Loss: 0.52176068, Validation R2: 0.756002

Epoch 142/1000
Training Loss: 0.35970282, Training R2: 0.873511
Validation Loss: 0.50549040, Validation R2: 0.766010

Epoch 143/1000
Training Loss: 0.35465796, Training R2: 0.876061
Validation Loss: 0.50714131, Validation R2: 0.765624

Epoch 144/1000
Training Loss: 0.35403761, Training R2: 0.876267
Validation Loss: 0.50568405, Validation R2: 0.765907

Epoch 145/1000
Training Loss: 0.35317273, Training R2: 0.876967
Validation Loss: 0.50149488, Validation R2: 0.770542
Saved best model with validation R2 0.770542 to best_finetuned_model.pth

Epoch 146/1000
Training Loss: 0.35129465, Training R2: 0.877990
Validation Loss: 0.50598107, Validation R2: 0.765773

Epoch 147/1000
Training Loss: 0.34994239, Training R2: 0.878955
Validation Loss: 0.50263607, Validation R2: 0.767176

Epoch 148/1000
Training Loss: 0.35080527, Training R2: 0.878574
Validation Loss: 0.50621410, Validation R2: 0.764794

Epoch 149/1000
Training Loss: 0.34852394, Training R2: 0.879707
Validation Loss: 0.50464842, Validation R2: 0.765163

Epoch 150/1000
Training Loss: 0.34570310, Training R2: 0.881364
Validation Loss: 0.50461658, Validation R2: 0.766763

Epoch 151/1000
Training Loss: 0.34715180, Training R2: 0.880886
Validation Loss: 0.51026929, Validation R2: 0.762070

Epoch 152/1000
Training Loss: 0.34555003, Training R2: 0.881818
Validation Loss: 0.50462934, Validation R2: 0.767759

Epoch 153/1000
Training Loss: 0.34289171, Training R2: 0.882623
Validation Loss: 0.51084009, Validation R2: 0.761262

Epoch 154/1000
Training Loss: 0.34391761, Training R2: 0.882724
Validation Loss: 0.51204369, Validation R2: 0.758432

Epoch 155/1000
Training Loss: 0.34385651, Training R2: 0.882709
Validation Loss: 0.50777623, Validation R2: 0.763001

Epoch 156/1000
Training Loss: 0.34018901, Training R2: 0.884234
Validation Loss: 0.51776304, Validation R2: 0.752922

Epoch 157/1000
Training Loss: 0.33960164, Training R2: 0.884770
Validation Loss: 0.50583041, Validation R2: 0.763208

Epoch 158/1000
Training Loss: 0.33977023, Training R2: 0.884914
Validation Loss: 0.50882058, Validation R2: 0.760774

Epoch 159/1000
Training Loss: 0.33584176, Training R2: 0.886422
Validation Loss: 0.50975037, Validation R2: 0.761686

Epoch 160/1000
Training Loss: 0.33656571, Training R2: 0.886449
Validation Loss: 0.50599575, Validation R2: 0.764923

Epoch 161/1000
Training Loss: 0.33467734, Training R2: 0.887615
Validation Loss: 0.50944224, Validation R2: 0.758847

Epoch 162/1000
Training Loss: 0.33368929, Training R2: 0.887928
Validation Loss: 0.50661145, Validation R2: 0.763524

Epoch 163/1000
Training Loss: 0.33217574, Training R2: 0.888603
Validation Loss: 0.51266471, Validation R2: 0.757148

Epoch 164/1000
Training Loss: 0.33326151, Training R2: 0.888451
Validation Loss: 0.51565814, Validation R2: 0.752788

Epoch 165/1000
Training Loss: 0.32978321, Training R2: 0.890250
Validation Loss: 0.51502939, Validation R2: 0.753852

Epoch 166/1000
Epoch 00166: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.32876719, Training R2: 0.890909
Validation Loss: 0.51483760, Validation R2: 0.753096

Epoch 167/1000
学习率已减少 2 次
Training Loss: 0.31521039, Training R2: 0.896186
Validation Loss: 0.51051790, Validation R2: 0.758237

Epoch 168/1000
Training Loss: 0.31234100, Training R2: 0.897250
Validation Loss: 0.50716273, Validation R2: 0.763450

Epoch 169/1000
Training Loss: 0.31138100, Training R2: 0.897744
Validation Loss: 0.50844811, Validation R2: 0.760047

Epoch 170/1000
Training Loss: 0.31131595, Training R2: 0.897707
Validation Loss: 0.50906498, Validation R2: 0.760556

Epoch 171/1000
Training Loss: 0.30939740, Training R2: 0.898462
Validation Loss: 0.51012727, Validation R2: 0.759592

Epoch 172/1000
Training Loss: 0.30910137, Training R2: 0.898846
Validation Loss: 0.50816664, Validation R2: 0.761568

Epoch 173/1000
Training Loss: 0.30998823, Training R2: 0.898615
Validation Loss: 0.50823140, Validation R2: 0.761128

Epoch 174/1000
Training Loss: 0.30754036, Training R2: 0.899801
Validation Loss: 0.50823171, Validation R2: 0.761994

Epoch 175/1000
Training Loss: 0.30542139, Training R2: 0.900385
Validation Loss: 0.51084495, Validation R2: 0.757599

Epoch 176/1000
Training Loss: 0.30587076, Training R2: 0.900100
Validation Loss: 0.51179161, Validation R2: 0.756466

Epoch 177/1000
Training Loss: 0.30463069, Training R2: 0.900741
Validation Loss: 0.51018587, Validation R2: 0.758903

Epoch 178/1000
Training Loss: 0.30389185, Training R2: 0.901358
Validation Loss: 0.50800851, Validation R2: 0.762016

Epoch 179/1000
Training Loss: 0.30539477, Training R2: 0.900741
Validation Loss: 0.50928556, Validation R2: 0.759877

Epoch 180/1000
Training Loss: 0.30252280, Training R2: 0.901783
Validation Loss: 0.51165204, Validation R2: 0.757320

Epoch 181/1000
Training Loss: 0.30187037, Training R2: 0.901968
Validation Loss: 0.50976395, Validation R2: 0.759210

Epoch 182/1000
Training Loss: 0.30141469, Training R2: 0.902387
Validation Loss: 0.51146735, Validation R2: 0.757619

Epoch 183/1000
Training Loss: 0.30148885, Training R2: 0.902415
Validation Loss: 0.51019588, Validation R2: 0.759152

Epoch 184/1000
Training Loss: 0.30059255, Training R2: 0.902837
Validation Loss: 0.51307037, Validation R2: 0.756769

Epoch 185/1000
Training Loss: 0.29946526, Training R2: 0.903303
Validation Loss: 0.51260766, Validation R2: 0.756118

Epoch 186/1000
Training Loss: 0.29850557, Training R2: 0.903756
Validation Loss: 0.51579066, Validation R2: 0.752344

Epoch 187/1000
Epoch 00187: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.29862227, Training R2: 0.903883
Validation Loss: 0.51209677, Validation R2: 0.755842

Epoch 188/1000
学习率已减少 3 次
Training Loss: 0.28931879, Training R2: 0.906793
Validation Loss: 0.50945470, Validation R2: 0.759816

Epoch 189/1000
Training Loss: 0.28774458, Training R2: 0.907125
Validation Loss: 0.51345635, Validation R2: 0.756041

Epoch 190/1000
Training Loss: 0.28727933, Training R2: 0.907408
Validation Loss: 0.51361461, Validation R2: 0.755839

Epoch 191/1000
Training Loss: 0.28724866, Training R2: 0.907454
Validation Loss: 0.51242737, Validation R2: 0.756464

Epoch 192/1000
Training Loss: 0.28624299, Training R2: 0.907774
Validation Loss: 0.51255677, Validation R2: 0.755823

Epoch 193/1000
Training Loss: 0.28594710, Training R2: 0.907880
Validation Loss: 0.51239458, Validation R2: 0.756091

Epoch 194/1000
Training Loss: 0.28539875, Training R2: 0.908096
Validation Loss: 0.51285160, Validation R2: 0.755092

Epoch 195/1000
Training Loss: 0.28549613, Training R2: 0.908191
Validation Loss: 0.51312579, Validation R2: 0.755457

Epoch 196/1000
Training Loss: 0.28383648, Training R2: 0.908707
Validation Loss: 0.51304287, Validation R2: 0.755345

Epoch 197/1000
Training Loss: 0.28437417, Training R2: 0.908594
Validation Loss: 0.51306270, Validation R2: 0.755814

Epoch 198/1000
Training Loss: 0.28367382, Training R2: 0.908779
Validation Loss: 0.51241818, Validation R2: 0.755613

Epoch 199/1000
Training Loss: 0.28326648, Training R2: 0.908994
Validation Loss: 0.51297158, Validation R2: 0.754850

Epoch 200/1000
Training Loss: 0.28340650, Training R2: 0.909082
Validation Loss: 0.51322352, Validation R2: 0.754750

Epoch 201/1000
Training Loss: 0.28229701, Training R2: 0.909443
Validation Loss: 0.51215764, Validation R2: 0.756336

Epoch 202/1000
Training Loss: 0.28209727, Training R2: 0.909518
Validation Loss: 0.51248965, Validation R2: 0.756158

Epoch 203/1000
Training Loss: 0.28218124, Training R2: 0.909525
Validation Loss: 0.51399607, Validation R2: 0.753640

Epoch 204/1000
Training Loss: 0.28145532, Training R2: 0.909788
Validation Loss: 0.51456654, Validation R2: 0.753975

Epoch 205/1000
Training Loss: 0.28033449, Training R2: 0.910161
Validation Loss: 0.51498605, Validation R2: 0.753364

Epoch 206/1000
Training Loss: 0.27984792, Training R2: 0.910439
Validation Loss: 0.51428022, Validation R2: 0.753905

Epoch 207/1000
Training Loss: 0.28012714, Training R2: 0.910319
Validation Loss: 0.51510631, Validation R2: 0.751961

Epoch 208/1000
Epoch 00208: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.27976114, Training R2: 0.910371
Validation Loss: 0.51401307, Validation R2: 0.754323

Epoch 209/1000
学习率已减少 4 次
Training Loss: 0.27496764, Training R2: 0.911750
Validation Loss: 0.51380342, Validation R2: 0.753992

Epoch 210/1000
Training Loss: 0.27431087, Training R2: 0.911847
Validation Loss: 0.51401536, Validation R2: 0.753677

Epoch 211/1000
Training Loss: 0.27380646, Training R2: 0.911997
Validation Loss: 0.51425967, Validation R2: 0.753723

Epoch 212/1000
Training Loss: 0.27336085, Training R2: 0.912165
Validation Loss: 0.51464030, Validation R2: 0.753236

Epoch 213/1000
Training Loss: 0.27319033, Training R2: 0.912274
Validation Loss: 0.51597928, Validation R2: 0.751958

Epoch 214/1000
Training Loss: 0.27300950, Training R2: 0.912268
Validation Loss: 0.51416951, Validation R2: 0.753482

Epoch 215/1000
Training Loss: 0.27251096, Training R2: 0.912320
Validation Loss: 0.51467924, Validation R2: 0.753260

Epoch 216/1000
Training Loss: 0.27232864, Training R2: 0.912445
Validation Loss: 0.51518869, Validation R2: 0.752285

Epoch 217/1000
Training Loss: 0.27218813, Training R2: 0.912528
Validation Loss: 0.51510272, Validation R2: 0.752925

Epoch 218/1000
Training Loss: 0.27187592, Training R2: 0.912633
Validation Loss: 0.51482752, Validation R2: 0.752934

Epoch 219/1000
Training Loss: 0.27132330, Training R2: 0.912796
Validation Loss: 0.51502839, Validation R2: 0.753191

Epoch 220/1000
Training Loss: 0.27132940, Training R2: 0.912818
Validation Loss: 0.51631720, Validation R2: 0.751708

Epoch 221/1000
Training Loss: 0.27096474, Training R2: 0.912945
Validation Loss: 0.51567800, Validation R2: 0.752295

Epoch 222/1000
Training Loss: 0.27129301, Training R2: 0.912949
Validation Loss: 0.51683283, Validation R2: 0.750310

Epoch 223/1000
Training Loss: 0.27062698, Training R2: 0.913022
Validation Loss: 0.51537881, Validation R2: 0.752300

Epoch 224/1000
Training Loss: 0.27055206, Training R2: 0.913124
Validation Loss: 0.51583159, Validation R2: 0.751988

Epoch 225/1000
Training Loss: 0.27045798, Training R2: 0.913221
Validation Loss: 0.51570621, Validation R2: 0.751530

Epoch 226/1000
Training Loss: 0.27005603, Training R2: 0.913318
Validation Loss: 0.51567663, Validation R2: 0.752297

Epoch 227/1000
Training Loss: 0.26962484, Training R2: 0.913408
Validation Loss: 0.51594061, Validation R2: 0.752225

Epoch 228/1000
Training Loss: 0.26929804, Training R2: 0.913571
Validation Loss: 0.51522617, Validation R2: 0.752509

Epoch 229/1000
Epoch 00229: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.26939987, Training R2: 0.913528
Validation Loss: 0.51515048, Validation R2: 0.752445

Epoch 230/1000
学习率已减少 5 次
Training Loss: 0.26689024, Training R2: 0.914112
Validation Loss: 0.51599953, Validation R2: 0.751669

Epoch 231/1000
Training Loss: 0.26644823, Training R2: 0.914168
Validation Loss: 0.51677423, Validation R2: 0.750752

Epoch 232/1000
Training Loss: 0.26614859, Training R2: 0.914216
Validation Loss: 0.51553318, Validation R2: 0.752078

Epoch 233/1000
Training Loss: 0.26603098, Training R2: 0.914285
Validation Loss: 0.51737952, Validation R2: 0.749997

Epoch 234/1000
Training Loss: 0.26583591, Training R2: 0.914324
Validation Loss: 0.51557610, Validation R2: 0.752131

Epoch 235/1000
Training Loss: 0.26579598, Training R2: 0.914353
Validation Loss: 0.51566451, Validation R2: 0.752123

Epoch 236/1000
Training Loss: 0.26564525, Training R2: 0.914383
Validation Loss: 0.51543569, Validation R2: 0.751860

Epoch 237/1000
Training Loss: 0.26548437, Training R2: 0.914424
Validation Loss: 0.51590578, Validation R2: 0.751722

Epoch 238/1000
Training Loss: 0.26525041, Training R2: 0.914430
Validation Loss: 0.51711965, Validation R2: 0.750306

Epoch 239/1000
Training Loss: 0.26523921, Training R2: 0.914481
Validation Loss: 0.51673187, Validation R2: 0.750796

Epoch 240/1000
Training Loss: 0.26509468, Training R2: 0.914506
Validation Loss: 0.51659497, Validation R2: 0.750852

Epoch 241/1000
Training Loss: 0.26493168, Training R2: 0.914551
Validation Loss: 0.51596561, Validation R2: 0.751731

Epoch 242/1000
Training Loss: 0.26495294, Training R2: 0.914605
Validation Loss: 0.51674327, Validation R2: 0.750947

Epoch 243/1000
Training Loss: 0.26473354, Training R2: 0.914659
Validation Loss: 0.51637409, Validation R2: 0.751383

Epoch 244/1000
Training Loss: 0.26467888, Training R2: 0.914635
Validation Loss: 0.51724857, Validation R2: 0.750273

Epoch 245/1000
Training Loss: 0.26449794, Training R2: 0.914766
Validation Loss: 0.51626124, Validation R2: 0.751114

Epoch 246/1000
Training Loss: 0.26436191, Training R2: 0.914747
Validation Loss: 0.51650117, Validation R2: 0.750870

Epoch 247/1000
Training Loss: 0.26426396, Training R2: 0.914810
Validation Loss: 0.51664775, Validation R2: 0.750936

Epoch 248/1000
Training Loss: 0.26408260, Training R2: 0.914818
Validation Loss: 0.51629480, Validation R2: 0.751241

Epoch 249/1000
Training Loss: 0.26400911, Training R2: 0.914894
Validation Loss: 0.51591064, Validation R2: 0.751536

Epoch 250/1000
Epoch 00250: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.26384808, Training R2: 0.914921
Validation Loss: 0.51671846, Validation R2: 0.750778

Epoch 251/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
