Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 3820035

Epoch 1/1000
Training Loss: 4.00349508, Training R2: -10.408820
Validation Loss: 1.47281492, Validation R2: -0.204161
Saved best model with validation R2 -0.204161 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.24480986, Training R2: -0.259350
Validation Loss: 1.35095346, Validation R2: -0.067500
Saved best model with validation R2 -0.067500 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.27454832, Training R2: -0.215471
Validation Loss: 1.30556369, Validation R2: -0.206475

Epoch 4/1000
Training Loss: 1.18690073, Training R2: -0.246126
Validation Loss: 1.25584459, Validation R2: -0.000073
Saved best model with validation R2 -0.000073 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.13803794, Training R2: -0.002756
Validation Loss: 1.23186493, Validation R2: -0.037446

Epoch 6/1000
Training Loss: 1.12928474, Training R2: -0.092764
Validation Loss: 1.23169839, Validation R2: -0.027420

Epoch 7/1000
Training Loss: 1.11720712, Training R2: -0.017595
Validation Loss: 1.23202515, Validation R2: -0.039791

Epoch 8/1000
Training Loss: 1.11685035, Training R2: -0.060601
Validation Loss: 1.23570502, Validation R2: -0.055655

Epoch 9/1000
Training Loss: 1.12104449, Training R2: -0.058793
Validation Loss: 1.23240602, Validation R2: -0.017935

Epoch 10/1000
Training Loss: 1.11733737, Training R2: -0.038498
Validation Loss: 1.25947833, Validation R2: -0.115057

Epoch 11/1000
Training Loss: 1.14110516, Training R2: -0.130492
Validation Loss: 1.25413454, Validation R2: 0.000045
Saved best model with validation R2 0.000045 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.13442519, Training R2: -0.002830
Validation Loss: 1.23168337, Validation R2: -0.028860

Epoch 13/1000
Training Loss: 1.11975009, Training R2: -0.050464
Validation Loss: 1.23173141, Validation R2: -0.034658

Epoch 14/1000
Training Loss: 1.11445841, Training R2: -0.027438
Validation Loss: 1.26348007, Validation R2: -0.001902

Epoch 15/1000
Training Loss: 1.15805193, Training R2: -0.020644
Validation Loss: 1.23313558, Validation R2: -0.046185

Epoch 16/1000
Training Loss: 1.13081134, Training R2: -0.106769
Validation Loss: 1.23703539, Validation R2: -0.006141

Epoch 17/1000
Training Loss: 1.12806687, Training R2: -0.005192
Validation Loss: 1.23450601, Validation R2: -0.051961

Epoch 18/1000
Training Loss: 1.13213753, Training R2: -0.114943
Validation Loss: 1.24533463, Validation R2: -0.000728

Epoch 19/1000
Training Loss: 1.14685858, Training R2: -0.010138
Validation Loss: 1.23159683, Validation R2: -0.032928

Epoch 20/1000
Training Loss: 1.12340936, Training R2: -0.082511
Validation Loss: 1.24181199, Validation R2: -0.074364

Epoch 21/1000
Training Loss: 1.12949084, Training R2: -0.056078
Validation Loss: 1.23421681, Validation R2: -0.051067

Epoch 22/1000
Training Loss: 1.12894667, Training R2: -0.095735
Validation Loss: 1.23265016, Validation R2: -0.044402

Epoch 23/1000
Training Loss: 1.11692132, Training R2: -0.048050
Validation Loss: 1.23351645, Validation R2: -0.048557

Epoch 24/1000
Training Loss: 1.11734384, Training R2: -0.040000
Validation Loss: 1.23242748, Validation R2: -0.043946

Epoch 25/1000
Training Loss: 1.11776711, Training R2: -0.062310
Validation Loss: 1.24926412, Validation R2: -0.093167

Epoch 26/1000
Training Loss: 1.12370105, Training R2: -0.087514
Validation Loss: 1.23713744, Validation R2: -0.004712

Epoch 27/1000
Training Loss: 1.12183870, Training R2: -0.010002
Validation Loss: 1.23241806, Validation R2: -0.045770

Epoch 28/1000
Training Loss: 1.11531130, Training R2: -0.041440
Validation Loss: 1.23246264, Validation R2: -0.011792

Epoch 29/1000
Training Loss: 1.11771282, Training R2: -0.006353
Validation Loss: 1.23023629, Validation R2: -0.042241

Epoch 30/1000
Training Loss: 1.11435559, Training R2: -0.056909
Validation Loss: 1.22995889, Validation R2: -0.049472

Epoch 31/1000
Training Loss: 1.10656141, Training R2: -0.045334
Validation Loss: 1.21483743, Validation R2: 0.030391
Saved best model with validation R2 0.030391 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 1.14586120, Training R2: -0.088000
Validation Loss: 1.36733603, Validation R2: -0.075739

Epoch 33/1000
Training Loss: 1.16702417, Training R2: -0.050745
Validation Loss: 1.33628511, Validation R2: -0.258177

Epoch 34/1000
Training Loss: 1.15373271, Training R2: -0.123720
Validation Loss: 1.29795480, Validation R2: -0.023966

Epoch 35/1000
Training Loss: 1.14322687, Training R2: -0.038979
Validation Loss: 1.25047290, Validation R2: -0.096831

Epoch 36/1000
Training Loss: 1.10793489, Training R2: -0.030261
Validation Loss: 1.28270936, Validation R2: -0.010873

Epoch 37/1000
Training Loss: 1.13949453, Training R2: -0.005879
Validation Loss: 1.32774961, Validation R2: -0.247174

Epoch 38/1000
Training Loss: 1.18990811, Training R2: -0.254408
Validation Loss: 1.29840326, Validation R2: -0.021385

Epoch 39/1000
Training Loss: 1.17651339, Training R2: -0.046973
Validation Loss: 1.24345851, Validation R2: -0.078885

Epoch 40/1000
Training Loss: 1.17487637, Training R2: -0.218867
Validation Loss: 1.28380382, Validation R2: -0.011982

Epoch 41/1000
Training Loss: 1.23406808, Training R2: -0.138044
Validation Loss: 1.24378264, Validation R2: -0.001576

Epoch 42/1000
Training Loss: 1.13227031, Training R2: -0.089521
Validation Loss: 1.26477027, Validation R2: -0.125651

Epoch 43/1000
Training Loss: 1.14672576, Training R2: -0.085070
Validation Loss: 1.25452387, Validation R2: -0.000036

Epoch 44/1000
Training Loss: 1.13017900, Training R2: -0.018656
Validation Loss: 1.23247683, Validation R2: -0.042655

Epoch 45/1000
Training Loss: 1.11442432, Training R2: -0.027481
Validation Loss: 1.24388278, Validation R2: -0.001444

Epoch 46/1000
Training Loss: 1.13153236, Training R2: -0.001473
Validation Loss: 1.23837936, Validation R2: -0.004920

Epoch 47/1000
Training Loss: 1.11674775, Training R2: -0.008325
Validation Loss: 1.26601541, Validation R2: -0.128169

Epoch 48/1000
Training Loss: 1.14822259, Training R2: -0.164363
Validation Loss: 1.24691939, Validation R2: -0.000434

Epoch 49/1000
Training Loss: 1.15012912, Training R2: -0.015213
Validation Loss: 1.23346424, Validation R2: -0.014343

Epoch 50/1000
Training Loss: 1.14817805, Training R2: -0.127398
Validation Loss: 1.23202443, Validation R2: -0.020488

Epoch 51/1000
Training Loss: 1.14014086, Training R2: -0.016902
Validation Loss: 1.27390170, Validation R2: -0.006123

Epoch 52/1000
Epoch 00052: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 1.13413579, Training R2: -0.031885
Validation Loss: 1.30436862, Validation R2: -0.204041

Epoch 53/1000
学习率已减少 1 次
Training Loss: 1.17043702, Training R2: -0.217028
Validation Loss: 1.23316538, Validation R2: -0.014945

Epoch 54/1000
Training Loss: 1.12822673, Training R2: -0.005733
Validation Loss: 1.28234541, Validation R2: -0.010924

Epoch 55/1000
Training Loss: 1.14688023, Training R2: -0.011152
Validation Loss: 1.23301578, Validation R2: -0.045933

Epoch 56/1000
Training Loss: 1.13196378, Training R2: -0.109973
Validation Loss: 1.26373065, Validation R2: -0.123744

Epoch 57/1000
Training Loss: 1.12962857, Training R2: -0.089525
Validation Loss: 1.24640250, Validation R2: -0.000372

Epoch 58/1000
Training Loss: 1.13358460, Training R2: -0.001301
Validation Loss: 1.23410439, Validation R2: -0.012076

Epoch 59/1000
Training Loss: 1.11355092, Training R2: -0.034163
Validation Loss: 1.25408328, Validation R2: -0.103513

Epoch 60/1000
Training Loss: 1.12788185, Training R2: -0.113165
Validation Loss: 1.23148465, Validation R2: -0.029438

Epoch 61/1000
Training Loss: 1.12324563, Training R2: -0.015936
Validation Loss: 1.23983717, Validation R2: -0.003205

Epoch 62/1000
Training Loss: 1.11842426, Training R2: -0.007741
Validation Loss: 1.23999357, Validation R2: -0.069267

Epoch 63/1000
Training Loss: 1.12996889, Training R2: -0.119548
Validation Loss: 1.24166834, Validation R2: -0.074321

Epoch 64/1000
Training Loss: 1.11748008, Training R2: -0.053109
Validation Loss: 1.23536217, Validation R2: -0.008140

Epoch 65/1000
Training Loss: 1.11875023, Training R2: -0.005380
Validation Loss: 1.23306942, Validation R2: -0.047517

Epoch 66/1000
Training Loss: 1.11857338, Training R2: -0.084718
Validation Loss: 1.24433434, Validation R2: -0.081454

Epoch 67/1000
Training Loss: 1.11459113, Training R2: -0.067568
Validation Loss: 1.23887694, Validation R2: -0.002994

Epoch 68/1000
Training Loss: 1.12598616, Training R2: 0.004567
Validation Loss: 1.25262940, Validation R2: 0.001180

Epoch 69/1000
Training Loss: 1.13005599, Training R2: 0.000954
Validation Loss: 1.23074734, Validation R2: -0.022482

Epoch 70/1000
Training Loss: 1.12697698, Training R2: -0.074131
Validation Loss: 1.24786425, Validation R2: -0.090531

Epoch 71/1000
Training Loss: 1.12264977, Training R2: -0.083544
Validation Loss: 1.23009241, Validation R2: -0.015797

Epoch 72/1000
Training Loss: 1.11531404, Training R2: -0.012175
Validation Loss: 1.22872317, Validation R2: -0.025008

Epoch 73/1000
Epoch 00073: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 1.11573984, Training R2: -0.046950
Validation Loss: 1.23668647, Validation R2: -0.065700

Epoch 74/1000
学习率已减少 2 次
Training Loss: 1.11624431, Training R2: -0.075338
Validation Loss: 1.22936559, Validation R2: -0.044198

Epoch 75/1000
Training Loss: 1.11277153, Training R2: -0.034538
Validation Loss: 1.22721183, Validation R2: -0.008009

Epoch 76/1000
Training Loss: 1.11231173, Training R2: 0.000619
Validation Loss: 1.22961175, Validation R2: -0.005898

Epoch 77/1000
Training Loss: 1.11093343, Training R2: 0.005538
Validation Loss: 1.22544944, Validation R2: 0.002370

Epoch 78/1000
Training Loss: 1.10867647, Training R2: 0.010646
Validation Loss: 1.22000015, Validation R2: -0.013479

Epoch 79/1000
Training Loss: 1.10691525, Training R2: -0.042225
Validation Loss: 1.22780061, Validation R2: -0.059428

Epoch 80/1000
Training Loss: 1.10833286, Training R2: -0.059063
Validation Loss: 1.21165049, Validation R2: 0.016358

Epoch 81/1000
Training Loss: 1.09902935, Training R2: 0.025993
Validation Loss: 1.20524037, Validation R2: 0.037098
Saved best model with validation R2 0.037098 to best_finetuned_model.pth

Epoch 82/1000
Training Loss: 1.08554917, Training R2: 0.052953
Validation Loss: 1.19112527, Validation R2: 0.054808
Saved best model with validation R2 0.054808 to best_finetuned_model.pth

Epoch 83/1000
Training Loss: 1.05243028, Training R2: 0.082765
Validation Loss: 1.16490746, Validation R2: 0.036632

Epoch 84/1000
Training Loss: 1.08801106, Training R2: -0.034483
Validation Loss: 1.17180634, Validation R2: 0.093547
Saved best model with validation R2 0.093547 to best_finetuned_model.pth

Epoch 85/1000
Training Loss: 1.11223721, Training R2: 0.049788
Validation Loss: 1.23907495, Validation R2: 0.012463

Epoch 86/1000
Training Loss: 1.10838868, Training R2: 0.008153
Validation Loss: 1.23375976, Validation R2: -0.070813

Epoch 87/1000
Training Loss: 1.11673765, Training R2: -0.098473
Validation Loss: 1.20279467, Validation R2: -0.017971

Epoch 88/1000
Training Loss: 1.08578537, Training R2: 0.017571
Validation Loss: 1.18733168, Validation R2: 0.066779

Epoch 89/1000
Training Loss: 1.05766978, Training R2: 0.080487
Validation Loss: 1.17238164, Validation R2: 0.056337

Epoch 90/1000
Training Loss: 1.05782955, Training R2: 0.048181
Validation Loss: 1.17643142, Validation R2: 0.072528

Epoch 91/1000
Training Loss: 1.06859117, Training R2: 0.047122
Validation Loss: 1.22097766, Validation R2: 0.071871

Epoch 92/1000
Training Loss: 1.06871180, Training R2: 0.092431
Validation Loss: 1.13474059, Validation R2: 0.102091
Saved best model with validation R2 0.102091 to best_finetuned_model.pth

Epoch 93/1000
Training Loss: 1.03195008, Training R2: 0.128810
Validation Loss: 1.13359439, Validation R2: 0.089560

Epoch 94/1000
Training Loss: 1.02213635, Training R2: 0.115303
Validation Loss: 1.16265225, Validation R2: 0.132639
Saved best model with validation R2 0.132639 to best_finetuned_model.pth

Epoch 95/1000
Training Loss: 1.08114202, Training R2: 0.089270
Validation Loss: 1.14017081, Validation R2: 0.141335
Saved best model with validation R2 0.141335 to best_finetuned_model.pth

Epoch 96/1000
Training Loss: 1.05894001, Training R2: 0.105544
Validation Loss: 1.14466989, Validation R2: 0.086362

Epoch 97/1000
Training Loss: 1.02635342, Training R2: 0.141492
Validation Loss: 1.17276728, Validation R2: 0.118663

Epoch 98/1000
Training Loss: 1.04026592, Training R2: 0.145407
Validation Loss: 1.12130570, Validation R2: 0.097802

Epoch 99/1000
Training Loss: 0.99415469, Training R2: 0.138218
Validation Loss: 1.09401274, Validation R2: 0.155305
Saved best model with validation R2 0.155305 to best_finetuned_model.pth

Epoch 100/1000
Training Loss: 0.94903978, Training R2: 0.245111
Validation Loss: 1.10620809, Validation R2: 0.171066
Saved best model with validation R2 0.171066 to best_finetuned_model.pth

Epoch 101/1000
Training Loss: 0.96172847, Training R2: 0.223980
Validation Loss: 1.11231196, Validation R2: 0.100263

Epoch 102/1000
Training Loss: 0.97748011, Training R2: 0.176241
Validation Loss: 1.08031487, Validation R2: 0.151531

Epoch 103/1000
Training Loss: 1.00577183, Training R2: 0.113437
Validation Loss: 1.12740839, Validation R2: 0.173400
Saved best model with validation R2 0.173400 to best_finetuned_model.pth

Epoch 104/1000
Training Loss: 0.96417902, Training R2: 0.232379
Validation Loss: 1.07639396, Validation R2: 0.223711
Saved best model with validation R2 0.223711 to best_finetuned_model.pth

Epoch 105/1000
Training Loss: 0.90781502, Training R2: 0.304400
Validation Loss: 1.11877537, Validation R2: 0.182264

Epoch 106/1000
Training Loss: 0.94284350, Training R2: 0.247859
Validation Loss: 1.03895092, Validation R2: 0.227024
Saved best model with validation R2 0.227024 to best_finetuned_model.pth

Epoch 107/1000
Training Loss: 0.89519012, Training R2: 0.312535
Validation Loss: 1.06138086, Validation R2: 0.219051

Epoch 108/1000
Training Loss: 0.90049658, Training R2: 0.313275
Validation Loss: 1.08792329, Validation R2: 0.157601

Epoch 109/1000
Training Loss: 0.97395196, Training R2: 0.184120
Validation Loss: 1.15884662, Validation R2: 0.139755

Epoch 110/1000
Training Loss: 1.02621404, Training R2: 0.171162
Validation Loss: 1.10215890, Validation R2: 0.167832

Epoch 111/1000
Training Loss: 0.96243285, Training R2: 0.201608
Validation Loss: 1.10776222, Validation R2: 0.191374

Epoch 112/1000
Training Loss: 1.07367072, Training R2: 0.104670
Validation Loss: 1.13718975, Validation R2: 0.154252

Epoch 113/1000
Training Loss: 1.02400142, Training R2: 0.084586
Validation Loss: 1.12239993, Validation R2: 0.052778

Epoch 114/1000
Training Loss: 1.03599182, Training R2: 0.089901
Validation Loss: 1.21665418, Validation R2: 0.047836

Epoch 115/1000
Training Loss: 1.09071827, Training R2: 0.066510
Validation Loss: 1.19359934, Validation R2: 0.021069

Epoch 116/1000
Training Loss: 1.07102725, Training R2: 0.052655
Validation Loss: 1.17996347, Validation R2: 0.017310

Epoch 117/1000
Training Loss: 1.05139709, Training R2: 0.071615
Validation Loss: 1.13105941, Validation R2: 0.076091

Epoch 118/1000
Training Loss: 1.00632943, Training R2: 0.131741
Validation Loss: 1.13054347, Validation R2: 0.140155

Epoch 119/1000
Training Loss: 0.98126703, Training R2: 0.190682
Validation Loss: 1.07534826, Validation R2: 0.180342

Epoch 120/1000
Training Loss: 0.95847878, Training R2: 0.210191
Validation Loss: 1.19042265, Validation R2: 0.107696

Epoch 121/1000
Training Loss: 0.98994259, Training R2: 0.164930
Validation Loss: 1.07779872, Validation R2: 0.131115

Epoch 122/1000
Training Loss: 0.98564643, Training R2: 0.141529
Validation Loss: 1.05340159, Validation R2: 0.206348

Epoch 123/1000
Training Loss: 0.92749293, Training R2: 0.264468
Validation Loss: 1.09061503, Validation R2: 0.159814

Epoch 124/1000
Training Loss: 0.93466822, Training R2: 0.236691
Validation Loss: 1.05274463, Validation R2: 0.221152

Epoch 125/1000
Training Loss: 0.90921605, Training R2: 0.281117
Validation Loss: 1.12724626, Validation R2: 0.165513

Epoch 126/1000
Training Loss: 1.00503759, Training R2: 0.178407
Validation Loss: 1.03467882, Validation R2: 0.218743

Epoch 127/1000
Epoch 00127: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 0.90450593, Training R2: 0.297928
Validation Loss: 1.03162491, Validation R2: 0.221650

Epoch 128/1000
学习率已减少 3 次
Training Loss: 0.88205313, Training R2: 0.302920
Validation Loss: 1.00267577, Validation R2: 0.240091
Saved best model with validation R2 0.240091 to best_finetuned_model.pth

Epoch 129/1000
Training Loss: 0.87281377, Training R2: 0.323008
Validation Loss: 1.01998138, Validation R2: 0.248266
Saved best model with validation R2 0.248266 to best_finetuned_model.pth

Epoch 130/1000
Training Loss: 0.86754893, Training R2: 0.334618
Validation Loss: 0.98383200, Validation R2: 0.267710
Saved best model with validation R2 0.267710 to best_finetuned_model.pth

Epoch 131/1000
Training Loss: 0.88656519, Training R2: 0.314553
Validation Loss: 1.03038454, Validation R2: 0.249471

Epoch 132/1000
Training Loss: 0.87396960, Training R2: 0.330666
Validation Loss: 0.98070830, Validation R2: 0.271298
Saved best model with validation R2 0.271298 to best_finetuned_model.pth

Epoch 133/1000
Training Loss: 0.86158132, Training R2: 0.341022
Validation Loss: 0.96741623, Validation R2: 0.274113
Saved best model with validation R2 0.274113 to best_finetuned_model.pth

Epoch 134/1000
Training Loss: 0.87722062, Training R2: 0.314738
Validation Loss: 1.04080629, Validation R2: 0.246234

Epoch 135/1000
Training Loss: 0.89301326, Training R2: 0.317541
Validation Loss: 0.97179860, Validation R2: 0.267273

Epoch 136/1000
Training Loss: 0.85969285, Training R2: 0.326086
Validation Loss: 0.98306316, Validation R2: 0.283514
Saved best model with validation R2 0.283514 to best_finetuned_model.pth

Epoch 137/1000
Training Loss: 0.83698153, Training R2: 0.370334
Validation Loss: 0.98961747, Validation R2: 0.284309
Saved best model with validation R2 0.284309 to best_finetuned_model.pth

Epoch 138/1000
Training Loss: 0.83002578, Training R2: 0.373305
Validation Loss: 0.96306580, Validation R2: 0.292269
Saved best model with validation R2 0.292269 to best_finetuned_model.pth

Epoch 139/1000
Training Loss: 0.83016686, Training R2: 0.373493
Validation Loss: 1.00232589, Validation R2: 0.277325

Epoch 140/1000
Training Loss: 0.82502899, Training R2: 0.376622
Validation Loss: 0.96675807, Validation R2: 0.296522
Saved best model with validation R2 0.296522 to best_finetuned_model.pth

Epoch 141/1000
Training Loss: 0.81136886, Training R2: 0.392971
Validation Loss: 0.96805233, Validation R2: 0.289849

Epoch 142/1000
Training Loss: 0.81928234, Training R2: 0.387357
Validation Loss: 0.98509151, Validation R2: 0.285998

Epoch 143/1000
Training Loss: 0.80727622, Training R2: 0.390308
Validation Loss: 0.94807643, Validation R2: 0.287870

Epoch 144/1000
Training Loss: 0.80073132, Training R2: 0.392479
Validation Loss: 0.94568938, Validation R2: 0.309088
Saved best model with validation R2 0.309088 to best_finetuned_model.pth

Epoch 145/1000
Training Loss: 0.79863973, Training R2: 0.407762
Validation Loss: 0.97824377, Validation R2: 0.292152

Epoch 146/1000
Training Loss: 0.79627595, Training R2: 0.407122
Validation Loss: 0.98275894, Validation R2: 0.233576

Epoch 147/1000
Training Loss: 0.84151672, Training R2: 0.338322
Validation Loss: 1.01124215, Validation R2: 0.276613

Epoch 148/1000
Training Loss: 0.82159348, Training R2: 0.385815
Validation Loss: 0.94698226, Validation R2: 0.319389
Saved best model with validation R2 0.319389 to best_finetuned_model.pth

Epoch 149/1000
Training Loss: 0.77738047, Training R2: 0.429019
Validation Loss: 0.93014950, Validation R2: 0.325696
Saved best model with validation R2 0.325696 to best_finetuned_model.pth

Epoch 150/1000
Training Loss: 0.78446124, Training R2: 0.411242
Validation Loss: 0.95215237, Validation R2: 0.309459

Epoch 151/1000
Training Loss: 0.79538687, Training R2: 0.396896
Validation Loss: 0.94969070, Validation R2: 0.272976

Epoch 152/1000
Training Loss: 0.81002033, Training R2: 0.376819
Validation Loss: 1.06166589, Validation R2: 0.234690

Epoch 153/1000
Training Loss: 0.87594141, Training R2: 0.336092
Validation Loss: 0.96941054, Validation R2: 0.249333

Epoch 154/1000
Training Loss: 0.81820269, Training R2: 0.360159
Validation Loss: 0.96213984, Validation R2: 0.308109

Epoch 155/1000
Training Loss: 0.78171952, Training R2: 0.421931
Validation Loss: 0.93210572, Validation R2: 0.312980

Epoch 156/1000
Training Loss: 0.76759977, Training R2: 0.428820
Validation Loss: 0.93781430, Validation R2: 0.311197

Epoch 157/1000
Training Loss: 0.76745960, Training R2: 0.432140
Validation Loss: 0.93818843, Validation R2: 0.317783

Epoch 158/1000
Training Loss: 0.76550557, Training R2: 0.439322
Validation Loss: 0.92471039, Validation R2: 0.310511

Epoch 159/1000
Training Loss: 0.76283528, Training R2: 0.433562
Validation Loss: 0.94400388, Validation R2: 0.312581

Epoch 160/1000
Training Loss: 0.76626628, Training R2: 0.436892
Validation Loss: 0.90522039, Validation R2: 0.328098
Saved best model with validation R2 0.328098 to best_finetuned_model.pth

Epoch 161/1000
Training Loss: 0.74769929, Training R2: 0.452032
Validation Loss: 0.90492445, Validation R2: 0.311178

Epoch 162/1000
Training Loss: 0.74931141, Training R2: 0.429684
Validation Loss: 0.91155785, Validation R2: 0.333718
Saved best model with validation R2 0.333718 to best_finetuned_model.pth

Epoch 163/1000
Training Loss: 0.74011255, Training R2: 0.453109
Validation Loss: 0.88482404, Validation R2: 0.323785

Epoch 164/1000
Training Loss: 0.72975337, Training R2: 0.448512
Validation Loss: 0.88309723, Validation R2: 0.345500
Saved best model with validation R2 0.345500 to best_finetuned_model.pth

Epoch 165/1000
Training Loss: 0.72007190, Training R2: 0.462411
Validation Loss: 0.88435286, Validation R2: 0.322051

Epoch 166/1000
Training Loss: 0.72389213, Training R2: 0.465118
Validation Loss: 0.87116516, Validation R2: 0.342313

Epoch 167/1000
Training Loss: 0.74256475, Training R2: 0.436217
Validation Loss: 0.94975394, Validation R2: 0.297292

Epoch 168/1000
Training Loss: 0.78539592, Training R2: 0.416953
Validation Loss: 0.93045706, Validation R2: 0.266232

Epoch 169/1000
Training Loss: 0.74451379, Training R2: 0.437261
Validation Loss: 1.00758100, Validation R2: 0.257978

Epoch 170/1000
Training Loss: 0.78786949, Training R2: 0.417288
Validation Loss: 0.96829534, Validation R2: 0.218921

Epoch 171/1000
Training Loss: 0.77653719, Training R2: 0.402175
Validation Loss: 0.88073540, Validation R2: 0.342351

Epoch 172/1000
Training Loss: 0.74454819, Training R2: 0.436525
Validation Loss: 0.85003734, Validation R2: 0.346400
Saved best model with validation R2 0.346400 to best_finetuned_model.pth

Epoch 173/1000
Training Loss: 0.74140326, Training R2: 0.446062
Validation Loss: 0.84963393, Validation R2: 0.337598

Epoch 174/1000
Training Loss: 0.72726988, Training R2: 0.458957
Validation Loss: 0.84897482, Validation R2: 0.347763
Saved best model with validation R2 0.347763 to best_finetuned_model.pth

Epoch 175/1000
Training Loss: 0.70538295, Training R2: 0.480376
Validation Loss: 0.84921372, Validation R2: 0.350568
Saved best model with validation R2 0.350568 to best_finetuned_model.pth

Epoch 176/1000
Training Loss: 0.70236186, Training R2: 0.490470
Validation Loss: 0.84001142, Validation R2: 0.339610

Epoch 177/1000
Training Loss: 0.70997078, Training R2: 0.475542
Validation Loss: 0.82854068, Validation R2: 0.358562
Saved best model with validation R2 0.358562 to best_finetuned_model.pth

Epoch 178/1000
Training Loss: 0.69514810, Training R2: 0.491337
Validation Loss: 0.82986647, Validation R2: 0.353867

Epoch 179/1000
Training Loss: 0.69570273, Training R2: 0.485735
Validation Loss: 0.81302708, Validation R2: 0.379950
Saved best model with validation R2 0.379950 to best_finetuned_model.pth

Epoch 180/1000
Training Loss: 0.68716251, Training R2: 0.498810
Validation Loss: 0.81423032, Validation R2: 0.377398

Epoch 181/1000
Training Loss: 0.68883328, Training R2: 0.506681
Validation Loss: 0.85734808, Validation R2: 0.330507

Epoch 182/1000
Training Loss: 0.73929023, Training R2: 0.447543
Validation Loss: 0.94623291, Validation R2: 0.310418

Epoch 183/1000
Training Loss: 0.77455026, Training R2: 0.433979
Validation Loss: 0.86888367, Validation R2: 0.294253

Epoch 184/1000
Training Loss: 0.74582133, Training R2: 0.426852
Validation Loss: 0.84972495, Validation R2: 0.367203

Epoch 185/1000
Training Loss: 0.71186180, Training R2: 0.493488
Validation Loss: 0.85694242, Validation R2: 0.362373

Epoch 186/1000
Training Loss: 0.73129471, Training R2: 0.457006
Validation Loss: 0.91173798, Validation R2: 0.328030

Epoch 187/1000
Training Loss: 0.75838258, Training R2: 0.453914
Validation Loss: 0.89396179, Validation R2: 0.279284

Epoch 188/1000
Training Loss: 0.76349550, Training R2: 0.397825
Validation Loss: 0.84427810, Validation R2: 0.336753

Epoch 189/1000
Training Loss: 0.72216124, Training R2: 0.481885
Validation Loss: 0.83190799, Validation R2: 0.320694

Epoch 190/1000
Training Loss: 0.72345709, Training R2: 0.453204
Validation Loss: 0.84763724, Validation R2: 0.319401

Epoch 191/1000
Training Loss: 0.72265436, Training R2: 0.461447
Validation Loss: 0.86948544, Validation R2: 0.262328

Epoch 192/1000
Training Loss: 0.73127794, Training R2: 0.431865
Validation Loss: 0.89506412, Validation R2: 0.262762

Epoch 193/1000
Training Loss: 0.77561291, Training R2: 0.412484
Validation Loss: 0.90916836, Validation R2: 0.244361

Epoch 194/1000
Training Loss: 0.74516671, Training R2: 0.387042
Validation Loss: 0.91813415, Validation R2: 0.220960

Epoch 195/1000
Training Loss: 0.74285423, Training R2: 0.412277
Validation Loss: 0.91101193, Validation R2: 0.225149

Epoch 196/1000
Training Loss: 0.72379295, Training R2: 0.421288
Validation Loss: 0.90212905, Validation R2: 0.238166

Epoch 197/1000
Training Loss: 0.70428499, Training R2: 0.453961
Validation Loss: 0.86268264, Validation R2: 0.333636

Epoch 198/1000
Training Loss: 0.70089804, Training R2: 0.477132
Validation Loss: 0.85325009, Validation R2: 0.355093

Epoch 199/1000
Training Loss: 0.71229774, Training R2: 0.489226
Validation Loss: 0.87268382, Validation R2: 0.369196

Epoch 200/1000
Training Loss: 0.71716542, Training R2: 0.481960
Validation Loss: 0.81462997, Validation R2: 0.385567
Saved best model with validation R2 0.385567 to best_finetuned_model.pth

Epoch 201/1000
Training Loss: 0.69293046, Training R2: 0.506122
Validation Loss: 0.80007488, Validation R2: 0.407833
Saved best model with validation R2 0.407833 to best_finetuned_model.pth

Epoch 202/1000
Training Loss: 0.67058546, Training R2: 0.526957
Validation Loss: 0.79930210, Validation R2: 0.392995

Epoch 203/1000
Training Loss: 0.67537257, Training R2: 0.520104
Validation Loss: 0.79418999, Validation R2: 0.400225

Epoch 204/1000
Training Loss: 0.66799717, Training R2: 0.527898
Validation Loss: 0.78097302, Validation R2: 0.408149
Saved best model with validation R2 0.408149 to best_finetuned_model.pth

Epoch 205/1000
Training Loss: 0.66035288, Training R2: 0.534361
Validation Loss: 0.78128731, Validation R2: 0.408926
Saved best model with validation R2 0.408926 to best_finetuned_model.pth

Epoch 206/1000
Training Loss: 0.65829740, Training R2: 0.532663
Validation Loss: 0.78686428, Validation R2: 0.403151

Epoch 207/1000
Training Loss: 0.65876887, Training R2: 0.534969
Validation Loss: 0.78949720, Validation R2: 0.395750

Epoch 208/1000
Training Loss: 0.66021106, Training R2: 0.535968
Validation Loss: 0.78257585, Validation R2: 0.403357

Epoch 209/1000
Training Loss: 0.65361908, Training R2: 0.539825
Validation Loss: 0.82843614, Validation R2: 0.356996

Epoch 210/1000
Training Loss: 0.70310496, Training R2: 0.490492
Validation Loss: 0.79902869, Validation R2: 0.391362

Epoch 211/1000
Training Loss: 0.65241425, Training R2: 0.545003
Validation Loss: 0.78720051, Validation R2: 0.398935

Epoch 212/1000
Training Loss: 0.65356197, Training R2: 0.545498
Validation Loss: 0.78483152, Validation R2: 0.408363

Epoch 213/1000
Training Loss: 0.64514051, Training R2: 0.552865
Validation Loss: 0.79908097, Validation R2: 0.400355

Epoch 214/1000
Training Loss: 0.65265164, Training R2: 0.546113
Validation Loss: 0.81630009, Validation R2: 0.379387

Epoch 215/1000
Training Loss: 0.68611943, Training R2: 0.519585
Validation Loss: 0.87399644, Validation R2: 0.357165

Epoch 216/1000
Training Loss: 0.74106763, Training R2: 0.454201
Validation Loss: 0.80366933, Validation R2: 0.374819

Epoch 217/1000
Training Loss: 0.67244714, Training R2: 0.527904
Validation Loss: 0.82444930, Validation R2: 0.364657

Epoch 218/1000
Training Loss: 0.68684584, Training R2: 0.510479
Validation Loss: 0.81200951, Validation R2: 0.356160

Epoch 219/1000
Training Loss: 0.66104865, Training R2: 0.520589
Validation Loss: 0.82520926, Validation R2: 0.344075

Epoch 220/1000
Training Loss: 0.66853346, Training R2: 0.510464
Validation Loss: 0.82680470, Validation R2: 0.345911

Epoch 221/1000
Training Loss: 0.65766207, Training R2: 0.517484
Validation Loss: 0.84302455, Validation R2: 0.321986

Epoch 222/1000
Training Loss: 0.67052386, Training R2: 0.501465
Validation Loss: 0.83191425, Validation R2: 0.363779

Epoch 223/1000
Training Loss: 0.65222883, Training R2: 0.527969
Validation Loss: 0.83776808, Validation R2: 0.344341

Epoch 224/1000
Training Loss: 0.66637508, Training R2: 0.513025
Validation Loss: 0.82771635, Validation R2: 0.385415

Epoch 225/1000
Training Loss: 0.66351328, Training R2: 0.523783
Validation Loss: 0.80532044, Validation R2: 0.380069

Epoch 226/1000
Epoch 00226: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 0.64235594, Training R2: 0.538135
Validation Loss: 0.81785870, Validation R2: 0.402113

Epoch 227/1000
学习率已减少 4 次
Training Loss: 0.65595820, Training R2: 0.540113
Validation Loss: 0.79187208, Validation R2: 0.405912

Epoch 228/1000
Training Loss: 0.64054444, Training R2: 0.552901
Validation Loss: 0.78882849, Validation R2: 0.415988
Saved best model with validation R2 0.415988 to best_finetuned_model.pth

Epoch 229/1000
Training Loss: 0.65641439, Training R2: 0.545887
Validation Loss: 0.80904961, Validation R2: 0.397199

Epoch 230/1000
Training Loss: 0.65906146, Training R2: 0.531612
Validation Loss: 0.81339812, Validation R2: 0.387384

Epoch 231/1000
Training Loss: 0.66642208, Training R2: 0.523094
Validation Loss: 0.83375835, Validation R2: 0.389782

Epoch 232/1000
Training Loss: 0.67402147, Training R2: 0.519662
Validation Loss: 0.83011460, Validation R2: 0.344803

Epoch 233/1000
Training Loss: 0.67564643, Training R2: 0.512373
Validation Loss: 0.81923658, Validation R2: 0.348887

Epoch 234/1000
Training Loss: 0.67251169, Training R2: 0.519052
Validation Loss: 0.82152694, Validation R2: 0.354745

Epoch 235/1000
Training Loss: 0.67642130, Training R2: 0.514046
Validation Loss: 0.83022213, Validation R2: 0.353222

Epoch 236/1000
Training Loss: 0.69016670, Training R2: 0.502448
Validation Loss: 0.83443069, Validation R2: 0.346730

Epoch 237/1000
Training Loss: 0.69484612, Training R2: 0.488499
Validation Loss: 0.83445770, Validation R2: 0.357337

Epoch 238/1000
Training Loss: 0.69492325, Training R2: 0.492248
Validation Loss: 0.82613659, Validation R2: 0.368433

Epoch 239/1000
Training Loss: 0.68616545, Training R2: 0.501008
Validation Loss: 0.81417751, Validation R2: 0.367368

Epoch 240/1000
Training Loss: 0.69371930, Training R2: 0.488679
Validation Loss: 0.81626111, Validation R2: 0.377699

Epoch 241/1000
Training Loss: 0.69460691, Training R2: 0.494689
Validation Loss: 0.82666850, Validation R2: 0.349528

Epoch 242/1000
Training Loss: 0.70583671, Training R2: 0.472557
Validation Loss: 0.82706481, Validation R2: 0.358547

Epoch 243/1000
Training Loss: 0.69642192, Training R2: 0.505407
Validation Loss: 0.81427747, Validation R2: 0.368553

Epoch 244/1000
Training Loss: 0.70076118, Training R2: 0.484977
Validation Loss: 0.81659025, Validation R2: 0.367375

Epoch 245/1000
Training Loss: 0.69543372, Training R2: 0.497909
Validation Loss: 0.82015824, Validation R2: 0.383644

Epoch 246/1000
Training Loss: 0.69027674, Training R2: 0.504848
Validation Loss: 0.82485032, Validation R2: 0.359752

Epoch 247/1000
Training Loss: 0.70075621, Training R2: 0.483663
Validation Loss: 0.82486522, Validation R2: 0.381175

Epoch 248/1000
Training Loss: 0.69735728, Training R2: 0.498512
Validation Loss: 0.81955999, Validation R2: 0.383702

Epoch 249/1000
Epoch 00249: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 0.69177840, Training R2: 0.504523
Validation Loss: 0.81591231, Validation R2: 0.372262

Epoch 250/1000
学习率已减少 5 次
Training Loss: 0.69487499, Training R2: 0.495507
Validation Loss: 0.81509382, Validation R2: 0.379128

Epoch 251/1000
Training Loss: 0.69337907, Training R2: 0.506123
Validation Loss: 0.83858609, Validation R2: 0.374069

Epoch 252/1000
Training Loss: 0.69420557, Training R2: 0.501520
Validation Loss: 0.81137860, Validation R2: 0.376103

Epoch 253/1000
Training Loss: 0.68424575, Training R2: 0.508364
Validation Loss: 0.81239307, Validation R2: 0.376302

Epoch 254/1000
Training Loss: 0.68193118, Training R2: 0.509994
Validation Loss: 0.81635892, Validation R2: 0.381136

Epoch 255/1000
Training Loss: 0.67999541, Training R2: 0.514618
Validation Loss: 0.80050170, Validation R2: 0.383646

Epoch 256/1000
Training Loss: 0.67403049, Training R2: 0.515674
Validation Loss: 0.79839581, Validation R2: 0.382831

Epoch 257/1000
Training Loss: 0.66590452, Training R2: 0.525076
Validation Loss: 0.80176741, Validation R2: 0.389231

Epoch 258/1000
Training Loss: 0.67572427, Training R2: 0.519659
Validation Loss: 0.79001081, Validation R2: 0.392049

Epoch 259/1000
Training Loss: 0.66564064, Training R2: 0.525458
Validation Loss: 0.80256313, Validation R2: 0.376789

Epoch 260/1000
Training Loss: 0.67695405, Training R2: 0.508314
Validation Loss: 0.79892892, Validation R2: 0.387187

Epoch 261/1000
Training Loss: 0.67481313, Training R2: 0.517588
Validation Loss: 0.80005974, Validation R2: 0.389864

Epoch 262/1000
Training Loss: 0.67150646, Training R2: 0.517240
Validation Loss: 0.81099606, Validation R2: 0.370478

Epoch 263/1000
Training Loss: 0.68643776, Training R2: 0.493377
Validation Loss: 0.80134201, Validation R2: 0.385479

Epoch 264/1000
Training Loss: 0.67324425, Training R2: 0.512828
Validation Loss: 0.80419326, Validation R2: 0.389873

Epoch 265/1000
Training Loss: 0.67158072, Training R2: 0.515851
Validation Loss: 0.79454046, Validation R2: 0.386093

Epoch 266/1000
Training Loss: 0.67583507, Training R2: 0.505566
Validation Loss: 0.79794478, Validation R2: 0.385417

Epoch 267/1000
Training Loss: 0.66835979, Training R2: 0.518499
Validation Loss: 0.80002767, Validation R2: 0.392639

Epoch 268/1000
Training Loss: 0.66632039, Training R2: 0.523314
Validation Loss: 0.79055828, Validation R2: 0.393631

Epoch 269/1000
Training Loss: 0.66341164, Training R2: 0.521233
Validation Loss: 0.79456466, Validation R2: 0.386421

Epoch 270/1000
Epoch 00270: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 0.66764290, Training R2: 0.514305
Validation Loss: 0.79305571, Validation R2: 0.392944

Epoch 271/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/r2_curve_dipole.png
