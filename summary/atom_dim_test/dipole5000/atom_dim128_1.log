Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.15825813, Training R2: 0.030806
Validation Loss: 1.07298975, Validation R2: 0.116085
Saved best model with validation R2 0.116085 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.08736745, Training R2: 0.126834
Validation Loss: 1.03877031, Validation R2: 0.181141
Saved best model with validation R2 0.181141 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.03754173, Training R2: 0.194627
Validation Loss: 0.99531169, Validation R2: 0.233973
Saved best model with validation R2 0.233973 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 0.98648869, Training R2: 0.257697
Validation Loss: 0.94794524, Validation R2: 0.312875
Saved best model with validation R2 0.312875 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 0.93434260, Training R2: 0.321621
Validation Loss: 0.90466983, Validation R2: 0.357041
Saved best model with validation R2 0.357041 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 0.93400127, Training R2: 0.330449
Validation Loss: 0.86691020, Validation R2: 0.406036
Saved best model with validation R2 0.406036 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 0.87359114, Training R2: 0.392090
Validation Loss: 0.87827106, Validation R2: 0.386590

Epoch 8/1000
Training Loss: 0.85728132, Training R2: 0.402847
Validation Loss: 0.83645954, Validation R2: 0.448999
Saved best model with validation R2 0.448999 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 0.85608558, Training R2: 0.408233
Validation Loss: 0.81857755, Validation R2: 0.463594
Saved best model with validation R2 0.463594 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.83900946, Training R2: 0.419010
Validation Loss: 0.81258922, Validation R2: 0.462297

Epoch 11/1000
Training Loss: 0.82125355, Training R2: 0.443002
Validation Loss: 0.80115526, Validation R2: 0.487199
Saved best model with validation R2 0.487199 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 0.81976992, Training R2: 0.445301
Validation Loss: 0.83714470, Validation R2: 0.421338

Epoch 13/1000
Training Loss: 0.81110072, Training R2: 0.444807
Validation Loss: 0.78579373, Validation R2: 0.502547
Saved best model with validation R2 0.502547 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 0.78532774, Training R2: 0.477554
Validation Loss: 0.75961966, Validation R2: 0.530626
Saved best model with validation R2 0.530626 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 0.79720223, Training R2: 0.458274
Validation Loss: 0.76515768, Validation R2: 0.525063

Epoch 16/1000
Training Loss: 0.78088121, Training R2: 0.476093
Validation Loss: 0.75200588, Validation R2: 0.535445
Saved best model with validation R2 0.535445 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.77785773, Training R2: 0.481103
Validation Loss: 0.74741074, Validation R2: 0.543389
Saved best model with validation R2 0.543389 to best_finetuned_model.pth

Epoch 18/1000
Training Loss: 0.74976616, Training R2: 0.508018
Validation Loss: 0.75118821, Validation R2: 0.539060

Epoch 19/1000
Training Loss: 0.75312140, Training R2: 0.500895
Validation Loss: 0.70889849, Validation R2: 0.569013
Saved best model with validation R2 0.569013 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 0.73990645, Training R2: 0.515218
Validation Loss: 0.71117263, Validation R2: 0.567291

Epoch 21/1000
Training Loss: 0.75541553, Training R2: 0.501611
Validation Loss: 0.74279502, Validation R2: 0.548451

Epoch 22/1000
Training Loss: 0.73425981, Training R2: 0.518853
Validation Loss: 0.71708388, Validation R2: 0.555277

Epoch 23/1000
Training Loss: 0.71451547, Training R2: 0.535742
Validation Loss: 0.70630817, Validation R2: 0.568334

Epoch 24/1000
Training Loss: 0.71700324, Training R2: 0.534421
Validation Loss: 0.78879043, Validation R2: 0.503002

Epoch 25/1000
Training Loss: 0.73950215, Training R2: 0.519003
Validation Loss: 0.73191041, Validation R2: 0.557158

Epoch 26/1000
Training Loss: 0.71071192, Training R2: 0.544766
Validation Loss: 0.70220269, Validation R2: 0.572010
Saved best model with validation R2 0.572010 to best_finetuned_model.pth

Epoch 27/1000
Training Loss: 0.70117725, Training R2: 0.550187
Validation Loss: 0.68419424, Validation R2: 0.588743
Saved best model with validation R2 0.588743 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 0.70105671, Training R2: 0.554607
Validation Loss: 0.68565358, Validation R2: 0.581214

Epoch 29/1000
Training Loss: 0.69080311, Training R2: 0.561378
Validation Loss: 0.67655779, Validation R2: 0.592793
Saved best model with validation R2 0.592793 to best_finetuned_model.pth

Epoch 30/1000
Training Loss: 0.68079652, Training R2: 0.570520
Validation Loss: 0.74286070, Validation R2: 0.547512

Epoch 31/1000
Training Loss: 0.71550874, Training R2: 0.543396
Validation Loss: 0.70495438, Validation R2: 0.583505

Epoch 32/1000
Training Loss: 0.69998869, Training R2: 0.560043
Validation Loss: 0.68097500, Validation R2: 0.591081

Epoch 33/1000
Training Loss: 0.71383553, Training R2: 0.546662
Validation Loss: 0.67232106, Validation R2: 0.597816
Saved best model with validation R2 0.597816 to best_finetuned_model.pth

Epoch 34/1000
Training Loss: 0.70071994, Training R2: 0.560627
Validation Loss: 0.67210339, Validation R2: 0.601527
Saved best model with validation R2 0.601527 to best_finetuned_model.pth

Epoch 35/1000
Training Loss: 0.68041293, Training R2: 0.576469
Validation Loss: 0.66914296, Validation R2: 0.601411

Epoch 36/1000
Training Loss: 0.66923461, Training R2: 0.588230
Validation Loss: 0.67416635, Validation R2: 0.601651
Saved best model with validation R2 0.601651 to best_finetuned_model.pth

Epoch 37/1000
Training Loss: 0.65837014, Training R2: 0.599086
Validation Loss: 0.65491673, Validation R2: 0.617361
Saved best model with validation R2 0.617361 to best_finetuned_model.pth

Epoch 38/1000
Training Loss: 0.66124486, Training R2: 0.591985
Validation Loss: 0.66665158, Validation R2: 0.619245
Saved best model with validation R2 0.619245 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.67112745, Training R2: 0.591060
Validation Loss: 0.64940641, Validation R2: 0.624146
Saved best model with validation R2 0.624146 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.65139069, Training R2: 0.608891
Validation Loss: 0.66002872, Validation R2: 0.621424

Epoch 41/1000
Training Loss: 0.64835281, Training R2: 0.612466
Validation Loss: 0.66671023, Validation R2: 0.614272

Epoch 42/1000
Training Loss: 0.65071022, Training R2: 0.610139
Validation Loss: 0.65829375, Validation R2: 0.617098

Epoch 43/1000
Training Loss: 0.64003019, Training R2: 0.621507
Validation Loss: 0.64076350, Validation R2: 0.633903
Saved best model with validation R2 0.633903 to best_finetuned_model.pth

Epoch 44/1000
Training Loss: 0.64816817, Training R2: 0.615470
Validation Loss: 0.63306313, Validation R2: 0.640716
Saved best model with validation R2 0.640716 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.65057540, Training R2: 0.618628
Validation Loss: 0.66143252, Validation R2: 0.617314

Epoch 46/1000
Training Loss: 0.66282702, Training R2: 0.606979
Validation Loss: 0.66448480, Validation R2: 0.605056

Epoch 47/1000
Training Loss: 0.64695164, Training R2: 0.618230
Validation Loss: 0.63212425, Validation R2: 0.638430

Epoch 48/1000
Training Loss: 0.62174860, Training R2: 0.640131
Validation Loss: 0.62540893, Validation R2: 0.650271
Saved best model with validation R2 0.650271 to best_finetuned_model.pth

Epoch 49/1000
Training Loss: 0.61581651, Training R2: 0.652402
Validation Loss: 0.62677721, Validation R2: 0.654064
Saved best model with validation R2 0.654064 to best_finetuned_model.pth

Epoch 50/1000
Training Loss: 0.62136973, Training R2: 0.648536
Validation Loss: 0.63195936, Validation R2: 0.652104

Epoch 51/1000
Training Loss: 0.61479917, Training R2: 0.652179
Validation Loss: 0.62509367, Validation R2: 0.654499
Saved best model with validation R2 0.654499 to best_finetuned_model.pth

Epoch 52/1000
Training Loss: 0.61494502, Training R2: 0.658481
Validation Loss: 0.62587831, Validation R2: 0.656811
Saved best model with validation R2 0.656811 to best_finetuned_model.pth

Epoch 53/1000
Training Loss: 0.59720247, Training R2: 0.670764
Validation Loss: 0.61834862, Validation R2: 0.657591
Saved best model with validation R2 0.657591 to best_finetuned_model.pth

Epoch 54/1000
Training Loss: 0.59460008, Training R2: 0.675031
Validation Loss: 0.63541902, Validation R2: 0.640277

Epoch 55/1000
Training Loss: 0.61223822, Training R2: 0.661563
Validation Loss: 0.63220743, Validation R2: 0.633649

Epoch 56/1000
Training Loss: 0.59695420, Training R2: 0.670841
Validation Loss: 0.60683797, Validation R2: 0.667581
Saved best model with validation R2 0.667581 to best_finetuned_model.pth

Epoch 57/1000
Training Loss: 0.58929985, Training R2: 0.680842
Validation Loss: 0.64684029, Validation R2: 0.630948

Epoch 58/1000
Training Loss: 0.59012913, Training R2: 0.679612
Validation Loss: 0.60613180, Validation R2: 0.664874

Epoch 59/1000
Training Loss: 0.58917774, Training R2: 0.687680
Validation Loss: 0.61670773, Validation R2: 0.661243

Epoch 60/1000
Training Loss: 0.59778814, Training R2: 0.679670
Validation Loss: 0.62573014, Validation R2: 0.656842

Epoch 61/1000
Training Loss: 0.60064720, Training R2: 0.680090
Validation Loss: 0.61911750, Validation R2: 0.657399

Epoch 62/1000
Training Loss: 0.59096540, Training R2: 0.686262
Validation Loss: 0.62134821, Validation R2: 0.665002

Epoch 63/1000
Training Loss: 0.57806098, Training R2: 0.697355
Validation Loss: 0.61314337, Validation R2: 0.662054

Epoch 64/1000
Training Loss: 0.56768762, Training R2: 0.708081
Validation Loss: 0.61050567, Validation R2: 0.667883
Saved best model with validation R2 0.667883 to best_finetuned_model.pth

Epoch 65/1000
Training Loss: 0.55590638, Training R2: 0.719928
Validation Loss: 0.61054368, Validation R2: 0.660824

Epoch 66/1000
Training Loss: 0.56910050, Training R2: 0.704671
Validation Loss: 0.61448945, Validation R2: 0.663614

Epoch 67/1000
Training Loss: 0.55466644, Training R2: 0.717956
Validation Loss: 0.60843035, Validation R2: 0.665520

Epoch 68/1000
Training Loss: 0.54304364, Training R2: 0.731289
Validation Loss: 0.60054423, Validation R2: 0.675344
Saved best model with validation R2 0.675344 to best_finetuned_model.pth

Epoch 69/1000
Training Loss: 0.57268759, Training R2: 0.706880
Validation Loss: 0.61566550, Validation R2: 0.662778

Epoch 70/1000
Training Loss: 0.56103882, Training R2: 0.714566
Validation Loss: 0.60503474, Validation R2: 0.661146

Epoch 71/1000
Training Loss: 0.57700458, Training R2: 0.708086
Validation Loss: 0.64291298, Validation R2: 0.635858

Epoch 72/1000
Training Loss: 0.59857745, Training R2: 0.685997
Validation Loss: 0.60624234, Validation R2: 0.654819

Epoch 73/1000
Training Loss: 0.58679245, Training R2: 0.692261
Validation Loss: 0.63008185, Validation R2: 0.638619

Epoch 74/1000
Training Loss: 0.56235104, Training R2: 0.720879
Validation Loss: 0.59218201, Validation R2: 0.677168
Saved best model with validation R2 0.677168 to best_finetuned_model.pth

Epoch 75/1000
Training Loss: 0.55223832, Training R2: 0.726000
Validation Loss: 0.59630958, Validation R2: 0.667079

Epoch 76/1000
Training Loss: 0.54865162, Training R2: 0.731806
Validation Loss: 0.62253230, Validation R2: 0.651166

Epoch 77/1000
Training Loss: 0.53364342, Training R2: 0.740902
Validation Loss: 0.58140825, Validation R2: 0.683420
Saved best model with validation R2 0.683420 to best_finetuned_model.pth

Epoch 78/1000
Training Loss: 0.52508314, Training R2: 0.747099
Validation Loss: 0.59419219, Validation R2: 0.672415

Epoch 79/1000
Training Loss: 0.52868111, Training R2: 0.744895
Validation Loss: 0.58389212, Validation R2: 0.686404
Saved best model with validation R2 0.686404 to best_finetuned_model.pth

Epoch 80/1000
Training Loss: 0.51862894, Training R2: 0.752688
Validation Loss: 0.59294201, Validation R2: 0.678591

Epoch 81/1000
Training Loss: 0.52806023, Training R2: 0.749085
Validation Loss: 0.65037866, Validation R2: 0.615794

Epoch 82/1000
Training Loss: 0.55066297, Training R2: 0.729104
Validation Loss: 0.58519146, Validation R2: 0.685614

Epoch 83/1000
Training Loss: 0.51720088, Training R2: 0.757264
Validation Loss: 0.64173812, Validation R2: 0.627319

Epoch 84/1000
Training Loss: 0.51688888, Training R2: 0.757425
Validation Loss: 0.59568004, Validation R2: 0.664467

Epoch 85/1000
Training Loss: 0.52203845, Training R2: 0.755532
Validation Loss: 0.58844841, Validation R2: 0.675504

Epoch 86/1000
Training Loss: 0.50338543, Training R2: 0.765451
Validation Loss: 0.58539767, Validation R2: 0.682573

Epoch 87/1000
Training Loss: 0.52350178, Training R2: 0.750569
Validation Loss: 0.65504133, Validation R2: 0.623405

Epoch 88/1000
Training Loss: 0.56493044, Training R2: 0.724195
Validation Loss: 0.63491336, Validation R2: 0.640966

Epoch 89/1000
Training Loss: 0.52217535, Training R2: 0.754305
Validation Loss: 0.60388262, Validation R2: 0.667333

Epoch 90/1000
Training Loss: 0.50503784, Training R2: 0.769486
Validation Loss: 0.59189540, Validation R2: 0.681957

Epoch 91/1000
Training Loss: 0.50477852, Training R2: 0.767925
Validation Loss: 0.60331569, Validation R2: 0.657391

Epoch 92/1000
Training Loss: 0.50766616, Training R2: 0.770401
Validation Loss: 0.58319026, Validation R2: 0.688770
Saved best model with validation R2 0.688770 to best_finetuned_model.pth

Epoch 93/1000
Training Loss: 0.49921378, Training R2: 0.773825
Validation Loss: 0.59008257, Validation R2: 0.686034

Epoch 94/1000
Training Loss: 0.49406734, Training R2: 0.775032
Validation Loss: 0.57479162, Validation R2: 0.694229
Saved best model with validation R2 0.694229 to best_finetuned_model.pth

Epoch 95/1000
Training Loss: 0.48185936, Training R2: 0.784564
Validation Loss: 0.57965713, Validation R2: 0.692187

Epoch 96/1000
Training Loss: 0.49517901, Training R2: 0.777741
Validation Loss: 0.59872529, Validation R2: 0.656176

Epoch 97/1000
Training Loss: 0.48576232, Training R2: 0.787995
Validation Loss: 0.57297897, Validation R2: 0.697653
Saved best model with validation R2 0.697653 to best_finetuned_model.pth

Epoch 98/1000
Training Loss: 0.48189717, Training R2: 0.790409
Validation Loss: 0.59159629, Validation R2: 0.675005

Epoch 99/1000
Training Loss: 0.48202165, Training R2: 0.788408
Validation Loss: 0.57072178, Validation R2: 0.692437

Epoch 100/1000
Training Loss: 0.50631048, Training R2: 0.774643
Validation Loss: 0.59187665, Validation R2: 0.674406

Epoch 101/1000
Training Loss: 0.47128720, Training R2: 0.796971
Validation Loss: 0.59068019, Validation R2: 0.679732

Epoch 102/1000
Training Loss: 0.46117436, Training R2: 0.798813
Validation Loss: 0.56554419, Validation R2: 0.701559
Saved best model with validation R2 0.701559 to best_finetuned_model.pth

Epoch 103/1000
Training Loss: 0.48087167, Training R2: 0.791284
Validation Loss: 0.59863440, Validation R2: 0.665942

Epoch 104/1000
Training Loss: 0.46574603, Training R2: 0.799387
Validation Loss: 0.57250014, Validation R2: 0.692708

Epoch 105/1000
Training Loss: 0.46596009, Training R2: 0.802398
Validation Loss: 0.57249128, Validation R2: 0.693707

Epoch 106/1000
Training Loss: 0.50099151, Training R2: 0.775467
Validation Loss: 0.56952402, Validation R2: 0.696296

Epoch 107/1000
Training Loss: 0.47768833, Training R2: 0.793944
Validation Loss: 0.57666696, Validation R2: 0.688725

Epoch 108/1000
Training Loss: 0.45972418, Training R2: 0.804326
Validation Loss: 0.56720848, Validation R2: 0.701937
Saved best model with validation R2 0.701937 to best_finetuned_model.pth

Epoch 109/1000
Training Loss: 0.45288506, Training R2: 0.808946
Validation Loss: 0.56583474, Validation R2: 0.697000

Epoch 110/1000
Training Loss: 0.46720421, Training R2: 0.798828
Validation Loss: 0.56422856, Validation R2: 0.709700
Saved best model with validation R2 0.709700 to best_finetuned_model.pth

Epoch 111/1000
Training Loss: 0.49228075, Training R2: 0.785277
Validation Loss: 0.56245499, Validation R2: 0.708350

Epoch 112/1000
Training Loss: 0.46021768, Training R2: 0.802670
Validation Loss: 0.57510706, Validation R2: 0.691926

Epoch 113/1000
Training Loss: 0.45000452, Training R2: 0.813559
Validation Loss: 0.58275729, Validation R2: 0.691733

Epoch 114/1000
Training Loss: 0.46891980, Training R2: 0.802924
Validation Loss: 0.57789261, Validation R2: 0.688954

Epoch 115/1000
Training Loss: 0.44256075, Training R2: 0.816897
Validation Loss: 0.58613674, Validation R2: 0.689428

Epoch 116/1000
Training Loss: 0.43738575, Training R2: 0.820633
Validation Loss: 0.55759128, Validation R2: 0.707910

Epoch 117/1000
Training Loss: 0.42951445, Training R2: 0.824320
Validation Loss: 0.56884418, Validation R2: 0.703187

Epoch 118/1000
Training Loss: 0.43302909, Training R2: 0.824245
Validation Loss: 0.57242638, Validation R2: 0.701280

Epoch 119/1000
Training Loss: 0.44330761, Training R2: 0.817541
Validation Loss: 0.56938247, Validation R2: 0.698664

Epoch 120/1000
Training Loss: 0.43667599, Training R2: 0.821790
Validation Loss: 0.57893029, Validation R2: 0.694784

Epoch 121/1000
Training Loss: 0.46464337, Training R2: 0.806253
Validation Loss: 0.66314214, Validation R2: 0.619058

Epoch 122/1000
Training Loss: 0.48158628, Training R2: 0.796248
Validation Loss: 0.58485185, Validation R2: 0.694111

Epoch 123/1000
Training Loss: 0.44782380, Training R2: 0.815590
Validation Loss: 0.56603170, Validation R2: 0.707269

Epoch 124/1000
Training Loss: 0.44851382, Training R2: 0.814449
Validation Loss: 0.57699330, Validation R2: 0.702455

Epoch 125/1000
Training Loss: 0.47769762, Training R2: 0.795528
Validation Loss: 0.56673830, Validation R2: 0.700821

Epoch 126/1000
Training Loss: 0.41654472, Training R2: 0.835029
Validation Loss: 0.58309199, Validation R2: 0.698794

Epoch 127/1000
Training Loss: 0.42897653, Training R2: 0.829598
Validation Loss: 0.58653524, Validation R2: 0.670550

Epoch 128/1000
Training Loss: 0.42719265, Training R2: 0.831225
Validation Loss: 0.56011227, Validation R2: 0.709155

Epoch 129/1000
Training Loss: 0.41328362, Training R2: 0.835522
Validation Loss: 0.55605865, Validation R2: 0.713752
Saved best model with validation R2 0.713752 to best_finetuned_model.pth

Epoch 130/1000
Training Loss: 0.40300214, Training R2: 0.845285
Validation Loss: 0.56520495, Validation R2: 0.706679

Epoch 131/1000
Training Loss: 0.39967615, Training R2: 0.845422
Validation Loss: 0.58411327, Validation R2: 0.683586

Epoch 132/1000
Training Loss: 0.41642856, Training R2: 0.837339
Validation Loss: 0.54844712, Validation R2: 0.714291
Saved best model with validation R2 0.714291 to best_finetuned_model.pth

Epoch 133/1000
Training Loss: 0.39187970, Training R2: 0.849013
Validation Loss: 0.56474190, Validation R2: 0.708253

Epoch 134/1000
Training Loss: 0.39411757, Training R2: 0.849668
Validation Loss: 0.54730816, Validation R2: 0.720162
Saved best model with validation R2 0.720162 to best_finetuned_model.pth

Epoch 135/1000
Training Loss: 0.39275218, Training R2: 0.848086
Validation Loss: 0.55683349, Validation R2: 0.713995

Epoch 136/1000
Training Loss: 0.38417010, Training R2: 0.853798
Validation Loss: 0.54772399, Validation R2: 0.721424
Saved best model with validation R2 0.721424 to best_finetuned_model.pth

Epoch 137/1000
Training Loss: 0.39193919, Training R2: 0.850467
Validation Loss: 0.54611633, Validation R2: 0.726200
Saved best model with validation R2 0.726200 to best_finetuned_model.pth

Epoch 138/1000
Training Loss: 0.37986500, Training R2: 0.856421
Validation Loss: 0.55543650, Validation R2: 0.717368

Epoch 139/1000
Training Loss: 0.38354069, Training R2: 0.854521
Validation Loss: 0.55472961, Validation R2: 0.711942

Epoch 140/1000
Training Loss: 0.38924701, Training R2: 0.853122
Validation Loss: 0.55081652, Validation R2: 0.721093

Epoch 141/1000
Training Loss: 0.39995595, Training R2: 0.846383
Validation Loss: 0.58930337, Validation R2: 0.689595

Epoch 142/1000
Training Loss: 0.39601427, Training R2: 0.852773
Validation Loss: 0.55046813, Validation R2: 0.726829
Saved best model with validation R2 0.726829 to best_finetuned_model.pth

Epoch 143/1000
Training Loss: 0.39219577, Training R2: 0.851539
Validation Loss: 0.55757572, Validation R2: 0.711670

Epoch 144/1000
Training Loss: 0.40469221, Training R2: 0.848257
Validation Loss: 0.55130392, Validation R2: 0.719500

Epoch 145/1000
Training Loss: 0.37807205, Training R2: 0.860641
Validation Loss: 0.53865490, Validation R2: 0.731302
Saved best model with validation R2 0.731302 to best_finetuned_model.pth

Epoch 146/1000
Training Loss: 0.38154099, Training R2: 0.857414
Validation Loss: 0.56991462, Validation R2: 0.707107

Epoch 147/1000
Training Loss: 0.37886348, Training R2: 0.861944
Validation Loss: 0.53600137, Validation R2: 0.727421

Epoch 148/1000
Training Loss: 0.37621297, Training R2: 0.863040
Validation Loss: 0.60736789, Validation R2: 0.658428

Epoch 149/1000
Training Loss: 0.40081040, Training R2: 0.849317
Validation Loss: 0.55528460, Validation R2: 0.708444

Epoch 150/1000
Training Loss: 0.37524909, Training R2: 0.862983
Validation Loss: 0.55116455, Validation R2: 0.712680

Epoch 151/1000
Training Loss: 0.38297619, Training R2: 0.860956
Validation Loss: 0.57363177, Validation R2: 0.694982

Epoch 152/1000
Training Loss: 0.38223942, Training R2: 0.861499
Validation Loss: 0.57247098, Validation R2: 0.708041

Epoch 153/1000
Training Loss: 0.37023871, Training R2: 0.865610
Validation Loss: 0.57813686, Validation R2: 0.687176

Epoch 154/1000
Training Loss: 0.39240182, Training R2: 0.853674
Validation Loss: 0.54454363, Validation R2: 0.724723

Epoch 155/1000
Training Loss: 0.37482153, Training R2: 0.864347
Validation Loss: 0.55405653, Validation R2: 0.715211

Epoch 156/1000
Training Loss: 0.36605929, Training R2: 0.870366
Validation Loss: 0.54405754, Validation R2: 0.724108

Epoch 157/1000
Training Loss: 0.36799178, Training R2: 0.868050
Validation Loss: 0.54445199, Validation R2: 0.722365

Epoch 158/1000
Training Loss: 0.34221200, Training R2: 0.877667
Validation Loss: 0.55989609, Validation R2: 0.707669

Epoch 159/1000
Training Loss: 0.35033376, Training R2: 0.877183
Validation Loss: 0.53679416, Validation R2: 0.726368

Epoch 160/1000
Training Loss: 0.35108617, Training R2: 0.877495
Validation Loss: 0.56378400, Validation R2: 0.704140

Epoch 161/1000
Training Loss: 0.35780989, Training R2: 0.874836
Validation Loss: 0.57816109, Validation R2: 0.686083

Epoch 162/1000
Training Loss: 0.39390398, Training R2: 0.857054
Validation Loss: 0.54720447, Validation R2: 0.721543

Epoch 163/1000
Training Loss: 0.36021885, Training R2: 0.871749
Validation Loss: 0.56429645, Validation R2: 0.702527

Epoch 164/1000
Training Loss: 0.38387850, Training R2: 0.862822
Validation Loss: 0.56158145, Validation R2: 0.709350

Epoch 165/1000
Training Loss: 0.35065487, Training R2: 0.878034
Validation Loss: 0.55365599, Validation R2: 0.715798

Epoch 166/1000
Epoch 00166: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.35302271, Training R2: 0.878759
Validation Loss: 0.55250720, Validation R2: 0.713685

Epoch 167/1000
学习率已减少 1 次
Training Loss: 0.32215762, Training R2: 0.890922
Validation Loss: 0.53582768, Validation R2: 0.730909

Epoch 168/1000
Training Loss: 0.30417142, Training R2: 0.896880
Validation Loss: 0.53547631, Validation R2: 0.729957

Epoch 169/1000
Training Loss: 0.30668154, Training R2: 0.896613
Validation Loss: 0.53192917, Validation R2: 0.735049
Saved best model with validation R2 0.735049 to best_finetuned_model.pth

Epoch 170/1000
Training Loss: 0.29621440, Training R2: 0.899778
Validation Loss: 0.53645396, Validation R2: 0.724723

Epoch 171/1000
Training Loss: 0.29972392, Training R2: 0.898087
Validation Loss: 0.53656767, Validation R2: 0.729663

Epoch 172/1000
Training Loss: 0.29590080, Training R2: 0.900724
Validation Loss: 0.55014260, Validation R2: 0.716017

Epoch 173/1000
Training Loss: 0.29394640, Training R2: 0.901455
Validation Loss: 0.54246784, Validation R2: 0.721788

Epoch 174/1000
Training Loss: 0.28938791, Training R2: 0.902874
Validation Loss: 0.53511662, Validation R2: 0.730851

Epoch 175/1000
Training Loss: 0.29438291, Training R2: 0.902423
Validation Loss: 0.53058340, Validation R2: 0.734882

Epoch 176/1000
Training Loss: 0.28550876, Training R2: 0.905889
Validation Loss: 0.53690520, Validation R2: 0.730619

Epoch 177/1000
Training Loss: 0.28922608, Training R2: 0.903501
Validation Loss: 0.54683393, Validation R2: 0.719189

Epoch 178/1000
Training Loss: 0.28871784, Training R2: 0.904452
Validation Loss: 0.53342441, Validation R2: 0.732462

Epoch 179/1000
Training Loss: 0.29259081, Training R2: 0.903486
Validation Loss: 0.54543030, Validation R2: 0.720943

Epoch 180/1000
Training Loss: 0.29126377, Training R2: 0.903292
Validation Loss: 0.55980610, Validation R2: 0.710301

Epoch 181/1000
Training Loss: 0.29078591, Training R2: 0.904524
Validation Loss: 0.53562976, Validation R2: 0.728799

Epoch 182/1000
Training Loss: 0.28675225, Training R2: 0.905936
Validation Loss: 0.54120356, Validation R2: 0.721948

Epoch 183/1000
Training Loss: 0.28877386, Training R2: 0.904414
Validation Loss: 0.55481697, Validation R2: 0.715659

Epoch 184/1000
Training Loss: 0.27899339, Training R2: 0.907981
Validation Loss: 0.53406794, Validation R2: 0.729979

Epoch 185/1000
Training Loss: 0.26976186, Training R2: 0.912297
Validation Loss: 0.54193304, Validation R2: 0.724971

Epoch 186/1000
Training Loss: 0.26827922, Training R2: 0.912147
Validation Loss: 0.54544120, Validation R2: 0.720401

Epoch 187/1000
Training Loss: 0.28035656, Training R2: 0.908814
Validation Loss: 0.54615378, Validation R2: 0.721576

Epoch 188/1000
Training Loss: 0.27656136, Training R2: 0.910913
Validation Loss: 0.54663172, Validation R2: 0.714752

Epoch 189/1000
Training Loss: 0.27829487, Training R2: 0.909307
Validation Loss: 0.54659014, Validation R2: 0.715216

Epoch 190/1000
Epoch 00190: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.27148514, Training R2: 0.913193
Validation Loss: 0.53866770, Validation R2: 0.725206

Epoch 191/1000
学习率已减少 2 次
Training Loss: 0.25745673, Training R2: 0.916286
Validation Loss: 0.53890090, Validation R2: 0.724541

Epoch 192/1000
Training Loss: 0.25595069, Training R2: 0.916782
Validation Loss: 0.53827055, Validation R2: 0.723421

Epoch 193/1000
Training Loss: 0.24821755, Training R2: 0.919118
Validation Loss: 0.53884395, Validation R2: 0.722904

Epoch 194/1000
Training Loss: 0.24623412, Training R2: 0.919160
Validation Loss: 0.53378600, Validation R2: 0.727611

Epoch 195/1000
Training Loss: 0.24602068, Training R2: 0.919680
Validation Loss: 0.53394901, Validation R2: 0.726953

Epoch 196/1000
Training Loss: 0.24490706, Training R2: 0.920425
Validation Loss: 0.53028975, Validation R2: 0.729062

Epoch 197/1000
Training Loss: 0.24273180, Training R2: 0.920829
Validation Loss: 0.53779460, Validation R2: 0.723390

Epoch 198/1000
Training Loss: 0.24212017, Training R2: 0.921544
Validation Loss: 0.53478138, Validation R2: 0.726874

Epoch 199/1000
Training Loss: 0.23992954, Training R2: 0.921516
Validation Loss: 0.54319463, Validation R2: 0.722048

Epoch 200/1000
Training Loss: 0.23858831, Training R2: 0.922440
Validation Loss: 0.53756015, Validation R2: 0.723164

Epoch 201/1000
Training Loss: 0.24493647, Training R2: 0.921466
Validation Loss: 0.53706670, Validation R2: 0.723957

Epoch 202/1000
Training Loss: 0.23856287, Training R2: 0.922213
Validation Loss: 0.53494164, Validation R2: 0.727032

Epoch 203/1000
Training Loss: 0.24553913, Training R2: 0.921847
Validation Loss: 0.53665060, Validation R2: 0.724974

Epoch 204/1000
Training Loss: 0.23866645, Training R2: 0.922903
Validation Loss: 0.53377999, Validation R2: 0.725525

Epoch 205/1000
Training Loss: 0.23690199, Training R2: 0.923308
Validation Loss: 0.53767995, Validation R2: 0.724444

Epoch 206/1000
Training Loss: 0.23059639, Training R2: 0.924858
Validation Loss: 0.53610554, Validation R2: 0.726658

Epoch 207/1000
Training Loss: 0.23264870, Training R2: 0.925326
Validation Loss: 0.53894942, Validation R2: 0.720374

Epoch 208/1000
Training Loss: 0.23298430, Training R2: 0.925011
Validation Loss: 0.53710272, Validation R2: 0.724642

Epoch 209/1000
Training Loss: 0.23315751, Training R2: 0.925416
Validation Loss: 0.53693729, Validation R2: 0.725239

Epoch 210/1000
Training Loss: 0.22669923, Training R2: 0.926624
Validation Loss: 0.53808157, Validation R2: 0.723682

Epoch 211/1000
Epoch 00211: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.22730512, Training R2: 0.926556
Validation Loss: 0.53945192, Validation R2: 0.720553

Epoch 212/1000
学习率已减少 3 次
Training Loss: 0.22190980, Training R2: 0.927977
Validation Loss: 0.53842864, Validation R2: 0.722446

Epoch 213/1000
Training Loss: 0.21936599, Training R2: 0.928652
Validation Loss: 0.53540579, Validation R2: 0.725735

Epoch 214/1000
Training Loss: 0.21508820, Training R2: 0.929331
Validation Loss: 0.53653368, Validation R2: 0.724364

Epoch 215/1000
Training Loss: 0.21489657, Training R2: 0.929230
Validation Loss: 0.53707650, Validation R2: 0.722163

Epoch 216/1000
Training Loss: 0.21562617, Training R2: 0.929408
Validation Loss: 0.53786433, Validation R2: 0.722388

Epoch 217/1000
Training Loss: 0.21368917, Training R2: 0.929693
Validation Loss: 0.53535815, Validation R2: 0.724115

Epoch 218/1000
Training Loss: 0.21421466, Training R2: 0.929963
Validation Loss: 0.53768574, Validation R2: 0.724396

Epoch 219/1000
Training Loss: 0.21515808, Training R2: 0.930134
Validation Loss: 0.53469711, Validation R2: 0.724591

Epoch 220/1000
Training Loss: 0.21184757, Training R2: 0.930675
Validation Loss: 0.53848651, Validation R2: 0.722731

Epoch 221/1000
Training Loss: 0.21011059, Training R2: 0.930555
Validation Loss: 0.53509422, Validation R2: 0.724129

Epoch 222/1000
Training Loss: 0.21181684, Training R2: 0.930700
Validation Loss: 0.53729628, Validation R2: 0.722726

Epoch 223/1000
Training Loss: 0.20963130, Training R2: 0.931205
Validation Loss: 0.53734508, Validation R2: 0.722464

Epoch 224/1000
Training Loss: 0.21081000, Training R2: 0.931206
Validation Loss: 0.53729284, Validation R2: 0.721037

Epoch 225/1000
Training Loss: 0.21156312, Training R2: 0.930769
Validation Loss: 0.53681813, Validation R2: 0.723766

Epoch 226/1000
Training Loss: 0.20995657, Training R2: 0.931872
Validation Loss: 0.53777036, Validation R2: 0.723752

Epoch 227/1000
Training Loss: 0.21128724, Training R2: 0.931522
Validation Loss: 0.53787686, Validation R2: 0.720515

Epoch 228/1000
Training Loss: 0.20983968, Training R2: 0.931459
Validation Loss: 0.53690195, Validation R2: 0.722291

Epoch 229/1000
Training Loss: 0.20697634, Training R2: 0.932078
Validation Loss: 0.53672495, Validation R2: 0.724582

Epoch 230/1000
Training Loss: 0.20881360, Training R2: 0.931992
Validation Loss: 0.53550496, Validation R2: 0.722891

Epoch 231/1000
Training Loss: 0.20755554, Training R2: 0.931842
Validation Loss: 0.54123069, Validation R2: 0.719376

Epoch 232/1000
Epoch 00232: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.20857232, Training R2: 0.932304
Validation Loss: 0.53696074, Validation R2: 0.723617

Epoch 233/1000
学习率已减少 4 次
Training Loss: 0.20420337, Training R2: 0.932868
Validation Loss: 0.53733309, Validation R2: 0.723165

Epoch 234/1000
Training Loss: 0.19937644, Training R2: 0.933866
Validation Loss: 0.53712476, Validation R2: 0.722749

Epoch 235/1000
Training Loss: 0.19891034, Training R2: 0.933668
Validation Loss: 0.53856442, Validation R2: 0.721637

Epoch 236/1000
Training Loss: 0.19855764, Training R2: 0.933876
Validation Loss: 0.53828925, Validation R2: 0.720775

Epoch 237/1000
Training Loss: 0.19808221, Training R2: 0.933815
Validation Loss: 0.53598875, Validation R2: 0.722543

Epoch 238/1000
Training Loss: 0.19758929, Training R2: 0.934006
Validation Loss: 0.53732954, Validation R2: 0.722112

Epoch 239/1000
Training Loss: 0.19913427, Training R2: 0.933842
Validation Loss: 0.53820379, Validation R2: 0.721404

Epoch 240/1000
Training Loss: 0.19796641, Training R2: 0.934312
Validation Loss: 0.53859314, Validation R2: 0.721112

Epoch 241/1000
Training Loss: 0.19823170, Training R2: 0.934319
Validation Loss: 0.53850364, Validation R2: 0.720824

Epoch 242/1000
Training Loss: 0.19751043, Training R2: 0.934199
Validation Loss: 0.53926684, Validation R2: 0.720763

Epoch 243/1000
Training Loss: 0.20071209, Training R2: 0.934131
Validation Loss: 0.54024922, Validation R2: 0.721105

Epoch 244/1000
Training Loss: 0.19942693, Training R2: 0.934167
Validation Loss: 0.53813725, Validation R2: 0.721409

Epoch 245/1000
Training Loss: 0.19556430, Training R2: 0.934748
Validation Loss: 0.53762748, Validation R2: 0.721385

Epoch 246/1000
Training Loss: 0.19632910, Training R2: 0.934584
Validation Loss: 0.53538793, Validation R2: 0.723186

Epoch 247/1000
Training Loss: 0.19532463, Training R2: 0.934663
Validation Loss: 0.53876913, Validation R2: 0.721049

Epoch 248/1000
Training Loss: 0.19498860, Training R2: 0.934993
Validation Loss: 0.53806726, Validation R2: 0.720589

Epoch 249/1000
Training Loss: 0.19488859, Training R2: 0.935125
Validation Loss: 0.53770446, Validation R2: 0.722219

Epoch 250/1000
Training Loss: 0.19452276, Training R2: 0.934966
Validation Loss: 0.53723662, Validation R2: 0.722012

Epoch 251/1000
Training Loss: 0.19544555, Training R2: 0.934830
Validation Loss: 0.53730841, Validation R2: 0.722812

Epoch 252/1000
Training Loss: 0.19511953, Training R2: 0.934877
Validation Loss: 0.53756604, Validation R2: 0.721287

Epoch 253/1000
Epoch 00253: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.19379088, Training R2: 0.935233
Validation Loss: 0.53634659, Validation R2: 0.722921

Epoch 254/1000
学习率已减少 5 次
Training Loss: 0.19168762, Training R2: 0.935634
Validation Loss: 0.53710032, Validation R2: 0.721954

Epoch 255/1000
Training Loss: 0.19095695, Training R2: 0.935666
Validation Loss: 0.53698953, Validation R2: 0.721610

Epoch 256/1000
Training Loss: 0.19087259, Training R2: 0.935818
Validation Loss: 0.53771205, Validation R2: 0.721063

Epoch 257/1000
Training Loss: 0.19116575, Training R2: 0.935745
Validation Loss: 0.53692062, Validation R2: 0.722021

Epoch 258/1000
Training Loss: 0.19039208, Training R2: 0.935936
Validation Loss: 0.53666645, Validation R2: 0.722100

Epoch 259/1000
Training Loss: 0.19000566, Training R2: 0.935827
Validation Loss: 0.53815608, Validation R2: 0.721125

Epoch 260/1000
Training Loss: 0.18982549, Training R2: 0.935783
Validation Loss: 0.53695499, Validation R2: 0.722363

Epoch 261/1000
Training Loss: 0.18892989, Training R2: 0.935996
Validation Loss: 0.53871834, Validation R2: 0.720666

Epoch 262/1000
Training Loss: 0.18948021, Training R2: 0.935929
Validation Loss: 0.53724420, Validation R2: 0.721519

Epoch 263/1000
Training Loss: 0.18890354, Training R2: 0.935998
Validation Loss: 0.53789108, Validation R2: 0.720968

Epoch 264/1000
Training Loss: 0.18880982, Training R2: 0.936029
Validation Loss: 0.53742466, Validation R2: 0.721352

Epoch 265/1000
Training Loss: 0.18862910, Training R2: 0.936107
Validation Loss: 0.53884786, Validation R2: 0.720513

Epoch 266/1000
Training Loss: 0.19115922, Training R2: 0.935985
Validation Loss: 0.53767299, Validation R2: 0.720874

Epoch 267/1000
Training Loss: 0.19006094, Training R2: 0.936071
Validation Loss: 0.53701660, Validation R2: 0.721511

Epoch 268/1000
Training Loss: 0.18894736, Training R2: 0.936218
Validation Loss: 0.53745883, Validation R2: 0.721941

Epoch 269/1000
Training Loss: 0.18838121, Training R2: 0.936315
Validation Loss: 0.53803026, Validation R2: 0.720706

Epoch 270/1000
Training Loss: 0.18822917, Training R2: 0.936372
Validation Loss: 0.53779893, Validation R2: 0.721055

Epoch 271/1000
Training Loss: 0.18774969, Training R2: 0.936433
Validation Loss: 0.53815599, Validation R2: 0.721238

Epoch 272/1000
Training Loss: 0.18779464, Training R2: 0.936492
Validation Loss: 0.53785158, Validation R2: 0.721013

Epoch 273/1000
Training Loss: 0.18792497, Training R2: 0.936435
Validation Loss: 0.53734048, Validation R2: 0.721282

Epoch 274/1000
Epoch 00274: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.18740976, Training R2: 0.936497
Validation Loss: 0.53745396, Validation R2: 0.721522

Epoch 275/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
