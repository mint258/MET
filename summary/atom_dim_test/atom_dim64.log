Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 291843

Epoch 1/1000
Training Loss: 2.26259967, Training R2: -2.634714
Validation Loss: 1.25964701, Validation R2: -0.212511
Saved best model with validation R2 -0.212511 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.32399202, Training R2: -0.207045
Validation Loss: 1.09615159, Validation R2: -0.047176
Saved best model with validation R2 -0.047176 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.16252588, Training R2: -0.079271
Validation Loss: 1.10313237, Validation R2: -0.104195

Epoch 4/1000
Training Loss: 1.14889918, Training R2: -0.018647
Validation Loss: 1.08992577, Validation R2: -0.029837
Saved best model with validation R2 -0.029837 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.13855811, Training R2: -0.021946
Validation Loss: 1.09514344, Validation R2: -0.115088

Epoch 6/1000
Training Loss: 1.13003666, Training R2: -0.018109
Validation Loss: 1.06471360, Validation R2: 0.010568
Saved best model with validation R2 0.010568 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 1.10436172, Training R2: 0.031137
Validation Loss: 1.05196595, Validation R2: -0.038924

Epoch 8/1000
Training Loss: 1.06843521, Training R2: 0.081171
Validation Loss: 1.20076132, Validation R2: -0.235506

Epoch 9/1000
Training Loss: 1.14663603, Training R2: 0.013670
Validation Loss: 1.08745873, Validation R2: 0.057089
Saved best model with validation R2 0.057089 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 1.09433081, Training R2: 0.079575
Validation Loss: 1.10405993, Validation R2: -0.147007

Epoch 11/1000
Training Loss: 1.06911832, Training R2: 0.066721
Validation Loss: 1.03253341, Validation R2: 0.108499
Saved best model with validation R2 0.108499 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.05623505, Training R2: 0.138998
Validation Loss: 1.05133820, Validation R2: 0.033566

Epoch 13/1000
Training Loss: 1.02725157, Training R2: 0.139996
Validation Loss: 0.97581643, Validation R2: 0.187245
Saved best model with validation R2 0.187245 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 0.99963691, Training R2: 0.175566
Validation Loss: 1.00099921, Validation R2: 0.161939

Epoch 15/1000
Training Loss: 1.08154203, Training R2: 0.131549
Validation Loss: 1.02295136, Validation R2: 0.017907

Epoch 16/1000
Training Loss: 1.02163161, Training R2: 0.129665
Validation Loss: 0.96821094, Validation R2: 0.177812

Epoch 17/1000
Training Loss: 1.00521791, Training R2: 0.159495
Validation Loss: 0.95447892, Validation R2: 0.206179
Saved best model with validation R2 0.206179 to best_finetuned_model.pth

Epoch 18/1000
Training Loss: 0.95509171, Training R2: 0.235649
Validation Loss: 0.93772346, Validation R2: 0.254186
Saved best model with validation R2 0.254186 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.96723824, Training R2: 0.243199
Validation Loss: 0.90215325, Validation R2: 0.242441

Epoch 20/1000
Training Loss: 0.90371642, Training R2: 0.282647
Validation Loss: 0.85309714, Validation R2: 0.315393
Saved best model with validation R2 0.315393 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.87068413, Training R2: 0.320191
Validation Loss: 0.92592496, Validation R2: 0.164380

Epoch 22/1000
Training Loss: 0.87835012, Training R2: 0.308857
Validation Loss: 0.85577530, Validation R2: 0.311543

Epoch 23/1000
Training Loss: 0.84847619, Training R2: 0.344795
Validation Loss: 0.84525216, Validation R2: 0.308195

Epoch 24/1000
Training Loss: 0.85409430, Training R2: 0.343912
Validation Loss: 0.94324642, Validation R2: 0.245202

Epoch 25/1000
Training Loss: 0.88705872, Training R2: 0.320302
Validation Loss: 0.92990148, Validation R2: 0.162817

Epoch 26/1000
Training Loss: 0.85122189, Training R2: 0.360201
Validation Loss: 0.90790373, Validation R2: 0.201257

Epoch 27/1000
Training Loss: 0.84524997, Training R2: 0.336209
Validation Loss: 0.97171956, Validation R2: 0.218877

Epoch 28/1000
Training Loss: 0.89934169, Training R2: 0.316462
Validation Loss: 0.92731941, Validation R2: 0.176627

Epoch 29/1000
Training Loss: 0.84499584, Training R2: 0.368404
Validation Loss: 0.82628536, Validation R2: 0.347015
Saved best model with validation R2 0.347015 to best_finetuned_model.pth

Epoch 30/1000
Training Loss: 0.81703332, Training R2: 0.390882
Validation Loss: 0.81467462, Validation R2: 0.336788

Epoch 31/1000
Training Loss: 0.79300445, Training R2: 0.415359
Validation Loss: 0.82539535, Validation R2: 0.328771

Epoch 32/1000
Training Loss: 0.77590565, Training R2: 0.434756
Validation Loss: 0.83344632, Validation R2: 0.364194
Saved best model with validation R2 0.364194 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 0.78406259, Training R2: 0.418136
Validation Loss: 0.88380492, Validation R2: 0.222689

Epoch 34/1000
Training Loss: 0.79808507, Training R2: 0.409599
Validation Loss: 0.83184665, Validation R2: 0.336520

Epoch 35/1000
Training Loss: 0.76517949, Training R2: 0.423977
Validation Loss: 0.94108772, Validation R2: 0.222388

Epoch 36/1000
Training Loss: 0.82478436, Training R2: 0.407602
Validation Loss: 0.85161334, Validation R2: 0.275226

Epoch 37/1000
Training Loss: 0.80550972, Training R2: 0.409065
Validation Loss: 0.83489269, Validation R2: 0.300856

Epoch 38/1000
Training Loss: 0.83475780, Training R2: 0.345538
Validation Loss: 0.87644291, Validation R2: 0.324184

Epoch 39/1000
Training Loss: 0.85861372, Training R2: 0.366711
Validation Loss: 1.05746078, Validation R2: 0.008013

Epoch 40/1000
Training Loss: 0.95563079, Training R2: 0.236937
Validation Loss: 0.87268925, Validation R2: 0.346523

Epoch 41/1000
Training Loss: 0.93927077, Training R2: 0.320497
Validation Loss: 0.84136975, Validation R2: 0.310985

Epoch 42/1000
Training Loss: 0.89262260, Training R2: 0.252154
Validation Loss: 0.83120352, Validation R2: 0.316215

Epoch 43/1000
Training Loss: 0.78567010, Training R2: 0.429134
Validation Loss: 0.81515425, Validation R2: 0.403243
Saved best model with validation R2 0.403243 to best_finetuned_model.pth

Epoch 44/1000
Training Loss: 0.75287992, Training R2: 0.465173
Validation Loss: 0.80506301, Validation R2: 0.351787

Epoch 45/1000
Training Loss: 0.75670752, Training R2: 0.464756
Validation Loss: 0.79886514, Validation R2: 0.399127

Epoch 46/1000
Training Loss: 0.73108907, Training R2: 0.491008
Validation Loss: 0.83110684, Validation R2: 0.318537

Epoch 47/1000
Training Loss: 0.72442476, Training R2: 0.485358
Validation Loss: 0.81396270, Validation R2: 0.364832

Epoch 48/1000
Training Loss: 0.74656966, Training R2: 0.486407
Validation Loss: 0.77975988, Validation R2: 0.385619

Epoch 49/1000
Training Loss: 0.70738262, Training R2: 0.499396
Validation Loss: 0.77078819, Validation R2: 0.403794
Saved best model with validation R2 0.403794 to best_finetuned_model.pth

Epoch 50/1000
Training Loss: 0.67720186, Training R2: 0.531960
Validation Loss: 0.80444908, Validation R2: 0.353020

Epoch 51/1000
Training Loss: 0.69558061, Training R2: 0.489365
Validation Loss: 0.78364098, Validation R2: 0.389819

Epoch 52/1000
Training Loss: 0.67604350, Training R2: 0.527131
Validation Loss: 0.80383247, Validation R2: 0.345393

Epoch 53/1000
Training Loss: 0.67313254, Training R2: 0.510716
Validation Loss: 0.80962104, Validation R2: 0.375175

Epoch 54/1000
Training Loss: 0.72605568, Training R2: 0.487432
Validation Loss: 0.85766590, Validation R2: 0.276075

Epoch 55/1000
Training Loss: 0.71102454, Training R2: 0.467211
Validation Loss: 0.78621143, Validation R2: 0.398143

Epoch 56/1000
Training Loss: 0.68630617, Training R2: 0.499131
Validation Loss: 0.94114453, Validation R2: 0.191801

Epoch 57/1000
Training Loss: 0.88190346, Training R2: 0.296055
Validation Loss: 0.89549226, Validation R2: 0.252392

Epoch 58/1000
Training Loss: 0.81682035, Training R2: 0.381376
Validation Loss: 0.80849808, Validation R2: 0.408638
Saved best model with validation R2 0.408638 to best_finetuned_model.pth

Epoch 59/1000
Training Loss: 0.77646098, Training R2: 0.460897
Validation Loss: 0.73133892, Validation R2: 0.434054
Saved best model with validation R2 0.434054 to best_finetuned_model.pth

Epoch 60/1000
Training Loss: 0.71515030, Training R2: 0.503344
Validation Loss: 0.78112066, Validation R2: 0.393826

Epoch 61/1000
Training Loss: 0.69148455, Training R2: 0.533661
Validation Loss: 0.82723832, Validation R2: 0.342311

Epoch 62/1000
Training Loss: 0.70826027, Training R2: 0.457736
Validation Loss: 0.81802940, Validation R2: 0.305437

Epoch 63/1000
Training Loss: 0.67284017, Training R2: 0.515843
Validation Loss: 0.80315125, Validation R2: 0.326062

Epoch 64/1000
Training Loss: 0.65777347, Training R2: 0.525068
Validation Loss: 0.76999474, Validation R2: 0.389762

Epoch 65/1000
Training Loss: 0.65756883, Training R2: 0.542710
Validation Loss: 0.76873165, Validation R2: 0.387173

Epoch 66/1000
Training Loss: 0.64310174, Training R2: 0.548668
Validation Loss: 0.74841034, Validation R2: 0.411556

Epoch 67/1000
Training Loss: 0.63637347, Training R2: 0.548193
Validation Loss: 0.73800635, Validation R2: 0.409279

Epoch 68/1000
Training Loss: 0.63736256, Training R2: 0.557590
Validation Loss: 0.76293427, Validation R2: 0.394538

Epoch 69/1000
Training Loss: 0.61447889, Training R2: 0.578528
Validation Loss: 0.73051846, Validation R2: 0.451860
Saved best model with validation R2 0.451860 to best_finetuned_model.pth

Epoch 70/1000
Training Loss: 0.62163891, Training R2: 0.566295
Validation Loss: 0.74054325, Validation R2: 0.422355

Epoch 71/1000
Training Loss: 0.59942884, Training R2: 0.588191
Validation Loss: 0.83807844, Validation R2: 0.286252

Epoch 72/1000
Training Loss: 0.68111725, Training R2: 0.496826
Validation Loss: 0.80406660, Validation R2: 0.380812

Epoch 73/1000
Training Loss: 0.65722648, Training R2: 0.555902
Validation Loss: 0.77111244, Validation R2: 0.381710

Epoch 74/1000
Training Loss: 0.61754925, Training R2: 0.582497
Validation Loss: 0.74526203, Validation R2: 0.423528

Epoch 75/1000
Training Loss: 0.61287285, Training R2: 0.581315
Validation Loss: 0.74747056, Validation R2: 0.405638

Epoch 76/1000
Training Loss: 0.61882761, Training R2: 0.568136
Validation Loss: 0.75474793, Validation R2: 0.401915

Epoch 77/1000
Training Loss: 0.61107684, Training R2: 0.581242
Validation Loss: 0.73636717, Validation R2: 0.426041

Epoch 78/1000
Training Loss: 0.58744390, Training R2: 0.603594
Validation Loss: 0.78305340, Validation R2: 0.339447

Epoch 79/1000
Training Loss: 0.60431208, Training R2: 0.577813
Validation Loss: 0.81912130, Validation R2: 0.367001

Epoch 80/1000
Training Loss: 0.65364171, Training R2: 0.575807
Validation Loss: 0.85680485, Validation R2: 0.270363

Epoch 81/1000
Training Loss: 0.65611208, Training R2: 0.557898
Validation Loss: 0.73390657, Validation R2: 0.424302

Epoch 82/1000
Training Loss: 0.61101367, Training R2: 0.599489
Validation Loss: 0.75160176, Validation R2: 0.416112

Epoch 83/1000
Training Loss: 0.57802985, Training R2: 0.614710
Validation Loss: 0.75257045, Validation R2: 0.403400

Epoch 84/1000
Training Loss: 0.59251100, Training R2: 0.575922
Validation Loss: 0.75971806, Validation R2: 0.413591

Epoch 85/1000
Training Loss: 0.59158544, Training R2: 0.613007
Validation Loss: 0.77175307, Validation R2: 0.374041

Epoch 86/1000
Training Loss: 0.59829520, Training R2: 0.581142
Validation Loss: 0.74767572, Validation R2: 0.452339
Saved best model with validation R2 0.452339 to best_finetuned_model.pth

Epoch 87/1000
Training Loss: 0.61617235, Training R2: 0.584033
Validation Loss: 0.72992730, Validation R2: 0.465677
Saved best model with validation R2 0.465677 to best_finetuned_model.pth

Epoch 88/1000
Training Loss: 0.65639518, Training R2: 0.547752
Validation Loss: 0.80206311, Validation R2: 0.359400

Epoch 89/1000
Training Loss: 0.63885544, Training R2: 0.553821
Validation Loss: 0.74196708, Validation R2: 0.439609

Epoch 90/1000
Training Loss: 0.64467678, Training R2: 0.572816
Validation Loss: 0.82419300, Validation R2: 0.303743

Epoch 91/1000
Training Loss: 0.61944301, Training R2: 0.590866
Validation Loss: 0.71345389, Validation R2: 0.465156

Epoch 92/1000
Training Loss: 0.64349024, Training R2: 0.572373
Validation Loss: 0.73873597, Validation R2: 0.446495

Epoch 93/1000
Training Loss: 0.60952873, Training R2: 0.604532
Validation Loss: 0.72960770, Validation R2: 0.445415

Epoch 94/1000
Training Loss: 0.58774591, Training R2: 0.606638
Validation Loss: 0.70480603, Validation R2: 0.490528
Saved best model with validation R2 0.490528 to best_finetuned_model.pth

Epoch 95/1000
Training Loss: 0.58452584, Training R2: 0.598298
Validation Loss: 0.69965130, Validation R2: 0.504708
Saved best model with validation R2 0.504708 to best_finetuned_model.pth

Epoch 96/1000
Training Loss: 0.57478565, Training R2: 0.612616
Validation Loss: 0.72112364, Validation R2: 0.473657

Epoch 97/1000
Training Loss: 0.57542693, Training R2: 0.620507
Validation Loss: 0.69440812, Validation R2: 0.498971

Epoch 98/1000
Training Loss: 0.57558532, Training R2: 0.611533
Validation Loss: 0.71346158, Validation R2: 0.470383

Epoch 99/1000
Training Loss: 0.58667680, Training R2: 0.602920
Validation Loss: 0.71987754, Validation R2: 0.458253

Epoch 100/1000
Training Loss: 0.56551712, Training R2: 0.625547
Validation Loss: 0.71329618, Validation R2: 0.479398

Epoch 101/1000
Training Loss: 0.57314271, Training R2: 0.622892
Validation Loss: 0.74053252, Validation R2: 0.451169

Epoch 102/1000
Training Loss: 0.56664533, Training R2: 0.627645
Validation Loss: 0.71328062, Validation R2: 0.483020

Epoch 103/1000
Training Loss: 0.57875742, Training R2: 0.620310
Validation Loss: 0.70101607, Validation R2: 0.485888

Epoch 104/1000
Training Loss: 0.56922235, Training R2: 0.615152
Validation Loss: 0.76791888, Validation R2: 0.411330

Epoch 105/1000
Training Loss: 0.62502145, Training R2: 0.528365
Validation Loss: 0.68024886, Validation R2: 0.500858

Epoch 106/1000
Training Loss: 0.57946770, Training R2: 0.594651
Validation Loss: 0.76551068, Validation R2: 0.406241

Epoch 107/1000
Training Loss: 0.68641711, Training R2: 0.514653
Validation Loss: 0.79950744, Validation R2: 0.354235

Epoch 108/1000
Training Loss: 0.60845311, Training R2: 0.591508
Validation Loss: 0.71307266, Validation R2: 0.512464
Saved best model with validation R2 0.512464 to best_finetuned_model.pth

Epoch 109/1000
Training Loss: 0.60142798, Training R2: 0.604483
Validation Loss: 0.72483277, Validation R2: 0.467433

Epoch 110/1000
Training Loss: 0.59530856, Training R2: 0.606400
Validation Loss: 0.66034353, Validation R2: 0.553468
Saved best model with validation R2 0.553468 to best_finetuned_model.pth

Epoch 111/1000
Training Loss: 0.57526943, Training R2: 0.606939
Validation Loss: 0.66746110, Validation R2: 0.512833

Epoch 112/1000
Training Loss: 0.60460932, Training R2: 0.583432
Validation Loss: 0.65671301, Validation R2: 0.530764

Epoch 113/1000
Training Loss: 0.57608676, Training R2: 0.618070
Validation Loss: 0.69285536, Validation R2: 0.520372

Epoch 114/1000
Training Loss: 0.59452816, Training R2: 0.607390
Validation Loss: 0.64837289, Validation R2: 0.542912

Epoch 115/1000
Training Loss: 0.56937264, Training R2: 0.614795
Validation Loss: 0.71246153, Validation R2: 0.502144

Epoch 116/1000
Training Loss: 0.62223631, Training R2: 0.588232
Validation Loss: 0.77448475, Validation R2: 0.434183

Epoch 117/1000
Training Loss: 0.60863276, Training R2: 0.590446
Validation Loss: 0.66426343, Validation R2: 0.522267

Epoch 118/1000
Training Loss: 0.59749131, Training R2: 0.616890
Validation Loss: 0.67153829, Validation R2: 0.521435

Epoch 119/1000
Training Loss: 0.58328170, Training R2: 0.611012
Validation Loss: 0.72059536, Validation R2: 0.459501

Epoch 120/1000
Training Loss: 0.60485008, Training R2: 0.582787
Validation Loss: 0.66893929, Validation R2: 0.513189

Epoch 121/1000
Training Loss: 0.54062551, Training R2: 0.642521
Validation Loss: 0.69350934, Validation R2: 0.503772

Epoch 122/1000
Training Loss: 0.57246910, Training R2: 0.626778
Validation Loss: 0.72582501, Validation R2: 0.455093

Epoch 123/1000
Training Loss: 0.55037647, Training R2: 0.637768
Validation Loss: 0.64962202, Validation R2: 0.533997

Epoch 124/1000
Training Loss: 0.53699152, Training R2: 0.622812
Validation Loss: 0.65835130, Validation R2: 0.536331

Epoch 125/1000
Training Loss: 0.54834693, Training R2: 0.634892
Validation Loss: 0.69910109, Validation R2: 0.509943

Epoch 126/1000
Training Loss: 0.54564626, Training R2: 0.640572
Validation Loss: 0.66681808, Validation R2: 0.542042

Epoch 127/1000
Training Loss: 0.54284983, Training R2: 0.649933
Validation Loss: 0.71272171, Validation R2: 0.475256

Epoch 128/1000
Training Loss: 0.55876075, Training R2: 0.635661
Validation Loss: 0.70490754, Validation R2: 0.477981

Epoch 129/1000
Training Loss: 0.53743776, Training R2: 0.613536
Validation Loss: 0.67696059, Validation R2: 0.511200

Epoch 130/1000
Training Loss: 0.52095786, Training R2: 0.637477
Validation Loss: 0.66245741, Validation R2: 0.501031

Epoch 131/1000
Epoch 00131: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 0.52287551, Training R2: 0.663546
Validation Loss: 0.66980183, Validation R2: 0.514971

Epoch 132/1000
学习率已减少 1 次
Training Loss: 0.51411151, Training R2: 0.665634
Validation Loss: 0.65620726, Validation R2: 0.505470

Epoch 133/1000
Training Loss: 0.50135547, Training R2: 0.664052
Validation Loss: 0.68044460, Validation R2: 0.489882

Epoch 134/1000
Training Loss: 0.49379145, Training R2: 0.669928
Validation Loss: 0.63963455, Validation R2: 0.531853

Epoch 135/1000
Training Loss: 0.48035167, Training R2: 0.679622
Validation Loss: 0.69905990, Validation R2: 0.467799

Epoch 136/1000
Training Loss: 0.49632032, Training R2: 0.661389
Validation Loss: 0.68355739, Validation R2: 0.463213

Epoch 137/1000
Training Loss: 0.47487125, Training R2: 0.676880
Validation Loss: 0.66329741, Validation R2: 0.493651

Epoch 138/1000
Training Loss: 0.48929350, Training R2: 0.678941
Validation Loss: 0.66962266, Validation R2: 0.501395

Epoch 139/1000
Training Loss: 0.46957396, Training R2: 0.687424
Validation Loss: 0.67329895, Validation R2: 0.481096

Epoch 140/1000
Training Loss: 0.47438731, Training R2: 0.680290
Validation Loss: 0.67070448, Validation R2: 0.485612

Epoch 141/1000
Training Loss: 0.46484759, Training R2: 0.682623
Validation Loss: 0.66148406, Validation R2: 0.479304

Epoch 142/1000
Training Loss: 0.48859844, Training R2: 0.673370
Validation Loss: 0.65710282, Validation R2: 0.492100

Epoch 143/1000
Training Loss: 0.45208961, Training R2: 0.699057
Validation Loss: 0.66121060, Validation R2: 0.503134

Epoch 144/1000
Training Loss: 0.47486349, Training R2: 0.676710
Validation Loss: 0.64945769, Validation R2: 0.523064

Epoch 145/1000
Training Loss: 0.45453616, Training R2: 0.695477
Validation Loss: 0.66289300, Validation R2: 0.486245

Epoch 146/1000
Training Loss: 0.46434453, Training R2: 0.689385
Validation Loss: 0.68856752, Validation R2: 0.479683

Epoch 147/1000
Training Loss: 0.46878275, Training R2: 0.670481
Validation Loss: 0.66581208, Validation R2: 0.509494

Epoch 148/1000
Training Loss: 0.46223210, Training R2: 0.689344
Validation Loss: 0.68226212, Validation R2: 0.484222

Epoch 149/1000
Training Loss: 0.46849938, Training R2: 0.692248
Validation Loss: 0.66136181, Validation R2: 0.494869

Epoch 150/1000
Training Loss: 0.45803127, Training R2: 0.698157
Validation Loss: 0.64599776, Validation R2: 0.507687

Epoch 151/1000
Training Loss: 0.45207161, Training R2: 0.700220
Validation Loss: 0.66552001, Validation R2: 0.491292

Epoch 152/1000
Epoch 00152: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 0.45707511, Training R2: 0.682063
Validation Loss: 0.65787321, Validation R2: 0.499618

Epoch 153/1000
学习率已减少 2 次
Training Loss: 0.48638377, Training R2: 0.683910
Validation Loss: 0.65251660, Validation R2: 0.516337

Epoch 154/1000
Training Loss: 0.44900348, Training R2: 0.698524
Validation Loss: 0.65704942, Validation R2: 0.489594

Epoch 155/1000
Training Loss: 0.43925822, Training R2: 0.714568
Validation Loss: 0.65071702, Validation R2: 0.495309

Epoch 156/1000
Training Loss: 0.43438244, Training R2: 0.714298
Validation Loss: 0.65067816, Validation R2: 0.505370

Epoch 157/1000
Training Loss: 0.42659446, Training R2: 0.719975
Validation Loss: 0.63504696, Validation R2: 0.525535

Epoch 158/1000
Training Loss: 0.42188712, Training R2: 0.719527
Validation Loss: 0.63344365, Validation R2: 0.537803

Epoch 159/1000
Training Loss: 0.43626372, Training R2: 0.712831
Validation Loss: 0.63316441, Validation R2: 0.530107

Epoch 160/1000
Training Loss: 0.43058552, Training R2: 0.713312
Validation Loss: 0.63218862, Validation R2: 0.532370

Epoch 161/1000
Training Loss: 0.41900519, Training R2: 0.720262
Validation Loss: 0.63734484, Validation R2: 0.530170

Epoch 162/1000
Training Loss: 0.40919053, Training R2: 0.731082
Validation Loss: 0.64830536, Validation R2: 0.497644

Epoch 163/1000
Training Loss: 0.41654508, Training R2: 0.730617
Validation Loss: 0.67301130, Validation R2: 0.480221

Epoch 164/1000
Training Loss: 0.41236860, Training R2: 0.736967
Validation Loss: 0.65500456, Validation R2: 0.501099

Epoch 165/1000
Training Loss: 0.40894969, Training R2: 0.735749
Validation Loss: 0.65842742, Validation R2: 0.493674

Epoch 166/1000
Training Loss: 0.41566291, Training R2: 0.731834
Validation Loss: 0.65255821, Validation R2: 0.497423

Epoch 167/1000
Training Loss: 0.40116942, Training R2: 0.740068
Validation Loss: 0.65497518, Validation R2: 0.490118

Epoch 168/1000
Training Loss: 0.39431188, Training R2: 0.743445
Validation Loss: 0.63758904, Validation R2: 0.520251

Epoch 169/1000
Training Loss: 0.39463140, Training R2: 0.739526
Validation Loss: 0.63888413, Validation R2: 0.523299

Epoch 170/1000
Training Loss: 0.39239549, Training R2: 0.742463
Validation Loss: 0.64597905, Validation R2: 0.483855

Epoch 171/1000
Training Loss: 0.39535848, Training R2: 0.743749
Validation Loss: 0.64891523, Validation R2: 0.499414

Epoch 172/1000
Training Loss: 0.38882148, Training R2: 0.746892
Validation Loss: 0.64034069, Validation R2: 0.508519

Epoch 173/1000
Epoch 00173: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 0.39031374, Training R2: 0.747201
Validation Loss: 0.63986009, Validation R2: 0.509207

Epoch 174/1000
学习率已减少 3 次
Training Loss: 0.38340110, Training R2: 0.752480
Validation Loss: 0.64143515, Validation R2: 0.496858

Epoch 175/1000
Training Loss: 0.37991507, Training R2: 0.755632
Validation Loss: 0.64504546, Validation R2: 0.484196

Epoch 176/1000
Training Loss: 0.37682392, Training R2: 0.758919
Validation Loss: 0.64513862, Validation R2: 0.481980

Epoch 177/1000
Training Loss: 0.37353892, Training R2: 0.760943
Validation Loss: 0.64668804, Validation R2: 0.477177

Epoch 178/1000
Training Loss: 0.37255533, Training R2: 0.761360
Validation Loss: 0.64238846, Validation R2: 0.479238

Epoch 179/1000
Training Loss: 0.37130810, Training R2: 0.759501
Validation Loss: 0.64528120, Validation R2: 0.484405

Epoch 180/1000
Training Loss: 0.36990886, Training R2: 0.760573
Validation Loss: 0.64898908, Validation R2: 0.476107

Epoch 181/1000
Training Loss: 0.36854159, Training R2: 0.763923
Validation Loss: 0.64494801, Validation R2: 0.476532

Epoch 182/1000
Training Loss: 0.36573263, Training R2: 0.762595
Validation Loss: 0.64100170, Validation R2: 0.482701

Epoch 183/1000
Training Loss: 0.36421519, Training R2: 0.762074
Validation Loss: 0.63694137, Validation R2: 0.490851

Epoch 184/1000
Training Loss: 0.36394917, Training R2: 0.760249
Validation Loss: 0.63927495, Validation R2: 0.492565

Epoch 185/1000
Training Loss: 0.36173840, Training R2: 0.763069
Validation Loss: 0.64614499, Validation R2: 0.483943

Epoch 186/1000
Training Loss: 0.35637033, Training R2: 0.767068
Validation Loss: 0.64467800, Validation R2: 0.469350

Epoch 187/1000
Training Loss: 0.36030862, Training R2: 0.766212
Validation Loss: 0.64650995, Validation R2: 0.463761

Epoch 188/1000
Training Loss: 0.36006359, Training R2: 0.768815
Validation Loss: 0.64664596, Validation R2: 0.471315

Epoch 189/1000
Training Loss: 0.35562240, Training R2: 0.769293
Validation Loss: 0.64607036, Validation R2: 0.486451

Epoch 190/1000
Training Loss: 0.36054500, Training R2: 0.771108
Validation Loss: 0.64851177, Validation R2: 0.475389

Epoch 191/1000
Training Loss: 0.35663630, Training R2: 0.772250
Validation Loss: 0.65122807, Validation R2: 0.464424

Epoch 192/1000
Training Loss: 0.35404254, Training R2: 0.777847
Validation Loss: 0.65300596, Validation R2: 0.461149

Epoch 193/1000
Training Loss: 0.35081795, Training R2: 0.778607
Validation Loss: 0.65204728, Validation R2: 0.446484

Epoch 194/1000
Epoch 00194: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 0.35009626, Training R2: 0.776094
Validation Loss: 0.65975708, Validation R2: 0.441983

Epoch 195/1000
学习率已减少 4 次
Training Loss: 0.35321953, Training R2: 0.777373
Validation Loss: 0.65626371, Validation R2: 0.441683

Epoch 196/1000
Training Loss: 0.34269794, Training R2: 0.779567
Validation Loss: 0.65451056, Validation R2: 0.439321

Epoch 197/1000
Training Loss: 0.34280252, Training R2: 0.779911
Validation Loss: 0.65463805, Validation R2: 0.444531

Epoch 198/1000
Training Loss: 0.34728587, Training R2: 0.775887
Validation Loss: 0.65368515, Validation R2: 0.442636

Epoch 199/1000
Training Loss: 0.33752226, Training R2: 0.778619
Validation Loss: 0.65539962, Validation R2: 0.432036

Epoch 200/1000
Training Loss: 0.33501183, Training R2: 0.783519
Validation Loss: 0.65646607, Validation R2: 0.434861

Epoch 201/1000
Training Loss: 0.33487072, Training R2: 0.784603
Validation Loss: 0.65713042, Validation R2: 0.432526

Epoch 202/1000
Training Loss: 0.33325541, Training R2: 0.786112
Validation Loss: 0.65591079, Validation R2: 0.438003

Epoch 203/1000
Training Loss: 0.33088983, Training R2: 0.786532
Validation Loss: 0.65796030, Validation R2: 0.437905

Epoch 204/1000
Training Loss: 0.33160736, Training R2: 0.786281
Validation Loss: 0.66112053, Validation R2: 0.424927

Epoch 205/1000
Training Loss: 0.33272262, Training R2: 0.787094
Validation Loss: 0.66486126, Validation R2: 0.420818

Epoch 206/1000
Training Loss: 0.32984699, Training R2: 0.789617
Validation Loss: 0.66253561, Validation R2: 0.425142

Epoch 207/1000
Training Loss: 0.32768988, Training R2: 0.789611
Validation Loss: 0.65454590, Validation R2: 0.439342

Epoch 208/1000
Training Loss: 0.32801922, Training R2: 0.788952
Validation Loss: 0.65857357, Validation R2: 0.421337

Epoch 209/1000
Training Loss: 0.32716696, Training R2: 0.791176
Validation Loss: 0.65993041, Validation R2: 0.420079

Epoch 210/1000
Training Loss: 0.32369432, Training R2: 0.792028
Validation Loss: 0.65626419, Validation R2: 0.428453

Epoch 211/1000
Training Loss: 0.32674386, Training R2: 0.789351
Validation Loss: 0.66109741, Validation R2: 0.417615

Epoch 212/1000
Training Loss: 0.32585795, Training R2: 0.793776
Validation Loss: 0.67466450, Validation R2: 0.391315

Epoch 213/1000
Training Loss: 0.32593445, Training R2: 0.797483
Validation Loss: 0.66301084, Validation R2: 0.418175

Epoch 214/1000
Training Loss: 0.32611456, Training R2: 0.790028
Validation Loss: 0.65346944, Validation R2: 0.441764

Epoch 215/1000
Epoch 00215: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 0.32929333, Training R2: 0.788599
Validation Loss: 0.66037792, Validation R2: 0.424760

Epoch 216/1000
学习率已减少 5 次
Training Loss: 0.32166008, Training R2: 0.794214
Validation Loss: 0.66404068, Validation R2: 0.413665

Epoch 217/1000
Training Loss: 0.31810350, Training R2: 0.796434
Validation Loss: 0.66486245, Validation R2: 0.411794

Epoch 218/1000
Training Loss: 0.31598464, Training R2: 0.796672
Validation Loss: 0.66243631, Validation R2: 0.414062

Epoch 219/1000
Training Loss: 0.31540021, Training R2: 0.796798
Validation Loss: 0.66033834, Validation R2: 0.416127

Epoch 220/1000
Training Loss: 0.31470068, Training R2: 0.797859
Validation Loss: 0.66100270, Validation R2: 0.411489

Epoch 221/1000
Training Loss: 0.31524376, Training R2: 0.798275
Validation Loss: 0.66054505, Validation R2: 0.410202

Epoch 222/1000
Training Loss: 0.31493981, Training R2: 0.798270
Validation Loss: 0.65844351, Validation R2: 0.416036

Epoch 223/1000
Training Loss: 0.31734220, Training R2: 0.797591
Validation Loss: 0.65988785, Validation R2: 0.413454

Epoch 224/1000
Training Loss: 0.31431225, Training R2: 0.799896
Validation Loss: 0.66306531, Validation R2: 0.402360

Epoch 225/1000
Training Loss: 0.31555796, Training R2: 0.799770
Validation Loss: 0.66297507, Validation R2: 0.404952

Epoch 226/1000
Training Loss: 0.31292541, Training R2: 0.801026
Validation Loss: 0.65992916, Validation R2: 0.412051

Epoch 227/1000
Training Loss: 0.31172828, Training R2: 0.800934
Validation Loss: 0.65884537, Validation R2: 0.412738

Epoch 228/1000
Training Loss: 0.31038002, Training R2: 0.800586
Validation Loss: 0.66064495, Validation R2: 0.409174

Epoch 229/1000
Training Loss: 0.30999228, Training R2: 0.801279
Validation Loss: 0.66210788, Validation R2: 0.410627

Epoch 230/1000
Training Loss: 0.30959157, Training R2: 0.801483
Validation Loss: 0.65940076, Validation R2: 0.416676

Epoch 231/1000
Training Loss: 0.30844262, Training R2: 0.800986
Validation Loss: 0.65817559, Validation R2: 0.419332

Epoch 232/1000
Training Loss: 0.30874775, Training R2: 0.800138
Validation Loss: 0.65909517, Validation R2: 0.416913

Epoch 233/1000
Training Loss: 0.30759881, Training R2: 0.800651
Validation Loss: 0.66111553, Validation R2: 0.410086

Epoch 234/1000
Training Loss: 0.30841997, Training R2: 0.801588
Validation Loss: 0.66075081, Validation R2: 0.406103

Epoch 235/1000
Training Loss: 0.30688768, Training R2: 0.802231
Validation Loss: 0.65651453, Validation R2: 0.413413

Epoch 236/1000
Epoch 00236: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 0.30652071, Training R2: 0.801680
Validation Loss: 0.65601808, Validation R2: 0.414726

Epoch 237/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/r2_curve_dipole.png
