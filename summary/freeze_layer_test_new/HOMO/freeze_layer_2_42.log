Using device: cuda
Selected target_properties: ['HOMO_energy']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1092227

Epoch 1/1000
Training Loss: 0.82631570, Training R2: -655.145508
Validation Loss: 0.49536261, Validation R2: -251.527191
Saved best model with validation R2 -251.527191 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 0.48009487, Training R2: -215.428970
Validation Loss: 0.23217753, Validation R2: -58.506577
Saved best model with validation R2 -58.506577 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 0.16034331, Training R2: -26.234716
Validation Loss: 0.02887923, Validation R2: -0.523766
Saved best model with validation R2 -0.523766 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 0.11684260, Training R2: -15.182030
Validation Loss: 0.15162593, Validation R2: -23.553022

Epoch 5/1000
Training Loss: 0.17228479, Training R2: -27.277411
Validation Loss: 0.19652425, Validation R2: -39.469109

Epoch 6/1000
Training Loss: 0.25449605, Training R2: -58.250103
Validation Loss: 0.02590901, Validation R2: -0.306647
Saved best model with validation R2 -0.306647 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 0.13961728, Training R2: -22.708588
Validation Loss: 0.12310877, Validation R2: -15.586937

Epoch 8/1000
Training Loss: 0.09084923, Training R2: -8.312907
Validation Loss: 0.04991847, Validation R2: -2.443438

Epoch 9/1000
Training Loss: 0.07486431, Training R2: -5.159232
Validation Loss: 0.02619266, Validation R2: -0.305184
Saved best model with validation R2 -0.305184 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.04756417, Training R2: -2.053807
Validation Loss: 0.04647122, Validation R2: -1.872961

Epoch 11/1000
Training Loss: 0.03866007, Training R2: -0.925669
Validation Loss: 0.03589978, Validation R2: -0.870862

Epoch 12/1000
Training Loss: 0.03388585, Training R2: -0.573990
Validation Loss: 0.02427851, Validation R2: -0.069450
Saved best model with validation R2 -0.069450 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 0.03351094, Training R2: -0.544098
Validation Loss: 0.03410622, Validation R2: -0.662775

Epoch 14/1000
Training Loss: 0.02944463, Training R2: -0.268683
Validation Loss: 0.02142590, Validation R2: 0.093179
Saved best model with validation R2 0.093179 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 0.02420824, Training R2: 0.070736
Validation Loss: 0.02699581, Validation R2: -0.239390

Epoch 16/1000
Training Loss: 0.02563051, Training R2: -0.015485
Validation Loss: 0.03265981, Validation R2: -0.658332

Epoch 17/1000
Training Loss: 0.02753432, Training R2: -0.122098
Validation Loss: 0.03837936, Validation R2: -1.131136

Epoch 18/1000
Training Loss: 0.03306554, Training R2: -0.465947
Validation Loss: 0.02768387, Validation R2: -0.280043

Epoch 19/1000
Training Loss: 0.02834514, Training R2: -0.145045
Validation Loss: 0.03503736, Validation R2: -0.818859

Epoch 20/1000
Training Loss: 0.03279744, Training R2: -0.403088
Validation Loss: 0.04226488, Validation R2: -1.446058

Epoch 21/1000
Training Loss: 0.03664231, Training R2: -0.662998
Validation Loss: 0.03122566, Validation R2: -0.466253

Epoch 22/1000
Training Loss: 0.03191530, Training R2: -0.374722
Validation Loss: 0.03371636, Validation R2: -0.685183

Epoch 23/1000
Training Loss: 0.03188173, Training R2: -0.345553
Validation Loss: 0.03395553, Validation R2: -0.737436

Epoch 24/1000
Training Loss: 0.03237721, Training R2: -0.388670
Validation Loss: 0.03538745, Validation R2: -0.864355

Epoch 25/1000
Training Loss: 0.03302648, Training R2: -0.397316
Validation Loss: 0.04510389, Validation R2: -1.745123

Epoch 26/1000
Training Loss: 0.03980198, Training R2: -0.911764
Validation Loss: 0.02728638, Validation R2: -0.194407

Epoch 27/1000
Training Loss: 0.02832753, Training R2: -0.107896
Validation Loss: 0.03401915, Validation R2: -0.696067

Epoch 28/1000
Training Loss: 0.03025140, Training R2: -0.239438
Validation Loss: 0.04290625, Validation R2: -1.527045

Epoch 29/1000
Training Loss: 0.03727784, Training R2: -0.712295
Validation Loss: 0.03549338, Validation R2: -0.884232

Epoch 30/1000
Training Loss: 0.03495204, Training R2: -0.566966
Validation Loss: 0.02403425, Validation R2: -0.045601

Epoch 31/1000
Training Loss: 0.02517111, Training R2: 0.043292
Validation Loss: 0.03457684, Validation R2: -0.805161

Epoch 32/1000
Training Loss: 0.02612031, Training R2: -0.029339
Validation Loss: 0.02674390, Validation R2: -0.194992

Epoch 33/1000
Training Loss: 0.02335552, Training R2: 0.144634
Validation Loss: 0.02426914, Validation R2: -0.018734

Epoch 34/1000
Training Loss: 0.02329261, Training R2: 0.162200
Validation Loss: 0.02524773, Validation R2: -0.083998

Epoch 35/1000
Epoch 00035: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.02596290, Training R2: 0.016818
Validation Loss: 0.03654501, Validation R2: -0.919270

Epoch 36/1000
学习率已减少 1 次
Training Loss: 0.03137039, Training R2: -0.330414
Validation Loss: 0.02504934, Validation R2: -0.096683

Epoch 37/1000
Training Loss: 0.02799447, Training R2: -0.072100
Validation Loss: 0.03728705, Validation R2: -1.022418

Epoch 38/1000
Training Loss: 0.03242289, Training R2: -0.374100
Validation Loss: 0.02974130, Validation R2: -0.374516

Epoch 39/1000
Training Loss: 0.02705274, Training R2: -0.042597
Validation Loss: 0.02362626, Validation R2: 0.031769

Epoch 40/1000
Training Loss: 0.02399873, Training R2: 0.129073
Validation Loss: 0.03390809, Validation R2: -0.702985

Epoch 41/1000
Training Loss: 0.02778924, Training R2: -0.087051
Validation Loss: 0.02363778, Validation R2: 0.011778

Epoch 42/1000
Training Loss: 0.02526014, Training R2: 0.058289
Validation Loss: 0.03135056, Validation R2: -0.491982

Epoch 43/1000
Training Loss: 0.02793649, Training R2: -0.120367
Validation Loss: 0.02407232, Validation R2: 0.023372

Epoch 44/1000
Training Loss: 0.02590933, Training R2: 0.027357
Validation Loss: 0.03028671, Validation R2: -0.438009

Epoch 45/1000
Training Loss: 0.02533662, Training R2: 0.089441
Validation Loss: 0.02388746, Validation R2: 0.005557

Epoch 46/1000
Training Loss: 0.02354480, Training R2: 0.167629
Validation Loss: 0.02214777, Validation R2: 0.116552
Saved best model with validation R2 0.116552 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.02324577, Training R2: 0.179830
Validation Loss: 0.02265076, Validation R2: 0.091738

Epoch 48/1000
Training Loss: 0.02274177, Training R2: 0.198190
Validation Loss: 0.02348578, Validation R2: 0.033492

Epoch 49/1000
Training Loss: 0.02288606, Training R2: 0.179494
Validation Loss: 0.02204867, Validation R2: 0.110723

Epoch 50/1000
Training Loss: 0.02148275, Training R2: 0.241035
Validation Loss: 0.02217362, Validation R2: 0.105137

Epoch 51/1000
Training Loss: 0.02133249, Training R2: 0.247593
Validation Loss: 0.02921112, Validation R2: -0.353769

Epoch 52/1000
Training Loss: 0.02497942, Training R2: 0.068727
Validation Loss: 0.03319404, Validation R2: -0.652130

Epoch 53/1000
Training Loss: 0.02898275, Training R2: -0.130381
Validation Loss: 0.02218349, Validation R2: 0.109318

Epoch 54/1000
Training Loss: 0.02499876, Training R2: 0.095427
Validation Loss: 0.02732977, Validation R2: -0.187058

Epoch 55/1000
Training Loss: 0.02472114, Training R2: 0.102313
Validation Loss: 0.02325648, Validation R2: 0.065465

Epoch 56/1000
Training Loss: 0.02240267, Training R2: 0.214284
Validation Loss: 0.02203640, Validation R2: 0.113026

Epoch 57/1000
Training Loss: 0.02140024, Training R2: 0.255456
Validation Loss: 0.02295389, Validation R2: 0.053585

Epoch 58/1000
Training Loss: 0.02189329, Training R2: 0.219774
Validation Loss: 0.02224167, Validation R2: 0.102924

Epoch 59/1000
Training Loss: 0.02145886, Training R2: 0.249081
Validation Loss: 0.02326222, Validation R2: 0.057571

Epoch 60/1000
Training Loss: 0.02196394, Training R2: 0.211067
Validation Loss: 0.02409495, Validation R2: -0.006151

Epoch 61/1000
Training Loss: 0.02271007, Training R2: 0.202849
Validation Loss: 0.02646799, Validation R2: -0.158389

Epoch 62/1000
Training Loss: 0.02337010, Training R2: 0.170183
Validation Loss: 0.02398884, Validation R2: -0.015514

Epoch 63/1000
Training Loss: 0.02246122, Training R2: 0.215461
Validation Loss: 0.03196473, Validation R2: -0.561454

Epoch 64/1000
Training Loss: 0.02914229, Training R2: -0.148995
Validation Loss: 0.02329322, Validation R2: 0.030069

Epoch 65/1000
Training Loss: 0.02439967, Training R2: 0.131116
Validation Loss: 0.02453910, Validation R2: -0.020647

Epoch 66/1000
Training Loss: 0.02426195, Training R2: 0.116583
Validation Loss: 0.02290069, Validation R2: 0.075617

Epoch 67/1000
Epoch 00067: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.02172625, Training R2: 0.255110
Validation Loss: 0.02319760, Validation R2: 0.062845

Epoch 68/1000
学习率已减少 2 次
Training Loss: 0.02177656, Training R2: 0.248234
Validation Loss: 0.02405746, Validation R2: -0.022112

Epoch 69/1000
Training Loss: 0.02132429, Training R2: 0.260664
Validation Loss: 0.02355183, Validation R2: 0.041610

Epoch 70/1000
Training Loss: 0.02217760, Training R2: 0.230321
Validation Loss: 0.02171912, Validation R2: 0.127923
Saved best model with validation R2 0.127923 to best_finetuned_model.pth

Epoch 71/1000
Training Loss: 0.02151163, Training R2: 0.241692
Validation Loss: 0.02150186, Validation R2: 0.140277
Saved best model with validation R2 0.140277 to best_finetuned_model.pth

Epoch 72/1000
Training Loss: 0.02117921, Training R2: 0.270429
Validation Loss: 0.02147956, Validation R2: 0.142223
Saved best model with validation R2 0.142223 to best_finetuned_model.pth

Epoch 73/1000
Training Loss: 0.02133639, Training R2: 0.261723
Validation Loss: 0.02221699, Validation R2: 0.112087

Epoch 74/1000
Training Loss: 0.02147829, Training R2: 0.257790
Validation Loss: 0.02164213, Validation R2: 0.131201

Epoch 75/1000
Training Loss: 0.02095151, Training R2: 0.275183
Validation Loss: 0.02182332, Validation R2: 0.118897

Epoch 76/1000
Training Loss: 0.02115779, Training R2: 0.262285
Validation Loss: 0.02315794, Validation R2: 0.032843

Epoch 77/1000
Training Loss: 0.02120356, Training R2: 0.265335
Validation Loss: 0.02241138, Validation R2: 0.093148

Epoch 78/1000
Training Loss: 0.02133642, Training R2: 0.237048
Validation Loss: 0.02202497, Validation R2: 0.110488

Epoch 79/1000
Training Loss: 0.02395413, Training R2: 0.130576
Validation Loss: 0.02423505, Validation R2: -0.017201

Epoch 80/1000
Training Loss: 0.02178053, Training R2: 0.247771
Validation Loss: 0.02185586, Validation R2: 0.120376

Epoch 81/1000
Training Loss: 0.02139389, Training R2: 0.260908
Validation Loss: 0.02255359, Validation R2: 0.088414

Epoch 82/1000
Training Loss: 0.02250644, Training R2: 0.196766
Validation Loss: 0.02360249, Validation R2: 0.013749

Epoch 83/1000
Training Loss: 0.02283799, Training R2: 0.167101
Validation Loss: 0.02313714, Validation R2: 0.049516

Epoch 84/1000
Training Loss: 0.02216969, Training R2: 0.229354
Validation Loss: 0.02339367, Validation R2: 0.034975

Epoch 85/1000
Training Loss: 0.02194497, Training R2: 0.238079
Validation Loss: 0.02226623, Validation R2: 0.097676

Epoch 86/1000
Training Loss: 0.02167384, Training R2: 0.257056
Validation Loss: 0.02183064, Validation R2: 0.117279

Epoch 87/1000
Training Loss: 0.02087857, Training R2: 0.277647
Validation Loss: 0.02193520, Validation R2: 0.109530

Epoch 88/1000
Training Loss: 0.02074922, Training R2: 0.286079
Validation Loss: 0.02182528, Validation R2: 0.115313

Epoch 89/1000
Training Loss: 0.02067386, Training R2: 0.293180
Validation Loss: 0.02182337, Validation R2: 0.121346

Epoch 90/1000
Training Loss: 0.02090841, Training R2: 0.280768
Validation Loss: 0.02229545, Validation R2: 0.102487

Epoch 91/1000
Training Loss: 0.02049944, Training R2: 0.306887
Validation Loss: 0.02417831, Validation R2: -0.014976

Epoch 92/1000
Training Loss: 0.02250333, Training R2: 0.212057
Validation Loss: 0.02256445, Validation R2: 0.090181

Epoch 93/1000
Epoch 00093: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.02121203, Training R2: 0.274189
Validation Loss: 0.02172996, Validation R2: 0.125896

Epoch 94/1000
学习率已减少 3 次
Training Loss: 0.02071728, Training R2: 0.293984
Validation Loss: 0.02157143, Validation R2: 0.134027

Epoch 95/1000
Training Loss: 0.02068739, Training R2: 0.290400
Validation Loss: 0.02172873, Validation R2: 0.122104

Epoch 96/1000
Training Loss: 0.02055715, Training R2: 0.295355
Validation Loss: 0.02170710, Validation R2: 0.126134

Epoch 97/1000
Training Loss: 0.02067808, Training R2: 0.290070
Validation Loss: 0.02183912, Validation R2: 0.113091

Epoch 98/1000
Training Loss: 0.02063062, Training R2: 0.291363
Validation Loss: 0.02177498, Validation R2: 0.119188

Epoch 99/1000
Training Loss: 0.02061963, Training R2: 0.292877
Validation Loss: 0.02171602, Validation R2: 0.121238

Epoch 100/1000
Training Loss: 0.02050243, Training R2: 0.297022
Validation Loss: 0.02182545, Validation R2: 0.115134

Epoch 101/1000
Training Loss: 0.02049924, Training R2: 0.297443
Validation Loss: 0.02162665, Validation R2: 0.129580

Epoch 102/1000
Training Loss: 0.02068065, Training R2: 0.293631
Validation Loss: 0.02164969, Validation R2: 0.128999

Epoch 103/1000
Training Loss: 0.02048495, Training R2: 0.302178
Validation Loss: 0.02148776, Validation R2: 0.136230

Epoch 104/1000
Training Loss: 0.02054047, Training R2: 0.299206
Validation Loss: 0.02154642, Validation R2: 0.131063

Epoch 105/1000
Training Loss: 0.02052148, Training R2: 0.295583
Validation Loss: 0.02174446, Validation R2: 0.118442

Epoch 106/1000
Training Loss: 0.02144642, Training R2: 0.255443
Validation Loss: 0.02369025, Validation R2: 0.025221

Epoch 107/1000
Training Loss: 0.02157977, Training R2: 0.258627
Validation Loss: 0.02224476, Validation R2: 0.093525

Epoch 108/1000
Training Loss: 0.02119568, Training R2: 0.259025
Validation Loss: 0.02360220, Validation R2: 0.028433

Epoch 109/1000
Training Loss: 0.02117552, Training R2: 0.279476
Validation Loss: 0.02263794, Validation R2: 0.079582

Epoch 110/1000
Training Loss: 0.02144926, Training R2: 0.254047
Validation Loss: 0.02221792, Validation R2: 0.100852

Epoch 111/1000
Training Loss: 0.02063241, Training R2: 0.293273
Validation Loss: 0.02166116, Validation R2: 0.128106

Epoch 112/1000
Training Loss: 0.02046550, Training R2: 0.297964
Validation Loss: 0.02220213, Validation R2: 0.099852

Epoch 113/1000
Training Loss: 0.02049465, Training R2: 0.296776
Validation Loss: 0.02191808, Validation R2: 0.110677

Epoch 114/1000
Epoch 00114: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.02052052, Training R2: 0.293282
Validation Loss: 0.02200508, Validation R2: 0.105775

Epoch 115/1000
学习率已减少 4 次
Training Loss: 0.02044689, Training R2: 0.295785
Validation Loss: 0.02164194, Validation R2: 0.123314

Epoch 116/1000
Training Loss: 0.02042871, Training R2: 0.298874
Validation Loss: 0.02169641, Validation R2: 0.120826

Epoch 117/1000
Training Loss: 0.02042658, Training R2: 0.298805
Validation Loss: 0.02178759, Validation R2: 0.116757

Epoch 118/1000
Training Loss: 0.02032001, Training R2: 0.305071
Validation Loss: 0.02155883, Validation R2: 0.128197

Epoch 119/1000
Training Loss: 0.02033862, Training R2: 0.303119
Validation Loss: 0.02196447, Validation R2: 0.110320

Epoch 120/1000
Training Loss: 0.02042421, Training R2: 0.300535
Validation Loss: 0.02156125, Validation R2: 0.128202

Epoch 121/1000
Training Loss: 0.02069589, Training R2: 0.285829
Validation Loss: 0.02158243, Validation R2: 0.127351

Epoch 122/1000
Training Loss: 0.02064534, Training R2: 0.294941
Validation Loss: 0.02182895, Validation R2: 0.115649

Epoch 123/1000
Training Loss: 0.02055944, Training R2: 0.297742
Validation Loss: 0.02176908, Validation R2: 0.118476

Epoch 124/1000
Training Loss: 0.02064848, Training R2: 0.291403
Validation Loss: 0.02205895, Validation R2: 0.107700

Epoch 125/1000
Training Loss: 0.02043035, Training R2: 0.303985
Validation Loss: 0.02151474, Validation R2: 0.133512

Epoch 126/1000
Training Loss: 0.02045639, Training R2: 0.300523
Validation Loss: 0.02163528, Validation R2: 0.128152

Epoch 127/1000
Training Loss: 0.02038456, Training R2: 0.306033
Validation Loss: 0.02157590, Validation R2: 0.131600

Epoch 128/1000
Training Loss: 0.02077054, Training R2: 0.292217
Validation Loss: 0.02146330, Validation R2: 0.136255

Epoch 129/1000
Training Loss: 0.02065031, Training R2: 0.298908
Validation Loss: 0.02192774, Validation R2: 0.115998

Epoch 130/1000
Training Loss: 0.02036801, Training R2: 0.305577
Validation Loss: 0.02192243, Validation R2: 0.110762

Epoch 131/1000
Training Loss: 0.02094545, Training R2: 0.277381
Validation Loss: 0.02232471, Validation R2: 0.098265

Epoch 132/1000
Training Loss: 0.02093372, Training R2: 0.282869
Validation Loss: 0.02152687, Validation R2: 0.134213

Epoch 133/1000
Training Loss: 0.02108015, Training R2: 0.272751
Validation Loss: 0.02158514, Validation R2: 0.131625

Epoch 134/1000
Training Loss: 0.02069959, Training R2: 0.291784
Validation Loss: 0.02270214, Validation R2: 0.077742

Epoch 135/1000
Epoch 00135: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.02046548, Training R2: 0.295610
Validation Loss: 0.02155377, Validation R2: 0.130829

Epoch 136/1000
学习率已减少 5 次
Training Loss: 0.02044089, Training R2: 0.302605
Validation Loss: 0.02191685, Validation R2: 0.118129

Epoch 137/1000
Training Loss: 0.02052749, Training R2: 0.305802
Validation Loss: 0.02187690, Validation R2: 0.120141

Epoch 138/1000
Training Loss: 0.02034211, Training R2: 0.309211
Validation Loss: 0.02151040, Validation R2: 0.132836

Epoch 139/1000
Training Loss: 0.02048043, Training R2: 0.301991
Validation Loss: 0.02162379, Validation R2: 0.130733

Epoch 140/1000
Training Loss: 0.02037061, Training R2: 0.309090
Validation Loss: 0.02228296, Validation R2: 0.100317

Epoch 141/1000
Training Loss: 0.02044241, Training R2: 0.305852
Validation Loss: 0.02152906, Validation R2: 0.132778

Epoch 142/1000
Training Loss: 0.02037024, Training R2: 0.306667
Validation Loss: 0.02156305, Validation R2: 0.129355

Epoch 143/1000
Training Loss: 0.02057508, Training R2: 0.296387
Validation Loss: 0.02155844, Validation R2: 0.130294

Epoch 144/1000
Training Loss: 0.02030165, Training R2: 0.305407
Validation Loss: 0.02232202, Validation R2: 0.095512

Epoch 145/1000
Training Loss: 0.02056164, Training R2: 0.295992
Validation Loss: 0.02170043, Validation R2: 0.122713

Epoch 146/1000
Training Loss: 0.02021511, Training R2: 0.311995
Validation Loss: 0.02153176, Validation R2: 0.130576

Epoch 147/1000
Training Loss: 0.02032251, Training R2: 0.306182
Validation Loss: 0.02166924, Validation R2: 0.124646

Epoch 148/1000
Training Loss: 0.02023438, Training R2: 0.311294
Validation Loss: 0.02200277, Validation R2: 0.111270

Epoch 149/1000
Training Loss: 0.02028515, Training R2: 0.307986
Validation Loss: 0.02157269, Validation R2: 0.129563

Epoch 150/1000
Training Loss: 0.02029011, Training R2: 0.309201
Validation Loss: 0.02155502, Validation R2: 0.130162

Epoch 151/1000
Training Loss: 0.02021324, Training R2: 0.310238
Validation Loss: 0.02170023, Validation R2: 0.124573

Epoch 152/1000
Training Loss: 0.02028990, Training R2: 0.307606
Validation Loss: 0.02147312, Validation R2: 0.135040

Epoch 153/1000
Training Loss: 0.02021777, Training R2: 0.311124
Validation Loss: 0.02190516, Validation R2: 0.117251

Epoch 154/1000
Training Loss: 0.02056841, Training R2: 0.301335
Validation Loss: 0.02189686, Validation R2: 0.117638

Epoch 155/1000
Training Loss: 0.02028987, Training R2: 0.309634
Validation Loss: 0.02143702, Validation R2: 0.135801

Epoch 156/1000
Epoch 00156: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.02042702, Training R2: 0.304287
Validation Loss: 0.02149649, Validation R2: 0.134854

Epoch 157/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_HOMO_energy.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_HOMO_energy.png
