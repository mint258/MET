Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 20000, Training: 16000, Validation: 4000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.12352794, Training R2: -0.038969
Validation Loss: 0.91045701, Validation R2: 0.317193
Saved best model with validation R2 0.317193 to finetune_dipole20000.pth

Epoch 2/1000
Training Loss: 0.83630241, Training R2: 0.378856
Validation Loss: 0.79513148, Validation R2: 0.427417
Saved best model with validation R2 0.427417 to finetune_dipole20000.pth

Epoch 3/1000
Training Loss: 0.79762714, Training R2: 0.420534
Validation Loss: 0.79276747, Validation R2: 0.425737

Epoch 4/1000
Training Loss: 0.79549239, Training R2: 0.424714
Validation Loss: 0.76724075, Validation R2: 0.455133
Saved best model with validation R2 0.455133 to finetune_dipole20000.pth

Epoch 5/1000
Training Loss: 0.77512458, Training R2: 0.442929
Validation Loss: 0.75322550, Validation R2: 0.461359
Saved best model with validation R2 0.461359 to finetune_dipole20000.pth

Epoch 6/1000
Training Loss: 0.75843750, Training R2: 0.455895
Validation Loss: 0.76010087, Validation R2: 0.464421
Saved best model with validation R2 0.464421 to finetune_dipole20000.pth

Epoch 7/1000
Training Loss: 0.75100410, Training R2: 0.464692
Validation Loss: 0.75504241, Validation R2: 0.472483
Saved best model with validation R2 0.472483 to finetune_dipole20000.pth

Epoch 8/1000
Training Loss: 0.72901151, Training R2: 0.483012
Validation Loss: 0.72367610, Validation R2: 0.493267
Saved best model with validation R2 0.493267 to finetune_dipole20000.pth

Epoch 9/1000
Training Loss: 0.72464398, Training R2: 0.491484
Validation Loss: 0.70704829, Validation R2: 0.510910
Saved best model with validation R2 0.510910 to finetune_dipole20000.pth

Epoch 10/1000
Training Loss: 0.71051018, Training R2: 0.506029
Validation Loss: 0.71964047, Validation R2: 0.501549

Epoch 11/1000
Training Loss: 0.71098094, Training R2: 0.509573
Validation Loss: 0.68834162, Validation R2: 0.541569
Saved best model with validation R2 0.541569 to finetune_dipole20000.pth

Epoch 12/1000
Training Loss: 0.69575572, Training R2: 0.523546
Validation Loss: 0.67505423, Validation R2: 0.552838
Saved best model with validation R2 0.552838 to finetune_dipole20000.pth

Epoch 13/1000
Training Loss: 0.68488628, Training R2: 0.537052
Validation Loss: 0.68162991, Validation R2: 0.547394

Epoch 14/1000
Training Loss: 0.67706766, Training R2: 0.549293
Validation Loss: 0.71168985, Validation R2: 0.542645

Epoch 15/1000
Training Loss: 0.66191984, Training R2: 0.567977
Validation Loss: 0.65451811, Validation R2: 0.580828
Saved best model with validation R2 0.580828 to finetune_dipole20000.pth

Epoch 16/1000
Training Loss: 0.65842216, Training R2: 0.570590
Validation Loss: 0.64171537, Validation R2: 0.586986
Saved best model with validation R2 0.586986 to finetune_dipole20000.pth

Epoch 17/1000
Training Loss: 0.64312062, Training R2: 0.590923
Validation Loss: 0.64507922, Validation R2: 0.583001

Epoch 18/1000
Training Loss: 0.64464280, Training R2: 0.591240
Validation Loss: 0.63129537, Validation R2: 0.611286
Saved best model with validation R2 0.611286 to finetune_dipole20000.pth

Epoch 19/1000
Training Loss: 0.63490400, Training R2: 0.603728
Validation Loss: 0.62996786, Validation R2: 0.610230

Epoch 20/1000
Training Loss: 0.63013919, Training R2: 0.607026
Validation Loss: 0.65186512, Validation R2: 0.593932

Epoch 21/1000
Training Loss: 0.61805744, Training R2: 0.624106
Validation Loss: 0.63251411, Validation R2: 0.610884

Epoch 22/1000
Training Loss: 0.61545224, Training R2: 0.629980
Validation Loss: 0.61442999, Validation R2: 0.640573
Saved best model with validation R2 0.640573 to finetune_dipole20000.pth

Epoch 23/1000
Training Loss: 0.59996241, Training R2: 0.645003
Validation Loss: 0.64986377, Validation R2: 0.608426

Epoch 24/1000
Training Loss: 0.60444556, Training R2: 0.645995
Validation Loss: 0.62014903, Validation R2: 0.632182

Epoch 25/1000
Training Loss: 0.60150898, Training R2: 0.652815
Validation Loss: 0.61668783, Validation R2: 0.655969
Saved best model with validation R2 0.655969 to finetune_dipole20000.pth

Epoch 26/1000
Training Loss: 0.58511112, Training R2: 0.671643
Validation Loss: 0.60936930, Validation R2: 0.665361
Saved best model with validation R2 0.665361 to finetune_dipole20000.pth

Epoch 27/1000
Training Loss: 0.60701171, Training R2: 0.653663
Validation Loss: 0.60765603, Validation R2: 0.641783

Epoch 28/1000
Training Loss: 0.58187873, Training R2: 0.663759
Validation Loss: 0.59952416, Validation R2: 0.654110

Epoch 29/1000
Training Loss: 0.58211177, Training R2: 0.681303
Validation Loss: 0.67684267, Validation R2: 0.584256

Epoch 30/1000
Training Loss: 0.57915971, Training R2: 0.680877
Validation Loss: 0.58920757, Validation R2: 0.679016
Saved best model with validation R2 0.679016 to finetune_dipole20000.pth

Epoch 31/1000
Training Loss: 0.56798093, Training R2: 0.696035
Validation Loss: 0.60275958, Validation R2: 0.662406

Epoch 32/1000
Training Loss: 0.56567159, Training R2: 0.697083
Validation Loss: 0.58311219, Validation R2: 0.681071
Saved best model with validation R2 0.681071 to finetune_dipole20000.pth

Epoch 33/1000
Training Loss: 0.55887201, Training R2: 0.702672
Validation Loss: 0.58373054, Validation R2: 0.687851
Saved best model with validation R2 0.687851 to finetune_dipole20000.pth

Epoch 34/1000
Training Loss: 0.56385473, Training R2: 0.702303
Validation Loss: 0.57628462, Validation R2: 0.693111
Saved best model with validation R2 0.693111 to finetune_dipole20000.pth

Epoch 35/1000
Training Loss: 0.55712458, Training R2: 0.707558
Validation Loss: 0.57067236, Validation R2: 0.693273
Saved best model with validation R2 0.693273 to finetune_dipole20000.pth

Epoch 36/1000
Training Loss: 0.54741168, Training R2: 0.718388
Validation Loss: 0.56429504, Validation R2: 0.700896
Saved best model with validation R2 0.700896 to finetune_dipole20000.pth

Epoch 37/1000
Training Loss: 0.55147313, Training R2: 0.715589
Validation Loss: 0.56490305, Validation R2: 0.702805
Saved best model with validation R2 0.702805 to finetune_dipole20000.pth

Epoch 38/1000
Training Loss: 0.54080986, Training R2: 0.723031
Validation Loss: 0.58105256, Validation R2: 0.681494

Epoch 39/1000
Training Loss: 0.54798294, Training R2: 0.720203
Validation Loss: 0.58948703, Validation R2: 0.680128

Epoch 40/1000
Training Loss: 0.53947872, Training R2: 0.724460
Validation Loss: 0.55097888, Validation R2: 0.713358
Saved best model with validation R2 0.713358 to finetune_dipole20000.pth

Epoch 41/1000
Training Loss: 0.54199150, Training R2: 0.722946
Validation Loss: 0.55969447, Validation R2: 0.710671

Epoch 42/1000
Training Loss: 0.54088708, Training R2: 0.726170
Validation Loss: 0.55726125, Validation R2: 0.715096
Saved best model with validation R2 0.715096 to finetune_dipole20000.pth

Epoch 43/1000
Training Loss: 0.53843022, Training R2: 0.729470
Validation Loss: 0.55334861, Validation R2: 0.713415

Epoch 44/1000
Training Loss: 0.52353746, Training R2: 0.740034
Validation Loss: 0.54563758, Validation R2: 0.717413
Saved best model with validation R2 0.717413 to finetune_dipole20000.pth

Epoch 45/1000
Training Loss: 0.52057851, Training R2: 0.740037
Validation Loss: 0.55485176, Validation R2: 0.708473

Epoch 46/1000
Training Loss: 0.51370417, Training R2: 0.746689
Validation Loss: 0.57053069, Validation R2: 0.693788

Epoch 47/1000
Training Loss: 0.51074045, Training R2: 0.750049
Validation Loss: 0.58321722, Validation R2: 0.692227

Epoch 48/1000
Training Loss: 0.52227659, Training R2: 0.741579
Validation Loss: 0.58998222, Validation R2: 0.686649

Epoch 49/1000
Training Loss: 0.51043924, Training R2: 0.750894
Validation Loss: 0.55615312, Validation R2: 0.708382

Epoch 50/1000
Training Loss: 0.51018253, Training R2: 0.751886
Validation Loss: 0.53223188, Validation R2: 0.731011
Saved best model with validation R2 0.731011 to finetune_dipole20000.pth

Epoch 51/1000
Training Loss: 0.49270720, Training R2: 0.763821
Validation Loss: 0.53667009, Validation R2: 0.731841
Saved best model with validation R2 0.731841 to finetune_dipole20000.pth

Epoch 52/1000
Training Loss: 0.50302283, Training R2: 0.756246
Validation Loss: 0.56525828, Validation R2: 0.703240

Epoch 53/1000
Training Loss: 0.50007906, Training R2: 0.762210
Validation Loss: 0.55312240, Validation R2: 0.705742

Epoch 54/1000
Training Loss: 0.49600634, Training R2: 0.762814
Validation Loss: 0.55579899, Validation R2: 0.706219

Epoch 55/1000
Training Loss: 0.49234708, Training R2: 0.766730
Validation Loss: 0.52569487, Validation R2: 0.738164
Saved best model with validation R2 0.738164 to finetune_dipole20000.pth

Epoch 56/1000
Training Loss: 0.48697805, Training R2: 0.770453
Validation Loss: 0.52306037, Validation R2: 0.737975

Epoch 57/1000
Training Loss: 0.48021287, Training R2: 0.774188
Validation Loss: 0.52587177, Validation R2: 0.736496

Epoch 58/1000
Training Loss: 0.49044335, Training R2: 0.767012
Validation Loss: 0.52627084, Validation R2: 0.738512
Saved best model with validation R2 0.738512 to finetune_dipole20000.pth

Epoch 59/1000
Training Loss: 0.47969669, Training R2: 0.776732
Validation Loss: 0.53182110, Validation R2: 0.737483

Epoch 60/1000
Training Loss: 0.48988399, Training R2: 0.768826
Validation Loss: 0.55995673, Validation R2: 0.708592

Epoch 61/1000
Training Loss: 0.47581712, Training R2: 0.777185
Validation Loss: 0.51869251, Validation R2: 0.742838
Saved best model with validation R2 0.742838 to finetune_dipole20000.pth

Epoch 62/1000
Training Loss: 0.46789289, Training R2: 0.784214
Validation Loss: 0.51574030, Validation R2: 0.742946
Saved best model with validation R2 0.742946 to finetune_dipole20000.pth

Epoch 63/1000
Training Loss: 0.48167144, Training R2: 0.774589
Validation Loss: 0.51368253, Validation R2: 0.745908
Saved best model with validation R2 0.745908 to finetune_dipole20000.pth

Epoch 64/1000
Training Loss: 0.47851715, Training R2: 0.776909
Validation Loss: 0.51349730, Validation R2: 0.748863
Saved best model with validation R2 0.748863 to finetune_dipole20000.pth

Epoch 65/1000
Training Loss: 0.46596099, Training R2: 0.786314
Validation Loss: 0.50732053, Validation R2: 0.751649
Saved best model with validation R2 0.751649 to finetune_dipole20000.pth

Epoch 66/1000
Training Loss: 0.48975880, Training R2: 0.763694
Validation Loss: 0.53570545, Validation R2: 0.732663

Epoch 67/1000
Training Loss: 0.46131800, Training R2: 0.788786
Validation Loss: 0.54549357, Validation R2: 0.724144

Epoch 68/1000
Training Loss: 0.46127570, Training R2: 0.789424
Validation Loss: 0.51291056, Validation R2: 0.747028

Epoch 69/1000
Training Loss: 0.45207659, Training R2: 0.795968
Validation Loss: 0.51213537, Validation R2: 0.744386

Epoch 70/1000
Training Loss: 0.45765484, Training R2: 0.793568
Validation Loss: 0.60813670, Validation R2: 0.659806

Epoch 71/1000
Training Loss: 0.47005925, Training R2: 0.785679
Validation Loss: 0.51839100, Validation R2: 0.745547

Epoch 72/1000
Training Loss: 0.44863059, Training R2: 0.800007
Validation Loss: 0.51670942, Validation R2: 0.747709

Epoch 73/1000
Training Loss: 0.44888678, Training R2: 0.799220
Validation Loss: 0.50628333, Validation R2: 0.755208
Saved best model with validation R2 0.755208 to finetune_dipole20000.pth

Epoch 74/1000
Training Loss: 0.44546205, Training R2: 0.802209
Validation Loss: 0.51280400, Validation R2: 0.748348

Epoch 75/1000
Training Loss: 0.43766033, Training R2: 0.806970
Validation Loss: 0.51103209, Validation R2: 0.749845

Epoch 76/1000
Training Loss: 0.44339063, Training R2: 0.803689
Validation Loss: 0.52636176, Validation R2: 0.733222

Epoch 77/1000
Training Loss: 0.44255193, Training R2: 0.804038
Validation Loss: 0.53308307, Validation R2: 0.737861

Epoch 78/1000
Training Loss: 0.44066395, Training R2: 0.805348
Validation Loss: 0.53751135, Validation R2: 0.717103

Epoch 79/1000
Training Loss: 0.43878321, Training R2: 0.806827
Validation Loss: 0.51371731, Validation R2: 0.747566

Epoch 80/1000
Training Loss: 0.42529623, Training R2: 0.816144
Validation Loss: 0.54100411, Validation R2: 0.728342

Epoch 81/1000
Training Loss: 0.43682272, Training R2: 0.807384
Validation Loss: 0.53192243, Validation R2: 0.728930

Epoch 82/1000
Training Loss: 0.43063094, Training R2: 0.812616
Validation Loss: 0.49295815, Validation R2: 0.761300
Saved best model with validation R2 0.761300 to finetune_dipole20000.pth

Epoch 83/1000
Training Loss: 0.42429794, Training R2: 0.817946
Validation Loss: 0.51626098, Validation R2: 0.742610

Epoch 84/1000
Training Loss: 0.42885868, Training R2: 0.814811
Validation Loss: 0.51464396, Validation R2: 0.742057

Epoch 85/1000
Training Loss: 0.41765006, Training R2: 0.821850
Validation Loss: 0.50187031, Validation R2: 0.754504

Epoch 86/1000
Training Loss: 0.41244145, Training R2: 0.827209
Validation Loss: 0.53467086, Validation R2: 0.729580

Epoch 87/1000
Training Loss: 0.41275624, Training R2: 0.825785
Validation Loss: 0.50379449, Validation R2: 0.754382

Epoch 88/1000
Training Loss: 0.40782727, Training R2: 0.828819
Validation Loss: 0.49320620, Validation R2: 0.761416
Saved best model with validation R2 0.761416 to finetune_dipole20000.pth

Epoch 89/1000
Training Loss: 0.40000805, Training R2: 0.834729
Validation Loss: 0.51088040, Validation R2: 0.750067

Epoch 90/1000
Training Loss: 0.41327810, Training R2: 0.827181
Validation Loss: 0.52882134, Validation R2: 0.728467

Epoch 91/1000
Training Loss: 0.40641661, Training R2: 0.830570
Validation Loss: 0.50362377, Validation R2: 0.759675

Epoch 92/1000
Training Loss: 0.40410251, Training R2: 0.832718
Validation Loss: 0.49426751, Validation R2: 0.762844
Saved best model with validation R2 0.762844 to finetune_dipole20000.pth

Epoch 93/1000
Training Loss: 0.39752840, Training R2: 0.836924
Validation Loss: 0.49812404, Validation R2: 0.758755

Epoch 94/1000
Training Loss: 0.40966947, Training R2: 0.829968
Validation Loss: 0.51979142, Validation R2: 0.739488

Epoch 95/1000
Training Loss: 0.39524554, Training R2: 0.838401
Validation Loss: 0.49834581, Validation R2: 0.756891

Epoch 96/1000
Training Loss: 0.39469866, Training R2: 0.839924
Validation Loss: 0.49818558, Validation R2: 0.759187

Epoch 97/1000
Training Loss: 0.39101347, Training R2: 0.841482
Validation Loss: 0.49849476, Validation R2: 0.756552

Epoch 98/1000
Training Loss: 0.38002166, Training R2: 0.849686
Validation Loss: 0.50998283, Validation R2: 0.752677

Epoch 99/1000
Training Loss: 0.39162726, Training R2: 0.842238
Validation Loss: 0.49780029, Validation R2: 0.754994

Epoch 100/1000
Training Loss: 0.38064184, Training R2: 0.849467
Validation Loss: 0.51285127, Validation R2: 0.740602

Epoch 101/1000
Training Loss: 0.38634025, Training R2: 0.845882
Validation Loss: 0.48661011, Validation R2: 0.765571
Saved best model with validation R2 0.765571 to finetune_dipole20000.pth

Epoch 102/1000
Training Loss: 0.36678405, Training R2: 0.857656
Validation Loss: 0.49892141, Validation R2: 0.753445

Epoch 103/1000
Training Loss: 0.37346746, Training R2: 0.854324
Validation Loss: 0.48914192, Validation R2: 0.762219

Epoch 104/1000
Training Loss: 0.36594792, Training R2: 0.859290
Validation Loss: 0.48732039, Validation R2: 0.764098

Epoch 105/1000
Training Loss: 0.38771026, Training R2: 0.847835
Validation Loss: 0.49167051, Validation R2: 0.759935

Epoch 106/1000
Training Loss: 0.36758827, Training R2: 0.859359
Validation Loss: 0.49082834, Validation R2: 0.764824

Epoch 107/1000
Training Loss: 0.36018758, Training R2: 0.863838
Validation Loss: 0.49590925, Validation R2: 0.757203

Epoch 108/1000
Training Loss: 0.35486105, Training R2: 0.865100
Validation Loss: 0.48779626, Validation R2: 0.763947

Epoch 109/1000
Training Loss: 0.34979956, Training R2: 0.869483
Validation Loss: 0.48819259, Validation R2: 0.766405
Saved best model with validation R2 0.766405 to finetune_dipole20000.pth

Epoch 110/1000
Training Loss: 0.35328551, Training R2: 0.867987
Validation Loss: 0.49253029, Validation R2: 0.757389

Epoch 111/1000
Training Loss: 0.35887345, Training R2: 0.864896
Validation Loss: 0.48732563, Validation R2: 0.760233

Epoch 112/1000
Training Loss: 0.34776521, Training R2: 0.870513
Validation Loss: 0.48338137, Validation R2: 0.763002

Epoch 113/1000
Training Loss: 0.34357799, Training R2: 0.873664
Validation Loss: 0.48286113, Validation R2: 0.770679
Saved best model with validation R2 0.770679 to finetune_dipole20000.pth

Epoch 114/1000
Training Loss: 0.35156270, Training R2: 0.868862
Validation Loss: 0.49703448, Validation R2: 0.755784

Epoch 115/1000
Training Loss: 0.34496476, Training R2: 0.873221
Validation Loss: 0.49066698, Validation R2: 0.762154

Epoch 116/1000
Training Loss: 0.34192483, Training R2: 0.876842
Validation Loss: 0.48258640, Validation R2: 0.768194

Epoch 117/1000
Training Loss: 0.33867993, Training R2: 0.877074
Validation Loss: 0.51170865, Validation R2: 0.748434

Epoch 118/1000
Training Loss: 0.33809526, Training R2: 0.877975
Validation Loss: 0.48158359, Validation R2: 0.764058

Epoch 119/1000
Training Loss: 0.33150219, Training R2: 0.882451
Validation Loss: 0.50642876, Validation R2: 0.746720

Epoch 120/1000
Training Loss: 0.32632264, Training R2: 0.885401
Validation Loss: 0.47620568, Validation R2: 0.770980
Saved best model with validation R2 0.770980 to finetune_dipole20000.pth

Epoch 121/1000
Training Loss: 0.32587041, Training R2: 0.885844
Validation Loss: 0.48771034, Validation R2: 0.761380

Epoch 122/1000
Training Loss: 0.32893194, Training R2: 0.884321
Validation Loss: 0.49003472, Validation R2: 0.763026

Epoch 123/1000
Training Loss: 0.32005958, Training R2: 0.888706
Validation Loss: 0.49444685, Validation R2: 0.763765

Epoch 124/1000
Training Loss: 0.31726680, Training R2: 0.890023
Validation Loss: 0.48831327, Validation R2: 0.765638

Epoch 125/1000
Training Loss: 0.31421359, Training R2: 0.893197
Validation Loss: 0.50511450, Validation R2: 0.750476

Epoch 126/1000
Training Loss: 0.30989505, Training R2: 0.894560
Validation Loss: 0.49207935, Validation R2: 0.762714

Epoch 127/1000
Training Loss: 0.31882456, Training R2: 0.892084
Validation Loss: 0.48182117, Validation R2: 0.768407

Epoch 128/1000
Training Loss: 0.32688848, Training R2: 0.887413
Validation Loss: 0.48364896, Validation R2: 0.762686

Epoch 129/1000
Training Loss: 0.31689005, Training R2: 0.892230
Validation Loss: 0.48060218, Validation R2: 0.768544

Epoch 130/1000
Training Loss: 0.31791995, Training R2: 0.893262
Validation Loss: 0.48801442, Validation R2: 0.763071

Epoch 131/1000
Training Loss: 0.30044494, Training R2: 0.901143
Validation Loss: 0.48798238, Validation R2: 0.759432

Epoch 132/1000
Training Loss: 0.29455868, Training R2: 0.903442
Validation Loss: 0.47659339, Validation R2: 0.771049
Saved best model with validation R2 0.771049 to finetune_dipole20000.pth

Epoch 133/1000
Training Loss: 0.30967340, Training R2: 0.897102
Validation Loss: 0.48455969, Validation R2: 0.766987

Epoch 134/1000
Training Loss: 0.30291958, Training R2: 0.900557
Validation Loss: 0.47672095, Validation R2: 0.770257

Epoch 135/1000
Training Loss: 0.29162466, Training R2: 0.906002
Validation Loss: 0.48755312, Validation R2: 0.760860

Epoch 136/1000
Training Loss: 0.29046770, Training R2: 0.907081
Validation Loss: 0.48155990, Validation R2: 0.764885

Epoch 137/1000
Training Loss: 0.29015410, Training R2: 0.906874
Validation Loss: 0.47397441, Validation R2: 0.773289
Saved best model with validation R2 0.773289 to finetune_dipole20000.pth

Epoch 138/1000
Training Loss: 0.27726944, Training R2: 0.912431
Validation Loss: 0.47905470, Validation R2: 0.769159

Epoch 139/1000
Training Loss: 0.29305861, Training R2: 0.905677
Validation Loss: 0.48618720, Validation R2: 0.767351

Epoch 140/1000
Training Loss: 0.27652723, Training R2: 0.913756
Validation Loss: 0.49918663, Validation R2: 0.750785

Epoch 141/1000
Training Loss: 0.28506109, Training R2: 0.910415
Validation Loss: 0.48738402, Validation R2: 0.757810

Epoch 142/1000
Training Loss: 0.28656426, Training R2: 0.910440
Validation Loss: 0.48219981, Validation R2: 0.766721

Epoch 143/1000
Training Loss: 0.28262145, Training R2: 0.912158
Validation Loss: 0.48235092, Validation R2: 0.763824

Epoch 144/1000
Training Loss: 0.27421949, Training R2: 0.916619
Validation Loss: 0.47990878, Validation R2: 0.763699

Epoch 145/1000
Training Loss: 0.27854544, Training R2: 0.914985
Validation Loss: 0.49887849, Validation R2: 0.753531

Epoch 146/1000
Training Loss: 0.28661861, Training R2: 0.911137
Validation Loss: 0.47481033, Validation R2: 0.767293

Epoch 147/1000
Training Loss: 0.26363166, Training R2: 0.921515
Validation Loss: 0.48442697, Validation R2: 0.761277

Epoch 148/1000
Training Loss: 0.28283976, Training R2: 0.913290
Validation Loss: 0.48277283, Validation R2: 0.761542

Epoch 149/1000
Training Loss: 0.28047781, Training R2: 0.914117
Validation Loss: 0.47939912, Validation R2: 0.765862

Epoch 150/1000
Training Loss: 0.25733137, Training R2: 0.924996
Validation Loss: 0.48114562, Validation R2: 0.764440

Epoch 151/1000
Training Loss: 0.26175710, Training R2: 0.923402
Validation Loss: 0.47382637, Validation R2: 0.771467

Epoch 152/1000
Training Loss: 0.25829317, Training R2: 0.924574
Validation Loss: 0.48962403, Validation R2: 0.755725

Epoch 153/1000
Training Loss: 0.25440195, Training R2: 0.926662
Validation Loss: 0.48540193, Validation R2: 0.758770

Epoch 154/1000
Training Loss: 0.25930105, Training R2: 0.924566
Validation Loss: 0.48146620, Validation R2: 0.760218

Epoch 155/1000
Training Loss: 0.25125028, Training R2: 0.928596
Validation Loss: 0.48181656, Validation R2: 0.761638

Epoch 156/1000
Training Loss: 0.26581531, Training R2: 0.922630
Validation Loss: 0.47787058, Validation R2: 0.767220

Epoch 157/1000
Training Loss: 0.25803858, Training R2: 0.926325
Validation Loss: 0.48821209, Validation R2: 0.757903

Epoch 158/1000
Epoch 00158: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.25026566, Training R2: 0.929351
Validation Loss: 0.48092085, Validation R2: 0.766547

Epoch 159/1000
学习率已减少 1 次
Training Loss: 0.21887517, Training R2: 0.941406
Validation Loss: 0.46771332, Validation R2: 0.773286

Epoch 160/1000
Training Loss: 0.20682448, Training R2: 0.945210
Validation Loss: 0.47085431, Validation R2: 0.769714

Epoch 161/1000
Training Loss: 0.20484020, Training R2: 0.946187
Validation Loss: 0.47208950, Validation R2: 0.770169

Epoch 162/1000
Training Loss: 0.20501990, Training R2: 0.946002
Validation Loss: 0.47317846, Validation R2: 0.771003

Epoch 163/1000
Training Loss: 0.20391354, Training R2: 0.946841
Validation Loss: 0.47639185, Validation R2: 0.764296

Epoch 164/1000
Training Loss: 0.19917802, Training R2: 0.948783
Validation Loss: 0.46827826, Validation R2: 0.773998
Saved best model with validation R2 0.773998 to finetune_dipole20000.pth

Epoch 165/1000
Training Loss: 0.20125754, Training R2: 0.947888
Validation Loss: 0.46942977, Validation R2: 0.771660

Epoch 166/1000
Training Loss: 0.20030667, Training R2: 0.948439
Validation Loss: 0.46941074, Validation R2: 0.771959

Epoch 167/1000
Training Loss: 0.19766794, Training R2: 0.949490
Validation Loss: 0.46906703, Validation R2: 0.772145

Epoch 168/1000
Training Loss: 0.18896406, Training R2: 0.952153
Validation Loss: 0.47042733, Validation R2: 0.769632

Epoch 169/1000
Training Loss: 0.19196953, Training R2: 0.951343
Validation Loss: 0.47335074, Validation R2: 0.767975

Epoch 170/1000
Training Loss: 0.19472139, Training R2: 0.950801
Validation Loss: 0.48294728, Validation R2: 0.757312

Epoch 171/1000
Training Loss: 0.18951939, Training R2: 0.952607
Validation Loss: 0.47377387, Validation R2: 0.769031

Epoch 172/1000
Training Loss: 0.18406213, Training R2: 0.954100
Validation Loss: 0.47659721, Validation R2: 0.762859

Epoch 173/1000
Training Loss: 0.18390093, Training R2: 0.954308
Validation Loss: 0.47021115, Validation R2: 0.768373

Epoch 174/1000
Training Loss: 0.18361402, Training R2: 0.954559
Validation Loss: 0.47052709, Validation R2: 0.771113

Epoch 175/1000
Training Loss: 0.18684594, Training R2: 0.954028
Validation Loss: 0.47321385, Validation R2: 0.767260

Epoch 176/1000
Training Loss: 0.17970181, Training R2: 0.956492
Validation Loss: 0.47433009, Validation R2: 0.765345

Epoch 177/1000
Training Loss: 0.18379625, Training R2: 0.955088
Validation Loss: 0.47765047, Validation R2: 0.762970

Epoch 178/1000
Training Loss: 0.18375498, Training R2: 0.955486
Validation Loss: 0.47686692, Validation R2: 0.764160

Epoch 179/1000
Training Loss: 0.18297986, Training R2: 0.955540
Validation Loss: 0.47656635, Validation R2: 0.765143

Epoch 180/1000
Training Loss: 0.17828242, Training R2: 0.957130
Validation Loss: 0.47788232, Validation R2: 0.763564

Epoch 181/1000
Training Loss: 0.17837506, Training R2: 0.957986
Validation Loss: 0.48022343, Validation R2: 0.761018

Epoch 182/1000
Training Loss: 0.17612146, Training R2: 0.958527
Validation Loss: 0.47627758, Validation R2: 0.764993

Epoch 183/1000
Training Loss: 0.16892888, Training R2: 0.960420
Validation Loss: 0.47031640, Validation R2: 0.768858

Epoch 184/1000
Training Loss: 0.17743355, Training R2: 0.958257
Validation Loss: 0.48125720, Validation R2: 0.760181

Epoch 185/1000
Epoch 00185: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.17321988, Training R2: 0.959878
Validation Loss: 0.47663954, Validation R2: 0.763522

Epoch 186/1000
学习率已减少 2 次
Training Loss: 0.15424824, Training R2: 0.964468
Validation Loss: 0.47036712, Validation R2: 0.768322

Epoch 187/1000
Training Loss: 0.14479544, Training R2: 0.966139
Validation Loss: 0.47347805, Validation R2: 0.765540

Epoch 188/1000
Training Loss: 0.14419365, Training R2: 0.966398
Validation Loss: 0.47158593, Validation R2: 0.767579

Epoch 189/1000
Training Loss: 0.14274042, Training R2: 0.966899
Validation Loss: 0.47768699, Validation R2: 0.763546

Epoch 190/1000
Training Loss: 0.14237098, Training R2: 0.967055
Validation Loss: 0.47302331, Validation R2: 0.766178

Epoch 191/1000
Training Loss: 0.14139510, Training R2: 0.967149
Validation Loss: 0.47132417, Validation R2: 0.767759

Epoch 192/1000
Training Loss: 0.13731579, Training R2: 0.968027
Validation Loss: 0.47047748, Validation R2: 0.768985

Epoch 193/1000
Training Loss: 0.13838652, Training R2: 0.967946
Validation Loss: 0.47362124, Validation R2: 0.766468

Epoch 194/1000
Training Loss: 0.13851819, Training R2: 0.968102
Validation Loss: 0.47224267, Validation R2: 0.766276

Epoch 195/1000
Training Loss: 0.13759155, Training R2: 0.968297
Validation Loss: 0.47566379, Validation R2: 0.763117

Epoch 196/1000
Training Loss: 0.13636649, Training R2: 0.968707
Validation Loss: 0.47478602, Validation R2: 0.765422

Epoch 197/1000
Training Loss: 0.13581338, Training R2: 0.969100
Validation Loss: 0.47563830, Validation R2: 0.763449

Epoch 198/1000
Training Loss: 0.13437428, Training R2: 0.969490
Validation Loss: 0.47579641, Validation R2: 0.761307

Epoch 199/1000
Training Loss: 0.13465764, Training R2: 0.969491
Validation Loss: 0.47166402, Validation R2: 0.767169

Epoch 200/1000
Training Loss: 0.13345588, Training R2: 0.969728
Validation Loss: 0.47617192, Validation R2: 0.763975

Epoch 201/1000
Training Loss: 0.13004160, Training R2: 0.970545
Validation Loss: 0.47496518, Validation R2: 0.764223

Epoch 202/1000
Training Loss: 0.12989241, Training R2: 0.970613
Validation Loss: 0.47428883, Validation R2: 0.763758

Epoch 203/1000
Training Loss: 0.13044990, Training R2: 0.970719
Validation Loss: 0.47650295, Validation R2: 0.762555

Epoch 204/1000
Training Loss: 0.12957811, Training R2: 0.970917
Validation Loss: 0.47852257, Validation R2: 0.760626

Epoch 205/1000
Training Loss: 0.12961578, Training R2: 0.971049
Validation Loss: 0.47719526, Validation R2: 0.762280

Epoch 206/1000
Epoch 00206: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.12689109, Training R2: 0.971620
Validation Loss: 0.47677352, Validation R2: 0.762864

Epoch 207/1000
学习率已减少 3 次
Training Loss: 0.11820952, Training R2: 0.972935
Validation Loss: 0.47391990, Validation R2: 0.765541

Epoch 208/1000
Training Loss: 0.11486421, Training R2: 0.973373
Validation Loss: 0.47507047, Validation R2: 0.763971

Epoch 209/1000
Training Loss: 0.11438432, Training R2: 0.973617
Validation Loss: 0.47528634, Validation R2: 0.763904

Epoch 210/1000
Training Loss: 0.11275557, Training R2: 0.973749
Validation Loss: 0.47494405, Validation R2: 0.764163

Epoch 211/1000
Training Loss: 0.11220789, Training R2: 0.973985
Validation Loss: 0.47547277, Validation R2: 0.763590

Epoch 212/1000
Training Loss: 0.11450526, Training R2: 0.973624
Validation Loss: 0.47600535, Validation R2: 0.762902

Epoch 213/1000
Training Loss: 0.11001427, Training R2: 0.974315
Validation Loss: 0.47451435, Validation R2: 0.764186

Epoch 214/1000
Training Loss: 0.10962329, Training R2: 0.974488
Validation Loss: 0.47576954, Validation R2: 0.763675

Epoch 215/1000
Training Loss: 0.11052596, Training R2: 0.974468
Validation Loss: 0.47721378, Validation R2: 0.761438

Epoch 216/1000
Training Loss: 0.10957434, Training R2: 0.974521
Validation Loss: 0.47510115, Validation R2: 0.764149

Epoch 217/1000
Training Loss: 0.10750584, Training R2: 0.974817
Validation Loss: 0.47515702, Validation R2: 0.763475

Epoch 218/1000
Training Loss: 0.10843734, Training R2: 0.974836
Validation Loss: 0.47424732, Validation R2: 0.764717

Epoch 219/1000
Training Loss: 0.10714959, Training R2: 0.975023
Validation Loss: 0.47535835, Validation R2: 0.764001

Epoch 220/1000
Training Loss: 0.10675188, Training R2: 0.975049
Validation Loss: 0.47544411, Validation R2: 0.763297

Epoch 221/1000
Training Loss: 0.10704761, Training R2: 0.975145
Validation Loss: 0.47504912, Validation R2: 0.763307

Epoch 222/1000
Training Loss: 0.10700544, Training R2: 0.975153
Validation Loss: 0.47669903, Validation R2: 0.762718

Epoch 223/1000
Training Loss: 0.10629739, Training R2: 0.975366
Validation Loss: 0.47606047, Validation R2: 0.762974

Epoch 224/1000
Training Loss: 0.10530507, Training R2: 0.975476
Validation Loss: 0.47611259, Validation R2: 0.762914

Epoch 225/1000
Training Loss: 0.10398674, Training R2: 0.975832
Validation Loss: 0.47496859, Validation R2: 0.764058

Epoch 226/1000
Training Loss: 0.10376580, Training R2: 0.975930
Validation Loss: 0.47640579, Validation R2: 0.762768

Epoch 227/1000
Epoch 00227: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.10389842, Training R2: 0.975956
Validation Loss: 0.47804530, Validation R2: 0.761325

Epoch 228/1000
学习率已减少 4 次
Training Loss: 0.09854046, Training R2: 0.976511
Validation Loss: 0.47695577, Validation R2: 0.761732

Epoch 229/1000
Training Loss: 0.09792000, Training R2: 0.976583
Validation Loss: 0.47548919, Validation R2: 0.763580

Epoch 230/1000
Training Loss: 0.09663490, Training R2: 0.976701
Validation Loss: 0.47624734, Validation R2: 0.762550

Epoch 231/1000
Training Loss: 0.09612066, Training R2: 0.976833
Validation Loss: 0.47696761, Validation R2: 0.761647

Epoch 232/1000
Training Loss: 0.09550583, Training R2: 0.976914
Validation Loss: 0.47744948, Validation R2: 0.761492

Epoch 233/1000
Training Loss: 0.09563715, Training R2: 0.976889
Validation Loss: 0.47695486, Validation R2: 0.761972

Epoch 234/1000
Training Loss: 0.09512229, Training R2: 0.976997
Validation Loss: 0.47678698, Validation R2: 0.761674

Epoch 235/1000
Training Loss: 0.09456456, Training R2: 0.977039
Validation Loss: 0.47754697, Validation R2: 0.761663

Epoch 236/1000
Training Loss: 0.09488945, Training R2: 0.977034
Validation Loss: 0.47638732, Validation R2: 0.762425

Epoch 237/1000
Training Loss: 0.09436813, Training R2: 0.977086
Validation Loss: 0.47707024, Validation R2: 0.761876

Epoch 238/1000
Training Loss: 0.09403281, Training R2: 0.977158
Validation Loss: 0.47797968, Validation R2: 0.761205

Epoch 239/1000
Training Loss: 0.09509479, Training R2: 0.977108
Validation Loss: 0.47850020, Validation R2: 0.760070

Epoch 240/1000
Training Loss: 0.09481206, Training R2: 0.977188
Validation Loss: 0.47738303, Validation R2: 0.761632

Epoch 241/1000
Training Loss: 0.09359368, Training R2: 0.977290
Validation Loss: 0.47798808, Validation R2: 0.761141

Epoch 242/1000
Training Loss: 0.09290973, Training R2: 0.977464
Validation Loss: 0.47706911, Validation R2: 0.761738

Epoch 243/1000
Training Loss: 0.09240699, Training R2: 0.977474
Validation Loss: 0.47739345, Validation R2: 0.761526

Epoch 244/1000
Training Loss: 0.09230554, Training R2: 0.977558
Validation Loss: 0.47706940, Validation R2: 0.761906

Epoch 245/1000
Training Loss: 0.09195317, Training R2: 0.977613
Validation Loss: 0.47730328, Validation R2: 0.761588

Epoch 246/1000
Training Loss: 0.09209235, Training R2: 0.977665
Validation Loss: 0.47665428, Validation R2: 0.761712

Epoch 247/1000
Training Loss: 0.09213165, Training R2: 0.977682
Validation Loss: 0.47807206, Validation R2: 0.761089

Epoch 248/1000
Epoch 00248: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.09203463, Training R2: 0.977755
Validation Loss: 0.47780432, Validation R2: 0.761274

Epoch 249/1000
学习率已减少 5 次
Training Loss: 0.08929832, Training R2: 0.977935
Validation Loss: 0.47789670, Validation R2: 0.761188

Epoch 250/1000
Training Loss: 0.08772984, Training R2: 0.978005
Validation Loss: 0.47746292, Validation R2: 0.761277

Epoch 251/1000
Training Loss: 0.08784874, Training R2: 0.978052
Validation Loss: 0.47805847, Validation R2: 0.761117

Epoch 252/1000
Training Loss: 0.08728735, Training R2: 0.978070
Validation Loss: 0.47784499, Validation R2: 0.761355

Epoch 253/1000
Training Loss: 0.08712545, Training R2: 0.978080
Validation Loss: 0.47774745, Validation R2: 0.761242

Epoch 254/1000
Training Loss: 0.08716083, Training R2: 0.978134
Validation Loss: 0.47781897, Validation R2: 0.761123

Epoch 255/1000
Training Loss: 0.08694303, Training R2: 0.978138
Validation Loss: 0.47810295, Validation R2: 0.760812

Epoch 256/1000
Training Loss: 0.08671429, Training R2: 0.978158
Validation Loss: 0.47830516, Validation R2: 0.760680

Epoch 257/1000
Training Loss: 0.08653723, Training R2: 0.978167
Validation Loss: 0.47793850, Validation R2: 0.761062

Epoch 258/1000
Training Loss: 0.08652913, Training R2: 0.978235
Validation Loss: 0.47771642, Validation R2: 0.761300

Epoch 259/1000
Training Loss: 0.08661178, Training R2: 0.978185
Validation Loss: 0.47826866, Validation R2: 0.760973

Epoch 260/1000
Training Loss: 0.08603107, Training R2: 0.978224
Validation Loss: 0.47810313, Validation R2: 0.760940

Epoch 261/1000
Training Loss: 0.08594753, Training R2: 0.978220
Validation Loss: 0.47854556, Validation R2: 0.760533

Epoch 262/1000
Training Loss: 0.08635920, Training R2: 0.978270
Validation Loss: 0.47831997, Validation R2: 0.760608

Epoch 263/1000
Training Loss: 0.08610118, Training R2: 0.978273
Validation Loss: 0.47829238, Validation R2: 0.760824

Epoch 264/1000
Training Loss: 0.08564241, Training R2: 0.978348
Validation Loss: 0.47815831, Validation R2: 0.761030

Epoch 265/1000
Training Loss: 0.08570962, Training R2: 0.978350
Validation Loss: 0.47839478, Validation R2: 0.760494

Epoch 266/1000
Training Loss: 0.08524948, Training R2: 0.978430
Validation Loss: 0.47862013, Validation R2: 0.760611

Epoch 267/1000
Training Loss: 0.08557804, Training R2: 0.978421
Validation Loss: 0.47799019, Validation R2: 0.761007

Epoch 268/1000
Training Loss: 0.08507517, Training R2: 0.978441
Validation Loss: 0.47826348, Validation R2: 0.760715

Epoch 269/1000
Epoch 00269: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.08492821, Training R2: 0.978500
Validation Loss: 0.47838286, Validation R2: 0.760681

Epoch 270/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
