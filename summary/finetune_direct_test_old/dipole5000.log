Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1025539

Epoch 1/1000
Training Loss: 1.48116124, Training R2: -0.599551
Validation Loss: 1.17426000, Validation R2: -0.156010
Saved best model with validation R2 -0.156010 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.21175637, Training R2: -0.042024
Validation Loss: 1.14404141, Validation R2: 0.012447
Saved best model with validation R2 0.012447 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.16794926, Training R2: 0.003602
Validation Loss: 1.07506088, Validation R2: 0.113763
Saved best model with validation R2 0.113763 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.09320257, Training R2: 0.130232
Validation Loss: 1.15863066, Validation R2: -0.084848

Epoch 5/1000
Training Loss: 1.08765778, Training R2: 0.138064
Validation Loss: 1.03280219, Validation R2: 0.150903
Saved best model with validation R2 0.150903 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.00926197, Training R2: 0.249980
Validation Loss: 0.99223367, Validation R2: 0.200140
Saved best model with validation R2 0.200140 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 1.00614416, Training R2: 0.252179
Validation Loss: 1.01451187, Validation R2: 0.184440

Epoch 8/1000
Training Loss: 0.96512345, Training R2: 0.307011
Validation Loss: 0.92558013, Validation R2: 0.296477
Saved best model with validation R2 0.296477 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 0.88102155, Training R2: 0.380695
Validation Loss: 0.84361412, Validation R2: 0.363219
Saved best model with validation R2 0.363219 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.84019225, Training R2: 0.423754
Validation Loss: 0.80203055, Validation R2: 0.399525
Saved best model with validation R2 0.399525 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 0.88683067, Training R2: 0.372421
Validation Loss: 0.92414036, Validation R2: 0.308092

Epoch 12/1000
Training Loss: 0.88913774, Training R2: 0.388639
Validation Loss: 0.84334768, Validation R2: 0.374853

Epoch 13/1000
Training Loss: 0.82072450, Training R2: 0.445778
Validation Loss: 0.82136082, Validation R2: 0.397233

Epoch 14/1000
Training Loss: 0.80369137, Training R2: 0.459165
Validation Loss: 0.79968240, Validation R2: 0.411106
Saved best model with validation R2 0.411106 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 0.77739288, Training R2: 0.480124
Validation Loss: 0.82757888, Validation R2: 0.400067

Epoch 16/1000
Training Loss: 0.81435083, Training R2: 0.444604
Validation Loss: 0.79896644, Validation R2: 0.428623
Saved best model with validation R2 0.428623 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.80794117, Training R2: 0.444108
Validation Loss: 0.81345115, Validation R2: 0.377951

Epoch 18/1000
Training Loss: 0.80517141, Training R2: 0.451703
Validation Loss: 0.78548535, Validation R2: 0.437387
Saved best model with validation R2 0.437387 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.77945543, Training R2: 0.479079
Validation Loss: 0.80548946, Validation R2: 0.416886

Epoch 20/1000
Training Loss: 0.79022493, Training R2: 0.476047
Validation Loss: 0.77818108, Validation R2: 0.442793
Saved best model with validation R2 0.442793 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.77365485, Training R2: 0.491669
Validation Loss: 0.76935564, Validation R2: 0.463043
Saved best model with validation R2 0.463043 to best_finetuned_model.pth

Epoch 22/1000
Training Loss: 0.78694979, Training R2: 0.478949
Validation Loss: 0.76508197, Validation R2: 0.454957

Epoch 23/1000
Training Loss: 0.75378925, Training R2: 0.516457
Validation Loss: 0.75619623, Validation R2: 0.455237

Epoch 24/1000
Training Loss: 0.72581012, Training R2: 0.535654
Validation Loss: 0.73739511, Validation R2: 0.495729
Saved best model with validation R2 0.495729 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 0.74754389, Training R2: 0.529022
Validation Loss: 0.74408395, Validation R2: 0.487536

Epoch 26/1000
Training Loss: 0.74241726, Training R2: 0.530269
Validation Loss: 0.76902900, Validation R2: 0.482149

Epoch 27/1000
Training Loss: 0.71385212, Training R2: 0.565437
Validation Loss: 0.72272292, Validation R2: 0.501929
Saved best model with validation R2 0.501929 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 0.72024842, Training R2: 0.551165
Validation Loss: 0.75416556, Validation R2: 0.492111

Epoch 29/1000
Training Loss: 0.70562142, Training R2: 0.571710
Validation Loss: 0.73373053, Validation R2: 0.491656

Epoch 30/1000
Training Loss: 0.70459636, Training R2: 0.575873
Validation Loss: 0.77620844, Validation R2: 0.436493

Epoch 31/1000
Training Loss: 0.70646036, Training R2: 0.573279
Validation Loss: 0.73388745, Validation R2: 0.519268
Saved best model with validation R2 0.519268 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 0.67728735, Training R2: 0.609028
Validation Loss: 0.69119988, Validation R2: 0.558968
Saved best model with validation R2 0.558968 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 0.68421027, Training R2: 0.598361
Validation Loss: 0.75647091, Validation R2: 0.476264

Epoch 34/1000
Training Loss: 0.68629722, Training R2: 0.591837
Validation Loss: 0.68981529, Validation R2: 0.539105

Epoch 35/1000
Training Loss: 0.65642004, Training R2: 0.624622
Validation Loss: 0.66965467, Validation R2: 0.575222
Saved best model with validation R2 0.575222 to best_finetuned_model.pth

Epoch 36/1000
Training Loss: 0.67858390, Training R2: 0.602470
Validation Loss: 0.74316284, Validation R2: 0.506144

Epoch 37/1000
Training Loss: 0.70823821, Training R2: 0.580069
Validation Loss: 0.75750534, Validation R2: 0.492522

Epoch 38/1000
Training Loss: 0.67003999, Training R2: 0.620501
Validation Loss: 0.66720700, Validation R2: 0.572192

Epoch 39/1000
Training Loss: 0.65744508, Training R2: 0.624877
Validation Loss: 0.67931191, Validation R2: 0.581323
Saved best model with validation R2 0.581323 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.68478369, Training R2: 0.604513
Validation Loss: 0.70166647, Validation R2: 0.522397

Epoch 41/1000
Training Loss: 0.73364844, Training R2: 0.524113
Validation Loss: 0.83023488, Validation R2: 0.385729

Epoch 42/1000
Training Loss: 0.90657849, Training R2: 0.308806
Validation Loss: 0.94456858, Validation R2: 0.250584

Epoch 43/1000
Training Loss: 0.83756914, Training R2: 0.404877
Validation Loss: 0.84419869, Validation R2: 0.362119

Epoch 44/1000
Training Loss: 0.81453723, Training R2: 0.450068
Validation Loss: 0.87490558, Validation R2: 0.345542

Epoch 45/1000
Training Loss: 0.82231349, Training R2: 0.440534
Validation Loss: 0.79778141, Validation R2: 0.418794

Epoch 46/1000
Training Loss: 0.79539225, Training R2: 0.492002
Validation Loss: 0.84559128, Validation R2: 0.359970

Epoch 47/1000
Training Loss: 0.81114392, Training R2: 0.480335
Validation Loss: 0.75586497, Validation R2: 0.466743

Epoch 48/1000
Training Loss: 0.76120128, Training R2: 0.525682
Validation Loss: 0.73961696, Validation R2: 0.505307

Epoch 49/1000
Training Loss: 0.73041679, Training R2: 0.561230
Validation Loss: 0.77088760, Validation R2: 0.475895

Epoch 50/1000
Training Loss: 0.72213985, Training R2: 0.568808
Validation Loss: 0.76107705, Validation R2: 0.490980

Epoch 51/1000
Training Loss: 0.72572175, Training R2: 0.569934
Validation Loss: 0.78165891, Validation R2: 0.443409

Epoch 52/1000
Training Loss: 0.75464919, Training R2: 0.543559
Validation Loss: 0.75355976, Validation R2: 0.492479

Epoch 53/1000
Training Loss: 0.80579671, Training R2: 0.500415
Validation Loss: 0.82215431, Validation R2: 0.433368

Epoch 54/1000
Training Loss: 0.78397547, Training R2: 0.509331
Validation Loss: 0.74500464, Validation R2: 0.511444

Epoch 55/1000
Training Loss: 0.74813384, Training R2: 0.546052
Validation Loss: 0.83243982, Validation R2: 0.420609

Epoch 56/1000
Training Loss: 0.77899259, Training R2: 0.501965
Validation Loss: 0.76302946, Validation R2: 0.497128

Epoch 57/1000
Training Loss: 0.77227774, Training R2: 0.517963
Validation Loss: 0.87448674, Validation R2: 0.322550

Epoch 58/1000
Training Loss: 0.83040604, Training R2: 0.450385
Validation Loss: 0.84005583, Validation R2: 0.390274

Epoch 59/1000
Training Loss: 0.82945556, Training R2: 0.455916
Validation Loss: 0.79404251, Validation R2: 0.456485

Epoch 60/1000
Epoch 00060: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 0.81524719, Training R2: 0.478505
Validation Loss: 0.78849586, Validation R2: 0.461844

Epoch 61/1000
学习率已减少 1 次
Training Loss: 0.75110137, Training R2: 0.532507
Validation Loss: 0.94653255, Validation R2: 0.261683

Epoch 62/1000
Training Loss: 1.10738405, Training R2: 0.127965
Validation Loss: 1.09380995, Validation R2: 0.024770

Epoch 63/1000
Training Loss: 1.03304662, Training R2: 0.168571
Validation Loss: 1.02939034, Validation R2: 0.121605

Epoch 64/1000
Training Loss: 0.92492294, Training R2: 0.300198
Validation Loss: 0.82030227, Validation R2: 0.366721

Epoch 65/1000
Training Loss: 0.85186790, Training R2: 0.380991
Validation Loss: 0.81157228, Validation R2: 0.378342

Epoch 66/1000
Training Loss: 0.82647287, Training R2: 0.406829
Validation Loss: 0.79771178, Validation R2: 0.389829

Epoch 67/1000
Training Loss: 0.83673510, Training R2: 0.405784
Validation Loss: 0.79428196, Validation R2: 0.417876

Epoch 68/1000
Training Loss: 0.83983352, Training R2: 0.440262
Validation Loss: 0.78753704, Validation R2: 0.441741

Epoch 69/1000
Training Loss: 0.85526718, Training R2: 0.400168
Validation Loss: 0.84198087, Validation R2: 0.351540

Epoch 70/1000
Training Loss: 0.81398787, Training R2: 0.455377
Validation Loss: 0.77620935, Validation R2: 0.456340

Epoch 71/1000
Training Loss: 0.78318255, Training R2: 0.486260
Validation Loss: 0.76805673, Validation R2: 0.474627

Epoch 72/1000
Training Loss: 0.76903945, Training R2: 0.508262
Validation Loss: 0.75754562, Validation R2: 0.505039

Epoch 73/1000
Training Loss: 0.77602341, Training R2: 0.517991
Validation Loss: 0.74826212, Validation R2: 0.507732

Epoch 74/1000
Training Loss: 0.76315721, Training R2: 0.526866
Validation Loss: 0.75460158, Validation R2: 0.499072

Epoch 75/1000
Training Loss: 0.79095875, Training R2: 0.501102
Validation Loss: 0.75430508, Validation R2: 0.457556

Epoch 76/1000
Training Loss: 0.77630150, Training R2: 0.506818
Validation Loss: 0.77385416, Validation R2: 0.454252

Epoch 77/1000
Training Loss: 0.73638525, Training R2: 0.567795
Validation Loss: 0.75071447, Validation R2: 0.485977

Epoch 78/1000
Training Loss: 0.73376981, Training R2: 0.562909
Validation Loss: 0.78857590, Validation R2: 0.433535

Epoch 79/1000
Training Loss: 0.92055370, Training R2: 0.350501
Validation Loss: 0.84532834, Validation R2: 0.372833

Epoch 80/1000
Training Loss: 0.84581171, Training R2: 0.445042
Validation Loss: 0.77886196, Validation R2: 0.463541

Epoch 81/1000
Epoch 00081: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 0.78358146, Training R2: 0.501332
Validation Loss: 0.75410349, Validation R2: 0.489131

Epoch 82/1000
学习率已减少 2 次
Training Loss: 0.73515358, Training R2: 0.549532
Validation Loss: 0.75742484, Validation R2: 0.480996

Epoch 83/1000
Training Loss: 0.72132846, Training R2: 0.563524
Validation Loss: 0.76098094, Validation R2: 0.483955

Epoch 84/1000
Training Loss: 0.71712522, Training R2: 0.562099
Validation Loss: 0.74886856, Validation R2: 0.489228

Epoch 85/1000
Training Loss: 0.71784465, Training R2: 0.557315
Validation Loss: 0.73365414, Validation R2: 0.498528

Epoch 86/1000
Training Loss: 0.71193753, Training R2: 0.569219
Validation Loss: 0.74591858, Validation R2: 0.468501

Epoch 87/1000
Training Loss: 0.71860521, Training R2: 0.553902
Validation Loss: 0.75513538, Validation R2: 0.448284

Epoch 88/1000
Training Loss: 0.72487787, Training R2: 0.545049
Validation Loss: 0.73761125, Validation R2: 0.477137

Epoch 89/1000
Training Loss: 0.70784407, Training R2: 0.565103
Validation Loss: 0.73455266, Validation R2: 0.482354

Epoch 90/1000
Training Loss: 0.70911521, Training R2: 0.565027
Validation Loss: 0.74056345, Validation R2: 0.479781

Epoch 91/1000
Training Loss: 0.70235945, Training R2: 0.569709
Validation Loss: 0.73385154, Validation R2: 0.494901

Epoch 92/1000
Training Loss: 0.70201115, Training R2: 0.572695
Validation Loss: 0.72886606, Validation R2: 0.500116

Epoch 93/1000
Training Loss: 0.69710622, Training R2: 0.576555
Validation Loss: 0.73654490, Validation R2: 0.484784

Epoch 94/1000
Training Loss: 0.69658796, Training R2: 0.579348
Validation Loss: 0.74345211, Validation R2: 0.477032

Epoch 95/1000
Training Loss: 0.71822180, Training R2: 0.555720
Validation Loss: 0.74880613, Validation R2: 0.475115

Epoch 96/1000
Training Loss: 0.70593977, Training R2: 0.570473
Validation Loss: 0.73636866, Validation R2: 0.480565

Epoch 97/1000
Training Loss: 0.71716131, Training R2: 0.544441
Validation Loss: 0.76731396, Validation R2: 0.456011

Epoch 98/1000
Training Loss: 0.72640590, Training R2: 0.544548
Validation Loss: 0.74486688, Validation R2: 0.475953

Epoch 99/1000
Training Loss: 0.71758255, Training R2: 0.544916
Validation Loss: 0.74926595, Validation R2: 0.475815

Epoch 100/1000
Training Loss: 0.72565076, Training R2: 0.526342
Validation Loss: 0.79109944, Validation R2: 0.416592

Epoch 101/1000
Training Loss: 0.74442405, Training R2: 0.511460
Validation Loss: 0.79457821, Validation R2: 0.403724

Epoch 102/1000
Epoch 00102: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 0.73118994, Training R2: 0.520245
Validation Loss: 0.74788935, Validation R2: 0.459576

Epoch 103/1000
学习率已减少 3 次
Training Loss: 0.71701937, Training R2: 0.531542
Validation Loss: 0.73586293, Validation R2: 0.472063

Epoch 104/1000
Training Loss: 0.71065959, Training R2: 0.541218
Validation Loss: 0.73273201, Validation R2: 0.471510

Epoch 105/1000
Training Loss: 0.71477056, Training R2: 0.533874
Validation Loss: 0.74527564, Validation R2: 0.458614

Epoch 106/1000
Training Loss: 0.71440963, Training R2: 0.534703
Validation Loss: 0.74191402, Validation R2: 0.461921

Epoch 107/1000
Training Loss: 0.70969386, Training R2: 0.536448
Validation Loss: 0.73386546, Validation R2: 0.472694

Epoch 108/1000
Training Loss: 0.71310086, Training R2: 0.534832
Validation Loss: 0.73226438, Validation R2: 0.478651

Epoch 109/1000
Training Loss: 0.70804595, Training R2: 0.541039
Validation Loss: 0.73331695, Validation R2: 0.474950

Epoch 110/1000
Training Loss: 0.70889413, Training R2: 0.534371
Validation Loss: 0.72825136, Validation R2: 0.480273

Epoch 111/1000
Training Loss: 0.71096670, Training R2: 0.534052
Validation Loss: 0.72789938, Validation R2: 0.482519

Epoch 112/1000
Training Loss: 0.71108994, Training R2: 0.530474
Validation Loss: 0.74519894, Validation R2: 0.464110

Epoch 113/1000
Training Loss: 0.71768937, Training R2: 0.527054
Validation Loss: 0.73696505, Validation R2: 0.479914

Epoch 114/1000
Training Loss: 0.71010120, Training R2: 0.538067
Validation Loss: 0.73997462, Validation R2: 0.472660

Epoch 115/1000
Training Loss: 0.70501187, Training R2: 0.542720
Validation Loss: 0.73419207, Validation R2: 0.476031

Epoch 116/1000
Training Loss: 0.70337234, Training R2: 0.540482
Validation Loss: 0.72754726, Validation R2: 0.484986

Epoch 117/1000
Training Loss: 0.70034544, Training R2: 0.547763
Validation Loss: 0.73450953, Validation R2: 0.477683

Epoch 118/1000
Training Loss: 0.69883691, Training R2: 0.563236
Validation Loss: 0.73543960, Validation R2: 0.472194

Epoch 119/1000
Training Loss: 0.69505744, Training R2: 0.571335
Validation Loss: 0.74158830, Validation R2: 0.469625

Epoch 120/1000
Training Loss: 0.69356857, Training R2: 0.574108
Validation Loss: 0.72862977, Validation R2: 0.486104

Epoch 121/1000
Training Loss: 0.69013203, Training R2: 0.576104
Validation Loss: 0.72289423, Validation R2: 0.491434

Epoch 122/1000
Training Loss: 0.68923884, Training R2: 0.576741
Validation Loss: 0.71885272, Validation R2: 0.485026

Epoch 123/1000
Epoch 00123: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 0.68763299, Training R2: 0.576994
Validation Loss: 0.73474951, Validation R2: 0.479717

Epoch 124/1000
学习率已减少 4 次
Training Loss: 0.68853728, Training R2: 0.575850
Validation Loss: 0.72015008, Validation R2: 0.492138

Epoch 125/1000
Training Loss: 0.68455248, Training R2: 0.580105
Validation Loss: 0.71452401, Validation R2: 0.506727

Epoch 126/1000
Training Loss: 0.68493886, Training R2: 0.581704
Validation Loss: 0.71211072, Validation R2: 0.509405

Epoch 127/1000
Training Loss: 0.68024445, Training R2: 0.585035
Validation Loss: 0.72165986, Validation R2: 0.502206

Epoch 128/1000
Training Loss: 0.68108332, Training R2: 0.585379
Validation Loss: 0.72179357, Validation R2: 0.502087

Epoch 129/1000
Training Loss: 0.68317335, Training R2: 0.581383
Validation Loss: 0.71858484, Validation R2: 0.500033

Epoch 130/1000
Training Loss: 0.68253802, Training R2: 0.582386
Validation Loss: 0.71994644, Validation R2: 0.494174

Epoch 131/1000
Training Loss: 0.68255943, Training R2: 0.582540
Validation Loss: 0.71885485, Validation R2: 0.495114

Epoch 132/1000
Training Loss: 0.68102843, Training R2: 0.584086
Validation Loss: 0.71166296, Validation R2: 0.507650

Epoch 133/1000
Training Loss: 0.67925235, Training R2: 0.587938
Validation Loss: 0.71083871, Validation R2: 0.509577

Epoch 134/1000
Training Loss: 0.67751205, Training R2: 0.587416
Validation Loss: 0.70786988, Validation R2: 0.512711

Epoch 135/1000
Training Loss: 0.67938926, Training R2: 0.586704
Validation Loss: 0.70810849, Validation R2: 0.511827

Epoch 136/1000
Training Loss: 0.68247123, Training R2: 0.587713
Validation Loss: 0.71336939, Validation R2: 0.506871

Epoch 137/1000
Training Loss: 0.67782136, Training R2: 0.588568
Validation Loss: 0.71031205, Validation R2: 0.509386

Epoch 138/1000
Training Loss: 0.67682014, Training R2: 0.589759
Validation Loss: 0.71295306, Validation R2: 0.507170

Epoch 139/1000
Training Loss: 0.67637170, Training R2: 0.591158
Validation Loss: 0.70779950, Validation R2: 0.511624

Epoch 140/1000
Training Loss: 0.67689461, Training R2: 0.590756
Validation Loss: 0.70915291, Validation R2: 0.509486

Epoch 141/1000
Training Loss: 0.67782100, Training R2: 0.589361
Validation Loss: 0.70741918, Validation R2: 0.510170

Epoch 142/1000
Training Loss: 0.67752170, Training R2: 0.591133
Validation Loss: 0.70362246, Validation R2: 0.518496

Epoch 143/1000
Training Loss: 0.67562292, Training R2: 0.592994
Validation Loss: 0.70967273, Validation R2: 0.511051

Epoch 144/1000
Epoch 00144: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 0.67343630, Training R2: 0.592342
Validation Loss: 0.70382753, Validation R2: 0.516921

Epoch 145/1000
学习率已减少 5 次
Training Loss: 0.67127815, Training R2: 0.595907
Validation Loss: 0.70478824, Validation R2: 0.516015

Epoch 146/1000
Training Loss: 0.67080972, Training R2: 0.596690
Validation Loss: 0.71015707, Validation R2: 0.511124

Epoch 147/1000
Training Loss: 0.67191579, Training R2: 0.596186
Validation Loss: 0.70482724, Validation R2: 0.515624

Epoch 148/1000
Training Loss: 0.67184790, Training R2: 0.597884
Validation Loss: 0.70389970, Validation R2: 0.520348

Epoch 149/1000
Training Loss: 0.67010873, Training R2: 0.602219
Validation Loss: 0.70231090, Validation R2: 0.526290

Epoch 150/1000
Training Loss: 0.66983060, Training R2: 0.602594
Validation Loss: 0.70100087, Validation R2: 0.528461

Epoch 151/1000
Training Loss: 0.66850599, Training R2: 0.605357
Validation Loss: 0.70693669, Validation R2: 0.523751

Epoch 152/1000
Training Loss: 0.67347373, Training R2: 0.599954
Validation Loss: 0.70799202, Validation R2: 0.524117

Epoch 153/1000
Training Loss: 0.67112197, Training R2: 0.600359
Validation Loss: 0.71176388, Validation R2: 0.521337

Epoch 154/1000
Training Loss: 0.66888945, Training R2: 0.601235
Validation Loss: 0.69850210, Validation R2: 0.532086

Epoch 155/1000
Training Loss: 0.66772637, Training R2: 0.601385
Validation Loss: 0.69947938, Validation R2: 0.530095

Epoch 156/1000
Training Loss: 0.66748916, Training R2: 0.602463
Validation Loss: 0.70242432, Validation R2: 0.523763

Epoch 157/1000
Training Loss: 0.66618895, Training R2: 0.604375
Validation Loss: 0.70096473, Validation R2: 0.525938

Epoch 158/1000
Training Loss: 0.66699468, Training R2: 0.603565
Validation Loss: 0.70272907, Validation R2: 0.522737

Epoch 159/1000
Training Loss: 0.66658543, Training R2: 0.603354
Validation Loss: 0.70238990, Validation R2: 0.524342

Epoch 160/1000
Training Loss: 0.66629323, Training R2: 0.603819
Validation Loss: 0.70253490, Validation R2: 0.524875

Epoch 161/1000
Training Loss: 0.66435420, Training R2: 0.604741
Validation Loss: 0.70207442, Validation R2: 0.524620

Epoch 162/1000
Training Loss: 0.66424018, Training R2: 0.604875
Validation Loss: 0.70097137, Validation R2: 0.526270

Epoch 163/1000
Training Loss: 0.66276055, Training R2: 0.607087
Validation Loss: 0.69896998, Validation R2: 0.527988

Epoch 164/1000
Training Loss: 0.66239605, Training R2: 0.607550
Validation Loss: 0.70126419, Validation R2: 0.526133

Epoch 165/1000
Epoch 00165: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 0.66440601, Training R2: 0.605379
Validation Loss: 0.70118222, Validation R2: 0.526682

Epoch 166/1000
学习率已减少 6 次
Training Loss: 0.66094872, Training R2: 0.608712
Validation Loss: 0.69862406, Validation R2: 0.528889

Epoch 167/1000
Training Loss: 0.66010851, Training R2: 0.609510
Validation Loss: 0.69569201, Validation R2: 0.531149

Epoch 168/1000
Training Loss: 0.66000586, Training R2: 0.609977
Validation Loss: 0.69520323, Validation R2: 0.531288

Epoch 169/1000
Training Loss: 0.65953405, Training R2: 0.610873
Validation Loss: 0.69568399, Validation R2: 0.531398

Epoch 170/1000
Training Loss: 0.65880637, Training R2: 0.610922
Validation Loss: 0.69579251, Validation R2: 0.531849

Epoch 171/1000
Training Loss: 0.65953326, Training R2: 0.611002
Validation Loss: 0.69685739, Validation R2: 0.530665

Epoch 172/1000
Training Loss: 0.65851767, Training R2: 0.610950
Validation Loss: 0.69711261, Validation R2: 0.530897

Epoch 173/1000
Training Loss: 0.65806615, Training R2: 0.611315
Validation Loss: 0.69605293, Validation R2: 0.531535

Epoch 174/1000
Training Loss: 0.65813116, Training R2: 0.611615
Validation Loss: 0.69707478, Validation R2: 0.531000

Epoch 175/1000
Training Loss: 0.65738055, Training R2: 0.612585
Validation Loss: 0.69763498, Validation R2: 0.530868

Epoch 176/1000
Training Loss: 0.65790692, Training R2: 0.612062
Validation Loss: 0.69590604, Validation R2: 0.532065

Epoch 177/1000
Training Loss: 0.65728845, Training R2: 0.612521
Validation Loss: 0.69678855, Validation R2: 0.531190

Epoch 178/1000
Training Loss: 0.65613300, Training R2: 0.613751
Validation Loss: 0.69658105, Validation R2: 0.530933

Epoch 179/1000
Training Loss: 0.65555226, Training R2: 0.614648
Validation Loss: 0.69727963, Validation R2: 0.529701

Epoch 180/1000
Training Loss: 0.65690720, Training R2: 0.614021
Validation Loss: 0.69323926, Validation R2: 0.533796

Epoch 181/1000
Training Loss: 0.65550663, Training R2: 0.614963
Validation Loss: 0.69593892, Validation R2: 0.530591

Epoch 182/1000
Training Loss: 0.65536896, Training R2: 0.615735
Validation Loss: 0.69548622, Validation R2: 0.531781

Epoch 183/1000
Training Loss: 0.65502828, Training R2: 0.616103
Validation Loss: 0.69447700, Validation R2: 0.532058

Epoch 184/1000
Training Loss: 0.65407916, Training R2: 0.617143
Validation Loss: 0.69412149, Validation R2: 0.532558

Epoch 185/1000
Training Loss: 0.65533546, Training R2: 0.616558
Validation Loss: 0.69382924, Validation R2: 0.532455

Epoch 186/1000
Epoch 00186: reducing learning rate of group 0 to 7.8125e-06.
Training Loss: 0.65456326, Training R2: 0.616444
Validation Loss: 0.69589390, Validation R2: 0.532172

Epoch 187/1000
学习率已减少 7 次
Training Loss: 0.65174199, Training R2: 0.619150
Validation Loss: 0.69641649, Validation R2: 0.531750

Epoch 188/1000
Training Loss: 0.65142680, Training R2: 0.619553
Validation Loss: 0.69545207, Validation R2: 0.532432

Epoch 189/1000
Training Loss: 0.65270647, Training R2: 0.618525
Validation Loss: 0.69520432, Validation R2: 0.532555

Epoch 190/1000
Training Loss: 0.65102833, Training R2: 0.620624
Validation Loss: 0.69428817, Validation R2: 0.538056

Epoch 191/1000
Training Loss: 0.65098619, Training R2: 0.620894
Validation Loss: 0.69271139, Validation R2: 0.535577

Epoch 192/1000
Training Loss: 0.65077126, Training R2: 0.621232
Validation Loss: 0.69384347, Validation R2: 0.534414

Epoch 193/1000
Training Loss: 0.65027134, Training R2: 0.621551
Validation Loss: 0.69379347, Validation R2: 0.534690

Epoch 194/1000
Training Loss: 0.65051874, Training R2: 0.621464
Validation Loss: 0.69432684, Validation R2: 0.534228

Epoch 195/1000
Training Loss: 0.64922371, Training R2: 0.621836
Validation Loss: 0.69385556, Validation R2: 0.534784

Epoch 196/1000
Training Loss: 0.64950394, Training R2: 0.622234
Validation Loss: 0.69492433, Validation R2: 0.533622

Epoch 197/1000
Training Loss: 0.64965176, Training R2: 0.622797
Validation Loss: 0.69370487, Validation R2: 0.534807

Epoch 198/1000
Training Loss: 0.64948368, Training R2: 0.622440
Validation Loss: 0.69420389, Validation R2: 0.534371

Epoch 199/1000
Training Loss: 0.64914042, Training R2: 0.622814
Validation Loss: 0.69409704, Validation R2: 0.534392

Epoch 200/1000
Training Loss: 0.64881222, Training R2: 0.622871
Validation Loss: 0.69370960, Validation R2: 0.534867

Epoch 201/1000
Training Loss: 0.64839482, Training R2: 0.623302
Validation Loss: 0.69391487, Validation R2: 0.534180

Epoch 202/1000
Training Loss: 0.64995373, Training R2: 0.622741
Validation Loss: 0.69307163, Validation R2: 0.535399

Epoch 203/1000
Training Loss: 0.64965358, Training R2: 0.622805
Validation Loss: 0.69267893, Validation R2: 0.535709

Epoch 204/1000
Training Loss: 0.64897008, Training R2: 0.623601
Validation Loss: 0.69251830, Validation R2: 0.535758

Epoch 205/1000
Training Loss: 0.64867821, Training R2: 0.623657
Validation Loss: 0.69331613, Validation R2: 0.534904

Epoch 206/1000
Training Loss: 0.64751553, Training R2: 0.625058
Validation Loss: 0.69228285, Validation R2: 0.537392

Epoch 207/1000
Epoch 00207: reducing learning rate of group 0 to 3.9063e-06.
Training Loss: 0.64781856, Training R2: 0.625375
Validation Loss: 0.69253879, Validation R2: 0.537260

Epoch 208/1000
学习率已减少 8 次
学习率已减少 8 次，达到最大允许次数 7，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/r2_curve_dipole.png
