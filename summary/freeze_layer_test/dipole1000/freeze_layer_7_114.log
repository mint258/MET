Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.27719959, Training R2: -0.183933
Validation Loss: 1.05820143, Validation R2: -0.065308
Saved best model with validation R2 -0.065308 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.15299531, Training R2: -0.010820
Validation Loss: 1.11879563, Validation R2: -0.040285
Saved best model with validation R2 -0.040285 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.18791644, Training R2: 0.004411
Validation Loss: 1.06365669, Validation R2: -0.037809
Saved best model with validation R2 -0.037809 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.17795652, Training R2: -0.142282
Validation Loss: 1.05514538, Validation R2: -0.015004
Saved best model with validation R2 -0.015004 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.13650568, Training R2: 0.008217
Validation Loss: 1.05737436, Validation R2: 0.057888
Saved best model with validation R2 0.057888 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.13919411, Training R2: 0.036368
Validation Loss: 1.04456043, Validation R2: -0.000294

Epoch 7/1000
Training Loss: 1.13531483, Training R2: -0.066781
Validation Loss: 1.06420672, Validation R2: -0.071530

Epoch 8/1000
Training Loss: 1.12916937, Training R2: -0.053640
Validation Loss: 1.01965010, Validation R2: 0.068148
Saved best model with validation R2 0.068148 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.11174380, Training R2: 0.029180
Validation Loss: 1.02152681, Validation R2: 0.027580

Epoch 10/1000
Training Loss: 1.10953676, Training R2: -0.021643
Validation Loss: 1.01095498, Validation R2: 0.086561
Saved best model with validation R2 0.086561 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 1.12626432, Training R2: 0.052088
Validation Loss: 1.01750970, Validation R2: 0.092428
Saved best model with validation R2 0.092428 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.11053692, Training R2: 0.058563
Validation Loss: 1.05092728, Validation R2: -0.018529

Epoch 13/1000
Training Loss: 1.13029346, Training R2: -0.040689
Validation Loss: 1.02618361, Validation R2: 0.061205

Epoch 14/1000
Training Loss: 1.11270072, Training R2: 0.050975
Validation Loss: 1.03192294, Validation R2: 0.077856

Epoch 15/1000
Training Loss: 1.11059479, Training R2: 0.050355
Validation Loss: 1.04327941, Validation R2: -0.006984

Epoch 16/1000
Training Loss: 1.12248857, Training R2: -0.037262
Validation Loss: 1.02249956, Validation R2: 0.068186

Epoch 17/1000
Training Loss: 1.11104445, Training R2: 0.063108
Validation Loss: 1.02877069, Validation R2: 0.083756

Epoch 18/1000
Training Loss: 1.11375892, Training R2: 0.072829
Validation Loss: 1.01984966, Validation R2: 0.057963

Epoch 19/1000
Training Loss: 1.09891877, Training R2: 0.040027
Validation Loss: 1.02462029, Validation R2: 0.038244

Epoch 20/1000
Training Loss: 1.10425596, Training R2: 0.005960
Validation Loss: 1.01726580, Validation R2: 0.058550

Epoch 21/1000
Training Loss: 1.09545889, Training R2: 0.036866
Validation Loss: 1.01098430, Validation R2: 0.078233

Epoch 22/1000
Training Loss: 1.09534732, Training R2: 0.041005
Validation Loss: 1.01221454, Validation R2: 0.053128

Epoch 23/1000
Training Loss: 1.09299858, Training R2: 0.027215
Validation Loss: 1.00246561, Validation R2: 0.081702

Epoch 24/1000
Training Loss: 1.08808670, Training R2: 0.045790
Validation Loss: 0.99443358, Validation R2: 0.108376
Saved best model with validation R2 0.108376 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 1.08860610, Training R2: 0.077114
Validation Loss: 0.99166912, Validation R2: 0.124237
Saved best model with validation R2 0.124237 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 1.08983103, Training R2: 0.088223
Validation Loss: 1.00356662, Validation R2: 0.074126

Epoch 27/1000
Training Loss: 1.10011997, Training R2: 0.020550
Validation Loss: 0.98933303, Validation R2: 0.109018

Epoch 28/1000
Training Loss: 1.08044908, Training R2: 0.073500
Validation Loss: 0.98280483, Validation R2: 0.130858
Saved best model with validation R2 0.130858 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 1.07889484, Training R2: 0.076149
Validation Loss: 0.98310208, Validation R2: 0.115692

Epoch 30/1000
Training Loss: 1.07272770, Training R2: 0.080062
Validation Loss: 0.97016805, Validation R2: 0.151582
Saved best model with validation R2 0.151582 to best_finetuned_model.pth

Epoch 31/1000
Training Loss: 1.07127338, Training R2: 0.099315
Validation Loss: 0.96974242, Validation R2: 0.138096

Epoch 32/1000
Training Loss: 1.06983594, Training R2: 0.074913
Validation Loss: 0.97394454, Validation R2: 0.143559

Epoch 33/1000
Training Loss: 1.06746416, Training R2: 0.096246
Validation Loss: 0.96113110, Validation R2: 0.158004
Saved best model with validation R2 0.158004 to best_finetuned_model.pth

Epoch 34/1000
Training Loss: 1.06273194, Training R2: 0.090228
Validation Loss: 0.95489472, Validation R2: 0.181735
Saved best model with validation R2 0.181735 to best_finetuned_model.pth

Epoch 35/1000
Training Loss: 1.07505662, Training R2: 0.113960
Validation Loss: 0.96667433, Validation R2: 0.117768

Epoch 36/1000
Training Loss: 1.07776621, Training R2: 0.018382
Validation Loss: 0.94174498, Validation R2: 0.177760

Epoch 37/1000
Training Loss: 1.05543954, Training R2: 0.093187
Validation Loss: 0.94670528, Validation R2: 0.160057

Epoch 38/1000
Training Loss: 1.06272584, Training R2: 0.062627
Validation Loss: 0.93392330, Validation R2: 0.207361
Saved best model with validation R2 0.207361 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 1.03677335, Training R2: 0.143080
Validation Loss: 0.90933669, Validation R2: 0.218926
Saved best model with validation R2 0.218926 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 1.03121340, Training R2: 0.122697
Validation Loss: 1.00097620, Validation R2: 0.115563

Epoch 41/1000
Training Loss: 1.07976948, Training R2: 0.127339
Validation Loss: 0.90496701, Validation R2: 0.238492
Saved best model with validation R2 0.238492 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 1.06241352, Training R2: 0.133994
Validation Loss: 0.90012765, Validation R2: 0.245879
Saved best model with validation R2 0.245879 to best_finetuned_model.pth

Epoch 43/1000
Training Loss: 1.04790991, Training R2: 0.076277
Validation Loss: 0.90472919, Validation R2: 0.233844

Epoch 44/1000
Training Loss: 1.04790059, Training R2: 0.150823
Validation Loss: 0.88511521, Validation R2: 0.268858
Saved best model with validation R2 0.268858 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.99776818, Training R2: 0.163791
Validation Loss: 0.86804479, Validation R2: 0.296410
Saved best model with validation R2 0.296410 to best_finetuned_model.pth

Epoch 46/1000
Training Loss: 0.99041905, Training R2: 0.196493
Validation Loss: 0.85583222, Validation R2: 0.319333
Saved best model with validation R2 0.319333 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.98056513, Training R2: 0.211333
Validation Loss: 0.85676497, Validation R2: 0.287617

Epoch 48/1000
Training Loss: 0.95825023, Training R2: 0.204243
Validation Loss: 0.88576347, Validation R2: 0.274865

Epoch 49/1000
Training Loss: 0.96189789, Training R2: 0.212088
Validation Loss: 0.87032509, Validation R2: 0.264049

Epoch 50/1000
Training Loss: 0.95067415, Training R2: 0.209069
Validation Loss: 0.91656721, Validation R2: 0.189703

Epoch 51/1000
Training Loss: 0.94498245, Training R2: 0.190280
Validation Loss: 0.94915754, Validation R2: 0.189537

Epoch 52/1000
Training Loss: 0.99125569, Training R2: 0.147313
Validation Loss: 1.28243053, Validation R2: -0.344302

Epoch 53/1000
Training Loss: 1.23176061, Training R2: -0.085717
Validation Loss: 1.00547647, Validation R2: 0.029280

Epoch 54/1000
Training Loss: 1.09421608, Training R2: -0.028775
Validation Loss: 0.93218839, Validation R2: 0.211249

Epoch 55/1000
Training Loss: 1.04092505, Training R2: 0.172364
Validation Loss: 0.91028363, Validation R2: 0.245123

Epoch 56/1000
Training Loss: 1.00205448, Training R2: 0.168627
Validation Loss: 0.94142151, Validation R2: 0.151343

Epoch 57/1000
Training Loss: 0.97327926, Training R2: 0.189299
Validation Loss: 0.87609833, Validation R2: 0.299235

Epoch 58/1000
Training Loss: 0.94369712, Training R2: 0.284227
Validation Loss: 0.83722991, Validation R2: 0.329149
Saved best model with validation R2 0.329149 to best_finetuned_model.pth

Epoch 59/1000
Training Loss: 0.89631696, Training R2: 0.310154
Validation Loss: 0.84947586, Validation R2: 0.325407

Epoch 60/1000
Training Loss: 0.87484386, Training R2: 0.310974
Validation Loss: 0.85301495, Validation R2: 0.334569
Saved best model with validation R2 0.334569 to best_finetuned_model.pth

Epoch 61/1000
Training Loss: 0.85446006, Training R2: 0.332497
Validation Loss: 0.83168781, Validation R2: 0.361528
Saved best model with validation R2 0.361528 to best_finetuned_model.pth

Epoch 62/1000
Training Loss: 0.84575857, Training R2: 0.313805
Validation Loss: 0.82560468, Validation R2: 0.377146
Saved best model with validation R2 0.377146 to best_finetuned_model.pth

Epoch 63/1000
Training Loss: 0.82194426, Training R2: 0.361189
Validation Loss: 0.81405228, Validation R2: 0.369445

Epoch 64/1000
Training Loss: 0.82267442, Training R2: 0.339499
Validation Loss: 0.82573062, Validation R2: 0.330949

Epoch 65/1000
Training Loss: 0.83631270, Training R2: 0.330087
Validation Loss: 0.85881913, Validation R2: 0.298360

Epoch 66/1000
Training Loss: 0.83392662, Training R2: 0.322556
Validation Loss: 0.80877906, Validation R2: 0.368983

Epoch 67/1000
Training Loss: 0.82830044, Training R2: 0.346281
Validation Loss: 0.81124645, Validation R2: 0.375457

Epoch 68/1000
Training Loss: 0.80284532, Training R2: 0.366068
Validation Loss: 0.79728216, Validation R2: 0.400679
Saved best model with validation R2 0.400679 to best_finetuned_model.pth

Epoch 69/1000
Training Loss: 0.78942599, Training R2: 0.393998
Validation Loss: 0.79845887, Validation R2: 0.391095

Epoch 70/1000
Training Loss: 0.78113202, Training R2: 0.409054
Validation Loss: 0.79103178, Validation R2: 0.387993

Epoch 71/1000
Training Loss: 0.75854010, Training R2: 0.412599
Validation Loss: 0.84009415, Validation R2: 0.326458

Epoch 72/1000
Training Loss: 0.78523825, Training R2: 0.376551
Validation Loss: 0.87463254, Validation R2: 0.283743

Epoch 73/1000
Training Loss: 0.82514779, Training R2: 0.338920
Validation Loss: 0.93205613, Validation R2: 0.211442

Epoch 74/1000
Training Loss: 0.91395661, Training R2: 0.287638
Validation Loss: 0.90407348, Validation R2: 0.250521

Epoch 75/1000
Training Loss: 0.83450569, Training R2: 0.339906
Validation Loss: 0.84385180, Validation R2: 0.311890

Epoch 76/1000
Training Loss: 0.83112422, Training R2: 0.343809
Validation Loss: 0.78972036, Validation R2: 0.407249
Saved best model with validation R2 0.407249 to best_finetuned_model.pth

Epoch 77/1000
Training Loss: 0.80134905, Training R2: 0.392214
Validation Loss: 0.80726367, Validation R2: 0.336040

Epoch 78/1000
Training Loss: 0.84902693, Training R2: 0.292058
Validation Loss: 0.79330045, Validation R2: 0.365980

Epoch 79/1000
Training Loss: 0.73966771, Training R2: 0.441664
Validation Loss: 0.81320179, Validation R2: 0.351650

Epoch 80/1000
Training Loss: 0.74929408, Training R2: 0.417551
Validation Loss: 0.77172530, Validation R2: 0.390400

Epoch 81/1000
Training Loss: 0.71522551, Training R2: 0.456686
Validation Loss: 0.76773930, Validation R2: 0.390761

Epoch 82/1000
Training Loss: 0.72407425, Training R2: 0.450476
Validation Loss: 0.82419068, Validation R2: 0.336181

Epoch 83/1000
Training Loss: 0.75132967, Training R2: 0.407661
Validation Loss: 0.78852654, Validation R2: 0.377320

Epoch 84/1000
Training Loss: 0.73142525, Training R2: 0.426140
Validation Loss: 0.79797196, Validation R2: 0.357883

Epoch 85/1000
Training Loss: 0.78118684, Training R2: 0.377302
Validation Loss: 0.79134566, Validation R2: 0.355964

Epoch 86/1000
Training Loss: 0.73728837, Training R2: 0.413344
Validation Loss: 0.79077137, Validation R2: 0.365578

Epoch 87/1000
Training Loss: 0.73409081, Training R2: 0.432824
Validation Loss: 0.87105870, Validation R2: 0.214379

Epoch 88/1000
Training Loss: 0.87472943, Training R2: 0.259393
Validation Loss: 0.88748121, Validation R2: 0.251638

Epoch 89/1000
Training Loss: 0.87428617, Training R2: 0.282248
Validation Loss: 0.78313661, Validation R2: 0.377573

Epoch 90/1000
Training Loss: 0.77707068, Training R2: 0.406120
Validation Loss: 0.76730651, Validation R2: 0.412247
Saved best model with validation R2 0.412247 to best_finetuned_model.pth

Epoch 91/1000
Training Loss: 0.73973822, Training R2: 0.427878
Validation Loss: 0.81192195, Validation R2: 0.353868

Epoch 92/1000
Training Loss: 0.76098135, Training R2: 0.401057
Validation Loss: 0.79309553, Validation R2: 0.365575

Epoch 93/1000
Training Loss: 0.73347833, Training R2: 0.430165
Validation Loss: 0.78631496, Validation R2: 0.377362

Epoch 94/1000
Training Loss: 0.75613578, Training R2: 0.404941
Validation Loss: 0.71631140, Validation R2: 0.471876
Saved best model with validation R2 0.471876 to best_finetuned_model.pth

Epoch 95/1000
Training Loss: 0.70874825, Training R2: 0.460322
Validation Loss: 0.74506122, Validation R2: 0.441265

Epoch 96/1000
Training Loss: 0.73527048, Training R2: 0.452673
Validation Loss: 0.77137917, Validation R2: 0.387435

Epoch 97/1000
Training Loss: 0.72546981, Training R2: 0.428149
Validation Loss: 0.78542435, Validation R2: 0.383493

Epoch 98/1000
Training Loss: 0.71171731, Training R2: 0.465690
Validation Loss: 0.81533635, Validation R2: 0.356301

Epoch 99/1000
Training Loss: 0.70410899, Training R2: 0.444870
Validation Loss: 0.75971389, Validation R2: 0.405108

Epoch 100/1000
Training Loss: 0.69512991, Training R2: 0.461490
Validation Loss: 0.74393296, Validation R2: 0.406205

Epoch 101/1000
Training Loss: 0.67033949, Training R2: 0.483100
Validation Loss: 0.76877707, Validation R2: 0.409210

Epoch 102/1000
Training Loss: 0.67365834, Training R2: 0.475846
Validation Loss: 0.75507462, Validation R2: 0.413643

Epoch 103/1000
Training Loss: 0.67855343, Training R2: 0.468306
Validation Loss: 0.76531577, Validation R2: 0.391492

Epoch 104/1000
Training Loss: 0.68970347, Training R2: 0.478737
Validation Loss: 0.75765175, Validation R2: 0.421793

Epoch 105/1000
Training Loss: 0.66551120, Training R2: 0.483266
Validation Loss: 0.78226745, Validation R2: 0.361138

Epoch 106/1000
Training Loss: 0.68175506, Training R2: 0.476160
Validation Loss: 0.77048612, Validation R2: 0.389405

Epoch 107/1000
Training Loss: 0.67800278, Training R2: 0.487620
Validation Loss: 0.79078138, Validation R2: 0.378113

Epoch 108/1000
Training Loss: 0.68495552, Training R2: 0.474487
Validation Loss: 0.74840498, Validation R2: 0.415981

Epoch 109/1000
Training Loss: 0.67137522, Training R2: 0.491387
Validation Loss: 0.75097698, Validation R2: 0.396969

Epoch 110/1000
Training Loss: 0.73461227, Training R2: 0.445261
Validation Loss: 0.75493348, Validation R2: 0.419242

Epoch 111/1000
Training Loss: 0.67696614, Training R2: 0.473675
Validation Loss: 0.77778274, Validation R2: 0.352668

Epoch 112/1000
Training Loss: 0.71751033, Training R2: 0.463640
Validation Loss: 0.75419354, Validation R2: 0.396759

Epoch 113/1000
Training Loss: 0.69449173, Training R2: 0.488611
Validation Loss: 0.73091519, Validation R2: 0.457245

Epoch 114/1000
Training Loss: 0.66989899, Training R2: 0.477274
Validation Loss: 0.73798943, Validation R2: 0.428092

Epoch 115/1000
Epoch 00115: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.66382332, Training R2: 0.488675
Validation Loss: 0.77927768, Validation R2: 0.372126

Epoch 116/1000
学习率已减少 1 次
Training Loss: 0.66046012, Training R2: 0.487972
Validation Loss: 0.75409544, Validation R2: 0.397044

Epoch 117/1000
Training Loss: 0.65005003, Training R2: 0.499273
Validation Loss: 0.77483302, Validation R2: 0.386429

Epoch 118/1000
Training Loss: 0.62185437, Training R2: 0.520770
Validation Loss: 0.74726653, Validation R2: 0.404568

Epoch 119/1000
Training Loss: 0.64405149, Training R2: 0.506722
Validation Loss: 0.80489141, Validation R2: 0.362518

Epoch 120/1000
Training Loss: 0.64156317, Training R2: 0.498188
Validation Loss: 0.75039345, Validation R2: 0.383853

Epoch 121/1000
Training Loss: 0.62550661, Training R2: 0.522695
Validation Loss: 0.78510511, Validation R2: 0.366886

Epoch 122/1000
Training Loss: 0.62009601, Training R2: 0.521453
Validation Loss: 0.76829863, Validation R2: 0.392659

Epoch 123/1000
Training Loss: 0.61298531, Training R2: 0.519897
Validation Loss: 0.74688607, Validation R2: 0.403692

Epoch 124/1000
Training Loss: 0.61915819, Training R2: 0.525341
Validation Loss: 0.74396712, Validation R2: 0.407823

Epoch 125/1000
Training Loss: 0.59911880, Training R2: 0.536068
Validation Loss: 0.75941300, Validation R2: 0.396929

Epoch 126/1000
Training Loss: 0.60495302, Training R2: 0.538927
Validation Loss: 0.74444473, Validation R2: 0.401547

Epoch 127/1000
Training Loss: 0.59451707, Training R2: 0.541918
Validation Loss: 0.74724442, Validation R2: 0.421042

Epoch 128/1000
Training Loss: 0.58818409, Training R2: 0.545682
Validation Loss: 0.75477660, Validation R2: 0.413960

Epoch 129/1000
Training Loss: 0.58826505, Training R2: 0.551576
Validation Loss: 0.73616487, Validation R2: 0.417865

Epoch 130/1000
Training Loss: 0.58770816, Training R2: 0.552653
Validation Loss: 0.74616438, Validation R2: 0.410979

Epoch 131/1000
Training Loss: 0.57902209, Training R2: 0.559099
Validation Loss: 0.75217706, Validation R2: 0.388812

Epoch 132/1000
Training Loss: 0.58646429, Training R2: 0.544396
Validation Loss: 0.77929813, Validation R2: 0.372492

Epoch 133/1000
Training Loss: 0.59833912, Training R2: 0.532825
Validation Loss: 0.74298900, Validation R2: 0.412290

Epoch 134/1000
Training Loss: 0.57445240, Training R2: 0.541635
Validation Loss: 0.74264538, Validation R2: 0.403237

Epoch 135/1000
Training Loss: 0.58104647, Training R2: 0.548599
Validation Loss: 0.77151871, Validation R2: 0.398007

Epoch 136/1000
Epoch 00136: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.59112602, Training R2: 0.544016
Validation Loss: 0.75119370, Validation R2: 0.395412

Epoch 137/1000
学习率已减少 2 次
Training Loss: 0.61192906, Training R2: 0.540214
Validation Loss: 0.76713300, Validation R2: 0.392092

Epoch 138/1000
Training Loss: 0.56831639, Training R2: 0.556286
Validation Loss: 0.75075084, Validation R2: 0.399073

Epoch 139/1000
Training Loss: 0.56315126, Training R2: 0.561388
Validation Loss: 0.75404984, Validation R2: 0.400428

Epoch 140/1000
Training Loss: 0.56092634, Training R2: 0.566098
Validation Loss: 0.75564480, Validation R2: 0.399417

Epoch 141/1000
Training Loss: 0.55876625, Training R2: 0.565226
Validation Loss: 0.74599552, Validation R2: 0.402126

Epoch 142/1000
Training Loss: 0.55682700, Training R2: 0.573226
Validation Loss: 0.74563491, Validation R2: 0.398323

Epoch 143/1000
Training Loss: 0.55536897, Training R2: 0.569546
Validation Loss: 0.76049262, Validation R2: 0.396403

Epoch 144/1000
Training Loss: 0.55396197, Training R2: 0.568723
Validation Loss: 0.74260420, Validation R2: 0.407866

Epoch 145/1000
Training Loss: 0.54691133, Training R2: 0.573817
Validation Loss: 0.73592007, Validation R2: 0.418125

Epoch 146/1000
Training Loss: 0.54245337, Training R2: 0.581357
Validation Loss: 0.72536439, Validation R2: 0.431994

Epoch 147/1000
Training Loss: 0.54522851, Training R2: 0.583705
Validation Loss: 0.73245382, Validation R2: 0.438274

Epoch 148/1000
Training Loss: 0.54424858, Training R2: 0.577778
Validation Loss: 0.71673280, Validation R2: 0.440751

Epoch 149/1000
Training Loss: 0.54925249, Training R2: 0.577829
Validation Loss: 0.73945600, Validation R2: 0.429606

Epoch 150/1000
Training Loss: 0.54547559, Training R2: 0.581313
Validation Loss: 0.73541015, Validation R2: 0.426202

Epoch 151/1000
Training Loss: 0.54252380, Training R2: 0.582527
Validation Loss: 0.73500454, Validation R2: 0.413926

Epoch 152/1000
Training Loss: 0.53860678, Training R2: 0.588807
Validation Loss: 0.74682260, Validation R2: 0.413144

Epoch 153/1000
Training Loss: 0.53643597, Training R2: 0.586252
Validation Loss: 0.72610831, Validation R2: 0.430575

Epoch 154/1000
Training Loss: 0.54144952, Training R2: 0.586822
Validation Loss: 0.73797292, Validation R2: 0.419914

Epoch 155/1000
Training Loss: 0.53428078, Training R2: 0.589943
Validation Loss: 0.74126530, Validation R2: 0.411803

Epoch 156/1000
Training Loss: 0.53984329, Training R2: 0.586390
Validation Loss: 0.73067749, Validation R2: 0.415178

Epoch 157/1000
Epoch 00157: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.53589862, Training R2: 0.599240
Validation Loss: 0.74603957, Validation R2: 0.413205

Epoch 158/1000
学习率已减少 3 次
Training Loss: 0.52987898, Training R2: 0.593777
Validation Loss: 0.73222059, Validation R2: 0.423099

Epoch 159/1000
Training Loss: 0.52768532, Training R2: 0.600505
Validation Loss: 0.72971791, Validation R2: 0.425472

Epoch 160/1000
Training Loss: 0.52341652, Training R2: 0.599432
Validation Loss: 0.74323690, Validation R2: 0.420865

Epoch 161/1000
Training Loss: 0.52264628, Training R2: 0.597800
Validation Loss: 0.72468930, Validation R2: 0.429013

Epoch 162/1000
Training Loss: 0.52142880, Training R2: 0.601269
Validation Loss: 0.74068666, Validation R2: 0.415741

Epoch 163/1000
Training Loss: 0.52920857, Training R2: 0.591375
Validation Loss: 0.73726887, Validation R2: 0.416706

Epoch 164/1000
Training Loss: 0.52516001, Training R2: 0.600707
Validation Loss: 0.73365903, Validation R2: 0.414255

Epoch 165/1000
Training Loss: 0.52008837, Training R2: 0.600568
Validation Loss: 0.75275266, Validation R2: 0.402785

Epoch 166/1000
Training Loss: 0.52266256, Training R2: 0.595713
Validation Loss: 0.73138273, Validation R2: 0.414021

Epoch 167/1000
Training Loss: 0.51863473, Training R2: 0.603122
Validation Loss: 0.73932058, Validation R2: 0.413162

Epoch 168/1000
Training Loss: 0.51801677, Training R2: 0.601558
Validation Loss: 0.74423903, Validation R2: 0.412695

Epoch 169/1000
Training Loss: 0.51565631, Training R2: 0.607591
Validation Loss: 0.73393780, Validation R2: 0.419721

Epoch 170/1000
Training Loss: 0.51668231, Training R2: 0.602800
Validation Loss: 0.74304473, Validation R2: 0.414087

Epoch 171/1000
Training Loss: 0.51640714, Training R2: 0.601177
Validation Loss: 0.72540158, Validation R2: 0.424487

Epoch 172/1000
Training Loss: 0.51402601, Training R2: 0.607097
Validation Loss: 0.74017888, Validation R2: 0.418339

Epoch 173/1000
Training Loss: 0.51786735, Training R2: 0.601556
Validation Loss: 0.74013352, Validation R2: 0.416349

Epoch 174/1000
Training Loss: 0.50752310, Training R2: 0.608036
Validation Loss: 0.73200291, Validation R2: 0.415572

Epoch 175/1000
Training Loss: 0.50948815, Training R2: 0.609765
Validation Loss: 0.75410855, Validation R2: 0.399201

Epoch 176/1000
Training Loss: 0.51599003, Training R2: 0.600952
Validation Loss: 0.72658551, Validation R2: 0.421293

Epoch 177/1000
Training Loss: 0.51239006, Training R2: 0.611788
Validation Loss: 0.73003662, Validation R2: 0.426614

Epoch 178/1000
Epoch 00178: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.50748319, Training R2: 0.609770
Validation Loss: 0.72902787, Validation R2: 0.427838

Epoch 179/1000
学习率已减少 4 次
Training Loss: 0.50716926, Training R2: 0.611532
Validation Loss: 0.72451782, Validation R2: 0.428244

Epoch 180/1000
Training Loss: 0.50079601, Training R2: 0.613538
Validation Loss: 0.73675734, Validation R2: 0.414698

Epoch 181/1000
Training Loss: 0.50480379, Training R2: 0.608888
Validation Loss: 0.73642516, Validation R2: 0.409456

Epoch 182/1000
Training Loss: 0.50176467, Training R2: 0.611315
Validation Loss: 0.73744941, Validation R2: 0.407587

Epoch 183/1000
Training Loss: 0.49910363, Training R2: 0.613002
Validation Loss: 0.73783582, Validation R2: 0.407488

Epoch 184/1000
Training Loss: 0.49908214, Training R2: 0.612906
Validation Loss: 0.73801565, Validation R2: 0.407623

Epoch 185/1000
Training Loss: 0.50102437, Training R2: 0.614967
Validation Loss: 0.74481583, Validation R2: 0.405975

Epoch 186/1000
Training Loss: 0.50169851, Training R2: 0.610777
Validation Loss: 0.73916924, Validation R2: 0.409669

Epoch 187/1000
Training Loss: 0.50070688, Training R2: 0.612269
Validation Loss: 0.73998916, Validation R2: 0.406380

Epoch 188/1000
Training Loss: 0.50046436, Training R2: 0.609893
Validation Loss: 0.74591011, Validation R2: 0.400616

Epoch 189/1000
Training Loss: 0.49914698, Training R2: 0.610681
Validation Loss: 0.74086791, Validation R2: 0.405948

Epoch 190/1000
Training Loss: 0.49696051, Training R2: 0.613286
Validation Loss: 0.74044269, Validation R2: 0.405752

Epoch 191/1000
Training Loss: 0.49714913, Training R2: 0.613314
Validation Loss: 0.73071766, Validation R2: 0.414422

Epoch 192/1000
Training Loss: 0.49485990, Training R2: 0.616451
Validation Loss: 0.73385280, Validation R2: 0.415132

Epoch 193/1000
Training Loss: 0.49629759, Training R2: 0.616971
Validation Loss: 0.73093033, Validation R2: 0.419954

Epoch 194/1000
Training Loss: 0.49953708, Training R2: 0.614606
Validation Loss: 0.73676932, Validation R2: 0.415818

Epoch 195/1000
Training Loss: 0.49701646, Training R2: 0.616355
Validation Loss: 0.73293138, Validation R2: 0.414434

Epoch 196/1000
Training Loss: 0.49430520, Training R2: 0.617157
Validation Loss: 0.73885465, Validation R2: 0.407825

Epoch 197/1000
Training Loss: 0.49804867, Training R2: 0.614983
Validation Loss: 0.73241836, Validation R2: 0.411520

Epoch 198/1000
Training Loss: 0.49443290, Training R2: 0.619082
Validation Loss: 0.73783636, Validation R2: 0.413792

Epoch 199/1000
Epoch 00199: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.49460529, Training R2: 0.619190
Validation Loss: 0.74215531, Validation R2: 0.414918

Epoch 200/1000
学习率已减少 5 次
Training Loss: 0.49573263, Training R2: 0.616226
Validation Loss: 0.73784608, Validation R2: 0.415610

Epoch 201/1000
Training Loss: 0.49315946, Training R2: 0.617672
Validation Loss: 0.73284274, Validation R2: 0.416712

Epoch 202/1000
Training Loss: 0.49128185, Training R2: 0.620833
Validation Loss: 0.73458225, Validation R2: 0.413309

Epoch 203/1000
Training Loss: 0.49112576, Training R2: 0.620459
Validation Loss: 0.73662686, Validation R2: 0.410816

Epoch 204/1000
Training Loss: 0.48903415, Training R2: 0.620448
Validation Loss: 0.73775488, Validation R2: 0.411530

Epoch 205/1000
Training Loss: 0.48895961, Training R2: 0.620791
Validation Loss: 0.73997402, Validation R2: 0.411070

Epoch 206/1000
Training Loss: 0.48986116, Training R2: 0.619051
Validation Loss: 0.73915797, Validation R2: 0.410765

Epoch 207/1000
Training Loss: 0.48960700, Training R2: 0.618759
Validation Loss: 0.73593509, Validation R2: 0.411208

Epoch 208/1000
Training Loss: 0.48789907, Training R2: 0.621136
Validation Loss: 0.73685265, Validation R2: 0.409907

Epoch 209/1000
Training Loss: 0.48921667, Training R2: 0.620639
Validation Loss: 0.73935848, Validation R2: 0.408770

Epoch 210/1000
Training Loss: 0.48889448, Training R2: 0.621271
Validation Loss: 0.73544908, Validation R2: 0.410270

Epoch 211/1000
Training Loss: 0.49117530, Training R2: 0.620573
Validation Loss: 0.73565626, Validation R2: 0.408920

Epoch 212/1000
Training Loss: 0.48799376, Training R2: 0.620568
Validation Loss: 0.73775458, Validation R2: 0.407345

Epoch 213/1000
Training Loss: 0.48667248, Training R2: 0.620404
Validation Loss: 0.73378330, Validation R2: 0.410537

Epoch 214/1000
Training Loss: 0.48608379, Training R2: 0.621717
Validation Loss: 0.73169601, Validation R2: 0.412791

Epoch 215/1000
Training Loss: 0.48555695, Training R2: 0.622511
Validation Loss: 0.73229015, Validation R2: 0.414045

Epoch 216/1000
Training Loss: 0.48680915, Training R2: 0.621051
Validation Loss: 0.73212707, Validation R2: 0.415334

Epoch 217/1000
Training Loss: 0.48692140, Training R2: 0.622868
Validation Loss: 0.72930950, Validation R2: 0.414174

Epoch 218/1000
Training Loss: 0.48653972, Training R2: 0.623442
Validation Loss: 0.73645276, Validation R2: 0.407994

Epoch 219/1000
Training Loss: 0.48568469, Training R2: 0.620296
Validation Loss: 0.73640531, Validation R2: 0.407024

Epoch 220/1000
Epoch 00220: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.48626817, Training R2: 0.620262
Validation Loss: 0.73170531, Validation R2: 0.410590

Epoch 221/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
