Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1092227

Epoch 1/1000
Training Loss: 1.98940641, Training R2: -1.816517
Validation Loss: 1.26302695, Validation R2: -0.223729
Saved best model with validation R2 -0.223729 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.23159744, Training R2: -0.062063
Validation Loss: 1.15206909, Validation R2: -0.266003

Epoch 3/1000
Training Loss: 1.15887420, Training R2: -0.122680
Validation Loss: 1.07820261, Validation R2: 0.026078
Saved best model with validation R2 0.026078 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.15134021, Training R2: 0.031630
Validation Loss: 1.08236229, Validation R2: 0.039208
Saved best model with validation R2 0.039208 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.12486377, Training R2: 0.038913
Validation Loss: 1.10799301, Validation R2: -0.156605

Epoch 6/1000
Training Loss: 1.13835282, Training R2: -0.092919
Validation Loss: 1.07346439, Validation R2: -0.009426

Epoch 7/1000
Training Loss: 1.12810205, Training R2: 0.034899
Validation Loss: 1.07755244, Validation R2: 0.054310
Saved best model with validation R2 0.054310 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 1.11976161, Training R2: 0.054652
Validation Loss: 1.09500384, Validation R2: -0.105547

Epoch 9/1000
Training Loss: 1.11234080, Training R2: -0.046466
Validation Loss: 1.06884789, Validation R2: -0.003630

Epoch 10/1000
Training Loss: 1.10163999, Training R2: 0.052368
Validation Loss: 1.06419802, Validation R2: 0.023546

Epoch 11/1000
Training Loss: 1.09080914, Training R2: 0.015388
Validation Loss: 1.06730700, Validation R2: -0.002283

Epoch 12/1000
Training Loss: 1.09882036, Training R2: 0.062964
Validation Loss: 1.07348716, Validation R2: 0.059752
Saved best model with validation R2 0.059752 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 1.09209105, Training R2: 0.065446
Validation Loss: 1.11715853, Validation R2: -0.172859

Epoch 14/1000
Training Loss: 1.11018165, Training R2: -0.043594
Validation Loss: 1.07146037, Validation R2: 0.044124

Epoch 15/1000
Training Loss: 1.11576735, Training R2: 0.073256
Validation Loss: 1.07341099, Validation R2: 0.061011
Saved best model with validation R2 0.061011 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 1.09436618, Training R2: 0.069400
Validation Loss: 1.11515987, Validation R2: -0.137001

Epoch 17/1000
Training Loss: 1.09985401, Training R2: -0.007836
Validation Loss: 1.06277108, Validation R2: 0.044085

Epoch 18/1000
Training Loss: 1.08725947, Training R2: 0.078978
Validation Loss: 1.06542277, Validation R2: 0.022309

Epoch 19/1000
Training Loss: 1.07786357, Training R2: 0.051839
Validation Loss: 1.07918572, Validation R2: -0.041387

Epoch 20/1000
Training Loss: 1.08000842, Training R2: 0.036235
Validation Loss: 1.06049275, Validation R2: 0.052849

Epoch 21/1000
Training Loss: 1.07926646, Training R2: 0.079882
Validation Loss: 1.07248986, Validation R2: 0.014285

Epoch 22/1000
Training Loss: 1.07728008, Training R2: 0.070344
Validation Loss: 1.06234157, Validation R2: 0.071887
Saved best model with validation R2 0.071887 to best_finetuned_model.pth

Epoch 23/1000
Training Loss: 1.09507662, Training R2: 0.087747
Validation Loss: 1.06085086, Validation R2: 0.042863

Epoch 24/1000
Training Loss: 1.06981530, Training R2: 0.076120
Validation Loss: 1.09102297, Validation R2: -0.064443

Epoch 25/1000
Training Loss: 1.08841633, Training R2: 0.013059
Validation Loss: 1.05830479, Validation R2: 0.043107

Epoch 26/1000
Training Loss: 1.07922474, Training R2: 0.088452
Validation Loss: 1.06771612, Validation R2: 0.008135

Epoch 27/1000
Training Loss: 1.07713216, Training R2: 0.042069
Validation Loss: 1.06831145, Validation R2: 0.012472

Epoch 28/1000
Training Loss: 1.07341141, Training R2: 0.089329
Validation Loss: 1.05473411, Validation R2: 0.085040
Saved best model with validation R2 0.085040 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 1.07435648, Training R2: 0.097747
Validation Loss: 1.06935382, Validation R2: 0.034493

Epoch 30/1000
Training Loss: 1.06771534, Training R2: 0.091460
Validation Loss: 1.05640292, Validation R2: 0.070853

Epoch 31/1000
Training Loss: 1.06680450, Training R2: 0.089114
Validation Loss: 1.06541395, Validation R2: 0.012190

Epoch 32/1000
Training Loss: 1.06330499, Training R2: 0.071079
Validation Loss: 1.04914200, Validation R2: 0.068863

Epoch 33/1000
Training Loss: 1.06188917, Training R2: 0.090904
Validation Loss: 1.07741511, Validation R2: -0.043083

Epoch 34/1000
Training Loss: 1.06509070, Training R2: 0.060358
Validation Loss: 1.03942537, Validation R2: 0.094512
Saved best model with validation R2 0.094512 to best_finetuned_model.pth

Epoch 35/1000
Training Loss: 1.06426613, Training R2: 0.100563
Validation Loss: 1.07499659, Validation R2: -0.009810

Epoch 36/1000
Training Loss: 1.06677108, Training R2: 0.067796
Validation Loss: 1.04389560, Validation R2: 0.042992

Epoch 37/1000
Training Loss: 1.06672350, Training R2: 0.039543
Validation Loss: 1.05658138, Validation R2: -0.014573

Epoch 38/1000
Training Loss: 1.07220645, Training R2: 0.057260
Validation Loss: 1.05204475, Validation R2: -0.000499

Epoch 39/1000
Training Loss: 1.07249015, Training R2: 0.020315
Validation Loss: 1.04119039, Validation R2: 0.053244

Epoch 40/1000
Training Loss: 1.05839754, Training R2: 0.100702
Validation Loss: 1.06450653, Validation R2: 0.024037

Epoch 41/1000
Training Loss: 1.05512794, Training R2: 0.096837
Validation Loss: 1.03211963, Validation R2: 0.101858
Saved best model with validation R2 0.101858 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 1.05451361, Training R2: 0.095896
Validation Loss: 1.03208005, Validation R2: 0.100649

Epoch 43/1000
Training Loss: 1.07207724, Training R2: 0.117314
Validation Loss: 1.05397761, Validation R2: -0.015488

Epoch 44/1000
Training Loss: 1.07305556, Training R2: 0.008325
Validation Loss: 1.03412998, Validation R2: 0.099836

Epoch 45/1000
Training Loss: 1.09072795, Training R2: 0.104497
Validation Loss: 1.03421831, Validation R2: 0.090261

Epoch 46/1000
Training Loss: 1.06099624, Training R2: 0.077693
Validation Loss: 1.04529357, Validation R2: 0.046540

Epoch 47/1000
Training Loss: 1.05876413, Training R2: 0.107325
Validation Loss: 1.03155541, Validation R2: 0.091878

Epoch 48/1000
Training Loss: 1.05314598, Training R2: 0.080819
Validation Loss: 1.03306925, Validation R2: 0.076005

Epoch 49/1000
Training Loss: 1.05835556, Training R2: 0.129533
Validation Loss: 1.02868378, Validation R2: 0.103151
Saved best model with validation R2 0.103151 to best_finetuned_model.pth

Epoch 50/1000
Training Loss: 1.04995939, Training R2: 0.073681
Validation Loss: 1.07182205, Validation R2: -0.074940

Epoch 51/1000
Training Loss: 1.05848120, Training R2: 0.070499
Validation Loss: 1.05288756, Validation R2: 0.107198
Saved best model with validation R2 0.107198 to best_finetuned_model.pth

Epoch 52/1000
Training Loss: 1.09982916, Training R2: 0.096171
Validation Loss: 1.07282829, Validation R2: -0.046285

Epoch 53/1000
Training Loss: 1.06395756, Training R2: 0.033111
Validation Loss: 1.03261554, Validation R2: 0.119762
Saved best model with validation R2 0.119762 to best_finetuned_model.pth

Epoch 54/1000
Training Loss: 1.07141588, Training R2: 0.118828
Validation Loss: 1.03354895, Validation R2: 0.039619

Epoch 55/1000
Training Loss: 1.06123837, Training R2: 0.031425
Validation Loss: 1.02681613, Validation R2: 0.106247

Epoch 56/1000
Training Loss: 1.09316746, Training R2: 0.109365
Validation Loss: 1.03357995, Validation R2: 0.097054

Epoch 57/1000
Training Loss: 1.08071849, Training R2: 0.021314
Validation Loss: 1.04688931, Validation R2: 0.033440

Epoch 58/1000
Training Loss: 1.04199782, Training R2: 0.131464
Validation Loss: 1.03655922, Validation R2: 0.110193

Epoch 59/1000
Training Loss: 1.05596924, Training R2: 0.112151
Validation Loss: 1.05318153, Validation R2: -0.006801

Epoch 60/1000
Training Loss: 1.03685073, Training R2: 0.097095
Validation Loss: 1.02144492, Validation R2: 0.118542

Epoch 61/1000
Training Loss: 1.02574246, Training R2: 0.136164
Validation Loss: 1.02568340, Validation R2: 0.087551

Epoch 62/1000
Training Loss: 1.02229599, Training R2: 0.145307
Validation Loss: 1.01541591, Validation R2: 0.131013
Saved best model with validation R2 0.131013 to best_finetuned_model.pth

Epoch 63/1000
Training Loss: 1.02500583, Training R2: 0.131359
Validation Loss: 1.01051021, Validation R2: 0.126107

Epoch 64/1000
Training Loss: 1.05000468, Training R2: 0.140290
Validation Loss: 1.01181924, Validation R2: 0.135597
Saved best model with validation R2 0.135597 to best_finetuned_model.pth

Epoch 65/1000
Training Loss: 1.01641926, Training R2: 0.142846
Validation Loss: 1.06445467, Validation R2: -0.049670

Epoch 66/1000
Training Loss: 1.04090767, Training R2: 0.053601
Validation Loss: 1.01606977, Validation R2: 0.129603

Epoch 67/1000
Training Loss: 1.05777026, Training R2: 0.147862
Validation Loss: 1.00876153, Validation R2: 0.086658

Epoch 68/1000
Training Loss: 1.03848437, Training R2: 0.071145
Validation Loss: 1.02234435, Validation R2: 0.049488

Epoch 69/1000
Training Loss: 1.00694321, Training R2: 0.146597
Validation Loss: 1.00114524, Validation R2: 0.140708
Saved best model with validation R2 0.140708 to best_finetuned_model.pth

Epoch 70/1000
Training Loss: 1.00669589, Training R2: 0.155595
Validation Loss: 1.02197373, Validation R2: 0.064228

Epoch 71/1000
Training Loss: 0.99590764, Training R2: 0.145664
Validation Loss: 1.01143169, Validation R2: 0.138615

Epoch 72/1000
Training Loss: 1.00560815, Training R2: 0.176212
Validation Loss: 1.00767040, Validation R2: 0.076778

Epoch 73/1000
Training Loss: 0.98591190, Training R2: 0.170461
Validation Loss: 0.98813140, Validation R2: 0.147344
Saved best model with validation R2 0.147344 to best_finetuned_model.pth

Epoch 74/1000
Training Loss: 0.98522066, Training R2: 0.174878
Validation Loss: 0.98109740, Validation R2: 0.153085
Saved best model with validation R2 0.153085 to best_finetuned_model.pth

Epoch 75/1000
Training Loss: 1.01422166, Training R2: 0.175915
Validation Loss: 0.98886657, Validation R2: 0.104125

Epoch 76/1000
Training Loss: 0.96982944, Training R2: 0.173111
Validation Loss: 1.07761955, Validation R2: 0.092303

Epoch 77/1000
Training Loss: 1.08964349, Training R2: 0.123799
Validation Loss: 1.05024719, Validation R2: -0.049129

Epoch 78/1000
Training Loss: 1.01512726, Training R2: 0.086268
Validation Loss: 0.98057264, Validation R2: 0.161715
Saved best model with validation R2 0.161715 to best_finetuned_model.pth

Epoch 79/1000
Training Loss: 0.96885025, Training R2: 0.195704
Validation Loss: 1.03263116, Validation R2: 0.040397

Epoch 80/1000
Training Loss: 0.99183630, Training R2: 0.154037
Validation Loss: 0.96508086, Validation R2: 0.146182

Epoch 81/1000
Training Loss: 0.98472847, Training R2: 0.132450
Validation Loss: 0.97420943, Validation R2: 0.143381

Epoch 82/1000
Training Loss: 0.99113888, Training R2: 0.194223
Validation Loss: 0.96284443, Validation R2: 0.147764

Epoch 83/1000
Training Loss: 0.94810110, Training R2: 0.200174
Validation Loss: 0.95538539, Validation R2: 0.190761
Saved best model with validation R2 0.190761 to best_finetuned_model.pth

Epoch 84/1000
Training Loss: 0.94388856, Training R2: 0.217242
Validation Loss: 0.95552033, Validation R2: 0.196274
Saved best model with validation R2 0.196274 to best_finetuned_model.pth

Epoch 85/1000
Training Loss: 0.95449385, Training R2: 0.214690
Validation Loss: 1.09483719, Validation R2: -0.123728

Epoch 86/1000
Training Loss: 1.00951631, Training R2: 0.116251
Validation Loss: 0.94947052, Validation R2: 0.195398

Epoch 87/1000
Training Loss: 0.93910063, Training R2: 0.201277
Validation Loss: 0.97705626, Validation R2: 0.183132

Epoch 88/1000
Training Loss: 1.00757860, Training R2: 0.197670
Validation Loss: 1.01568139, Validation R2: -0.010018

Epoch 89/1000
Training Loss: 1.01629973, Training R2: 0.097058
Validation Loss: 0.97708350, Validation R2: 0.168746

Epoch 90/1000
Training Loss: 0.98081918, Training R2: 0.216575
Validation Loss: 0.99222881, Validation R2: 0.080387

Epoch 91/1000
Training Loss: 0.95536156, Training R2: 0.196690
Validation Loss: 0.97030556, Validation R2: 0.167353

Epoch 92/1000
Training Loss: 0.92344128, Training R2: 0.247136
Validation Loss: 0.97779912, Validation R2: 0.094626

Epoch 93/1000
Training Loss: 0.90952382, Training R2: 0.249884
Validation Loss: 0.95150846, Validation R2: 0.151715

Epoch 94/1000
Training Loss: 0.89743551, Training R2: 0.248572
Validation Loss: 0.93580043, Validation R2: 0.176986

Epoch 95/1000
Training Loss: 0.89672267, Training R2: 0.253612
Validation Loss: 0.93277526, Validation R2: 0.161870

Epoch 96/1000
Training Loss: 0.87978820, Training R2: 0.271763
Validation Loss: 0.95384824, Validation R2: 0.132604

Epoch 97/1000
Training Loss: 0.88681032, Training R2: 0.263422
Validation Loss: 0.95842052, Validation R2: 0.136150

Epoch 98/1000
Training Loss: 0.88660232, Training R2: 0.254831
Validation Loss: 0.94730037, Validation R2: 0.167386

Epoch 99/1000
Training Loss: 0.86595229, Training R2: 0.282656
Validation Loss: 0.94163114, Validation R2: 0.168581

Epoch 100/1000
Training Loss: 0.87308898, Training R2: 0.267015
Validation Loss: 0.95445204, Validation R2: 0.085558

Epoch 101/1000
Training Loss: 0.87223565, Training R2: 0.270085
Validation Loss: 1.11275005, Validation R2: -0.199330

Epoch 102/1000
Training Loss: 0.96006636, Training R2: 0.158701
Validation Loss: 1.04608881, Validation R2: 0.116405

Epoch 103/1000
Training Loss: 0.96831922, Training R2: 0.223890
Validation Loss: 1.00132167, Validation R2: 0.016685

Epoch 104/1000
Training Loss: 0.92035200, Training R2: 0.225727
Validation Loss: 0.94291365, Validation R2: 0.188434

Epoch 105/1000
Epoch 00105: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.92145792, Training R2: 0.241727
Validation Loss: 0.94865185, Validation R2: 0.138228

Epoch 106/1000
学习率已减少 1 次
Training Loss: 0.88004749, Training R2: 0.276938
Validation Loss: 0.92915314, Validation R2: 0.183862

Epoch 107/1000
Training Loss: 0.86558263, Training R2: 0.293959
Validation Loss: 0.93612045, Validation R2: 0.126939

Epoch 108/1000
Training Loss: 0.86106925, Training R2: 0.292565
Validation Loss: 0.93030620, Validation R2: 0.152214

Epoch 109/1000
Training Loss: 0.85240904, Training R2: 0.300503
Validation Loss: 0.93075633, Validation R2: 0.163979

Epoch 110/1000
Training Loss: 0.84757823, Training R2: 0.299811
Validation Loss: 0.96477139, Validation R2: 0.070414

Epoch 111/1000
Training Loss: 0.89651236, Training R2: 0.234729
Validation Loss: 0.91909099, Validation R2: 0.187765

Epoch 112/1000
Training Loss: 0.86909878, Training R2: 0.301139
Validation Loss: 0.92627090, Validation R2: 0.154724

Epoch 113/1000
Training Loss: 0.85980723, Training R2: 0.273295
Validation Loss: 0.93263751, Validation R2: 0.162431

Epoch 114/1000
Training Loss: 0.87695523, Training R2: 0.286320
Validation Loss: 0.94881606, Validation R2: 0.135669

Epoch 115/1000
Training Loss: 0.86471143, Training R2: 0.282240
Validation Loss: 0.92219251, Validation R2: 0.167177

Epoch 116/1000
Training Loss: 0.86252623, Training R2: 0.307747
Validation Loss: 0.91319835, Validation R2: 0.201756
Saved best model with validation R2 0.201756 to best_finetuned_model.pth

Epoch 117/1000
Training Loss: 0.84809886, Training R2: 0.310923
Validation Loss: 0.97309047, Validation R2: 0.052519

Epoch 118/1000
Training Loss: 0.86704407, Training R2: 0.275068
Validation Loss: 0.90508717, Validation R2: 0.213754
Saved best model with validation R2 0.213754 to best_finetuned_model.pth

Epoch 119/1000
Training Loss: 0.83737841, Training R2: 0.316826
Validation Loss: 0.92818314, Validation R2: 0.158943

Epoch 120/1000
Training Loss: 0.83387832, Training R2: 0.303475
Validation Loss: 0.90554440, Validation R2: 0.204931

Epoch 121/1000
Training Loss: 0.83284107, Training R2: 0.316750
Validation Loss: 0.92014951, Validation R2: 0.174351

Epoch 122/1000
Training Loss: 0.83181100, Training R2: 0.318494
Validation Loss: 0.92199135, Validation R2: 0.174769

Epoch 123/1000
Training Loss: 0.81835519, Training R2: 0.335583
Validation Loss: 0.91923577, Validation R2: 0.175954

Epoch 124/1000
Training Loss: 0.82062377, Training R2: 0.328897
Validation Loss: 0.92133290, Validation R2: 0.175897

Epoch 125/1000
Training Loss: 0.81364415, Training R2: 0.337524
Validation Loss: 0.91693372, Validation R2: 0.200688

Epoch 126/1000
Training Loss: 0.80671231, Training R2: 0.339952
Validation Loss: 0.91663557, Validation R2: 0.184310

Epoch 127/1000
Training Loss: 0.80641990, Training R2: 0.332493
Validation Loss: 0.90916592, Validation R2: 0.198528

Epoch 128/1000
Training Loss: 0.80167924, Training R2: 0.333410
Validation Loss: 0.90836293, Validation R2: 0.195355

Epoch 129/1000
Training Loss: 0.80154864, Training R2: 0.337266
Validation Loss: 0.90469277, Validation R2: 0.202304

Epoch 130/1000
Training Loss: 0.80308440, Training R2: 0.345345
Validation Loss: 0.91135055, Validation R2: 0.164337

Epoch 131/1000
Training Loss: 0.79699884, Training R2: 0.351251
Validation Loss: 0.90617889, Validation R2: 0.213324

Epoch 132/1000
Training Loss: 0.79606058, Training R2: 0.353793
Validation Loss: 0.90664917, Validation R2: 0.213398

Epoch 133/1000
Training Loss: 0.79114333, Training R2: 0.356354
Validation Loss: 0.92994595, Validation R2: 0.155376

Epoch 134/1000
Training Loss: 0.78766575, Training R2: 0.364327
Validation Loss: 0.89820784, Validation R2: 0.193537

Epoch 135/1000
Training Loss: 0.80651535, Training R2: 0.349397
Validation Loss: 0.89063460, Validation R2: 0.252287
Saved best model with validation R2 0.252287 to best_finetuned_model.pth

Epoch 136/1000
Training Loss: 0.79487885, Training R2: 0.354040
Validation Loss: 0.91417229, Validation R2: 0.217965

Epoch 137/1000
Training Loss: 0.79556534, Training R2: 0.356207
Validation Loss: 0.91441166, Validation R2: 0.184854

Epoch 138/1000
Training Loss: 0.78327440, Training R2: 0.367270
Validation Loss: 0.95170957, Validation R2: 0.206990

Epoch 139/1000
Training Loss: 0.83653995, Training R2: 0.341742
Validation Loss: 1.02444673, Validation R2: -0.054703

Epoch 140/1000
Training Loss: 0.84658906, Training R2: 0.299714
Validation Loss: 0.92533231, Validation R2: 0.224617

Epoch 141/1000
Training Loss: 0.83856346, Training R2: 0.306765
Validation Loss: 0.89940614, Validation R2: 0.211079

Epoch 142/1000
Training Loss: 0.82312854, Training R2: 0.334257
Validation Loss: 0.88669288, Validation R2: 0.237852

Epoch 143/1000
Training Loss: 0.78637461, Training R2: 0.368624
Validation Loss: 0.88431609, Validation R2: 0.210472

Epoch 144/1000
Training Loss: 0.78047306, Training R2: 0.375693
Validation Loss: 0.87215561, Validation R2: 0.266765
Saved best model with validation R2 0.266765 to best_finetuned_model.pth

Epoch 145/1000
Training Loss: 0.78436929, Training R2: 0.374868
Validation Loss: 0.91651684, Validation R2: 0.178521

Epoch 146/1000
Training Loss: 0.80703352, Training R2: 0.337735
Validation Loss: 0.87845045, Validation R2: 0.254427

Epoch 147/1000
Training Loss: 0.78492302, Training R2: 0.363228
Validation Loss: 0.94313735, Validation R2: 0.093007

Epoch 148/1000
Training Loss: 0.83047022, Training R2: 0.306285
Validation Loss: 0.88296324, Validation R2: 0.229868

Epoch 149/1000
Training Loss: 0.77224148, Training R2: 0.381607
Validation Loss: 0.87940115, Validation R2: 0.249831

Epoch 150/1000
Training Loss: 0.76717000, Training R2: 0.383385
Validation Loss: 0.89115781, Validation R2: 0.210462

Epoch 151/1000
Training Loss: 0.76274793, Training R2: 0.384598
Validation Loss: 0.91914630, Validation R2: 0.145705

Epoch 152/1000
Training Loss: 0.78061785, Training R2: 0.355514
Validation Loss: 0.94450748, Validation R2: 0.157736

Epoch 153/1000
Training Loss: 0.81671769, Training R2: 0.323222
Validation Loss: 0.92787147, Validation R2: 0.160889

Epoch 154/1000
Training Loss: 0.77988070, Training R2: 0.358917
Validation Loss: 0.90932828, Validation R2: 0.184914

Epoch 155/1000
Training Loss: 0.76586637, Training R2: 0.372490
Validation Loss: 0.86346388, Validation R2: 0.289560
Saved best model with validation R2 0.289560 to best_finetuned_model.pth

Epoch 156/1000
Training Loss: 0.76356850, Training R2: 0.395994
Validation Loss: 0.90943968, Validation R2: 0.166521

Epoch 157/1000
Training Loss: 0.76129108, Training R2: 0.389175
Validation Loss: 0.86306000, Validation R2: 0.245882

Epoch 158/1000
Training Loss: 0.76233067, Training R2: 0.396613
Validation Loss: 0.88935864, Validation R2: 0.243432

Epoch 159/1000
Training Loss: 0.76807674, Training R2: 0.395907
Validation Loss: 0.92918259, Validation R2: 0.102568

Epoch 160/1000
Training Loss: 0.76961464, Training R2: 0.370064
Validation Loss: 0.89228559, Validation R2: 0.263842

Epoch 161/1000
Training Loss: 0.77921740, Training R2: 0.378408
Validation Loss: 0.86621076, Validation R2: 0.264467

Epoch 162/1000
Training Loss: 0.76733254, Training R2: 0.384357
Validation Loss: 0.89525414, Validation R2: 0.212800

Epoch 163/1000
Training Loss: 0.74462414, Training R2: 0.402676
Validation Loss: 0.89508903, Validation R2: 0.212048

Epoch 164/1000
Training Loss: 0.74143725, Training R2: 0.406180
Validation Loss: 0.90590030, Validation R2: 0.199050

Epoch 165/1000
Training Loss: 0.72970348, Training R2: 0.414484
Validation Loss: 0.92286289, Validation R2: 0.214517

Epoch 166/1000
Training Loss: 0.78832168, Training R2: 0.363487
Validation Loss: 0.94970775, Validation R2: 0.111389

Epoch 167/1000
Training Loss: 0.75358100, Training R2: 0.402705
Validation Loss: 0.89030427, Validation R2: 0.206313

Epoch 168/1000
Training Loss: 0.73231655, Training R2: 0.408092
Validation Loss: 0.92866117, Validation R2: 0.124665

Epoch 169/1000
Training Loss: 0.74848280, Training R2: 0.397014
Validation Loss: 0.89643002, Validation R2: 0.210205

Epoch 170/1000
Training Loss: 0.75773823, Training R2: 0.374829
Validation Loss: 0.87200230, Validation R2: 0.268446

Epoch 171/1000
Training Loss: 0.75733741, Training R2: 0.411184
Validation Loss: 0.92370784, Validation R2: 0.105460

Epoch 172/1000
Training Loss: 0.74407263, Training R2: 0.392489
Validation Loss: 0.88494354, Validation R2: 0.242353

Epoch 173/1000
Training Loss: 0.72646920, Training R2: 0.435687
Validation Loss: 0.90124464, Validation R2: 0.184268

Epoch 174/1000
Training Loss: 0.74209121, Training R2: 0.409421
Validation Loss: 0.87236148, Validation R2: 0.248525

Epoch 175/1000
Training Loss: 0.73122847, Training R2: 0.413211
Validation Loss: 0.90190428, Validation R2: 0.195622

Epoch 176/1000
Epoch 00176: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.73430021, Training R2: 0.424525
Validation Loss: 0.92194051, Validation R2: 0.105459

Epoch 177/1000
学习率已减少 2 次
Training Loss: 0.73347684, Training R2: 0.400970
Validation Loss: 0.90055019, Validation R2: 0.204902

Epoch 178/1000
Training Loss: 0.70466437, Training R2: 0.447362
Validation Loss: 0.89055908, Validation R2: 0.238824

Epoch 179/1000
Training Loss: 0.70212853, Training R2: 0.436036
Validation Loss: 0.88351685, Validation R2: 0.241218

Epoch 180/1000
Training Loss: 0.69825397, Training R2: 0.439100
Validation Loss: 0.91353613, Validation R2: 0.189885

Epoch 181/1000
Training Loss: 0.71476903, Training R2: 0.419581
Validation Loss: 0.89441496, Validation R2: 0.213842

Epoch 182/1000
Training Loss: 0.70018229, Training R2: 0.449892
Validation Loss: 0.87479192, Validation R2: 0.239443

Epoch 183/1000
Training Loss: 0.69449076, Training R2: 0.458426
Validation Loss: 0.91458875, Validation R2: 0.182093

Epoch 184/1000
Training Loss: 0.69476578, Training R2: 0.449838
Validation Loss: 0.90235031, Validation R2: 0.241810

Epoch 185/1000
Training Loss: 0.71270099, Training R2: 0.434927
Validation Loss: 0.90292585, Validation R2: 0.187631

Epoch 186/1000
Training Loss: 0.68875391, Training R2: 0.446369
Validation Loss: 0.87853551, Validation R2: 0.243945

Epoch 187/1000
Training Loss: 0.68401108, Training R2: 0.460972
Validation Loss: 0.90631145, Validation R2: 0.190794

Epoch 188/1000
Training Loss: 0.69858097, Training R2: 0.441577
Validation Loss: 0.89011395, Validation R2: 0.241340

Epoch 189/1000
Training Loss: 0.68168024, Training R2: 0.457880
Validation Loss: 0.90701705, Validation R2: 0.148684

Epoch 190/1000
Training Loss: 0.74676456, Training R2: 0.379636
Validation Loss: 0.88224244, Validation R2: 0.232892

Epoch 191/1000
Training Loss: 0.74332048, Training R2: 0.424088
Validation Loss: 0.90175229, Validation R2: 0.223068

Epoch 192/1000
Training Loss: 0.69761058, Training R2: 0.447896
Validation Loss: 0.89269537, Validation R2: 0.229859

Epoch 193/1000
Training Loss: 0.68273126, Training R2: 0.461917
Validation Loss: 0.85585302, Validation R2: 0.281276

Epoch 194/1000
Training Loss: 0.69383445, Training R2: 0.444718
Validation Loss: 0.87209141, Validation R2: 0.229308

Epoch 195/1000
Training Loss: 0.68473004, Training R2: 0.465487
Validation Loss: 0.88455212, Validation R2: 0.237364

Epoch 196/1000
Training Loss: 0.67507490, Training R2: 0.461514
Validation Loss: 0.89939743, Validation R2: 0.207369

Epoch 197/1000
Epoch 00197: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.66434706, Training R2: 0.471011
Validation Loss: 0.87967253, Validation R2: 0.218956

Epoch 198/1000
学习率已减少 3 次
Training Loss: 0.67132001, Training R2: 0.460831
Validation Loss: 0.88562745, Validation R2: 0.206833

Epoch 199/1000
Training Loss: 0.66385766, Training R2: 0.469173
Validation Loss: 0.88323188, Validation R2: 0.244216

Epoch 200/1000
Training Loss: 0.65970480, Training R2: 0.476465
Validation Loss: 0.89703894, Validation R2: 0.222964

Epoch 201/1000
Training Loss: 0.66039737, Training R2: 0.475549
Validation Loss: 0.89691579, Validation R2: 0.223514

Epoch 202/1000
Training Loss: 0.65532082, Training R2: 0.476241
Validation Loss: 0.88451290, Validation R2: 0.234728

Epoch 203/1000
Training Loss: 0.65063391, Training R2: 0.482229
Validation Loss: 0.88022459, Validation R2: 0.241386

Epoch 204/1000
Training Loss: 0.64952918, Training R2: 0.486486
Validation Loss: 0.88341117, Validation R2: 0.237987

Epoch 205/1000
Training Loss: 0.64931242, Training R2: 0.483584
Validation Loss: 0.89048302, Validation R2: 0.223640

Epoch 206/1000
Training Loss: 0.65103562, Training R2: 0.478886
Validation Loss: 0.88679546, Validation R2: 0.223729

Epoch 207/1000
Training Loss: 0.64859307, Training R2: 0.482570
Validation Loss: 0.88352096, Validation R2: 0.232418

Epoch 208/1000
Training Loss: 0.64280279, Training R2: 0.488231
Validation Loss: 0.88388562, Validation R2: 0.238704

Epoch 209/1000
Training Loss: 0.64153795, Training R2: 0.490205
Validation Loss: 0.88927650, Validation R2: 0.221673

Epoch 210/1000
Training Loss: 0.64296100, Training R2: 0.484053
Validation Loss: 0.88522923, Validation R2: 0.231376

Epoch 211/1000
Training Loss: 0.63842835, Training R2: 0.492378
Validation Loss: 0.88730818, Validation R2: 0.225181

Epoch 212/1000
Training Loss: 0.64200598, Training R2: 0.488318
Validation Loss: 0.88430595, Validation R2: 0.234788

Epoch 213/1000
Training Loss: 0.63894600, Training R2: 0.494656
Validation Loss: 0.88824832, Validation R2: 0.223782

Epoch 214/1000
Training Loss: 0.63787973, Training R2: 0.495018
Validation Loss: 0.89243269, Validation R2: 0.207571

Epoch 215/1000
Training Loss: 0.63812779, Training R2: 0.493626
Validation Loss: 0.88020551, Validation R2: 0.244246

Epoch 216/1000
Training Loss: 0.64164939, Training R2: 0.492471
Validation Loss: 0.88776976, Validation R2: 0.224651

Epoch 217/1000
Training Loss: 0.64615826, Training R2: 0.486280
Validation Loss: 0.87821555, Validation R2: 0.240918

Epoch 218/1000
Epoch 00218: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.64366978, Training R2: 0.494704
Validation Loss: 0.87351507, Validation R2: 0.258731

Epoch 219/1000
学习率已减少 4 次
Training Loss: 0.64058149, Training R2: 0.496245
Validation Loss: 0.88371778, Validation R2: 0.220995

Epoch 220/1000
Training Loss: 0.63729532, Training R2: 0.494253
Validation Loss: 0.88663906, Validation R2: 0.223799

Epoch 221/1000
Training Loss: 0.63557718, Training R2: 0.493355
Validation Loss: 0.88611197, Validation R2: 0.238322

Epoch 222/1000
Training Loss: 0.63892529, Training R2: 0.496771
Validation Loss: 0.88799757, Validation R2: 0.225484

Epoch 223/1000
Training Loss: 0.63169650, Training R2: 0.498740
Validation Loss: 0.88352799, Validation R2: 0.227871

Epoch 224/1000
Training Loss: 0.63341752, Training R2: 0.495463
Validation Loss: 0.87923676, Validation R2: 0.234226

Epoch 225/1000
Training Loss: 0.63231678, Training R2: 0.500131
Validation Loss: 0.88628066, Validation R2: 0.219440

Epoch 226/1000
Training Loss: 0.62996638, Training R2: 0.502924
Validation Loss: 0.89009446, Validation R2: 0.217074

Epoch 227/1000
Training Loss: 0.62932143, Training R2: 0.504593
Validation Loss: 0.88846940, Validation R2: 0.226005

Epoch 228/1000
Training Loss: 0.62651748, Training R2: 0.505205
Validation Loss: 0.89007407, Validation R2: 0.218708

Epoch 229/1000
Training Loss: 0.62340597, Training R2: 0.505682
Validation Loss: 0.88403499, Validation R2: 0.227154

Epoch 230/1000
Training Loss: 0.62440497, Training R2: 0.506634
Validation Loss: 0.88358867, Validation R2: 0.231022

Epoch 231/1000
Training Loss: 0.62305122, Training R2: 0.507230
Validation Loss: 0.89051992, Validation R2: 0.222432

Epoch 232/1000
Training Loss: 0.62758292, Training R2: 0.498415
Validation Loss: 0.89691579, Validation R2: 0.208146

Epoch 233/1000
Training Loss: 0.63024817, Training R2: 0.497063
Validation Loss: 0.89634514, Validation R2: 0.209668

Epoch 234/1000
Training Loss: 0.62901510, Training R2: 0.499828
Validation Loss: 0.88441253, Validation R2: 0.235049

Epoch 235/1000
Training Loss: 0.62612710, Training R2: 0.502764
Validation Loss: 0.89261168, Validation R2: 0.204972

Epoch 236/1000
Training Loss: 0.63032756, Training R2: 0.497398
Validation Loss: 0.88800025, Validation R2: 0.221093

Epoch 237/1000
Training Loss: 0.62019362, Training R2: 0.509341
Validation Loss: 0.89160019, Validation R2: 0.221928

Epoch 238/1000
Training Loss: 0.61955601, Training R2: 0.510051
Validation Loss: 0.89941716, Validation R2: 0.203097

Epoch 239/1000
Epoch 00239: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.62297265, Training R2: 0.503886
Validation Loss: 0.89634430, Validation R2: 0.200578

Epoch 240/1000
学习率已减少 5 次
Training Loss: 0.62157723, Training R2: 0.503344
Validation Loss: 0.89197510, Validation R2: 0.218823

Epoch 241/1000
Training Loss: 0.61995715, Training R2: 0.507193
Validation Loss: 0.89094228, Validation R2: 0.222415

Epoch 242/1000
Training Loss: 0.61536510, Training R2: 0.512242
Validation Loss: 0.89206928, Validation R2: 0.213255

Epoch 243/1000
Training Loss: 0.61935366, Training R2: 0.502831
Validation Loss: 0.89186966, Validation R2: 0.213594

Epoch 244/1000
Training Loss: 0.61453397, Training R2: 0.510229
Validation Loss: 0.88884521, Validation R2: 0.221936

Epoch 245/1000
Training Loss: 0.61212685, Training R2: 0.513721
Validation Loss: 0.88835037, Validation R2: 0.219282

Epoch 246/1000
Training Loss: 0.61076627, Training R2: 0.514594
Validation Loss: 0.89030409, Validation R2: 0.216816

Epoch 247/1000
Training Loss: 0.61248418, Training R2: 0.511783
Validation Loss: 0.89165276, Validation R2: 0.217297

Epoch 248/1000
Training Loss: 0.61145231, Training R2: 0.514063
Validation Loss: 0.89409453, Validation R2: 0.213638

Epoch 249/1000
Training Loss: 0.61619534, Training R2: 0.508275
Validation Loss: 0.89454144, Validation R2: 0.213766

Epoch 250/1000
Training Loss: 0.61452532, Training R2: 0.511052
Validation Loss: 0.88884151, Validation R2: 0.222229

Epoch 251/1000
Training Loss: 0.61131181, Training R2: 0.514091
Validation Loss: 0.88675922, Validation R2: 0.224322

Epoch 252/1000
Training Loss: 0.61451258, Training R2: 0.507471
Validation Loss: 0.88865095, Validation R2: 0.219497

Epoch 253/1000
Training Loss: 0.61109331, Training R2: 0.512299
Validation Loss: 0.88945132, Validation R2: 0.218588

Epoch 254/1000
Training Loss: 0.60617491, Training R2: 0.516651
Validation Loss: 0.89542937, Validation R2: 0.210040

Epoch 255/1000
Training Loss: 0.61035525, Training R2: 0.512637
Validation Loss: 0.89785290, Validation R2: 0.207022

Epoch 256/1000
Training Loss: 0.61005256, Training R2: 0.513850
Validation Loss: 0.89688355, Validation R2: 0.210243

Epoch 257/1000
Training Loss: 0.61027445, Training R2: 0.511563
Validation Loss: 0.89393216, Validation R2: 0.208476

Epoch 258/1000
Training Loss: 0.61127933, Training R2: 0.509736
Validation Loss: 0.88939327, Validation R2: 0.217786

Epoch 259/1000
Training Loss: 0.60896778, Training R2: 0.514541
Validation Loss: 0.89097440, Validation R2: 0.216385

Epoch 260/1000
Epoch 00260: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.60986241, Training R2: 0.509584
Validation Loss: 0.89503157, Validation R2: 0.208106

Epoch 261/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
