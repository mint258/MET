Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Trainable
interaction_blocks.3.conv1.lin_rel.bias: Trainable
interaction_blocks.3.conv1.lin_root.weight: Trainable
interaction_blocks.3.conv2.lin_rel.weight: Trainable
interaction_blocks.3.conv2.lin_rel.bias: Trainable
interaction_blocks.3.conv2.lin_root.weight: Trainable
interaction_blocks.3.lin1.weight: Trainable
interaction_blocks.3.lin1.bias: Trainable
interaction_blocks.3.lin2.weight: Trainable
interaction_blocks.3.lin2.bias: Trainable
interaction_blocks.3.lin_cat.weight: Trainable
interaction_blocks.3.lin_cat.bias: Trainable
interaction_blocks.3.norm.weight: Trainable
interaction_blocks.3.norm.bias: Trainable
interaction_blocks.3.norm.mean_scale: Trainable
interaction_blocks.3.lin_feature1.lin1.weight: Trainable
interaction_blocks.3.lin_feature1.lin2.weight: Trainable
interaction_blocks.3.lin_feature2.lin1.weight: Trainable
interaction_blocks.3.lin_feature2.lin2.weight: Trainable
interaction_blocks.3.lin.weight: Trainable
interaction_blocks.3.lin.bias: Trainable
interaction_blocks.3.lins.0.weight: Trainable
interaction_blocks.3.lins.0.bias: Trainable
interaction_blocks.3.lins.1.weight: Trainable
interaction_blocks.3.lins.1.bias: Trainable
interaction_blocks.3.lins.2.weight: Trainable
interaction_blocks.3.lins.2.bias: Trainable
interaction_blocks.3.lins.3.weight: Trainable
interaction_blocks.3.lins.3.bias: Trainable
interaction_blocks.3.final.weight: Trainable
interaction_blocks.3.final.bias: Trainable
lins.0.weight: Trainable
lins.0.bias: Trainable
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 2241155

Epoch 1/1000
Training Loss: 1.27023281, Training R2: -0.186599
Validation Loss: 1.03004897, Validation R2: 0.034708
Saved best model with validation R2 0.034708 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.15224462, Training R2: 0.007945
Validation Loss: 1.09540522, Validation R2: 0.004590

Epoch 3/1000
Training Loss: 1.15644112, Training R2: 0.027195
Validation Loss: 1.07834291, Validation R2: -0.076080

Epoch 4/1000
Training Loss: 1.16189059, Training R2: -0.130593
Validation Loss: 1.02370012, Validation R2: 0.079748
Saved best model with validation R2 0.079748 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.13511083, Training R2: 0.049586
Validation Loss: 1.06730151, Validation R2: 0.043659

Epoch 6/1000
Training Loss: 1.13864563, Training R2: 0.054309
Validation Loss: 1.04023433, Validation R2: -0.001210

Epoch 7/1000
Training Loss: 1.12616313, Training R2: -0.071333
Validation Loss: 1.04013193, Validation R2: -0.015186

Epoch 8/1000
Training Loss: 1.07663918, Training R2: 0.032844
Validation Loss: 0.96362668, Validation R2: 0.154639
Saved best model with validation R2 0.154639 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.04366120, Training R2: 0.110391
Validation Loss: 0.98040515, Validation R2: 0.083678

Epoch 10/1000
Training Loss: 1.03365731, Training R2: 0.093718
Validation Loss: 0.92708862, Validation R2: 0.182153
Saved best model with validation R2 0.182153 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 0.99723620, Training R2: 0.204716
Validation Loss: 0.91917121, Validation R2: 0.196313
Saved best model with validation R2 0.196313 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 0.96108690, Training R2: 0.223704
Validation Loss: 0.95462817, Validation R2: 0.118964

Epoch 13/1000
Training Loss: 0.94944385, Training R2: 0.212948
Validation Loss: 0.91549933, Validation R2: 0.194432

Epoch 14/1000
Training Loss: 0.92238936, Training R2: 0.249217
Validation Loss: 0.93029857, Validation R2: 0.164815

Epoch 15/1000
Training Loss: 0.91554509, Training R2: 0.270643
Validation Loss: 0.97585958, Validation R2: 0.118924

Epoch 16/1000
Training Loss: 0.90657171, Training R2: 0.249817
Validation Loss: 1.03444076, Validation R2: 0.040454

Epoch 17/1000
Training Loss: 0.99134529, Training R2: 0.221595
Validation Loss: 0.98119205, Validation R2: 0.131224

Epoch 18/1000
Training Loss: 0.90895150, Training R2: 0.262392
Validation Loss: 0.98524070, Validation R2: 0.098312

Epoch 19/1000
Training Loss: 0.90418085, Training R2: 0.307159
Validation Loss: 0.97983533, Validation R2: 0.156508

Epoch 20/1000
Training Loss: 0.95937743, Training R2: 0.187973
Validation Loss: 0.85164076, Validation R2: 0.302831
Saved best model with validation R2 0.302831 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.84644311, Training R2: 0.366549
Validation Loss: 0.86248165, Validation R2: 0.298123

Epoch 22/1000
Training Loss: 0.79595403, Training R2: 0.401681
Validation Loss: 0.87749958, Validation R2: 0.247963

Epoch 23/1000
Training Loss: 0.78276111, Training R2: 0.434324
Validation Loss: 0.85698950, Validation R2: 0.323094
Saved best model with validation R2 0.323094 to best_finetuned_model.pth

Epoch 24/1000
Training Loss: 0.75238695, Training R2: 0.439169
Validation Loss: 0.80845809, Validation R2: 0.328216
Saved best model with validation R2 0.328216 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 0.74549048, Training R2: 0.461918
Validation Loss: 0.88005912, Validation R2: 0.299274

Epoch 26/1000
Training Loss: 0.72617546, Training R2: 0.472267
Validation Loss: 0.80484784, Validation R2: 0.299255

Epoch 27/1000
Training Loss: 0.70110790, Training R2: 0.512894
Validation Loss: 0.77727777, Validation R2: 0.394618
Saved best model with validation R2 0.394618 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 0.69221787, Training R2: 0.521726
Validation Loss: 0.81604421, Validation R2: 0.365773

Epoch 29/1000
Training Loss: 0.69921479, Training R2: 0.514155
Validation Loss: 0.80240005, Validation R2: 0.336236

Epoch 30/1000
Training Loss: 0.66452537, Training R2: 0.543234
Validation Loss: 0.82148391, Validation R2: 0.375806

Epoch 31/1000
Training Loss: 0.64118282, Training R2: 0.569628
Validation Loss: 0.76269788, Validation R2: 0.410979
Saved best model with validation R2 0.410979 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 0.62278469, Training R2: 0.569245
Validation Loss: 0.76849544, Validation R2: 0.409152

Epoch 33/1000
Training Loss: 0.61403525, Training R2: 0.574036
Validation Loss: 0.75873989, Validation R2: 0.402040

Epoch 34/1000
Training Loss: 0.60981012, Training R2: 0.594753
Validation Loss: 0.80996853, Validation R2: 0.366388

Epoch 35/1000
Training Loss: 0.62992114, Training R2: 0.577260
Validation Loss: 0.79958940, Validation R2: 0.394319

Epoch 36/1000
Training Loss: 0.60234107, Training R2: 0.587059
Validation Loss: 0.79413420, Validation R2: 0.402635

Epoch 37/1000
Training Loss: 0.57360394, Training R2: 0.616693
Validation Loss: 0.78742504, Validation R2: 0.390757

Epoch 38/1000
Training Loss: 0.55811535, Training R2: 0.617341
Validation Loss: 0.75875103, Validation R2: 0.414941
Saved best model with validation R2 0.414941 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.55209459, Training R2: 0.636058
Validation Loss: 0.74514526, Validation R2: 0.432014
Saved best model with validation R2 0.432014 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.52512368, Training R2: 0.659926
Validation Loss: 0.77314985, Validation R2: 0.423037

Epoch 41/1000
Training Loss: 0.51066375, Training R2: 0.669371
Validation Loss: 0.75446761, Validation R2: 0.438030
Saved best model with validation R2 0.438030 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 0.48959266, Training R2: 0.683868
Validation Loss: 0.73270494, Validation R2: 0.441368
Saved best model with validation R2 0.441368 to best_finetuned_model.pth

Epoch 43/1000
Training Loss: 0.47489199, Training R2: 0.693592
Validation Loss: 0.80525082, Validation R2: 0.404028

Epoch 44/1000
Training Loss: 0.53802329, Training R2: 0.654424
Validation Loss: 0.76480627, Validation R2: 0.428346

Epoch 45/1000
Training Loss: 0.46854674, Training R2: 0.695167
Validation Loss: 0.75144535, Validation R2: 0.442803
Saved best model with validation R2 0.442803 to best_finetuned_model.pth

Epoch 46/1000
Training Loss: 0.45466636, Training R2: 0.701907
Validation Loss: 0.75682539, Validation R2: 0.420459

Epoch 47/1000
Training Loss: 0.46896116, Training R2: 0.701460
Validation Loss: 0.75755215, Validation R2: 0.416177

Epoch 48/1000
Training Loss: 0.43730748, Training R2: 0.718839
Validation Loss: 0.78119385, Validation R2: 0.348400

Epoch 49/1000
Training Loss: 0.48646064, Training R2: 0.709024
Validation Loss: 0.81366730, Validation R2: 0.301273

Epoch 50/1000
Training Loss: 0.53774028, Training R2: 0.681507
Validation Loss: 0.78071719, Validation R2: 0.420988

Epoch 51/1000
Training Loss: 0.49793480, Training R2: 0.696095
Validation Loss: 0.80135298, Validation R2: 0.396093

Epoch 52/1000
Training Loss: 0.46047920, Training R2: 0.724719
Validation Loss: 0.76150167, Validation R2: 0.439913

Epoch 53/1000
Training Loss: 0.43653467, Training R2: 0.728959
Validation Loss: 0.73853630, Validation R2: 0.458341
Saved best model with validation R2 0.458341 to best_finetuned_model.pth

Epoch 54/1000
Training Loss: 0.43086004, Training R2: 0.724315
Validation Loss: 0.73552418, Validation R2: 0.388733

Epoch 55/1000
Training Loss: 0.44100186, Training R2: 0.738391
Validation Loss: 0.74104959, Validation R2: 0.425564

Epoch 56/1000
Training Loss: 0.45383742, Training R2: 0.720713
Validation Loss: 0.75612813, Validation R2: 0.433970

Epoch 57/1000
Training Loss: 0.43674363, Training R2: 0.741721
Validation Loss: 0.77297497, Validation R2: 0.399247

Epoch 58/1000
Training Loss: 0.44590703, Training R2: 0.741159
Validation Loss: 0.75971347, Validation R2: 0.455152

Epoch 59/1000
Training Loss: 0.44501144, Training R2: 0.745018
Validation Loss: 0.80742782, Validation R2: 0.408659

Epoch 60/1000
Training Loss: 0.43091607, Training R2: 0.742324
Validation Loss: 0.74638963, Validation R2: 0.431723

Epoch 61/1000
Training Loss: 0.38388943, Training R2: 0.767298
Validation Loss: 0.71294266, Validation R2: 0.469110
Saved best model with validation R2 0.469110 to best_finetuned_model.pth

Epoch 62/1000
Training Loss: 0.37009186, Training R2: 0.774023
Validation Loss: 0.74832779, Validation R2: 0.421543

Epoch 63/1000
Training Loss: 0.37672073, Training R2: 0.780513
Validation Loss: 0.73420578, Validation R2: 0.457992

Epoch 64/1000
Training Loss: 0.35724865, Training R2: 0.786574
Validation Loss: 0.73885602, Validation R2: 0.447312

Epoch 65/1000
Training Loss: 0.35877258, Training R2: 0.788342
Validation Loss: 0.78933907, Validation R2: 0.393867

Epoch 66/1000
Training Loss: 0.37611748, Training R2: 0.779153
Validation Loss: 0.72885716, Validation R2: 0.446132

Epoch 67/1000
Training Loss: 0.34328893, Training R2: 0.801032
Validation Loss: 0.73262358, Validation R2: 0.460065

Epoch 68/1000
Training Loss: 0.34636990, Training R2: 0.800820
Validation Loss: 0.74943340, Validation R2: 0.442019

Epoch 69/1000
Training Loss: 0.34722783, Training R2: 0.797668
Validation Loss: 0.77264631, Validation R2: 0.427739

Epoch 70/1000
Training Loss: 0.36820412, Training R2: 0.782382
Validation Loss: 0.73428577, Validation R2: 0.448825

Epoch 71/1000
Training Loss: 0.34423543, Training R2: 0.804245
Validation Loss: 0.72644967, Validation R2: 0.439680

Epoch 72/1000
Training Loss: 0.36565712, Training R2: 0.780618
Validation Loss: 0.73660529, Validation R2: 0.446325

Epoch 73/1000
Training Loss: 0.37655604, Training R2: 0.786396
Validation Loss: 0.73975384, Validation R2: 0.427890

Epoch 74/1000
Training Loss: 0.36601932, Training R2: 0.799867
Validation Loss: 0.74136078, Validation R2: 0.426610

Epoch 75/1000
Training Loss: 0.35123485, Training R2: 0.799225
Validation Loss: 0.73484343, Validation R2: 0.431271

Epoch 76/1000
Training Loss: 0.33483670, Training R2: 0.812716
Validation Loss: 0.75161368, Validation R2: 0.392996

Epoch 77/1000
Training Loss: 0.35534001, Training R2: 0.798947
Validation Loss: 0.74250984, Validation R2: 0.426392

Epoch 78/1000
Training Loss: 0.39018216, Training R2: 0.782228
Validation Loss: 0.77596915, Validation R2: 0.432520

Epoch 79/1000
Training Loss: 0.40320876, Training R2: 0.774677
Validation Loss: 0.73823243, Validation R2: 0.436359

Epoch 80/1000
Training Loss: 0.33441344, Training R2: 0.816540
Validation Loss: 0.75801337, Validation R2: 0.417904

Epoch 81/1000
Training Loss: 0.33471298, Training R2: 0.818712
Validation Loss: 0.71249884, Validation R2: 0.464497

Epoch 82/1000
Epoch 00082: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.32314326, Training R2: 0.816611
Validation Loss: 0.74097419, Validation R2: 0.428649

Epoch 83/1000
学习率已减少 1 次
Training Loss: 0.32270423, Training R2: 0.826947
Validation Loss: 0.73373258, Validation R2: 0.468167

Epoch 84/1000
Training Loss: 0.29248068, Training R2: 0.838800
Validation Loss: 0.72170597, Validation R2: 0.450029

Epoch 85/1000
Training Loss: 0.29192068, Training R2: 0.836662
Validation Loss: 0.72959340, Validation R2: 0.463406

Epoch 86/1000
Training Loss: 0.27619173, Training R2: 0.840829
Validation Loss: 0.70413589, Validation R2: 0.465267

Epoch 87/1000
Training Loss: 0.26910204, Training R2: 0.848183
Validation Loss: 0.70587391, Validation R2: 0.468402

Epoch 88/1000
Training Loss: 0.23898476, Training R2: 0.859761
Validation Loss: 0.71359128, Validation R2: 0.476627
Saved best model with validation R2 0.476627 to best_finetuned_model.pth

Epoch 89/1000
Training Loss: 0.25415183, Training R2: 0.851566
Validation Loss: 0.71354598, Validation R2: 0.463761

Epoch 90/1000
Training Loss: 0.24491473, Training R2: 0.860173
Validation Loss: 0.71944988, Validation R2: 0.437274

Epoch 91/1000
Training Loss: 0.24576501, Training R2: 0.862810
Validation Loss: 0.72496849, Validation R2: 0.453149

Epoch 92/1000
Training Loss: 0.25470553, Training R2: 0.858601
Validation Loss: 0.72109228, Validation R2: 0.451647

Epoch 93/1000
Training Loss: 0.24366197, Training R2: 0.860932
Validation Loss: 0.73429149, Validation R2: 0.421612

Epoch 94/1000
Training Loss: 0.22493244, Training R2: 0.870718
Validation Loss: 0.72412378, Validation R2: 0.441132

Epoch 95/1000
Training Loss: 0.22357325, Training R2: 0.872626
Validation Loss: 0.72665483, Validation R2: 0.447427

Epoch 96/1000
Training Loss: 0.21153175, Training R2: 0.878765
Validation Loss: 0.73427308, Validation R2: 0.452325

Epoch 97/1000
Training Loss: 0.23210979, Training R2: 0.872046
Validation Loss: 0.71134931, Validation R2: 0.460608

Epoch 98/1000
Training Loss: 0.22529615, Training R2: 0.873895
Validation Loss: 0.72368515, Validation R2: 0.438141

Epoch 99/1000
Training Loss: 0.20339759, Training R2: 0.881808
Validation Loss: 0.71957350, Validation R2: 0.450827

Epoch 100/1000
Training Loss: 0.18777694, Training R2: 0.881878
Validation Loss: 0.72573131, Validation R2: 0.425281

Epoch 101/1000
Training Loss: 0.19065285, Training R2: 0.883730
Validation Loss: 0.72710449, Validation R2: 0.431047

Epoch 102/1000
Training Loss: 0.19642215, Training R2: 0.883053
Validation Loss: 0.73521376, Validation R2: 0.426181

Epoch 103/1000
Training Loss: 0.19064912, Training R2: 0.883574
Validation Loss: 0.72575819, Validation R2: 0.438161

Epoch 104/1000
Training Loss: 0.19004067, Training R2: 0.886580
Validation Loss: 0.73249179, Validation R2: 0.420387

Epoch 105/1000
Training Loss: 0.17641647, Training R2: 0.891423
Validation Loss: 0.73421460, Validation R2: 0.422653

Epoch 106/1000
Training Loss: 0.17614564, Training R2: 0.893229
Validation Loss: 0.72036374, Validation R2: 0.436925

Epoch 107/1000
Training Loss: 0.17459389, Training R2: 0.893765
Validation Loss: 0.72796947, Validation R2: 0.434996

Epoch 108/1000
Training Loss: 0.17767075, Training R2: 0.891899
Validation Loss: 0.72934681, Validation R2: 0.439197

Epoch 109/1000
Epoch 00109: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.17309536, Training R2: 0.897499
Validation Loss: 0.72964185, Validation R2: 0.423431

Epoch 110/1000
学习率已减少 2 次
Training Loss: 0.16232344, Training R2: 0.901664
Validation Loss: 0.72763443, Validation R2: 0.420187

Epoch 111/1000
Training Loss: 0.14765613, Training R2: 0.902620
Validation Loss: 0.73556471, Validation R2: 0.416658

Epoch 112/1000
Training Loss: 0.15043342, Training R2: 0.901796
Validation Loss: 0.73055768, Validation R2: 0.427576

Epoch 113/1000
Training Loss: 0.15247290, Training R2: 0.902156
Validation Loss: 0.73369306, Validation R2: 0.413263

Epoch 114/1000
Training Loss: 0.14575846, Training R2: 0.903024
Validation Loss: 0.74283063, Validation R2: 0.409048

Epoch 115/1000
Training Loss: 0.14101688, Training R2: 0.904088
Validation Loss: 0.73742932, Validation R2: 0.411707

Epoch 116/1000
Training Loss: 0.14304573, Training R2: 0.906084
Validation Loss: 0.74554455, Validation R2: 0.389314

Epoch 117/1000
Training Loss: 0.13965535, Training R2: 0.908018
Validation Loss: 0.73140639, Validation R2: 0.417004

Epoch 118/1000
Training Loss: 0.13974609, Training R2: 0.905763
Validation Loss: 0.73615593, Validation R2: 0.409017

Epoch 119/1000
Training Loss: 0.13440500, Training R2: 0.909746
Validation Loss: 0.74043053, Validation R2: 0.413743

Epoch 120/1000
Training Loss: 0.14665594, Training R2: 0.907700
Validation Loss: 0.72356075, Validation R2: 0.430531

Epoch 121/1000
Training Loss: 0.15154965, Training R2: 0.903527
Validation Loss: 0.73872656, Validation R2: 0.396982

Epoch 122/1000
Training Loss: 0.15928133, Training R2: 0.906511
Validation Loss: 0.73457426, Validation R2: 0.411300

Epoch 123/1000
Training Loss: 0.13738174, Training R2: 0.909204
Validation Loss: 0.72289091, Validation R2: 0.435146

Epoch 124/1000
Training Loss: 0.14374315, Training R2: 0.907908
Validation Loss: 0.74113792, Validation R2: 0.415738

Epoch 125/1000
Training Loss: 0.15722652, Training R2: 0.909551
Validation Loss: 0.73248887, Validation R2: 0.408353

Epoch 126/1000
Training Loss: 0.13960920, Training R2: 0.911849
Validation Loss: 0.72902489, Validation R2: 0.416590

Epoch 127/1000
Training Loss: 0.12706752, Training R2: 0.910086
Validation Loss: 0.73233688, Validation R2: 0.418996

Epoch 128/1000
Training Loss: 0.12617238, Training R2: 0.910870
Validation Loss: 0.73395622, Validation R2: 0.409782

Epoch 129/1000
Training Loss: 0.12032331, Training R2: 0.911801
Validation Loss: 0.73205304, Validation R2: 0.414671

Epoch 130/1000
Epoch 00130: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.12247156, Training R2: 0.913524
Validation Loss: 0.73892063, Validation R2: 0.404092

Epoch 131/1000
学习率已减少 3 次
Training Loss: 0.11614721, Training R2: 0.915366
Validation Loss: 0.73612005, Validation R2: 0.409973

Epoch 132/1000
Training Loss: 0.11481103, Training R2: 0.914631
Validation Loss: 0.73404568, Validation R2: 0.412182

Epoch 133/1000
Training Loss: 0.11296467, Training R2: 0.914739
Validation Loss: 0.73321593, Validation R2: 0.411200

Epoch 134/1000
Training Loss: 0.11075111, Training R2: 0.915644
Validation Loss: 0.73483956, Validation R2: 0.411867

Epoch 135/1000
Training Loss: 0.10433578, Training R2: 0.915743
Validation Loss: 0.73159957, Validation R2: 0.419816

Epoch 136/1000
Training Loss: 0.10257980, Training R2: 0.916164
Validation Loss: 0.73093903, Validation R2: 0.421425

Epoch 137/1000
Training Loss: 0.10261696, Training R2: 0.916858
Validation Loss: 0.73337507, Validation R2: 0.421668

Epoch 138/1000
Training Loss: 0.11136795, Training R2: 0.916336
Validation Loss: 0.73214519, Validation R2: 0.416225

Epoch 139/1000
Training Loss: 0.10679398, Training R2: 0.915806
Validation Loss: 0.73751819, Validation R2: 0.406197

Epoch 140/1000
Training Loss: 0.11346899, Training R2: 0.915289
Validation Loss: 0.73306608, Validation R2: 0.419182

Epoch 141/1000
Training Loss: 0.10986190, Training R2: 0.915688
Validation Loss: 0.72979498, Validation R2: 0.421147

Epoch 142/1000
Training Loss: 0.10338009, Training R2: 0.917026
Validation Loss: 0.73210365, Validation R2: 0.410076

Epoch 143/1000
Training Loss: 0.10025347, Training R2: 0.917713
Validation Loss: 0.72838652, Validation R2: 0.419222

Epoch 144/1000
Training Loss: 0.09745702, Training R2: 0.917614
Validation Loss: 0.73192471, Validation R2: 0.414898

Epoch 145/1000
Training Loss: 0.09625219, Training R2: 0.918196
Validation Loss: 0.73474258, Validation R2: 0.414740

Epoch 146/1000
Training Loss: 0.10527193, Training R2: 0.917607
Validation Loss: 0.73066467, Validation R2: 0.420057

Epoch 147/1000
Training Loss: 0.09998093, Training R2: 0.916880
Validation Loss: 0.73083085, Validation R2: 0.418388

Epoch 148/1000
Training Loss: 0.09785768, Training R2: 0.917963
Validation Loss: 0.73690152, Validation R2: 0.403198

Epoch 149/1000
Training Loss: 0.10577988, Training R2: 0.919212
Validation Loss: 0.73368710, Validation R2: 0.414469

Epoch 150/1000
Training Loss: 0.10324130, Training R2: 0.919630
Validation Loss: 0.73126936, Validation R2: 0.419261

Epoch 151/1000
Epoch 00151: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.10031152, Training R2: 0.919059
Validation Loss: 0.73698300, Validation R2: 0.414804

Epoch 152/1000
学习率已减少 4 次
Training Loss: 0.09589221, Training R2: 0.918907
Validation Loss: 0.73550618, Validation R2: 0.414826

Epoch 153/1000
Training Loss: 0.09160622, Training R2: 0.919054
Validation Loss: 0.73388088, Validation R2: 0.418690

Epoch 154/1000
Training Loss: 0.08917371, Training R2: 0.919608
Validation Loss: 0.73220593, Validation R2: 0.419220

Epoch 155/1000
Training Loss: 0.09084729, Training R2: 0.920136
Validation Loss: 0.73398000, Validation R2: 0.414419

Epoch 156/1000
Training Loss: 0.08722852, Training R2: 0.920216
Validation Loss: 0.73282850, Validation R2: 0.417981

Epoch 157/1000
Training Loss: 0.08814716, Training R2: 0.920083
Validation Loss: 0.73512447, Validation R2: 0.412666

Epoch 158/1000
Training Loss: 0.08573338, Training R2: 0.920569
Validation Loss: 0.73569876, Validation R2: 0.413036

Epoch 159/1000
Training Loss: 0.08247440, Training R2: 0.920887
Validation Loss: 0.73642987, Validation R2: 0.413979

Epoch 160/1000
Training Loss: 0.08262442, Training R2: 0.920502
Validation Loss: 0.73468870, Validation R2: 0.415823

Epoch 161/1000
Training Loss: 0.08175355, Training R2: 0.920638
Validation Loss: 0.73455548, Validation R2: 0.415271

Epoch 162/1000
Training Loss: 0.08070334, Training R2: 0.920872
Validation Loss: 0.73377061, Validation R2: 0.417827

Epoch 163/1000
Training Loss: 0.08462383, Training R2: 0.920208
Validation Loss: 0.73487663, Validation R2: 0.414552

Epoch 164/1000
Training Loss: 0.08626932, Training R2: 0.921158
Validation Loss: 0.73354590, Validation R2: 0.411277

Epoch 165/1000
Training Loss: 0.08642764, Training R2: 0.921052
Validation Loss: 0.73513591, Validation R2: 0.411926

Epoch 166/1000
Training Loss: 0.08528310, Training R2: 0.921182
Validation Loss: 0.73553497, Validation R2: 0.413977

Epoch 167/1000
Training Loss: 0.08549106, Training R2: 0.921516
Validation Loss: 0.73529845, Validation R2: 0.412967

Epoch 168/1000
Training Loss: 0.08230150, Training R2: 0.921371
Validation Loss: 0.73674053, Validation R2: 0.412210

Epoch 169/1000
Training Loss: 0.08197357, Training R2: 0.920889
Validation Loss: 0.73460853, Validation R2: 0.413949

Epoch 170/1000
Training Loss: 0.08034343, Training R2: 0.921252
Validation Loss: 0.73621011, Validation R2: 0.410754

Epoch 171/1000
Training Loss: 0.07910799, Training R2: 0.921636
Validation Loss: 0.73502129, Validation R2: 0.414768

Epoch 172/1000
Epoch 00172: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.07990537, Training R2: 0.921058
Validation Loss: 0.73858976, Validation R2: 0.408791

Epoch 173/1000
学习率已减少 5 次
Training Loss: 0.07924264, Training R2: 0.921734
Validation Loss: 0.73730606, Validation R2: 0.411589

Epoch 174/1000
Training Loss: 0.07949883, Training R2: 0.921788
Validation Loss: 0.73652309, Validation R2: 0.411039

Epoch 175/1000
Training Loss: 0.07822722, Training R2: 0.921919
Validation Loss: 0.73781645, Validation R2: 0.410136

Epoch 176/1000
Training Loss: 0.07720764, Training R2: 0.921882
Validation Loss: 0.73647696, Validation R2: 0.412654

Epoch 177/1000
Training Loss: 0.07572133, Training R2: 0.921995
Validation Loss: 0.73558319, Validation R2: 0.413096

Epoch 178/1000
Training Loss: 0.07520417, Training R2: 0.922270
Validation Loss: 0.73665661, Validation R2: 0.412216

Epoch 179/1000
Training Loss: 0.07649436, Training R2: 0.922058
Validation Loss: 0.73511380, Validation R2: 0.413195

Epoch 180/1000
Training Loss: 0.07442804, Training R2: 0.922285
Validation Loss: 0.73761964, Validation R2: 0.409448

Epoch 181/1000
Training Loss: 0.07476724, Training R2: 0.922255
Validation Loss: 0.73322105, Validation R2: 0.415483

Epoch 182/1000
Training Loss: 0.07425920, Training R2: 0.921833
Validation Loss: 0.73609632, Validation R2: 0.412464

Epoch 183/1000
Training Loss: 0.07366970, Training R2: 0.922366
Validation Loss: 0.73486543, Validation R2: 0.412773

Epoch 184/1000
Training Loss: 0.07303056, Training R2: 0.922508
Validation Loss: 0.73684567, Validation R2: 0.412538

Epoch 185/1000
Training Loss: 0.07360055, Training R2: 0.922323
Validation Loss: 0.73477298, Validation R2: 0.413643

Epoch 186/1000
Training Loss: 0.07276102, Training R2: 0.922502
Validation Loss: 0.73652321, Validation R2: 0.411178

Epoch 187/1000
Training Loss: 0.07225743, Training R2: 0.922588
Validation Loss: 0.73481202, Validation R2: 0.412843

Epoch 188/1000
Training Loss: 0.07274556, Training R2: 0.922471
Validation Loss: 0.73782402, Validation R2: 0.409970

Epoch 189/1000
Training Loss: 0.07301488, Training R2: 0.922656
Validation Loss: 0.73844308, Validation R2: 0.410369

Epoch 190/1000
Training Loss: 0.07204708, Training R2: 0.922688
Validation Loss: 0.73675781, Validation R2: 0.412878

Epoch 191/1000
Training Loss: 0.07255291, Training R2: 0.922624
Validation Loss: 0.73691082, Validation R2: 0.412691

Epoch 192/1000
Training Loss: 0.07248132, Training R2: 0.922425
Validation Loss: 0.73516035, Validation R2: 0.413953

Epoch 193/1000
Epoch 00193: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.07227895, Training R2: 0.922653
Validation Loss: 0.73651868, Validation R2: 0.411038

Epoch 194/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
