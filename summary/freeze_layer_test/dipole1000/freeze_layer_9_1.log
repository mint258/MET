Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)
冻结层 9: lins.2 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Frozen
lins.2.bias: Frozen
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1026435

Epoch 1/1000
Training Loss: 1.42945816, Training R2: -0.726513
Validation Loss: 1.35992336, Validation R2: -0.074512
Saved best model with validation R2 -0.074512 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.18375095, Training R2: -0.063117
Validation Loss: 1.25671554, Validation R2: -0.115743

Epoch 3/1000
Training Loss: 1.14229955, Training R2: -0.166852
Validation Loss: 1.22345018, Validation R2: -0.025134
Saved best model with validation R2 -0.025134 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.10546706, Training R2: 0.012595
Validation Loss: 1.25472140, Validation R2: 0.007691
Saved best model with validation R2 0.007691 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.11962112, Training R2: 0.023971
Validation Loss: 1.21960306, Validation R2: -0.023979

Epoch 6/1000
Training Loss: 1.09035816, Training R2: -0.025787
Validation Loss: 1.20675254, Validation R2: -0.025016

Epoch 7/1000
Training Loss: 1.07443585, Training R2: 0.023254
Validation Loss: 1.18668258, Validation R2: 0.035275
Saved best model with validation R2 0.035275 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 1.07373942, Training R2: 0.010605
Validation Loss: 1.19994903, Validation R2: -0.004681

Epoch 9/1000
Training Loss: 1.06852254, Training R2: 0.056077
Validation Loss: 1.22334862, Validation R2: 0.013397

Epoch 10/1000
Training Loss: 1.08118843, Training R2: 0.068824
Validation Loss: 1.19967771, Validation R2: -0.020239

Epoch 11/1000
Training Loss: 1.07561271, Training R2: -0.028670
Validation Loss: 1.20119655, Validation R2: -0.022089

Epoch 12/1000
Training Loss: 1.06247953, Training R2: 0.041801
Validation Loss: 1.20670605, Validation R2: 0.021066

Epoch 13/1000
Training Loss: 1.06145345, Training R2: 0.075502
Validation Loss: 1.21687448, Validation R2: -0.070312

Epoch 14/1000
Training Loss: 1.08955376, Training R2: -0.053702
Validation Loss: 1.25060868, Validation R2: 0.018991

Epoch 15/1000
Training Loss: 1.13779382, Training R2: 0.024183
Validation Loss: 1.22260809, Validation R2: 0.030031

Epoch 16/1000
Training Loss: 1.07331362, Training R2: 0.040768
Validation Loss: 1.22411287, Validation R2: -0.108608

Epoch 17/1000
Training Loss: 1.08267253, Training R2: -0.052047
Validation Loss: 1.21975470, Validation R2: 0.030239

Epoch 18/1000
Training Loss: 1.11483344, Training R2: 0.044650
Validation Loss: 1.21532238, Validation R2: 0.030864

Epoch 19/1000
Training Loss: 1.07422203, Training R2: 0.022188
Validation Loss: 1.22827458, Validation R2: -0.121864

Epoch 20/1000
Training Loss: 1.08108679, Training R2: -0.039053
Validation Loss: 1.21263587, Validation R2: 0.033621

Epoch 21/1000
Training Loss: 1.07722213, Training R2: 0.080195
Validation Loss: 1.18859661, Validation R2: -0.004569

Epoch 22/1000
Training Loss: 1.06089825, Training R2: -0.001568
Validation Loss: 1.21045017, Validation R2: -0.079667

Epoch 23/1000
Training Loss: 1.07247983, Training R2: -0.026393
Validation Loss: 1.19174135, Validation R2: 0.033419

Epoch 24/1000
Training Loss: 1.06430863, Training R2: 0.081873
Validation Loss: 1.18569207, Validation R2: 0.026862

Epoch 25/1000
Training Loss: 1.05176462, Training R2: 0.074853
Validation Loss: 1.18621707, Validation R2: -0.029830

Epoch 26/1000
Training Loss: 1.08000876, Training R2: -0.055484
Validation Loss: 1.18431103, Validation R2: 0.026792

Epoch 27/1000
Training Loss: 1.06568884, Training R2: 0.084227
Validation Loss: 1.19664228, Validation R2: 0.040517
Saved best model with validation R2 0.040517 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 1.05211163, Training R2: 0.072086
Validation Loss: 1.21550977, Validation R2: -0.086654

Epoch 29/1000
Training Loss: 1.08142030, Training R2: -0.061579
Validation Loss: 1.19442785, Validation R2: 0.034743

Epoch 30/1000
Training Loss: 1.07635358, Training R2: 0.080467
Validation Loss: 1.19691074, Validation R2: 0.037459

Epoch 31/1000
Training Loss: 1.06028752, Training R2: 0.044297
Validation Loss: 1.18978906, Validation R2: -0.023629

Epoch 32/1000
Training Loss: 1.05245679, Training R2: 0.051119
Validation Loss: 1.18943870, Validation R2: 0.053867
Saved best model with validation R2 0.053867 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 1.04929960, Training R2: 0.093518
Validation Loss: 1.17981184, Validation R2: 0.018907

Epoch 34/1000
Training Loss: 1.04088631, Training R2: 0.060383
Validation Loss: 1.18075669, Validation R2: 0.014359

Epoch 35/1000
Training Loss: 1.04197334, Training R2: 0.051231
Validation Loss: 1.18177259, Validation R2: 0.044292

Epoch 36/1000
Training Loss: 1.03911148, Training R2: 0.086553
Validation Loss: 1.18164217, Validation R2: 0.052080

Epoch 37/1000
Training Loss: 1.04464264, Training R2: 0.101307
Validation Loss: 1.18042970, Validation R2: 0.048338

Epoch 38/1000
Training Loss: 1.03501175, Training R2: 0.095024
Validation Loss: 1.18196249, Validation R2: 0.001645

Epoch 39/1000
Training Loss: 1.04183335, Training R2: 0.035499
Validation Loss: 1.19845557, Validation R2: 0.043130

Epoch 40/1000
Training Loss: 1.06080715, Training R2: 0.096808
Validation Loss: 1.18390489, Validation R2: 0.014747

Epoch 41/1000
Training Loss: 1.05795634, Training R2: -0.006647
Validation Loss: 1.17843628, Validation R2: 0.016543

Epoch 42/1000
Training Loss: 1.05790342, Training R2: 0.077032
Validation Loss: 1.22241402, Validation R2: 0.048481

Epoch 43/1000
Training Loss: 1.06228174, Training R2: 0.081098
Validation Loss: 1.18652892, Validation R2: -0.004277

Epoch 44/1000
Training Loss: 1.03234629, Training R2: 0.066957
Validation Loss: 1.18992698, Validation R2: 0.056300
Saved best model with validation R2 0.056300 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 1.03411469, Training R2: 0.121656
Validation Loss: 1.18529963, Validation R2: 0.015400

Epoch 46/1000
Training Loss: 1.03787926, Training R2: 0.051740
Validation Loss: 1.17714119, Validation R2: 0.052951

Epoch 47/1000
Training Loss: 1.02092989, Training R2: 0.114928
Validation Loss: 1.17240739, Validation R2: 0.020387

Epoch 48/1000
Training Loss: 1.02709940, Training R2: 0.063800
Validation Loss: 1.17023873, Validation R2: 0.024049

Epoch 49/1000
Training Loss: 1.02621613, Training R2: 0.053802
Validation Loss: 1.17309225, Validation R2: 0.054942

Epoch 50/1000
Training Loss: 1.01370419, Training R2: 0.127552
Validation Loss: 1.19177759, Validation R2: 0.010052

Epoch 51/1000
Training Loss: 1.03158196, Training R2: 0.072866
Validation Loss: 1.18588817, Validation R2: 0.061445
Saved best model with validation R2 0.061445 to best_finetuned_model.pth

Epoch 52/1000
Training Loss: 1.02348834, Training R2: 0.128198
Validation Loss: 1.17397082, Validation R2: 0.028577

Epoch 53/1000
Training Loss: 1.01045016, Training R2: 0.111677
Validation Loss: 1.16114700, Validation R2: 0.078776
Saved best model with validation R2 0.078776 to best_finetuned_model.pth

Epoch 54/1000
Training Loss: 1.00202200, Training R2: 0.142571
Validation Loss: 1.17742324, Validation R2: 0.084222
Saved best model with validation R2 0.084222 to best_finetuned_model.pth

Epoch 55/1000
Training Loss: 1.01082850, Training R2: 0.153171
Validation Loss: 1.16936839, Validation R2: 0.089023
Saved best model with validation R2 0.089023 to best_finetuned_model.pth

Epoch 56/1000
Training Loss: 1.00790235, Training R2: 0.157474
Validation Loss: 1.15990567, Validation R2: 0.041702

Epoch 57/1000
Training Loss: 1.00186954, Training R2: 0.126854
Validation Loss: 1.24142575, Validation R2: 0.054238

Epoch 58/1000
Training Loss: 1.08627309, Training R2: 0.089901
Validation Loss: 1.18827832, Validation R2: 0.005964

Epoch 59/1000
Training Loss: 1.02132846, Training R2: 0.100281
Validation Loss: 1.17249835, Validation R2: 0.070560

Epoch 60/1000
Training Loss: 0.99990610, Training R2: 0.151682
Validation Loss: 1.18860304, Validation R2: 0.005049

Epoch 61/1000
Training Loss: 1.01043898, Training R2: 0.100620
Validation Loss: 1.19782948, Validation R2: 0.075214

Epoch 62/1000
Training Loss: 1.01621349, Training R2: 0.143660
Validation Loss: 1.16055453, Validation R2: 0.049034

Epoch 63/1000
Training Loss: 0.99248888, Training R2: 0.152275
Validation Loss: 1.15834010, Validation R2: 0.044404

Epoch 64/1000
Training Loss: 1.03957687, Training R2: 0.038201
Validation Loss: 1.19894922, Validation R2: 0.085119

Epoch 65/1000
Training Loss: 1.04982475, Training R2: 0.135473
Validation Loss: 1.15444076, Validation R2: 0.084252

Epoch 66/1000
Training Loss: 0.99042111, Training R2: 0.157513
Validation Loss: 1.16209698, Validation R2: 0.092088
Saved best model with validation R2 0.092088 to best_finetuned_model.pth

Epoch 67/1000
Training Loss: 1.00899807, Training R2: 0.161557
Validation Loss: 1.14882278, Validation R2: 0.077379

Epoch 68/1000
Training Loss: 0.99196372, Training R2: 0.142135
Validation Loss: 1.15046883, Validation R2: 0.066026

Epoch 69/1000
Training Loss: 0.98620185, Training R2: 0.151073
Validation Loss: 1.16020656, Validation R2: 0.088661

Epoch 70/1000
Training Loss: 0.98342444, Training R2: 0.174772
Validation Loss: 1.14695358, Validation R2: 0.052264

Epoch 71/1000
Training Loss: 0.98166886, Training R2: 0.154537
Validation Loss: 1.14950275, Validation R2: 0.085846

Epoch 72/1000
Training Loss: 0.98205816, Training R2: 0.174186
Validation Loss: 1.18184555, Validation R2: 0.094677
Saved best model with validation R2 0.094677 to best_finetuned_model.pth

Epoch 73/1000
Training Loss: 0.98248381, Training R2: 0.189720
Validation Loss: 1.13311923, Validation R2: 0.060087

Epoch 74/1000
Training Loss: 1.00108792, Training R2: 0.160825
Validation Loss: 1.29836321, Validation R2: -0.209329

Epoch 75/1000
Training Loss: 1.08299454, Training R2: -0.007458
Validation Loss: 1.19425941, Validation R2: 0.086076

Epoch 76/1000
Training Loss: 0.98847042, Training R2: 0.144545
Validation Loss: 1.23076439, Validation R2: -0.089434

Epoch 77/1000
Training Loss: 1.04289304, Training R2: 0.036892
Validation Loss: 1.18482220, Validation R2: 0.059183

Epoch 78/1000
Training Loss: 1.03431543, Training R2: 0.107925
Validation Loss: 1.16942751, Validation R2: 0.003024

Epoch 79/1000
Training Loss: 1.01409984, Training R2: 0.075561
Validation Loss: 1.15887535, Validation R2: 0.083079

Epoch 80/1000
Training Loss: 0.99815151, Training R2: 0.170290
Validation Loss: 1.15179360, Validation R2: 0.081216

Epoch 81/1000
Training Loss: 0.99596776, Training R2: 0.142686
Validation Loss: 1.17284167, Validation R2: 0.095563
Saved best model with validation R2 0.095563 to best_finetuned_model.pth

Epoch 82/1000
Training Loss: 0.99467824, Training R2: 0.186518
Validation Loss: 1.13968265, Validation R2: 0.044273

Epoch 83/1000
Training Loss: 0.98441588, Training R2: 0.124504
Validation Loss: 1.13157451, Validation R2: 0.088146

Epoch 84/1000
Training Loss: 0.96040470, Training R2: 0.182831
Validation Loss: 1.12468112, Validation R2: 0.095347

Epoch 85/1000
Training Loss: 0.94570446, Training R2: 0.211783
Validation Loss: 1.12346852, Validation R2: 0.099877
Saved best model with validation R2 0.099877 to best_finetuned_model.pth

Epoch 86/1000
Training Loss: 0.94205336, Training R2: 0.221247
Validation Loss: 1.11471069, Validation R2: 0.105754
Saved best model with validation R2 0.105754 to best_finetuned_model.pth

Epoch 87/1000
Training Loss: 0.93631229, Training R2: 0.209860
Validation Loss: 1.12898660, Validation R2: 0.125010
Saved best model with validation R2 0.125010 to best_finetuned_model.pth

Epoch 88/1000
Training Loss: 0.93911203, Training R2: 0.212244
Validation Loss: 1.30799460, Validation R2: 0.007610

Epoch 89/1000
Training Loss: 1.03956530, Training R2: 0.107766
Validation Loss: 1.14087212, Validation R2: 0.017237

Epoch 90/1000
Training Loss: 1.03539660, Training R2: 0.107120
Validation Loss: 1.11709797, Validation R2: 0.066242

Epoch 91/1000
Training Loss: 1.03016550, Training R2: 0.032057
Validation Loss: 1.21378851, Validation R2: 0.071536

Epoch 92/1000
Training Loss: 1.08973694, Training R2: 0.084623
Validation Loss: 1.15761423, Validation R2: 0.074674

Epoch 93/1000
Training Loss: 1.02364179, Training R2: 0.057207
Validation Loss: 1.17545485, Validation R2: -0.028005

Epoch 94/1000
Training Loss: 1.00767587, Training R2: 0.093577
Validation Loss: 1.19320488, Validation R2: 0.090903

Epoch 95/1000
Training Loss: 1.01308569, Training R2: 0.168450
Validation Loss: 1.15597725, Validation R2: 0.080666

Epoch 96/1000
Training Loss: 1.00081730, Training R2: 0.144144
Validation Loss: 1.15316153, Validation R2: 0.104134

Epoch 97/1000
Training Loss: 0.98831355, Training R2: 0.193854
Validation Loss: 1.13371074, Validation R2: 0.085830

Epoch 98/1000
Training Loss: 0.99526608, Training R2: 0.113541
Validation Loss: 1.13089597, Validation R2: 0.083313

Epoch 99/1000
Training Loss: 0.98334455, Training R2: 0.192223
Validation Loss: 1.13856602, Validation R2: 0.122894

Epoch 100/1000
Training Loss: 0.97103657, Training R2: 0.181579
Validation Loss: 1.14170647, Validation R2: 0.073486

Epoch 101/1000
Training Loss: 0.95037287, Training R2: 0.201661
Validation Loss: 1.14223886, Validation R2: 0.111055

Epoch 102/1000
Training Loss: 0.95019843, Training R2: 0.205900
Validation Loss: 1.11883843, Validation R2: 0.104226

Epoch 103/1000
Training Loss: 0.93065351, Training R2: 0.225856
Validation Loss: 1.13617754, Validation R2: 0.114919

Epoch 104/1000
Training Loss: 0.94129906, Training R2: 0.216628
Validation Loss: 1.11673951, Validation R2: 0.108827

Epoch 105/1000
Training Loss: 0.91918939, Training R2: 0.223934
Validation Loss: 1.15123498, Validation R2: 0.098036

Epoch 106/1000
Training Loss: 0.93726194, Training R2: 0.227847
Validation Loss: 1.19695449, Validation R2: -0.063776

Epoch 107/1000
Training Loss: 1.00641103, Training R2: 0.094021
Validation Loss: 1.18685842, Validation R2: 0.094763

Epoch 108/1000
Epoch 00108: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.98169749, Training R2: 0.134888
Validation Loss: 1.12609851, Validation R2: 0.118446

Epoch 109/1000
学习率已减少 1 次
Training Loss: 0.94696942, Training R2: 0.229207
Validation Loss: 1.10507417, Validation R2: 0.116020

Epoch 110/1000
Training Loss: 0.95374905, Training R2: 0.155851
Validation Loss: 1.10946357, Validation R2: 0.085982

Epoch 111/1000
Training Loss: 0.91627130, Training R2: 0.228498
Validation Loss: 1.15292060, Validation R2: 0.128816
Saved best model with validation R2 0.128816 to best_finetuned_model.pth

Epoch 112/1000
Training Loss: 0.92198323, Training R2: 0.252703
Validation Loss: 1.10049701, Validation R2: 0.088607

Epoch 113/1000
Training Loss: 0.94090967, Training R2: 0.177287
Validation Loss: 1.11842394, Validation R2: 0.142674
Saved best model with validation R2 0.142674 to best_finetuned_model.pth

Epoch 114/1000
Training Loss: 0.94538422, Training R2: 0.226764
Validation Loss: 1.11581004, Validation R2: 0.145491
Saved best model with validation R2 0.145491 to best_finetuned_model.pth

Epoch 115/1000
Training Loss: 0.91123445, Training R2: 0.237574
Validation Loss: 1.09753716, Validation R2: 0.109389

Epoch 116/1000
Training Loss: 0.90152122, Training R2: 0.252113
Validation Loss: 1.13278627, Validation R2: 0.127010

Epoch 117/1000
Training Loss: 0.90284423, Training R2: 0.252636
Validation Loss: 1.08990967, Validation R2: 0.118840

Epoch 118/1000
Training Loss: 0.88333986, Training R2: 0.261318
Validation Loss: 1.11009204, Validation R2: 0.145803
Saved best model with validation R2 0.145803 to best_finetuned_model.pth

Epoch 119/1000
Training Loss: 0.88073050, Training R2: 0.273877
Validation Loss: 1.09780288, Validation R2: 0.119050

Epoch 120/1000
Training Loss: 0.88721670, Training R2: 0.252775
Validation Loss: 1.13085258, Validation R2: 0.129332

Epoch 121/1000
Training Loss: 0.87667863, Training R2: 0.275600
Validation Loss: 1.09948862, Validation R2: 0.128550

Epoch 122/1000
Training Loss: 0.88030553, Training R2: 0.264127
Validation Loss: 1.10344422, Validation R2: 0.143034

Epoch 123/1000
Training Loss: 0.88456848, Training R2: 0.249675
Validation Loss: 1.11300302, Validation R2: 0.152451
Saved best model with validation R2 0.152451 to best_finetuned_model.pth

Epoch 124/1000
Training Loss: 0.86048078, Training R2: 0.285698
Validation Loss: 1.09370661, Validation R2: 0.113078

Epoch 125/1000
Training Loss: 0.86826717, Training R2: 0.265403
Validation Loss: 1.10960770, Validation R2: 0.138229

Epoch 126/1000
Training Loss: 0.85590385, Training R2: 0.290340
Validation Loss: 1.09223711, Validation R2: 0.130984

Epoch 127/1000
Training Loss: 0.85693863, Training R2: 0.287286
Validation Loss: 1.11810863, Validation R2: 0.146346

Epoch 128/1000
Training Loss: 0.85238749, Training R2: 0.287485
Validation Loss: 1.11134958, Validation R2: 0.142101

Epoch 129/1000
Training Loss: 0.84417225, Training R2: 0.292862
Validation Loss: 1.11792171, Validation R2: 0.143352

Epoch 130/1000
Training Loss: 0.84871116, Training R2: 0.287337
Validation Loss: 1.14330828, Validation R2: 0.134968

Epoch 131/1000
Training Loss: 0.86850121, Training R2: 0.267295
Validation Loss: 1.10244250, Validation R2: 0.151604

Epoch 132/1000
Training Loss: 0.85163427, Training R2: 0.289116
Validation Loss: 1.09144676, Validation R2: 0.153085
Saved best model with validation R2 0.153085 to best_finetuned_model.pth

Epoch 133/1000
Training Loss: 0.83616266, Training R2: 0.300970
Validation Loss: 1.08744156, Validation R2: 0.122936

Epoch 134/1000
Training Loss: 0.84004588, Training R2: 0.289333
Validation Loss: 1.10485697, Validation R2: 0.149482

Epoch 135/1000
Training Loss: 0.85004901, Training R2: 0.277564
Validation Loss: 1.11855555, Validation R2: 0.146823

Epoch 136/1000
Training Loss: 0.84995832, Training R2: 0.276463
Validation Loss: 1.16442311, Validation R2: 0.130004

Epoch 137/1000
Training Loss: 0.86916546, Training R2: 0.288312
Validation Loss: 1.13229883, Validation R2: 0.009144

Epoch 138/1000
Training Loss: 0.91575316, Training R2: 0.187856
Validation Loss: 1.11358809, Validation R2: 0.151174

Epoch 139/1000
Training Loss: 0.85503099, Training R2: 0.281070
Validation Loss: 1.06196856, Validation R2: 0.144630

Epoch 140/1000
Training Loss: 0.82685798, Training R2: 0.308879
Validation Loss: 1.09991443, Validation R2: 0.155387
Saved best model with validation R2 0.155387 to best_finetuned_model.pth

Epoch 141/1000
Training Loss: 0.83197753, Training R2: 0.297207
Validation Loss: 1.08613920, Validation R2: 0.120053

Epoch 142/1000
Training Loss: 0.83631725, Training R2: 0.292013
Validation Loss: 1.10876513, Validation R2: 0.156726
Saved best model with validation R2 0.156726 to best_finetuned_model.pth

Epoch 143/1000
Training Loss: 0.82549377, Training R2: 0.311665
Validation Loss: 1.12699652, Validation R2: 0.154765

Epoch 144/1000
Training Loss: 0.87047284, Training R2: 0.287846
Validation Loss: 1.11758995, Validation R2: 0.041358

Epoch 145/1000
Training Loss: 0.94872153, Training R2: 0.134811
Validation Loss: 1.12712204, Validation R2: 0.146958

Epoch 146/1000
Training Loss: 0.88331337, Training R2: 0.277565
Validation Loss: 1.06892443, Validation R2: 0.116793

Epoch 147/1000
Training Loss: 0.89153401, Training R2: 0.219197
Validation Loss: 1.09952223, Validation R2: 0.162279
Saved best model with validation R2 0.162279 to best_finetuned_model.pth

Epoch 148/1000
Training Loss: 0.83923754, Training R2: 0.312039
Validation Loss: 1.09108782, Validation R2: 0.151901

Epoch 149/1000
Training Loss: 0.81806924, Training R2: 0.310406
Validation Loss: 1.11209500, Validation R2: 0.156161

Epoch 150/1000
Training Loss: 0.81991400, Training R2: 0.315691
Validation Loss: 1.10357881, Validation R2: 0.144473

Epoch 151/1000
Training Loss: 0.81092884, Training R2: 0.312379
Validation Loss: 1.08403933, Validation R2: 0.126895

Epoch 152/1000
Training Loss: 0.81337780, Training R2: 0.300706
Validation Loss: 1.11057317, Validation R2: 0.141913

Epoch 153/1000
Training Loss: 0.81383679, Training R2: 0.307136
Validation Loss: 1.08883286, Validation R2: 0.133636

Epoch 154/1000
Training Loss: 0.80277403, Training R2: 0.320226
Validation Loss: 1.09886169, Validation R2: 0.140280

Epoch 155/1000
Training Loss: 0.80406044, Training R2: 0.320381
Validation Loss: 1.11513221, Validation R2: 0.151065

Epoch 156/1000
Training Loss: 0.82123011, Training R2: 0.305138
Validation Loss: 1.07060146, Validation R2: 0.138600

Epoch 157/1000
Training Loss: 0.81418166, Training R2: 0.301880
Validation Loss: 1.05803990, Validation R2: 0.139015

Epoch 158/1000
Training Loss: 0.83850020, Training R2: 0.274997
Validation Loss: 1.08811665, Validation R2: 0.163376
Saved best model with validation R2 0.163376 to best_finetuned_model.pth

Epoch 159/1000
Training Loss: 0.81702030, Training R2: 0.323374
Validation Loss: 1.07360923, Validation R2: 0.167393
Saved best model with validation R2 0.167393 to best_finetuned_model.pth

Epoch 160/1000
Training Loss: 0.80459954, Training R2: 0.323762
Validation Loss: 1.09512973, Validation R2: 0.119333

Epoch 161/1000
Training Loss: 0.80642240, Training R2: 0.313133
Validation Loss: 1.18077636, Validation R2: 0.107567

Epoch 162/1000
Training Loss: 0.84279703, Training R2: 0.311967
Validation Loss: 1.07039261, Validation R2: 0.131791

Epoch 163/1000
Training Loss: 0.81257590, Training R2: 0.326327
Validation Loss: 1.08123255, Validation R2: 0.163310

Epoch 164/1000
Training Loss: 0.80647980, Training R2: 0.319637
Validation Loss: 1.10036564, Validation R2: 0.153493

Epoch 165/1000
Training Loss: 0.81747347, Training R2: 0.327814
Validation Loss: 1.07259655, Validation R2: 0.109295

Epoch 166/1000
Training Loss: 0.81483138, Training R2: 0.306889
Validation Loss: 1.12135994, Validation R2: 0.142936

Epoch 167/1000
Training Loss: 0.80761724, Training R2: 0.320399
Validation Loss: 1.07991493, Validation R2: 0.157238

Epoch 168/1000
Training Loss: 0.78807453, Training R2: 0.338972
Validation Loss: 1.08889413, Validation R2: 0.125895

Epoch 169/1000
Training Loss: 0.80006560, Training R2: 0.314826
Validation Loss: 1.12692940, Validation R2: 0.137569

Epoch 170/1000
Training Loss: 0.80195834, Training R2: 0.328080
Validation Loss: 1.06618285, Validation R2: 0.138231

Epoch 171/1000
Training Loss: 0.80418816, Training R2: 0.312912
Validation Loss: 1.07764840, Validation R2: 0.144698

Epoch 172/1000
Training Loss: 0.78824332, Training R2: 0.331890
Validation Loss: 1.07151163, Validation R2: 0.168507
Saved best model with validation R2 0.168507 to best_finetuned_model.pth

Epoch 173/1000
Training Loss: 0.78456881, Training R2: 0.351267
Validation Loss: 1.08481860, Validation R2: 0.166935

Epoch 174/1000
Training Loss: 0.79351529, Training R2: 0.335181
Validation Loss: 1.08290005, Validation R2: 0.127640

Epoch 175/1000
Training Loss: 0.81312084, Training R2: 0.294608
Validation Loss: 1.06679666, Validation R2: 0.149633

Epoch 176/1000
Training Loss: 0.78635531, Training R2: 0.344978
Validation Loss: 1.08731091, Validation R2: 0.165692

Epoch 177/1000
Training Loss: 0.79322226, Training R2: 0.351248
Validation Loss: 1.05972362, Validation R2: 0.164688

Epoch 178/1000
Training Loss: 0.78011536, Training R2: 0.356345
Validation Loss: 1.06063318, Validation R2: 0.140451

Epoch 179/1000
Training Loss: 0.78150993, Training R2: 0.341180
Validation Loss: 1.08826220, Validation R2: 0.162725

Epoch 180/1000
Training Loss: 0.77416787, Training R2: 0.354319
Validation Loss: 1.07168853, Validation R2: 0.144072

Epoch 181/1000
Training Loss: 0.76888937, Training R2: 0.348883
Validation Loss: 1.07136309, Validation R2: 0.133080

Epoch 182/1000
Training Loss: 0.76566611, Training R2: 0.350971
Validation Loss: 1.10209382, Validation R2: 0.146696

Epoch 183/1000
Training Loss: 0.77835979, Training R2: 0.357982
Validation Loss: 1.08063972, Validation R2: 0.162020

Epoch 184/1000
Training Loss: 0.79037899, Training R2: 0.342189
Validation Loss: 1.11636913, Validation R2: 0.103097

Epoch 185/1000
Training Loss: 0.82637734, Training R2: 0.290318
Validation Loss: 1.15834498, Validation R2: 0.120740

Epoch 186/1000
Training Loss: 0.81873507, Training R2: 0.320962
Validation Loss: 1.06897402, Validation R2: 0.150250

Epoch 187/1000
Training Loss: 0.77452554, Training R2: 0.374067
Validation Loss: 1.07563758, Validation R2: 0.172378
Saved best model with validation R2 0.172378 to best_finetuned_model.pth

Epoch 188/1000
Training Loss: 0.77389599, Training R2: 0.360903
Validation Loss: 1.16161072, Validation R2: 0.095140

Epoch 189/1000
Training Loss: 0.90374891, Training R2: 0.235282
Validation Loss: 1.10097289, Validation R2: 0.077810

Epoch 190/1000
Training Loss: 0.86461609, Training R2: 0.256769
Validation Loss: 1.10939157, Validation R2: 0.143499

Epoch 191/1000
Training Loss: 0.79003440, Training R2: 0.361191
Validation Loss: 1.08394909, Validation R2: 0.136238

Epoch 192/1000
Training Loss: 0.79054455, Training R2: 0.336036
Validation Loss: 1.08475816, Validation R2: 0.160615

Epoch 193/1000
Training Loss: 0.76265320, Training R2: 0.371134
Validation Loss: 1.08021951, Validation R2: 0.166910

Epoch 194/1000
Training Loss: 0.77769709, Training R2: 0.370779
Validation Loss: 1.07283235, Validation R2: 0.146534

Epoch 195/1000
Training Loss: 0.75104293, Training R2: 0.373807
Validation Loss: 1.14459181, Validation R2: 0.118950

Epoch 196/1000
Training Loss: 0.80043470, Training R2: 0.341105
Validation Loss: 1.08087409, Validation R2: 0.103701

Epoch 197/1000
Training Loss: 0.78888030, Training R2: 0.344854
Validation Loss: 1.11280525, Validation R2: 0.140464

Epoch 198/1000
Training Loss: 0.76602139, Training R2: 0.377822
Validation Loss: 1.07626534, Validation R2: 0.123704

Epoch 199/1000
Training Loss: 0.76910082, Training R2: 0.363105
Validation Loss: 1.09927368, Validation R2: 0.162376

Epoch 200/1000
Training Loss: 0.76499736, Training R2: 0.373727
Validation Loss: 1.06499565, Validation R2: 0.155382

Epoch 201/1000
Training Loss: 0.75252223, Training R2: 0.388650
Validation Loss: 1.06832790, Validation R2: 0.126427

Epoch 202/1000
Training Loss: 0.80315527, Training R2: 0.306285
Validation Loss: 1.11406648, Validation R2: 0.141933

Epoch 203/1000
Training Loss: 0.78828279, Training R2: 0.354400
Validation Loss: 1.06978345, Validation R2: 0.114158

Epoch 204/1000
Training Loss: 0.75506505, Training R2: 0.363730
Validation Loss: 1.11602771, Validation R2: 0.128238

Epoch 205/1000
Training Loss: 0.75675529, Training R2: 0.364290
Validation Loss: 1.09625316, Validation R2: 0.134292

Epoch 206/1000
Training Loss: 0.75408386, Training R2: 0.383294
Validation Loss: 1.07692468, Validation R2: 0.118346

Epoch 207/1000
Training Loss: 0.75919543, Training R2: 0.361064
Validation Loss: 1.14472628, Validation R2: 0.115942

Epoch 208/1000
Epoch 00208: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.77677294, Training R2: 0.363228
Validation Loss: 1.10153496, Validation R2: 0.073577

Epoch 209/1000
学习率已减少 2 次
Training Loss: 0.79009646, Training R2: 0.334394
Validation Loss: 1.12278020, Validation R2: 0.144184

Epoch 210/1000
Training Loss: 0.79689207, Training R2: 0.346465
Validation Loss: 1.07429576, Validation R2: 0.153249

Epoch 211/1000
Training Loss: 0.73718933, Training R2: 0.386372
Validation Loss: 1.06853497, Validation R2: 0.153813

Epoch 212/1000
Training Loss: 0.72859891, Training R2: 0.404761
Validation Loss: 1.10092115, Validation R2: 0.148605

Epoch 213/1000
Training Loss: 0.72232382, Training R2: 0.402623
Validation Loss: 1.06855500, Validation R2: 0.135080

Epoch 214/1000
Training Loss: 0.74362895, Training R2: 0.383893
Validation Loss: 1.11627531, Validation R2: 0.137661

Epoch 215/1000
Training Loss: 0.74853631, Training R2: 0.388734
Validation Loss: 1.07815325, Validation R2: 0.138525

Epoch 216/1000
Training Loss: 0.73914694, Training R2: 0.390245
Validation Loss: 1.07470107, Validation R2: 0.139630

Epoch 217/1000
Training Loss: 0.72129941, Training R2: 0.402644
Validation Loss: 1.07682788, Validation R2: 0.148802

Epoch 218/1000
Training Loss: 0.71477936, Training R2: 0.405135
Validation Loss: 1.06998873, Validation R2: 0.147849

Epoch 219/1000
Training Loss: 0.70326550, Training R2: 0.418066
Validation Loss: 1.08340585, Validation R2: 0.153127

Epoch 220/1000
Training Loss: 0.71115170, Training R2: 0.416938
Validation Loss: 1.07062244, Validation R2: 0.144366

Epoch 221/1000
Training Loss: 0.70488146, Training R2: 0.418505
Validation Loss: 1.07596910, Validation R2: 0.147132

Epoch 222/1000
Training Loss: 0.70439221, Training R2: 0.416841
Validation Loss: 1.08037460, Validation R2: 0.136991

Epoch 223/1000
Training Loss: 0.70284869, Training R2: 0.423178
Validation Loss: 1.07503891, Validation R2: 0.145928

Epoch 224/1000
Training Loss: 0.70546804, Training R2: 0.413155
Validation Loss: 1.08809090, Validation R2: 0.146214

Epoch 225/1000
Training Loss: 0.73209730, Training R2: 0.392112
Validation Loss: 1.07807779, Validation R2: 0.137937

Epoch 226/1000
Training Loss: 0.71555163, Training R2: 0.407121
Validation Loss: 1.07913244, Validation R2: 0.155590

Epoch 227/1000
Training Loss: 0.71964678, Training R2: 0.422025
Validation Loss: 1.07173443, Validation R2: 0.150963

Epoch 228/1000
Training Loss: 0.70611421, Training R2: 0.416786
Validation Loss: 1.07266474, Validation R2: 0.147060

Epoch 229/1000
Epoch 00229: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.71059469, Training R2: 0.411766
Validation Loss: 1.07027543, Validation R2: 0.147680

Epoch 230/1000
学习率已减少 3 次
Training Loss: 0.69366485, Training R2: 0.422561
Validation Loss: 1.07412994, Validation R2: 0.138981

Epoch 231/1000
Training Loss: 0.69341033, Training R2: 0.432094
Validation Loss: 1.08410013, Validation R2: 0.142650

Epoch 232/1000
Training Loss: 0.69140061, Training R2: 0.432697
Validation Loss: 1.07668388, Validation R2: 0.134875

Epoch 233/1000
Training Loss: 0.69277855, Training R2: 0.424827
Validation Loss: 1.06910813, Validation R2: 0.139980

Epoch 234/1000
Training Loss: 0.68788567, Training R2: 0.430307
Validation Loss: 1.07818782, Validation R2: 0.133317

Epoch 235/1000
Training Loss: 0.69016104, Training R2: 0.435540
Validation Loss: 1.07478297, Validation R2: 0.142483

Epoch 236/1000
Training Loss: 0.68690182, Training R2: 0.438211
Validation Loss: 1.07667994, Validation R2: 0.131733

Epoch 237/1000
Training Loss: 0.68446091, Training R2: 0.432675
Validation Loss: 1.07475507, Validation R2: 0.141300

Epoch 238/1000
Training Loss: 0.68684967, Training R2: 0.433477
Validation Loss: 1.08872986, Validation R2: 0.131425

Epoch 239/1000
Training Loss: 0.68330637, Training R2: 0.435138
Validation Loss: 1.07341528, Validation R2: 0.135313

Epoch 240/1000
Training Loss: 0.68075888, Training R2: 0.432849
Validation Loss: 1.07703900, Validation R2: 0.137817

Epoch 241/1000
Training Loss: 0.67747667, Training R2: 0.441324
Validation Loss: 1.07592905, Validation R2: 0.139768

Epoch 242/1000
Training Loss: 0.67769103, Training R2: 0.440462
Validation Loss: 1.08239734, Validation R2: 0.134583

Epoch 243/1000
Training Loss: 0.68389734, Training R2: 0.443307
Validation Loss: 1.07773662, Validation R2: 0.140141

Epoch 244/1000
Training Loss: 0.68317770, Training R2: 0.436725
Validation Loss: 1.07464945, Validation R2: 0.128037

Epoch 245/1000
Training Loss: 0.68207216, Training R2: 0.435591
Validation Loss: 1.07772958, Validation R2: 0.145635

Epoch 246/1000
Training Loss: 0.67902500, Training R2: 0.439957
Validation Loss: 1.07198441, Validation R2: 0.129058

Epoch 247/1000
Training Loss: 0.69190005, Training R2: 0.430008
Validation Loss: 1.07482278, Validation R2: 0.140420

Epoch 248/1000
Training Loss: 0.68023039, Training R2: 0.442379
Validation Loss: 1.07603204, Validation R2: 0.130294

Epoch 249/1000
Training Loss: 0.68475414, Training R2: 0.429019
Validation Loss: 1.07797885, Validation R2: 0.130610

Epoch 250/1000
Epoch 00250: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.67529036, Training R2: 0.441919
Validation Loss: 1.08881009, Validation R2: 0.128828

Epoch 251/1000
学习率已减少 4 次
Training Loss: 0.67378396, Training R2: 0.446030
Validation Loss: 1.07875443, Validation R2: 0.128850

Epoch 252/1000
Training Loss: 0.67096210, Training R2: 0.446267
Validation Loss: 1.08039713, Validation R2: 0.133928

Epoch 253/1000
Training Loss: 0.67309809, Training R2: 0.450429
Validation Loss: 1.08662128, Validation R2: 0.134452

Epoch 254/1000
Training Loss: 0.67292642, Training R2: 0.451261
Validation Loss: 1.06868553, Validation R2: 0.138396

Epoch 255/1000
Training Loss: 0.67310683, Training R2: 0.444952
Validation Loss: 1.07269812, Validation R2: 0.128528

Epoch 256/1000
Training Loss: 0.67058328, Training R2: 0.446763
Validation Loss: 1.07847297, Validation R2: 0.129082

Epoch 257/1000
Training Loss: 0.66580307, Training R2: 0.450601
Validation Loss: 1.07732475, Validation R2: 0.130247

Epoch 258/1000
Training Loss: 0.66633988, Training R2: 0.450699
Validation Loss: 1.07792628, Validation R2: 0.130407

Epoch 259/1000
Training Loss: 0.66534907, Training R2: 0.452773
Validation Loss: 1.07925093, Validation R2: 0.129755

Epoch 260/1000
Training Loss: 0.66715815, Training R2: 0.449636
Validation Loss: 1.07867861, Validation R2: 0.127095

Epoch 261/1000
Training Loss: 0.66414532, Training R2: 0.453000
Validation Loss: 1.08096290, Validation R2: 0.129616

Epoch 262/1000
Training Loss: 0.66526583, Training R2: 0.455114
Validation Loss: 1.07821965, Validation R2: 0.128955

Epoch 263/1000
Training Loss: 0.66404880, Training R2: 0.451958
Validation Loss: 1.07027054, Validation R2: 0.135749

Epoch 264/1000
Training Loss: 0.66366750, Training R2: 0.453058
Validation Loss: 1.07395351, Validation R2: 0.136816

Epoch 265/1000
Training Loss: 0.66219935, Training R2: 0.456482
Validation Loss: 1.07705426, Validation R2: 0.126211

Epoch 266/1000
Training Loss: 0.66172393, Training R2: 0.453541
Validation Loss: 1.07129729, Validation R2: 0.137571

Epoch 267/1000
Training Loss: 0.66190786, Training R2: 0.455335
Validation Loss: 1.07965171, Validation R2: 0.132143

Epoch 268/1000
Training Loss: 0.66067030, Training R2: 0.458944
Validation Loss: 1.08005989, Validation R2: 0.128881

Epoch 269/1000
Training Loss: 0.66185060, Training R2: 0.454627
Validation Loss: 1.06896174, Validation R2: 0.137528

Epoch 270/1000
Training Loss: 0.66065983, Training R2: 0.456827
Validation Loss: 1.08338559, Validation R2: 0.131490

Epoch 271/1000
Epoch 00271: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.66322886, Training R2: 0.459174
Validation Loss: 1.07673824, Validation R2: 0.128292

Epoch 272/1000
学习率已减少 5 次
Training Loss: 0.65827052, Training R2: 0.457876
Validation Loss: 1.07528079, Validation R2: 0.126370

Epoch 273/1000
Training Loss: 0.66195182, Training R2: 0.454969
Validation Loss: 1.07659006, Validation R2: 0.126742

Epoch 274/1000
Training Loss: 0.66092930, Training R2: 0.459292
Validation Loss: 1.07626176, Validation R2: 0.136829

Epoch 275/1000
Training Loss: 0.66051819, Training R2: 0.459230
Validation Loss: 1.07153678, Validation R2: 0.134813

Epoch 276/1000
Training Loss: 0.65836140, Training R2: 0.457060
Validation Loss: 1.07083809, Validation R2: 0.135597

Epoch 277/1000
Training Loss: 0.65654201, Training R2: 0.460165
Validation Loss: 1.07874727, Validation R2: 0.129503

Epoch 278/1000
Training Loss: 0.65955434, Training R2: 0.461244
Validation Loss: 1.07130837, Validation R2: 0.139191

Epoch 279/1000
Training Loss: 0.65904294, Training R2: 0.460957
Validation Loss: 1.07390106, Validation R2: 0.129804

Epoch 280/1000
Training Loss: 0.65986190, Training R2: 0.459792
Validation Loss: 1.07530880, Validation R2: 0.130096

Epoch 281/1000
Training Loss: 0.65590055, Training R2: 0.461881
Validation Loss: 1.07038474, Validation R2: 0.138203

Epoch 282/1000
Training Loss: 0.65617740, Training R2: 0.460508
Validation Loss: 1.06794381, Validation R2: 0.137012

Epoch 283/1000
Training Loss: 0.65728848, Training R2: 0.457389
Validation Loss: 1.07414317, Validation R2: 0.126438

Epoch 284/1000
Training Loss: 0.65577865, Training R2: 0.459377
Validation Loss: 1.07059503, Validation R2: 0.137193

Epoch 285/1000
Training Loss: 0.65591368, Training R2: 0.460993
Validation Loss: 1.07148361, Validation R2: 0.137558

Epoch 286/1000
Training Loss: 0.65582135, Training R2: 0.462117
Validation Loss: 1.08016968, Validation R2: 0.128884

Epoch 287/1000
Training Loss: 0.65530496, Training R2: 0.462501
Validation Loss: 1.07859302, Validation R2: 0.128472

Epoch 288/1000
Training Loss: 0.65302203, Training R2: 0.462335
Validation Loss: 1.07240844, Validation R2: 0.135157

Epoch 289/1000
Training Loss: 0.65364904, Training R2: 0.460542
Validation Loss: 1.07770002, Validation R2: 0.125909

Epoch 290/1000
Training Loss: 0.65519779, Training R2: 0.460318
Validation Loss: 1.07261026, Validation R2: 0.139617

Epoch 291/1000
Training Loss: 0.65405793, Training R2: 0.463472
Validation Loss: 1.07722080, Validation R2: 0.131406

Epoch 292/1000
Epoch 00292: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.65480737, Training R2: 0.464765
Validation Loss: 1.07299125, Validation R2: 0.131814

Epoch 293/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
