Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)
冻结层 9: lins.2 (Linear)
冻结层 10: encoder (Sequential)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Frozen
lins.2.bias: Frozen
encoder.0.weight: Frozen
encoder.0.bias: Frozen
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 993539

Epoch 1/1000
Training Loss: 1.26735555, Training R2: -0.163272
Validation Loss: 1.04521060, Validation R2: -0.023559
Saved best model with validation R2 -0.023559 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.14501512, Training R2: 0.011158
Validation Loss: 1.08861756, Validation R2: 0.015128
Saved best model with validation R2 0.015128 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.15725915, Training R2: 0.026512
Validation Loss: 1.11202586, Validation R2: -0.151982

Epoch 4/1000
Training Loss: 1.19801821, Training R2: -0.198870
Validation Loss: 1.03536880, Validation R2: 0.056205
Saved best model with validation R2 0.056205 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.14728056, Training R2: 0.034679
Validation Loss: 1.07159233, Validation R2: 0.042058

Epoch 6/1000
Training Loss: 1.15219039, Training R2: 0.034768
Validation Loss: 1.03272080, Validation R2: 0.007294

Epoch 7/1000
Training Loss: 1.13335157, Training R2: -0.077476
Validation Loss: 1.05842316, Validation R2: -0.077807

Epoch 8/1000
Training Loss: 1.12638000, Training R2: -0.056742
Validation Loss: 1.00951326, Validation R2: 0.080909
Saved best model with validation R2 0.080909 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.10775043, Training R2: 0.035422
Validation Loss: 1.01923728, Validation R2: 0.022800

Epoch 10/1000
Training Loss: 1.11564892, Training R2: -0.024720
Validation Loss: 0.99608487, Validation R2: 0.102858
Saved best model with validation R2 0.102858 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 1.11605155, Training R2: 0.050674
Validation Loss: 1.01243544, Validation R2: 0.105020
Saved best model with validation R2 0.105020 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.10759525, Training R2: 0.052498
Validation Loss: 1.02736282, Validation R2: -0.008592

Epoch 13/1000
Training Loss: 1.12603108, Training R2: -0.071733
Validation Loss: 1.01075208, Validation R2: 0.074709

Epoch 14/1000
Training Loss: 1.11775428, Training R2: 0.043552
Validation Loss: 1.02444005, Validation R2: 0.099962

Epoch 15/1000
Training Loss: 1.10700659, Training R2: 0.050025
Validation Loss: 1.06667864, Validation R2: -0.070880

Epoch 16/1000
Training Loss: 1.14166889, Training R2: -0.082148
Validation Loss: 1.01532292, Validation R2: 0.090582

Epoch 17/1000
Training Loss: 1.13640778, Training R2: 0.046477
Validation Loss: 1.05840969, Validation R2: 0.062085

Epoch 18/1000
Training Loss: 1.14488329, Training R2: 0.051755
Validation Loss: 1.02419162, Validation R2: 0.055732

Epoch 19/1000
Training Loss: 1.12073043, Training R2: -0.020018
Validation Loss: 1.04766428, Validation R2: -0.024484

Epoch 20/1000
Training Loss: 1.11277947, Training R2: -0.006692
Validation Loss: 1.01533628, Validation R2: 0.088174

Epoch 21/1000
Training Loss: 1.10360229, Training R2: 0.046076
Validation Loss: 1.02414012, Validation R2: 0.029841

Epoch 22/1000
Training Loss: 1.10031836, Training R2: 0.006256
Validation Loss: 1.01437819, Validation R2: 0.056585

Epoch 23/1000
Training Loss: 1.09358889, Training R2: 0.040284
Validation Loss: 1.01028442, Validation R2: 0.076604

Epoch 24/1000
Training Loss: 1.09366407, Training R2: 0.033073
Validation Loss: 1.00916290, Validation R2: 0.066128

Epoch 25/1000
Training Loss: 1.09671255, Training R2: 0.044943
Validation Loss: 1.00257897, Validation R2: 0.111686
Saved best model with validation R2 0.111686 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 1.10290610, Training R2: 0.067963
Validation Loss: 1.00655186, Validation R2: 0.052600

Epoch 27/1000
Training Loss: 1.10271182, Training R2: -0.001556
Validation Loss: 1.00281835, Validation R2: 0.058954

Epoch 28/1000
Training Loss: 1.09236078, Training R2: 0.034673
Validation Loss: 1.00380468, Validation R2: 0.086503

Epoch 29/1000
Training Loss: 1.09290480, Training R2: 0.028785
Validation Loss: 1.01810920, Validation R2: 0.023911

Epoch 30/1000
Training Loss: 1.09418289, Training R2: 0.014728
Validation Loss: 0.99844038, Validation R2: 0.104410

Epoch 31/1000
Training Loss: 1.09605974, Training R2: 0.067621
Validation Loss: 0.99355733, Validation R2: 0.096701

Epoch 32/1000
Training Loss: 1.09024803, Training R2: 0.040193
Validation Loss: 1.01329064, Validation R2: 0.040128

Epoch 33/1000
Training Loss: 1.09762194, Training R2: 0.012987
Validation Loss: 1.00998628, Validation R2: 0.086335

Epoch 34/1000
Training Loss: 1.09538133, Training R2: 0.028546
Validation Loss: 1.00738466, Validation R2: 0.091134

Epoch 35/1000
Training Loss: 1.09634036, Training R2: 0.060636
Validation Loss: 1.00986063, Validation R2: 0.071505

Epoch 36/1000
Training Loss: 1.10190867, Training R2: 0.001807
Validation Loss: 1.02298188, Validation R2: 0.028844

Epoch 37/1000
Training Loss: 1.09977225, Training R2: 0.009478
Validation Loss: 1.01058578, Validation R2: 0.078780

Epoch 38/1000
Training Loss: 1.09907111, Training R2: 0.020218
Validation Loss: 1.00557017, Validation R2: 0.086488

Epoch 39/1000
Training Loss: 1.08867261, Training R2: 0.049446
Validation Loss: 0.99144745, Validation R2: 0.102864

Epoch 40/1000
Training Loss: 1.09259873, Training R2: 0.055856
Validation Loss: 0.99013090, Validation R2: 0.129702
Saved best model with validation R2 0.129702 to best_finetuned_model.pth

Epoch 41/1000
Training Loss: 1.12345569, Training R2: 0.073717
Validation Loss: 1.01961255, Validation R2: 0.111170

Epoch 42/1000
Training Loss: 1.10535529, Training R2: 0.087422
Validation Loss: 1.03405392, Validation R2: 0.014760

Epoch 43/1000
Training Loss: 1.10248051, Training R2: 0.006544
Validation Loss: 1.00057340, Validation R2: 0.123177

Epoch 44/1000
Training Loss: 1.12187651, Training R2: 0.070361
Validation Loss: 1.00652361, Validation R2: 0.112693

Epoch 45/1000
Training Loss: 1.08697935, Training R2: 0.054951
Validation Loss: 1.05475307, Validation R2: -0.038651

Epoch 46/1000
Training Loss: 1.10261894, Training R2: -0.015297
Validation Loss: 1.01352549, Validation R2: 0.107987

Epoch 47/1000
Training Loss: 1.12992965, Training R2: 0.062634
Validation Loss: 1.00164378, Validation R2: 0.108420

Epoch 48/1000
Training Loss: 1.11039360, Training R2: -0.009462
Validation Loss: 1.01498830, Validation R2: 0.057178

Epoch 49/1000
Training Loss: 1.10172668, Training R2: 0.057034
Validation Loss: 1.04968941, Validation R2: 0.072944

Epoch 50/1000
Training Loss: 1.12819427, Training R2: 0.069226
Validation Loss: 1.02907801, Validation R2: 0.030301

Epoch 51/1000
Training Loss: 1.13659487, Training R2: -0.084280
Validation Loss: 1.03690350, Validation R2: 0.005094

Epoch 52/1000
Training Loss: 1.10212036, Training R2: 0.034352
Validation Loss: 1.04811931, Validation R2: 0.075379

Epoch 53/1000
Training Loss: 1.15215318, Training R2: 0.057666
Validation Loss: 1.00471330, Validation R2: 0.105067

Epoch 54/1000
Training Loss: 1.10558777, Training R2: 0.048706
Validation Loss: 1.02263951, Validation R2: 0.026868

Epoch 55/1000
Training Loss: 1.10490089, Training R2: 0.037880
Validation Loss: 1.01702011, Validation R2: 0.099990

Epoch 56/1000
Training Loss: 1.09712893, Training R2: 0.053846
Validation Loss: 1.03284061, Validation R2: 0.016283

Epoch 57/1000
Training Loss: 1.09275937, Training R2: 0.008393
Validation Loss: 1.01172709, Validation R2: 0.085093

Epoch 58/1000
Training Loss: 1.08569240, Training R2: 0.053876
Validation Loss: 1.00412822, Validation R2: 0.110135

Epoch 59/1000
Training Loss: 1.09069176, Training R2: 0.074541
Validation Loss: 1.00143921, Validation R2: 0.071511

Epoch 60/1000
Training Loss: 1.09433550, Training R2: 0.001963
Validation Loss: 1.00962853, Validation R2: 0.053441

Epoch 61/1000
Epoch 00061: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 1.08122010, Training R2: 0.067931
Validation Loss: 1.01632929, Validation R2: 0.102135

Epoch 62/1000
学习率已减少 1 次
Training Loss: 1.10097225, Training R2: 0.070652
Validation Loss: 1.00545549, Validation R2: 0.086364

Epoch 63/1000
Training Loss: 1.07954994, Training R2: 0.034761
Validation Loss: 1.01661026, Validation R2: 0.032005

Epoch 64/1000
Training Loss: 1.07650012, Training R2: 0.013958
Validation Loss: 1.00343549, Validation R2: 0.079987

Epoch 65/1000
Training Loss: 1.07549668, Training R2: 0.067848
Validation Loss: 1.00035524, Validation R2: 0.102836

Epoch 66/1000
Training Loss: 1.07345602, Training R2: 0.081764
Validation Loss: 1.00515854, Validation R2: 0.078648

Epoch 67/1000
Training Loss: 1.06609460, Training R2: 0.055929
Validation Loss: 1.00995195, Validation R2: 0.065783

Epoch 68/1000
Training Loss: 1.06417641, Training R2: 0.062800
Validation Loss: 0.99949551, Validation R2: 0.099769

Epoch 69/1000
Training Loss: 1.06487342, Training R2: 0.077484
Validation Loss: 0.99790412, Validation R2: 0.088190

Epoch 70/1000
Training Loss: 1.06564340, Training R2: 0.057503
Validation Loss: 0.99933386, Validation R2: 0.074683

Epoch 71/1000
Training Loss: 1.06515355, Training R2: 0.056597
Validation Loss: 0.99231869, Validation R2: 0.092311

Epoch 72/1000
Training Loss: 1.06084276, Training R2: 0.069129
Validation Loss: 0.99213582, Validation R2: 0.097403

Epoch 73/1000
Training Loss: 1.05973573, Training R2: 0.079496
Validation Loss: 0.99367070, Validation R2: 0.092922

Epoch 74/1000
Training Loss: 1.05719015, Training R2: 0.067417
Validation Loss: 0.99826783, Validation R2: 0.079557

Epoch 75/1000
Training Loss: 1.05717049, Training R2: 0.082033
Validation Loss: 0.99568576, Validation R2: 0.100097

Epoch 76/1000
Training Loss: 1.05756546, Training R2: 0.078518
Validation Loss: 0.99503654, Validation R2: 0.083853

Epoch 77/1000
Training Loss: 1.04865423, Training R2: 0.078502
Validation Loss: 0.98456466, Validation R2: 0.105063

Epoch 78/1000
Training Loss: 1.04786139, Training R2: 0.083456
Validation Loss: 0.98566681, Validation R2: 0.089705

Epoch 79/1000
Training Loss: 1.05038813, Training R2: 0.066740
Validation Loss: 0.98015380, Validation R2: 0.111022

Epoch 80/1000
Training Loss: 1.04745296, Training R2: 0.095560
Validation Loss: 0.98225296, Validation R2: 0.107747

Epoch 81/1000
Training Loss: 1.04409228, Training R2: 0.095145
Validation Loss: 0.97997266, Validation R2: 0.107086

Epoch 82/1000
Epoch 00082: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 1.04243573, Training R2: 0.085103
Validation Loss: 0.99010479, Validation R2: 0.071859

Epoch 83/1000
学习率已减少 2 次
Training Loss: 1.04720198, Training R2: 0.050159
Validation Loss: 0.98555493, Validation R2: 0.095384

Epoch 84/1000
Training Loss: 1.03941687, Training R2: 0.094761
Validation Loss: 0.98802543, Validation R2: 0.119075

Epoch 85/1000
Training Loss: 1.04508711, Training R2: 0.098783
Validation Loss: 0.99265599, Validation R2: 0.083748

Epoch 86/1000
Training Loss: 1.04858631, Training R2: 0.046204
Validation Loss: 0.99312800, Validation R2: 0.072545

Epoch 87/1000
Training Loss: 1.03834891, Training R2: 0.079220
Validation Loss: 0.97926879, Validation R2: 0.123241

Epoch 88/1000
Training Loss: 1.05190061, Training R2: 0.105671
Validation Loss: 0.97908431, Validation R2: 0.114744

Epoch 89/1000
Training Loss: 1.03703389, Training R2: 0.087762
Validation Loss: 1.00193429, Validation R2: 0.049365

Epoch 90/1000
Training Loss: 1.05251347, Training R2: 0.037585
Validation Loss: 0.97933286, Validation R2: 0.118963

Epoch 91/1000
Training Loss: 1.06052668, Training R2: 0.110521
Validation Loss: 0.98787993, Validation R2: 0.113542

Epoch 92/1000
Training Loss: 1.03903928, Training R2: 0.119352
Validation Loss: 1.00576794, Validation R2: 0.025813

Epoch 93/1000
Training Loss: 1.07302445, Training R2: -0.010791
Validation Loss: 0.99471813, Validation R2: 0.056897

Epoch 94/1000
Training Loss: 1.04238162, Training R2: 0.070782
Validation Loss: 0.98515409, Validation R2: 0.120432

Epoch 95/1000
Training Loss: 1.05256839, Training R2: 0.106219
Validation Loss: 0.98365951, Validation R2: 0.119216

Epoch 96/1000
Training Loss: 1.03560367, Training R2: 0.096945
Validation Loss: 0.98850006, Validation R2: 0.091374

Epoch 97/1000
Training Loss: 1.03963759, Training R2: 0.067313
Validation Loss: 0.98060012, Validation R2: 0.117024

Epoch 98/1000
Training Loss: 1.03557155, Training R2: 0.109023
Validation Loss: 0.98118621, Validation R2: 0.132221
Saved best model with validation R2 0.132221 to best_finetuned_model.pth

Epoch 99/1000
Training Loss: 1.03586009, Training R2: 0.121437
Validation Loss: 0.97402436, Validation R2: 0.112907

Epoch 100/1000
Training Loss: 1.02870714, Training R2: 0.088099
Validation Loss: 0.98480392, Validation R2: 0.088521

Epoch 101/1000
Training Loss: 1.03430614, Training R2: 0.093721
Validation Loss: 0.97223037, Validation R2: 0.107038

Epoch 102/1000
Training Loss: 1.02433444, Training R2: 0.096067
Validation Loss: 0.97166455, Validation R2: 0.080046

Epoch 103/1000
Training Loss: 1.04249826, Training R2: 0.036103
Validation Loss: 0.97036505, Validation R2: 0.126423

Epoch 104/1000
Training Loss: 1.03397067, Training R2: 0.107359
Validation Loss: 0.97614789, Validation R2: 0.133993
Saved best model with validation R2 0.133993 to best_finetuned_model.pth

Epoch 105/1000
Training Loss: 1.03315458, Training R2: 0.084353
Validation Loss: 0.97436965, Validation R2: 0.097100

Epoch 106/1000
Training Loss: 1.02067875, Training R2: 0.094716
Validation Loss: 0.97620863, Validation R2: 0.115449

Epoch 107/1000
Training Loss: 1.04106843, Training R2: 0.114765
Validation Loss: 0.98818177, Validation R2: 0.087280

Epoch 108/1000
Training Loss: 1.05011395, Training R2: 0.040010
Validation Loss: 0.99036747, Validation R2: 0.059934

Epoch 109/1000
Training Loss: 1.03476060, Training R2: 0.082791
Validation Loss: 0.98825783, Validation R2: 0.125053

Epoch 110/1000
Training Loss: 1.05560811, Training R2: 0.125684
Validation Loss: 0.97898442, Validation R2: 0.135826
Saved best model with validation R2 0.135826 to best_finetuned_model.pth

Epoch 111/1000
Training Loss: 1.02655094, Training R2: 0.131952
Validation Loss: 0.97624296, Validation R2: 0.082489

Epoch 112/1000
Training Loss: 1.04605154, Training R2: 0.036313
Validation Loss: 0.96504730, Validation R2: 0.130909

Epoch 113/1000
Training Loss: 1.03034465, Training R2: 0.136162
Validation Loss: 0.98661292, Validation R2: 0.125498

Epoch 114/1000
Training Loss: 1.03851035, Training R2: 0.128501
Validation Loss: 0.97480744, Validation R2: 0.110443

Epoch 115/1000
Training Loss: 1.01490436, Training R2: 0.103451
Validation Loss: 0.96935481, Validation R2: 0.130114

Epoch 116/1000
Training Loss: 1.02210349, Training R2: 0.116339
Validation Loss: 0.97510558, Validation R2: 0.126937

Epoch 117/1000
Training Loss: 1.02616616, Training R2: 0.086500
Validation Loss: 0.97764319, Validation R2: 0.095991

Epoch 118/1000
Training Loss: 1.01302138, Training R2: 0.092163
Validation Loss: 0.97141814, Validation R2: 0.115264

Epoch 119/1000
Training Loss: 1.03526926, Training R2: 0.117487
Validation Loss: 0.96623379, Validation R2: 0.115718

Epoch 120/1000
Training Loss: 1.02707198, Training R2: 0.096592
Validation Loss: 0.98218453, Validation R2: 0.074198

Epoch 121/1000
Training Loss: 1.01840068, Training R2: 0.095276
Validation Loss: 0.96335846, Validation R2: 0.141587
Saved best model with validation R2 0.141587 to best_finetuned_model.pth

Epoch 122/1000
Training Loss: 1.01484605, Training R2: 0.144019
Validation Loss: 0.96358162, Validation R2: 0.144846
Saved best model with validation R2 0.144846 to best_finetuned_model.pth

Epoch 123/1000
Training Loss: 1.01214211, Training R2: 0.151380
Validation Loss: 0.97189289, Validation R2: 0.114203

Epoch 124/1000
Training Loss: 1.01423520, Training R2: 0.101742
Validation Loss: 0.97874075, Validation R2: 0.089076

Epoch 125/1000
Training Loss: 1.00598462, Training R2: 0.118012
Validation Loss: 0.97067565, Validation R2: 0.135465

Epoch 126/1000
Training Loss: 1.01341500, Training R2: 0.121658
Validation Loss: 0.96609294, Validation R2: 0.121667

Epoch 127/1000
Training Loss: 0.99663448, Training R2: 0.125647
Validation Loss: 0.96598941, Validation R2: 0.124993

Epoch 128/1000
Training Loss: 1.00434720, Training R2: 0.142134
Validation Loss: 0.96321988, Validation R2: 0.103915

Epoch 129/1000
Training Loss: 1.01233561, Training R2: 0.086108
Validation Loss: 0.95854765, Validation R2: 0.132953

Epoch 130/1000
Training Loss: 1.02600704, Training R2: 0.137404
Validation Loss: 0.99529356, Validation R2: 0.102892

Epoch 131/1000
Training Loss: 1.03182798, Training R2: 0.136048
Validation Loss: 0.96520686, Validation R2: 0.103540

Epoch 132/1000
Training Loss: 1.00338294, Training R2: 0.104445
Validation Loss: 0.95728344, Validation R2: 0.110257

Epoch 133/1000
Training Loss: 0.99865642, Training R2: 0.131501
Validation Loss: 0.95785642, Validation R2: 0.119121

Epoch 134/1000
Training Loss: 0.99413614, Training R2: 0.136518
Validation Loss: 0.94865596, Validation R2: 0.122994

Epoch 135/1000
Training Loss: 0.99119097, Training R2: 0.131404
Validation Loss: 0.94713008, Validation R2: 0.132059

Epoch 136/1000
Training Loss: 1.00024521, Training R2: 0.117492
Validation Loss: 0.95070356, Validation R2: 0.140373

Epoch 137/1000
Training Loss: 0.99113064, Training R2: 0.165195
Validation Loss: 0.96512723, Validation R2: 0.129688

Epoch 138/1000
Training Loss: 0.99022852, Training R2: 0.171103
Validation Loss: 0.98148304, Validation R2: 0.064803

Epoch 139/1000
Training Loss: 1.00529185, Training R2: 0.107638
Validation Loss: 0.97904068, Validation R2: 0.078238

Epoch 140/1000
Training Loss: 0.98646655, Training R2: 0.149771
Validation Loss: 0.97481352, Validation R2: 0.090202

Epoch 141/1000
Training Loss: 0.98719688, Training R2: 0.138215
Validation Loss: 0.96431953, Validation R2: 0.119396

Epoch 142/1000
Training Loss: 1.02221685, Training R2: 0.148689
Validation Loss: 0.97134578, Validation R2: 0.115108

Epoch 143/1000
Epoch 00143: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.98175936, Training R2: 0.169418
Validation Loss: 1.00328624, Validation R2: 0.015960

Epoch 144/1000
学习率已减少 3 次
Training Loss: 1.00932430, Training R2: 0.075686
Validation Loss: 0.96711129, Validation R2: 0.094129

Epoch 145/1000
Training Loss: 0.97558372, Training R2: 0.169044
Validation Loss: 0.96651471, Validation R2: 0.107468

Epoch 146/1000
Training Loss: 0.97431133, Training R2: 0.171003
Validation Loss: 0.96580762, Validation R2: 0.098788

Epoch 147/1000
Training Loss: 0.97045108, Training R2: 0.164796
Validation Loss: 0.96452266, Validation R2: 0.109846

Epoch 148/1000
Training Loss: 0.97200240, Training R2: 0.175115
Validation Loss: 0.96327865, Validation R2: 0.108311

Epoch 149/1000
Training Loss: 0.96890690, Training R2: 0.162628
Validation Loss: 0.96140873, Validation R2: 0.099896

Epoch 150/1000
Training Loss: 0.97041775, Training R2: 0.166650
Validation Loss: 0.95332390, Validation R2: 0.124279

Epoch 151/1000
Training Loss: 0.96245575, Training R2: 0.178267
Validation Loss: 0.95552236, Validation R2: 0.116769

Epoch 152/1000
Training Loss: 0.96041760, Training R2: 0.181732
Validation Loss: 0.96415412, Validation R2: 0.110341

Epoch 153/1000
Training Loss: 0.96255959, Training R2: 0.180343
Validation Loss: 0.96701378, Validation R2: 0.101080

Epoch 154/1000
Training Loss: 0.96239903, Training R2: 0.175302
Validation Loss: 0.95848602, Validation R2: 0.112050

Epoch 155/1000
Training Loss: 0.95594877, Training R2: 0.182990
Validation Loss: 0.96322495, Validation R2: 0.094157

Epoch 156/1000
Training Loss: 0.96194862, Training R2: 0.156338
Validation Loss: 0.96041667, Validation R2: 0.104168

Epoch 157/1000
Training Loss: 0.95926089, Training R2: 0.182222
Validation Loss: 0.97434688, Validation R2: 0.090778

Epoch 158/1000
Training Loss: 0.95208854, Training R2: 0.182931
Validation Loss: 0.98580170, Validation R2: 0.048756

Epoch 159/1000
Training Loss: 0.97550490, Training R2: 0.125809
Validation Loss: 0.96974379, Validation R2: 0.092020

Epoch 160/1000
Training Loss: 0.95166058, Training R2: 0.190364
Validation Loss: 0.96259326, Validation R2: 0.107414

Epoch 161/1000
Training Loss: 0.95905098, Training R2: 0.175088
Validation Loss: 0.95921677, Validation R2: 0.087262

Epoch 162/1000
Training Loss: 0.95883411, Training R2: 0.163585
Validation Loss: 0.94648451, Validation R2: 0.127620

Epoch 163/1000
Training Loss: 0.95499219, Training R2: 0.193368
Validation Loss: 0.93923712, Validation R2: 0.118448

Epoch 164/1000
Epoch 00164: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.95703178, Training R2: 0.165952
Validation Loss: 0.94569176, Validation R2: 0.118234

Epoch 165/1000
学习率已减少 4 次
Training Loss: 0.95087966, Training R2: 0.189792
Validation Loss: 0.95922214, Validation R2: 0.111270

Epoch 166/1000
Training Loss: 0.94664643, Training R2: 0.197109
Validation Loss: 0.96407926, Validation R2: 0.103895

Epoch 167/1000
Training Loss: 0.94349016, Training R2: 0.192632
Validation Loss: 0.96405864, Validation R2: 0.104146

Epoch 168/1000
Training Loss: 0.94040740, Training R2: 0.200423
Validation Loss: 0.97022748, Validation R2: 0.100473

Epoch 169/1000
Training Loss: 0.94426270, Training R2: 0.196741
Validation Loss: 0.97155708, Validation R2: 0.097083

Epoch 170/1000
Training Loss: 0.94160314, Training R2: 0.189880
Validation Loss: 0.96717107, Validation R2: 0.097822

Epoch 171/1000
Training Loss: 0.93875408, Training R2: 0.193841
Validation Loss: 0.96901488, Validation R2: 0.101858

Epoch 172/1000
Training Loss: 0.94642493, Training R2: 0.201047
Validation Loss: 0.96608907, Validation R2: 0.099888

Epoch 173/1000
Training Loss: 0.94597784, Training R2: 0.198419
Validation Loss: 0.95331419, Validation R2: 0.110593

Epoch 174/1000
Training Loss: 0.93721215, Training R2: 0.198468
Validation Loss: 0.95887202, Validation R2: 0.103627

Epoch 175/1000
Training Loss: 0.93687562, Training R2: 0.190706
Validation Loss: 0.96839368, Validation R2: 0.088483

Epoch 176/1000
Training Loss: 0.93838196, Training R2: 0.182303
Validation Loss: 0.97601271, Validation R2: 0.079848

Epoch 177/1000
Training Loss: 0.93527976, Training R2: 0.192030
Validation Loss: 0.97334576, Validation R2: 0.094228

Epoch 178/1000
Training Loss: 0.93348536, Training R2: 0.204341
Validation Loss: 0.97349548, Validation R2: 0.097572

Epoch 179/1000
Training Loss: 0.93616388, Training R2: 0.208014
Validation Loss: 0.96470457, Validation R2: 0.107366

Epoch 180/1000
Training Loss: 0.93223729, Training R2: 0.206938
Validation Loss: 0.95521820, Validation R2: 0.110725

Epoch 181/1000
Training Loss: 0.93464763, Training R2: 0.193148
Validation Loss: 0.95615780, Validation R2: 0.105022

Epoch 182/1000
Training Loss: 0.93110023, Training R2: 0.195557
Validation Loss: 0.96479750, Validation R2: 0.103865

Epoch 183/1000
Training Loss: 0.93312033, Training R2: 0.209899
Validation Loss: 0.97593993, Validation R2: 0.092567

Epoch 184/1000
Training Loss: 0.93267089, Training R2: 0.201219
Validation Loss: 0.97260731, Validation R2: 0.085231

Epoch 185/1000
Epoch 00185: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.92985239, Training R2: 0.198766
Validation Loss: 0.96746761, Validation R2: 0.101074

Epoch 186/1000
学习率已减少 5 次
Training Loss: 0.92574666, Training R2: 0.203685
Validation Loss: 0.96545041, Validation R2: 0.103103

Epoch 187/1000
Training Loss: 0.92502984, Training R2: 0.208390
Validation Loss: 0.96528333, Validation R2: 0.105087

Epoch 188/1000
Training Loss: 0.92476496, Training R2: 0.206262
Validation Loss: 0.96678084, Validation R2: 0.099263

Epoch 189/1000
Training Loss: 0.92676245, Training R2: 0.198541
Validation Loss: 0.96644300, Validation R2: 0.098278

Epoch 190/1000
Training Loss: 0.92426897, Training R2: 0.204955
Validation Loss: 0.96576107, Validation R2: 0.099940

Epoch 191/1000
Training Loss: 0.92797080, Training R2: 0.205671
Validation Loss: 0.96568877, Validation R2: 0.099252

Epoch 192/1000
Training Loss: 0.92687596, Training R2: 0.206535
Validation Loss: 0.96818084, Validation R2: 0.096254

Epoch 193/1000
Training Loss: 0.92567365, Training R2: 0.206626
Validation Loss: 0.97262955, Validation R2: 0.090624

Epoch 194/1000
Training Loss: 0.92389374, Training R2: 0.203166
Validation Loss: 0.97336853, Validation R2: 0.085561

Epoch 195/1000
Training Loss: 0.92512172, Training R2: 0.200231
Validation Loss: 0.97228903, Validation R2: 0.089853

Epoch 196/1000
Training Loss: 0.92225929, Training R2: 0.207880
Validation Loss: 0.97320539, Validation R2: 0.093437

Epoch 197/1000
Training Loss: 0.92298520, Training R2: 0.211794
Validation Loss: 0.97443175, Validation R2: 0.093458

Epoch 198/1000
Training Loss: 0.92483657, Training R2: 0.212881
Validation Loss: 0.97045445, Validation R2: 0.094697

Epoch 199/1000
Training Loss: 0.91980310, Training R2: 0.208084
Validation Loss: 0.96524322, Validation R2: 0.093339

Epoch 200/1000
Training Loss: 0.92183735, Training R2: 0.200414
Validation Loss: 0.96415555, Validation R2: 0.098257

Epoch 201/1000
Training Loss: 0.91853156, Training R2: 0.213066
Validation Loss: 0.96695584, Validation R2: 0.096280

Epoch 202/1000
Training Loss: 0.92219595, Training R2: 0.208642
Validation Loss: 0.96608090, Validation R2: 0.092806

Epoch 203/1000
Training Loss: 0.92187044, Training R2: 0.199793
Validation Loss: 0.96716571, Validation R2: 0.086911

Epoch 204/1000
Training Loss: 0.92212088, Training R2: 0.200002
Validation Loss: 0.97274345, Validation R2: 0.090567

Epoch 205/1000
Training Loss: 0.91857111, Training R2: 0.215429
Validation Loss: 0.97093052, Validation R2: 0.094071

Epoch 206/1000
Epoch 00206: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.91839461, Training R2: 0.211728
Validation Loss: 0.96768504, Validation R2: 0.090234

Epoch 207/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
