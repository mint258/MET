Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Trainable
lins.0.bias: Trainable
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1223811

Epoch 1/1000
Training Loss: 1.27893582, Training R2: -0.191618
Validation Loss: 1.08354378, Validation R2: -0.115899
Saved best model with validation R2 -0.115899 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.16023054, Training R2: -0.025170
Validation Loss: 1.12439036, Validation R2: -0.055124
Saved best model with validation R2 -0.055124 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.18977750, Training R2: -0.002136
Validation Loss: 1.05739975, Validation R2: -0.019444
Saved best model with validation R2 -0.019444 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.16712061, Training R2: -0.122974
Validation Loss: 1.06003916, Validation R2: -0.020551

Epoch 5/1000
Training Loss: 1.13854520, Training R2: 0.002375
Validation Loss: 1.06244373, Validation R2: 0.049497
Saved best model with validation R2 0.049497 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.13927402, Training R2: 0.029641
Validation Loss: 1.04888856, Validation R2: 0.001471

Epoch 7/1000
Training Loss: 1.13247413, Training R2: -0.051702
Validation Loss: 1.07051468, Validation R2: -0.060573

Epoch 8/1000
Training Loss: 1.13073060, Training R2: -0.050579
Validation Loss: 1.03352523, Validation R2: 0.045040

Epoch 9/1000
Training Loss: 1.10898111, Training R2: 0.021001
Validation Loss: 1.03989184, Validation R2: 0.012788

Epoch 10/1000
Training Loss: 1.11274657, Training R2: -0.023061
Validation Loss: 1.01962268, Validation R2: 0.071031
Saved best model with validation R2 0.071031 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 1.12096786, Training R2: 0.050149
Validation Loss: 1.01967943, Validation R2: 0.097139
Saved best model with validation R2 0.097139 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.10111161, Training R2: 0.066512
Validation Loss: 1.05857384, Validation R2: -0.050416

Epoch 13/1000
Training Loss: 1.12578174, Training R2: -0.069484
Validation Loss: 1.00996614, Validation R2: 0.094734

Epoch 14/1000
Training Loss: 1.11043048, Training R2: 0.063499
Validation Loss: 1.01997590, Validation R2: 0.102478
Saved best model with validation R2 0.102478 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 1.09584041, Training R2: 0.063778
Validation Loss: 1.04995692, Validation R2: -0.019577

Epoch 16/1000
Training Loss: 1.11135020, Training R2: -0.026831
Validation Loss: 1.00988591, Validation R2: 0.101555

Epoch 17/1000
Training Loss: 1.10969559, Training R2: 0.069483
Validation Loss: 1.02354336, Validation R2: 0.100386

Epoch 18/1000
Training Loss: 1.10005808, Training R2: 0.079989
Validation Loss: 1.01949430, Validation R2: 0.039846

Epoch 19/1000
Training Loss: 1.10220243, Training R2: -0.008577
Validation Loss: 1.00681496, Validation R2: 0.067827

Epoch 20/1000
Training Loss: 1.08083944, Training R2: 0.053342
Validation Loss: 1.00338197, Validation R2: 0.094163

Epoch 21/1000
Training Loss: 1.08143453, Training R2: 0.045887
Validation Loss: 1.01606905, Validation R2: 0.051553

Epoch 22/1000
Training Loss: 1.07717403, Training R2: 0.048025
Validation Loss: 0.99837041, Validation R2: 0.105074
Saved best model with validation R2 0.105074 to best_finetuned_model.pth

Epoch 23/1000
Training Loss: 1.06800776, Training R2: 0.082768
Validation Loss: 1.00281465, Validation R2: 0.092249

Epoch 24/1000
Training Loss: 1.07452991, Training R2: 0.069800
Validation Loss: 0.98934591, Validation R2: 0.125807
Saved best model with validation R2 0.125807 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 1.07162228, Training R2: 0.103893
Validation Loss: 0.98345733, Validation R2: 0.139878
Saved best model with validation R2 0.139878 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 1.06669020, Training R2: 0.092998
Validation Loss: 0.99057460, Validation R2: 0.095486

Epoch 27/1000
Training Loss: 1.06216781, Training R2: 0.071004
Validation Loss: 0.97314960, Validation R2: 0.141636
Saved best model with validation R2 0.141636 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 1.05133661, Training R2: 0.087898
Validation Loss: 0.96514481, Validation R2: 0.146316
Saved best model with validation R2 0.146316 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 1.04423869, Training R2: 0.118626
Validation Loss: 0.95289761, Validation R2: 0.174794
Saved best model with validation R2 0.174794 to best_finetuned_model.pth

Epoch 30/1000
Training Loss: 1.04227466, Training R2: 0.127495
Validation Loss: 0.95928967, Validation R2: 0.171231

Epoch 31/1000
Training Loss: 1.04862013, Training R2: 0.106075
Validation Loss: 0.94271177, Validation R2: 0.179355
Saved best model with validation R2 0.179355 to best_finetuned_model.pth

Epoch 32/1000
Training Loss: 1.02319912, Training R2: 0.132603
Validation Loss: 0.95213443, Validation R2: 0.193671
Saved best model with validation R2 0.193671 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 1.04181565, Training R2: 0.147318
Validation Loss: 0.97732848, Validation R2: 0.136946

Epoch 34/1000
Training Loss: 1.03574265, Training R2: 0.129359
Validation Loss: 0.98792166, Validation R2: 0.091646

Epoch 35/1000
Training Loss: 1.02927892, Training R2: 0.108453
Validation Loss: 0.90842837, Validation R2: 0.236278
Saved best model with validation R2 0.236278 to best_finetuned_model.pth

Epoch 36/1000
Training Loss: 1.02840154, Training R2: 0.131653
Validation Loss: 0.96553832, Validation R2: 0.122111

Epoch 37/1000
Training Loss: 1.05243701, Training R2: 0.065381
Validation Loss: 0.94699430, Validation R2: 0.195918

Epoch 38/1000
Training Loss: 1.03134470, Training R2: 0.130445
Validation Loss: 0.91252875, Validation R2: 0.242580
Saved best model with validation R2 0.242580 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.99510141, Training R2: 0.184976
Validation Loss: 0.92630458, Validation R2: 0.227664

Epoch 40/1000
Training Loss: 1.00221013, Training R2: 0.156751
Validation Loss: 1.11544657, Validation R2: -0.083979

Epoch 41/1000
Training Loss: 1.08691564, Training R2: 0.095890
Validation Loss: 0.97380382, Validation R2: 0.145643

Epoch 42/1000
Training Loss: 1.01032920, Training R2: 0.163625
Validation Loss: 0.94551361, Validation R2: 0.193409

Epoch 43/1000
Training Loss: 1.01444964, Training R2: 0.161131
Validation Loss: 0.94745106, Validation R2: 0.172811

Epoch 44/1000
Training Loss: 0.99749743, Training R2: 0.169728
Validation Loss: 0.92377156, Validation R2: 0.241212

Epoch 45/1000
Training Loss: 0.94269510, Training R2: 0.244107
Validation Loss: 0.89267951, Validation R2: 0.277492
Saved best model with validation R2 0.277492 to best_finetuned_model.pth

Epoch 46/1000
Training Loss: 0.95389317, Training R2: 0.227872
Validation Loss: 0.95650816, Validation R2: 0.196090

Epoch 47/1000
Training Loss: 0.97529884, Training R2: 0.212377
Validation Loss: 1.04228950, Validation R2: 0.032928

Epoch 48/1000
Training Loss: 1.01071116, Training R2: 0.140743
Validation Loss: 1.03046811, Validation R2: 0.098275

Epoch 49/1000
Training Loss: 0.97136909, Training R2: 0.228427
Validation Loss: 0.96886426, Validation R2: 0.132393

Epoch 50/1000
Training Loss: 0.94992653, Training R2: 0.211583
Validation Loss: 0.94260174, Validation R2: 0.206939

Epoch 51/1000
Training Loss: 0.95883394, Training R2: 0.261002
Validation Loss: 0.87357438, Validation R2: 0.305045
Saved best model with validation R2 0.305045 to best_finetuned_model.pth

Epoch 52/1000
Training Loss: 0.88272562, Training R2: 0.311846
Validation Loss: 0.96677685, Validation R2: 0.145536

Epoch 53/1000
Training Loss: 0.97834927, Training R2: 0.205186
Validation Loss: 1.02068853, Validation R2: 0.084809

Epoch 54/1000
Training Loss: 0.98913562, Training R2: 0.148062
Validation Loss: 0.91997784, Validation R2: 0.245832

Epoch 55/1000
Training Loss: 0.90316567, Training R2: 0.299557
Validation Loss: 0.89828652, Validation R2: 0.248692

Epoch 56/1000
Training Loss: 0.89084910, Training R2: 0.270315
Validation Loss: 0.87397993, Validation R2: 0.303896

Epoch 57/1000
Training Loss: 0.85566373, Training R2: 0.354635
Validation Loss: 0.85550129, Validation R2: 0.311782
Saved best model with validation R2 0.311782 to best_finetuned_model.pth

Epoch 58/1000
Training Loss: 0.81554181, Training R2: 0.361690
Validation Loss: 0.87381727, Validation R2: 0.275784

Epoch 59/1000
Training Loss: 0.81909695, Training R2: 0.348773
Validation Loss: 0.86938721, Validation R2: 0.271993

Epoch 60/1000
Training Loss: 0.82382664, Training R2: 0.349221
Validation Loss: 0.83423889, Validation R2: 0.319013
Saved best model with validation R2 0.319013 to best_finetuned_model.pth

Epoch 61/1000
Training Loss: 0.82334080, Training R2: 0.360825
Validation Loss: 0.84931195, Validation R2: 0.296687

Epoch 62/1000
Training Loss: 0.84320378, Training R2: 0.368886
Validation Loss: 0.84508407, Validation R2: 0.312039

Epoch 63/1000
Training Loss: 0.85391578, Training R2: 0.321761
Validation Loss: 0.83361995, Validation R2: 0.357182
Saved best model with validation R2 0.357182 to best_finetuned_model.pth

Epoch 64/1000
Training Loss: 0.81939350, Training R2: 0.398971
Validation Loss: 0.86068618, Validation R2: 0.306102

Epoch 65/1000
Training Loss: 0.80208879, Training R2: 0.390792
Validation Loss: 0.77296436, Validation R2: 0.414433
Saved best model with validation R2 0.414433 to best_finetuned_model.pth

Epoch 66/1000
Training Loss: 0.77914498, Training R2: 0.407217
Validation Loss: 0.80170280, Validation R2: 0.373049

Epoch 67/1000
Training Loss: 0.76828038, Training R2: 0.426973
Validation Loss: 0.82255799, Validation R2: 0.352049

Epoch 68/1000
Training Loss: 0.75282372, Training R2: 0.431075
Validation Loss: 0.81077200, Validation R2: 0.315355

Epoch 69/1000
Training Loss: 0.77462397, Training R2: 0.436023
Validation Loss: 0.79196316, Validation R2: 0.369251

Epoch 70/1000
Training Loss: 0.80175754, Training R2: 0.417530
Validation Loss: 0.79234236, Validation R2: 0.374742

Epoch 71/1000
Training Loss: 0.76326186, Training R2: 0.436746
Validation Loss: 0.89089799, Validation R2: 0.255171

Epoch 72/1000
Training Loss: 0.82875319, Training R2: 0.361789
Validation Loss: 0.79820043, Validation R2: 0.362325

Epoch 73/1000
Training Loss: 0.76455074, Training R2: 0.449444
Validation Loss: 0.77977186, Validation R2: 0.395861

Epoch 74/1000
Training Loss: 0.76736092, Training R2: 0.426343
Validation Loss: 0.79875845, Validation R2: 0.376205

Epoch 75/1000
Training Loss: 0.74578395, Training R2: 0.448750
Validation Loss: 0.82191890, Validation R2: 0.367428

Epoch 76/1000
Training Loss: 0.78949240, Training R2: 0.404102
Validation Loss: 0.76724821, Validation R2: 0.433458
Saved best model with validation R2 0.433458 to best_finetuned_model.pth

Epoch 77/1000
Training Loss: 0.75039027, Training R2: 0.456638
Validation Loss: 0.78492898, Validation R2: 0.421171

Epoch 78/1000
Training Loss: 0.74617990, Training R2: 0.440862
Validation Loss: 0.81551170, Validation R2: 0.349973

Epoch 79/1000
Training Loss: 0.73615170, Training R2: 0.475637
Validation Loss: 0.78043514, Validation R2: 0.420957

Epoch 80/1000
Training Loss: 0.71879929, Training R2: 0.481909
Validation Loss: 0.76771432, Validation R2: 0.370067

Epoch 81/1000
Training Loss: 0.70095049, Training R2: 0.496181
Validation Loss: 0.78354675, Validation R2: 0.384685

Epoch 82/1000
Training Loss: 0.72570731, Training R2: 0.440007
Validation Loss: 0.79458469, Validation R2: 0.376714

Epoch 83/1000
Training Loss: 0.74678993, Training R2: 0.424983
Validation Loss: 0.76120842, Validation R2: 0.417445

Epoch 84/1000
Training Loss: 0.71063913, Training R2: 0.479634
Validation Loss: 0.75947243, Validation R2: 0.432907

Epoch 85/1000
Training Loss: 0.71416622, Training R2: 0.496084
Validation Loss: 0.80136627, Validation R2: 0.373423

Epoch 86/1000
Training Loss: 0.73002770, Training R2: 0.443484
Validation Loss: 0.75657666, Validation R2: 0.391384

Epoch 87/1000
Training Loss: 0.68186155, Training R2: 0.502313
Validation Loss: 0.87977040, Validation R2: 0.291883

Epoch 88/1000
Training Loss: 0.81827757, Training R2: 0.404856
Validation Loss: 0.93703359, Validation R2: 0.197882

Epoch 89/1000
Training Loss: 0.84036743, Training R2: 0.327471
Validation Loss: 0.79795271, Validation R2: 0.373532

Epoch 90/1000
Training Loss: 0.76139791, Training R2: 0.462842
Validation Loss: 0.75208938, Validation R2: 0.424067

Epoch 91/1000
Training Loss: 0.67860970, Training R2: 0.526233
Validation Loss: 0.76644951, Validation R2: 0.376845

Epoch 92/1000
Training Loss: 0.66525294, Training R2: 0.536908
Validation Loss: 0.74096978, Validation R2: 0.372230

Epoch 93/1000
Training Loss: 0.65536584, Training R2: 0.542753
Validation Loss: 0.76567215, Validation R2: 0.386150

Epoch 94/1000
Training Loss: 0.67708052, Training R2: 0.515451
Validation Loss: 0.75187546, Validation R2: 0.408340

Epoch 95/1000
Training Loss: 0.66127520, Training R2: 0.528758
Validation Loss: 0.73268676, Validation R2: 0.412139

Epoch 96/1000
Training Loss: 0.63347471, Training R2: 0.553127
Validation Loss: 0.74869794, Validation R2: 0.387996

Epoch 97/1000
Epoch 00097: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.63230246, Training R2: 0.547891
Validation Loss: 0.79162675, Validation R2: 0.354463

Epoch 98/1000
学习率已减少 1 次
Training Loss: 0.65380491, Training R2: 0.548291
Validation Loss: 0.78510708, Validation R2: 0.356032

Epoch 99/1000
Training Loss: 0.66145215, Training R2: 0.515227
Validation Loss: 0.74868727, Validation R2: 0.391457

Epoch 100/1000
Training Loss: 0.63102790, Training R2: 0.561892
Validation Loss: 0.74429792, Validation R2: 0.386429

Epoch 101/1000
Training Loss: 0.60587144, Training R2: 0.578703
Validation Loss: 0.75304794, Validation R2: 0.378128

Epoch 102/1000
Training Loss: 0.64176961, Training R2: 0.560933
Validation Loss: 0.75112516, Validation R2: 0.376620

Epoch 103/1000
Training Loss: 0.65433443, Training R2: 0.529749
Validation Loss: 0.71947670, Validation R2: 0.411951

Epoch 104/1000
Training Loss: 0.64074229, Training R2: 0.557018
Validation Loss: 0.71261847, Validation R2: 0.439109
Saved best model with validation R2 0.439109 to best_finetuned_model.pth

Epoch 105/1000
Training Loss: 0.63101151, Training R2: 0.548409
Validation Loss: 0.70685685, Validation R2: 0.434581

Epoch 106/1000
Training Loss: 0.61538486, Training R2: 0.581737
Validation Loss: 0.74292076, Validation R2: 0.392162

Epoch 107/1000
Training Loss: 0.60933818, Training R2: 0.586680
Validation Loss: 0.74348283, Validation R2: 0.386395

Epoch 108/1000
Training Loss: 0.61186026, Training R2: 0.577744
Validation Loss: 0.72587371, Validation R2: 0.397554

Epoch 109/1000
Training Loss: 0.61222264, Training R2: 0.583359
Validation Loss: 0.72655404, Validation R2: 0.402130

Epoch 110/1000
Training Loss: 0.59819066, Training R2: 0.583982
Validation Loss: 0.74678814, Validation R2: 0.380091

Epoch 111/1000
Training Loss: 0.62426926, Training R2: 0.582901
Validation Loss: 0.76539910, Validation R2: 0.362921

Epoch 112/1000
Training Loss: 0.65069486, Training R2: 0.537916
Validation Loss: 0.72272426, Validation R2: 0.396007

Epoch 113/1000
Training Loss: 0.62629508, Training R2: 0.585179
Validation Loss: 0.71885419, Validation R2: 0.406438

Epoch 114/1000
Training Loss: 0.59622102, Training R2: 0.590313
Validation Loss: 0.72849941, Validation R2: 0.406098

Epoch 115/1000
Training Loss: 0.58442003, Training R2: 0.599173
Validation Loss: 0.72637343, Validation R2: 0.390952

Epoch 116/1000
Training Loss: 0.57142118, Training R2: 0.612836
Validation Loss: 0.73164451, Validation R2: 0.408658

Epoch 117/1000
Training Loss: 0.60486301, Training R2: 0.577807
Validation Loss: 0.70449609, Validation R2: 0.429924

Epoch 118/1000
Training Loss: 0.56508289, Training R2: 0.616701
Validation Loss: 0.72232765, Validation R2: 0.400750

Epoch 119/1000
Training Loss: 0.57040357, Training R2: 0.612057
Validation Loss: 0.72923595, Validation R2: 0.383469

Epoch 120/1000
Training Loss: 0.57073319, Training R2: 0.606659
Validation Loss: 0.71126759, Validation R2: 0.412172

Epoch 121/1000
Training Loss: 0.58094776, Training R2: 0.612180
Validation Loss: 0.71784317, Validation R2: 0.417253

Epoch 122/1000
Training Loss: 0.56816463, Training R2: 0.616152
Validation Loss: 0.72715336, Validation R2: 0.415709

Epoch 123/1000
Training Loss: 0.56984415, Training R2: 0.616749
Validation Loss: 0.72540790, Validation R2: 0.402468

Epoch 124/1000
Training Loss: 0.55634236, Training R2: 0.623068
Validation Loss: 0.75098288, Validation R2: 0.373410

Epoch 125/1000
Epoch 00125: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.55959595, Training R2: 0.615607
Validation Loss: 0.74362433, Validation R2: 0.366939

Epoch 126/1000
学习率已减少 2 次
Training Loss: 0.55685317, Training R2: 0.621087
Validation Loss: 0.74460125, Validation R2: 0.371087

Epoch 127/1000
Training Loss: 0.54532626, Training R2: 0.628428
Validation Loss: 0.74274868, Validation R2: 0.360787

Epoch 128/1000
Training Loss: 0.53746961, Training R2: 0.635693
Validation Loss: 0.73551786, Validation R2: 0.380864

Epoch 129/1000
Training Loss: 0.53343676, Training R2: 0.635026
Validation Loss: 0.73568523, Validation R2: 0.392474

Epoch 130/1000
Training Loss: 0.53459973, Training R2: 0.632715
Validation Loss: 0.72844630, Validation R2: 0.402739

Epoch 131/1000
Training Loss: 0.53274894, Training R2: 0.636927
Validation Loss: 0.72684538, Validation R2: 0.395138

Epoch 132/1000
Training Loss: 0.52628682, Training R2: 0.638887
Validation Loss: 0.73838735, Validation R2: 0.379355

Epoch 133/1000
Training Loss: 0.52946927, Training R2: 0.636831
Validation Loss: 0.73712891, Validation R2: 0.377738

Epoch 134/1000
Training Loss: 0.52457261, Training R2: 0.638709
Validation Loss: 0.74045563, Validation R2: 0.383594

Epoch 135/1000
Training Loss: 0.52930258, Training R2: 0.634804
Validation Loss: 0.72937989, Validation R2: 0.393738

Epoch 136/1000
Training Loss: 0.52215483, Training R2: 0.641294
Validation Loss: 0.72917843, Validation R2: 0.392364

Epoch 137/1000
Training Loss: 0.52359260, Training R2: 0.645725
Validation Loss: 0.74098575, Validation R2: 0.376520

Epoch 138/1000
Training Loss: 0.52080672, Training R2: 0.643257
Validation Loss: 0.74569184, Validation R2: 0.376176

Epoch 139/1000
Training Loss: 0.52131963, Training R2: 0.641106
Validation Loss: 0.73664171, Validation R2: 0.371955

Epoch 140/1000
Training Loss: 0.51690029, Training R2: 0.651442
Validation Loss: 0.73808277, Validation R2: 0.373692

Epoch 141/1000
Training Loss: 0.52226353, Training R2: 0.640716
Validation Loss: 0.74431914, Validation R2: 0.372480

Epoch 142/1000
Training Loss: 0.52105286, Training R2: 0.647884
Validation Loss: 0.73300445, Validation R2: 0.380974

Epoch 143/1000
Training Loss: 0.50969091, Training R2: 0.649520
Validation Loss: 0.73539084, Validation R2: 0.372510

Epoch 144/1000
Training Loss: 0.51080264, Training R2: 0.646268
Validation Loss: 0.74622053, Validation R2: 0.368465

Epoch 145/1000
Training Loss: 0.51284359, Training R2: 0.646064
Validation Loss: 0.75685102, Validation R2: 0.354081

Epoch 146/1000
Epoch 00146: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.51489898, Training R2: 0.644273
Validation Loss: 0.76063031, Validation R2: 0.347331

Epoch 147/1000
学习率已减少 3 次
Training Loss: 0.51144904, Training R2: 0.651345
Validation Loss: 0.75340068, Validation R2: 0.362388

Epoch 148/1000
Training Loss: 0.49919488, Training R2: 0.655420
Validation Loss: 0.74538571, Validation R2: 0.370745

Epoch 149/1000
Training Loss: 0.49904664, Training R2: 0.656263
Validation Loss: 0.74152654, Validation R2: 0.368675

Epoch 150/1000
Training Loss: 0.49565902, Training R2: 0.658694
Validation Loss: 0.74475247, Validation R2: 0.361399

Epoch 151/1000
Training Loss: 0.49777910, Training R2: 0.655564
Validation Loss: 0.74307281, Validation R2: 0.360842

Epoch 152/1000
Training Loss: 0.49887048, Training R2: 0.655170
Validation Loss: 0.74561936, Validation R2: 0.362646

Epoch 153/1000
Training Loss: 0.49474855, Training R2: 0.658135
Validation Loss: 0.74036771, Validation R2: 0.369588

Epoch 154/1000
Training Loss: 0.49704742, Training R2: 0.660298
Validation Loss: 0.74532408, Validation R2: 0.363275

Epoch 155/1000
Training Loss: 0.49309158, Training R2: 0.662057
Validation Loss: 0.74317801, Validation R2: 0.362730

Epoch 156/1000
Training Loss: 0.49391419, Training R2: 0.660337
Validation Loss: 0.74355072, Validation R2: 0.361803

Epoch 157/1000
Training Loss: 0.48984669, Training R2: 0.662971
Validation Loss: 0.74132216, Validation R2: 0.363084

Epoch 158/1000
Training Loss: 0.48759716, Training R2: 0.663318
Validation Loss: 0.74131131, Validation R2: 0.368846

Epoch 159/1000
Training Loss: 0.49027112, Training R2: 0.663055
Validation Loss: 0.74501371, Validation R2: 0.369362

Epoch 160/1000
Training Loss: 0.48963381, Training R2: 0.663993
Validation Loss: 0.73837018, Validation R2: 0.380475

Epoch 161/1000
Training Loss: 0.48769010, Training R2: 0.664954
Validation Loss: 0.73460644, Validation R2: 0.381850

Epoch 162/1000
Training Loss: 0.48659674, Training R2: 0.663705
Validation Loss: 0.74143553, Validation R2: 0.371976

Epoch 163/1000
Training Loss: 0.48449408, Training R2: 0.665175
Validation Loss: 0.74449754, Validation R2: 0.362454

Epoch 164/1000
Training Loss: 0.49073738, Training R2: 0.661038
Validation Loss: 0.73996395, Validation R2: 0.370258

Epoch 165/1000
Training Loss: 0.49240708, Training R2: 0.659218
Validation Loss: 0.73243630, Validation R2: 0.376537

Epoch 166/1000
Training Loss: 0.48060823, Training R2: 0.668033
Validation Loss: 0.74055099, Validation R2: 0.369370

Epoch 167/1000
Epoch 00167: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.48229245, Training R2: 0.669303
Validation Loss: 0.73974240, Validation R2: 0.363024

Epoch 168/1000
学习率已减少 4 次
Training Loss: 0.48228708, Training R2: 0.668672
Validation Loss: 0.74672478, Validation R2: 0.356710

Epoch 169/1000
Training Loss: 0.48078941, Training R2: 0.668504
Validation Loss: 0.74021119, Validation R2: 0.362061

Epoch 170/1000
Training Loss: 0.47722448, Training R2: 0.669734
Validation Loss: 0.73857582, Validation R2: 0.368071

Epoch 171/1000
Training Loss: 0.47961534, Training R2: 0.668570
Validation Loss: 0.74021608, Validation R2: 0.370498

Epoch 172/1000
Training Loss: 0.47875954, Training R2: 0.668534
Validation Loss: 0.74181747, Validation R2: 0.367058

Epoch 173/1000
Training Loss: 0.47535956, Training R2: 0.671591
Validation Loss: 0.74025238, Validation R2: 0.363208

Epoch 174/1000
Training Loss: 0.47754010, Training R2: 0.668081
Validation Loss: 0.75392419, Validation R2: 0.353602

Epoch 175/1000
Training Loss: 0.47761133, Training R2: 0.668751
Validation Loss: 0.74444640, Validation R2: 0.358796

Epoch 176/1000
Training Loss: 0.47524985, Training R2: 0.671285
Validation Loss: 0.74632734, Validation R2: 0.360796

Epoch 177/1000
Training Loss: 0.47539771, Training R2: 0.670898
Validation Loss: 0.74415946, Validation R2: 0.365202

Epoch 178/1000
Training Loss: 0.47439591, Training R2: 0.671459
Validation Loss: 0.74383825, Validation R2: 0.359630

Epoch 179/1000
Training Loss: 0.47608438, Training R2: 0.671533
Validation Loss: 0.75188816, Validation R2: 0.351587

Epoch 180/1000
Training Loss: 0.47366949, Training R2: 0.671103
Validation Loss: 0.74935383, Validation R2: 0.353578

Epoch 181/1000
Training Loss: 0.47420377, Training R2: 0.670573
Validation Loss: 0.74620306, Validation R2: 0.353573

Epoch 182/1000
Training Loss: 0.47271439, Training R2: 0.672440
Validation Loss: 0.74808937, Validation R2: 0.353328

Epoch 183/1000
Training Loss: 0.47159037, Training R2: 0.672372
Validation Loss: 0.74179298, Validation R2: 0.362551

Epoch 184/1000
Training Loss: 0.47136619, Training R2: 0.672606
Validation Loss: 0.74244779, Validation R2: 0.363382

Epoch 185/1000
Training Loss: 0.47132563, Training R2: 0.672834
Validation Loss: 0.75156224, Validation R2: 0.355563

Epoch 186/1000
Training Loss: 0.46928139, Training R2: 0.673442
Validation Loss: 0.74798071, Validation R2: 0.355324

Epoch 187/1000
Training Loss: 0.46950863, Training R2: 0.673120
Validation Loss: 0.75333619, Validation R2: 0.350956

Epoch 188/1000
Epoch 00188: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.47150092, Training R2: 0.672385
Validation Loss: 0.74748093, Validation R2: 0.355081

Epoch 189/1000
学习率已减少 5 次
Training Loss: 0.46845563, Training R2: 0.674376
Validation Loss: 0.74584442, Validation R2: 0.355552

Epoch 190/1000
Training Loss: 0.46915750, Training R2: 0.674006
Validation Loss: 0.74574035, Validation R2: 0.355357

Epoch 191/1000
Training Loss: 0.46829468, Training R2: 0.674742
Validation Loss: 0.74982375, Validation R2: 0.353171

Epoch 192/1000
Training Loss: 0.46793760, Training R2: 0.674358
Validation Loss: 0.74449253, Validation R2: 0.357149

Epoch 193/1000
Training Loss: 0.46755557, Training R2: 0.675397
Validation Loss: 0.74559784, Validation R2: 0.356187

Epoch 194/1000
Training Loss: 0.46811141, Training R2: 0.675266
Validation Loss: 0.75038552, Validation R2: 0.353509

Epoch 195/1000
Training Loss: 0.46794214, Training R2: 0.674449
Validation Loss: 0.74448097, Validation R2: 0.357308

Epoch 196/1000
Training Loss: 0.46588205, Training R2: 0.675071
Validation Loss: 0.74316305, Validation R2: 0.357249

Epoch 197/1000
Training Loss: 0.46655452, Training R2: 0.674827
Validation Loss: 0.74427003, Validation R2: 0.358180

Epoch 198/1000
Training Loss: 0.46422965, Training R2: 0.675523
Validation Loss: 0.74411446, Validation R2: 0.360895

Epoch 199/1000
Training Loss: 0.46468519, Training R2: 0.674785
Validation Loss: 0.74423081, Validation R2: 0.359610

Epoch 200/1000
Training Loss: 0.46436691, Training R2: 0.675707
Validation Loss: 0.74935514, Validation R2: 0.354193

Epoch 201/1000
Training Loss: 0.46482679, Training R2: 0.675919
Validation Loss: 0.74734855, Validation R2: 0.354789

Epoch 202/1000
Training Loss: 0.46422665, Training R2: 0.675828
Validation Loss: 0.74814969, Validation R2: 0.354473

Epoch 203/1000
Training Loss: 0.46418881, Training R2: 0.675212
Validation Loss: 0.74266952, Validation R2: 0.358124

Epoch 204/1000
Training Loss: 0.46156937, Training R2: 0.677748
Validation Loss: 0.74474102, Validation R2: 0.358789

Epoch 205/1000
Training Loss: 0.46503480, Training R2: 0.676147
Validation Loss: 0.74322128, Validation R2: 0.362145

Epoch 206/1000
Training Loss: 0.46673836, Training R2: 0.674883
Validation Loss: 0.74298650, Validation R2: 0.361201

Epoch 207/1000
Training Loss: 0.46478011, Training R2: 0.674811
Validation Loss: 0.74438351, Validation R2: 0.357820

Epoch 208/1000
Training Loss: 0.46301586, Training R2: 0.676286
Validation Loss: 0.74961805, Validation R2: 0.354047

Epoch 209/1000
Epoch 00209: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.46143737, Training R2: 0.677011
Validation Loss: 0.74933612, Validation R2: 0.355924

Epoch 210/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
