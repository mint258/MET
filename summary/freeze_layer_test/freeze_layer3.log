Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Trainable
interaction_blocks.1.conv1.lin_rel.bias: Trainable
interaction_blocks.1.conv1.lin_root.weight: Trainable
interaction_blocks.1.conv2.lin_rel.weight: Trainable
interaction_blocks.1.conv2.lin_rel.bias: Trainable
interaction_blocks.1.conv2.lin_root.weight: Trainable
interaction_blocks.1.lin1.weight: Trainable
interaction_blocks.1.lin1.bias: Trainable
interaction_blocks.1.lin2.weight: Trainable
interaction_blocks.1.lin2.bias: Trainable
interaction_blocks.1.lin_cat.weight: Trainable
interaction_blocks.1.lin_cat.bias: Trainable
interaction_blocks.1.norm.weight: Trainable
interaction_blocks.1.norm.bias: Trainable
interaction_blocks.1.norm.mean_scale: Trainable
interaction_blocks.1.lin_feature1.lin1.weight: Trainable
interaction_blocks.1.lin_feature1.lin2.weight: Trainable
interaction_blocks.1.lin_feature2.lin1.weight: Trainable
interaction_blocks.1.lin_feature2.lin2.weight: Trainable
interaction_blocks.1.lin.weight: Trainable
interaction_blocks.1.lin.bias: Trainable
interaction_blocks.1.lins.0.weight: Trainable
interaction_blocks.1.lins.0.bias: Trainable
interaction_blocks.1.lins.1.weight: Trainable
interaction_blocks.1.lins.1.bias: Trainable
interaction_blocks.1.lins.2.weight: Trainable
interaction_blocks.1.lins.2.bias: Trainable
interaction_blocks.1.lins.3.weight: Trainable
interaction_blocks.1.lins.3.bias: Trainable
interaction_blocks.1.final.weight: Trainable
interaction_blocks.1.final.bias: Trainable
interaction_blocks.2.conv1.lin_rel.weight: Trainable
interaction_blocks.2.conv1.lin_rel.bias: Trainable
interaction_blocks.2.conv1.lin_root.weight: Trainable
interaction_blocks.2.conv2.lin_rel.weight: Trainable
interaction_blocks.2.conv2.lin_rel.bias: Trainable
interaction_blocks.2.conv2.lin_root.weight: Trainable
interaction_blocks.2.lin1.weight: Trainable
interaction_blocks.2.lin1.bias: Trainable
interaction_blocks.2.lin2.weight: Trainable
interaction_blocks.2.lin2.bias: Trainable
interaction_blocks.2.lin_cat.weight: Trainable
interaction_blocks.2.lin_cat.bias: Trainable
interaction_blocks.2.norm.weight: Trainable
interaction_blocks.2.norm.bias: Trainable
interaction_blocks.2.norm.mean_scale: Trainable
interaction_blocks.2.lin_feature1.lin1.weight: Trainable
interaction_blocks.2.lin_feature1.lin2.weight: Trainable
interaction_blocks.2.lin_feature2.lin1.weight: Trainable
interaction_blocks.2.lin_feature2.lin2.weight: Trainable
interaction_blocks.2.lin.weight: Trainable
interaction_blocks.2.lin.bias: Trainable
interaction_blocks.2.lins.0.weight: Trainable
interaction_blocks.2.lins.0.bias: Trainable
interaction_blocks.2.lins.1.weight: Trainable
interaction_blocks.2.lins.1.bias: Trainable
interaction_blocks.2.lins.2.weight: Trainable
interaction_blocks.2.lins.2.bias: Trainable
interaction_blocks.2.lins.3.weight: Trainable
interaction_blocks.2.lins.3.bias: Trainable
interaction_blocks.2.final.weight: Trainable
interaction_blocks.2.final.bias: Trainable
interaction_blocks.3.conv1.lin_rel.weight: Trainable
interaction_blocks.3.conv1.lin_rel.bias: Trainable
interaction_blocks.3.conv1.lin_root.weight: Trainable
interaction_blocks.3.conv2.lin_rel.weight: Trainable
interaction_blocks.3.conv2.lin_rel.bias: Trainable
interaction_blocks.3.conv2.lin_root.weight: Trainable
interaction_blocks.3.lin1.weight: Trainable
interaction_blocks.3.lin1.bias: Trainable
interaction_blocks.3.lin2.weight: Trainable
interaction_blocks.3.lin2.bias: Trainable
interaction_blocks.3.lin_cat.weight: Trainable
interaction_blocks.3.lin_cat.bias: Trainable
interaction_blocks.3.norm.weight: Trainable
interaction_blocks.3.norm.bias: Trainable
interaction_blocks.3.norm.mean_scale: Trainable
interaction_blocks.3.lin_feature1.lin1.weight: Trainable
interaction_blocks.3.lin_feature1.lin2.weight: Trainable
interaction_blocks.3.lin_feature2.lin1.weight: Trainable
interaction_blocks.3.lin_feature2.lin2.weight: Trainable
interaction_blocks.3.lin.weight: Trainable
interaction_blocks.3.lin.bias: Trainable
interaction_blocks.3.lins.0.weight: Trainable
interaction_blocks.3.lins.0.bias: Trainable
interaction_blocks.3.lins.1.weight: Trainable
interaction_blocks.3.lins.1.bias: Trainable
interaction_blocks.3.lins.2.weight: Trainable
interaction_blocks.3.lins.2.bias: Trainable
interaction_blocks.3.lins.3.weight: Trainable
interaction_blocks.3.lins.3.bias: Trainable
interaction_blocks.3.final.weight: Trainable
interaction_blocks.3.final.bias: Trainable
lins.0.weight: Trainable
lins.0.bias: Trainable
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 4143363

Epoch 1/1000
Training Loss: 2.44944287, Training R2: -3.353895
Validation Loss: 1.24293721, Validation R2: -0.084461
Saved best model with validation R2 -0.084461 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.19500547, Training R2: -0.131710
Validation Loss: 1.25023460, Validation R2: -0.095144

Epoch 3/1000
Training Loss: 1.20199765, Training R2: -0.294339
Validation Loss: 1.23298693, Validation R2: -0.014076
Saved best model with validation R2 -0.014076 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.18346488, Training R2: -0.073114
Validation Loss: 1.28109002, Validation R2: -0.010168
Saved best model with validation R2 -0.010168 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.12825887, Training R2: -0.017920
Validation Loss: 1.27286196, Validation R2: -0.141658

Epoch 6/1000
Training Loss: 1.14008091, Training R2: -0.111575
Validation Loss: 1.23363090, Validation R2: -0.013769

Epoch 7/1000
Training Loss: 1.11905833, Training R2: -0.034135
Validation Loss: 1.23324025, Validation R2: -0.046804

Epoch 8/1000
Training Loss: 1.11679671, Training R2: -0.031820
Validation Loss: 1.23157167, Validation R2: -0.025797

Epoch 9/1000
Training Loss: 1.11802451, Training R2: -0.055633
Validation Loss: 1.24307990, Validation R2: -0.077805

Epoch 10/1000
Training Loss: 1.11877941, Training R2: -0.070034
Validation Loss: 1.23542488, Validation R2: -0.008141
Saved best model with validation R2 -0.008141 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 1.13649368, Training R2: -0.012061
Validation Loss: 1.25196290, Validation R2: 0.000678
Saved best model with validation R2 0.000678 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.12691649, Training R2: -0.007657
Validation Loss: 1.23376977, Validation R2: -0.050931

Epoch 13/1000
Training Loss: 1.11782648, Training R2: -0.071262
Validation Loss: 1.23054183, Validation R2: -0.030998

Epoch 14/1000
Training Loss: 1.11701288, Training R2: -0.011271
Validation Loss: 1.23680913, Validation R2: -0.003128

Epoch 15/1000
Training Loss: 1.11985981, Training R2: -0.025589
Validation Loss: 1.23107994, Validation R2: -0.044533

Epoch 16/1000
Training Loss: 1.11039231, Training R2: -0.023211
Validation Loss: 1.23477614, Validation R2: 0.000626

Epoch 17/1000
Training Loss: 1.11794854, Training R2: 0.006868
Validation Loss: 1.22561240, Validation R2: -0.022221

Epoch 18/1000
Training Loss: 1.10352700, Training R2: -0.030188
Validation Loss: 1.23903418, Validation R2: -0.079508

Epoch 19/1000
Training Loss: 1.11094692, Training R2: -0.084028
Validation Loss: 1.23363519, Validation R2: 0.001307
Saved best model with validation R2 0.001307 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 1.13297342, Training R2: 0.006589
Validation Loss: 1.23333049, Validation R2: -0.066184

Epoch 21/1000
Training Loss: 1.11847206, Training R2: -0.098468
Validation Loss: 1.25304508, Validation R2: 0.010761
Saved best model with validation R2 0.010761 to best_finetuned_model.pth

Epoch 22/1000
Training Loss: 1.14621551, Training R2: -0.007497
Validation Loss: 1.22801447, Validation R2: -0.014997

Epoch 23/1000
Training Loss: 1.11871067, Training R2: -0.045376
Validation Loss: 1.24626267, Validation R2: -0.084475

Epoch 24/1000
Training Loss: 1.12273677, Training R2: -0.076199
Validation Loss: 1.23238266, Validation R2: -0.026824

Epoch 25/1000
Training Loss: 1.11605528, Training R2: -0.039708
Validation Loss: 1.23095977, Validation R2: -0.009640

Epoch 26/1000
Training Loss: 1.13058755, Training R2: -0.009844
Validation Loss: 1.23476696, Validation R2: 0.001023

Epoch 27/1000
Training Loss: 1.11800144, Training R2: -0.019176
Validation Loss: 1.24224091, Validation R2: -0.079026

Epoch 28/1000
Training Loss: 1.11892159, Training R2: -0.099347
Validation Loss: 1.22541308, Validation R2: -0.001395

Epoch 29/1000
Training Loss: 1.11856985, Training R2: 0.007828
Validation Loss: 1.22232604, Validation R2: -0.014093

Epoch 30/1000
Training Loss: 1.13090658, Training R2: -0.113261
Validation Loss: 1.23383212, Validation R2: -0.035832

Epoch 31/1000
Training Loss: 1.11932930, Training R2: 0.000356
Validation Loss: 1.23449624, Validation R2: 0.002790

Epoch 32/1000
Training Loss: 1.10908527, Training R2: -0.016460
Validation Loss: 1.23897409, Validation R2: -0.078162

Epoch 33/1000
Training Loss: 1.10695954, Training R2: -0.053397
Validation Loss: 1.23068237, Validation R2: -0.002190

Epoch 34/1000
Training Loss: 1.10338775, Training R2: 0.015572
Validation Loss: 1.22208476, Validation R2: -0.023151

Epoch 35/1000
Training Loss: 1.09048600, Training R2: -0.008308
Validation Loss: 1.21044767, Validation R2: -0.024184

Epoch 36/1000
Training Loss: 1.08093715, Training R2: -0.007495
Validation Loss: 1.18684089, Validation R2: 0.045321
Saved best model with validation R2 0.045321 to best_finetuned_model.pth

Epoch 37/1000
Training Loss: 1.04741379, Training R2: 0.068391
Validation Loss: 1.33425295, Validation R2: -0.254546

Epoch 38/1000
Training Loss: 1.14437897, Training R2: -0.149255
Validation Loss: 1.40884578, Validation R2: -0.197106

Epoch 39/1000
Training Loss: 1.21073698, Training R2: -0.155207
Validation Loss: 1.25729394, Validation R2: -0.110158

Epoch 40/1000
Training Loss: 1.12194531, Training R2: -0.078769
Validation Loss: 1.24302185, Validation R2: -0.001958

Epoch 41/1000
Training Loss: 1.12645551, Training R2: -0.001294
Validation Loss: 1.23196340, Validation R2: -0.024616

Epoch 42/1000
Training Loss: 1.11783076, Training R2: -0.049361
Validation Loss: 1.24656069, Validation R2: -0.086145

Epoch 43/1000
Training Loss: 1.12410165, Training R2: -0.096522
Validation Loss: 1.23221171, Validation R2: -0.020216

Epoch 44/1000
Training Loss: 1.11836499, Training R2: -0.011674
Validation Loss: 1.23437440, Validation R2: -0.012363

Epoch 45/1000
Training Loss: 1.11840110, Training R2: -0.014102
Validation Loss: 1.23255396, Validation R2: -0.017948

Epoch 46/1000
Training Loss: 1.11844892, Training R2: -0.010065
Validation Loss: 1.23313797, Validation R2: -0.015821

Epoch 47/1000
Training Loss: 1.11875307, Training R2: -0.039068
Validation Loss: 1.24336243, Validation R2: -0.077956

Epoch 48/1000
Training Loss: 1.12043652, Training R2: -0.073594
Validation Loss: 1.23223579, Validation R2: -0.019769

Epoch 49/1000
Training Loss: 1.11982810, Training R2: -0.010524
Validation Loss: 1.23182654, Validation R2: -0.029581

Epoch 50/1000
Training Loss: 1.11793408, Training R2: -0.064886
Validation Loss: 1.24386704, Validation R2: -0.079232

Epoch 51/1000
Training Loss: 1.11689207, Training R2: -0.061873
Validation Loss: 1.24030626, Validation R2: -0.003481

Epoch 52/1000
Training Loss: 1.13016227, Training R2: 0.000649
Validation Loss: 1.23432076, Validation R2: -0.012414

Epoch 53/1000
Training Loss: 1.13590378, Training R2: -0.085810
Validation Loss: 1.23432589, Validation R2: -0.050792

Epoch 54/1000
Training Loss: 1.12344613, Training R2: -0.028805
Validation Loss: 1.25668228, Validation R2: -0.000294

Epoch 55/1000
Training Loss: 1.13250995, Training R2: -0.000811
Validation Loss: 1.23179746, Validation R2: -0.028083

Epoch 56/1000
Training Loss: 1.11765117, Training R2: -0.055231
Validation Loss: 1.24310839, Validation R2: -0.077325

Epoch 57/1000
Epoch 00057: reducing learning rate of group 0 to 5.0000e-04.
Training Loss: 1.12003589, Training R2: -0.082105
Validation Loss: 1.23208690, Validation R2: -0.021717

Epoch 58/1000
学习率已减少 1 次
Training Loss: 1.12156200, Training R2: -0.015372
Validation Loss: 1.24012315, Validation R2: -0.003524

Epoch 59/1000
Training Loss: 1.12597235, Training R2: -0.001632
Validation Loss: 1.23370707, Validation R2: -0.014030

Epoch 60/1000
Training Loss: 1.12150185, Training R2: -0.051924
Validation Loss: 1.24832225, Validation R2: -0.090106

Epoch 61/1000
Training Loss: 1.12400235, Training R2: -0.098579
Validation Loss: 1.23189127, Validation R2: -0.035694

Epoch 62/1000
Training Loss: 1.11763790, Training R2: -0.021674
Validation Loss: 1.23622525, Validation R2: -0.007843

Epoch 63/1000
Training Loss: 1.12020377, Training R2: -0.007260
Validation Loss: 1.23187292, Validation R2: -0.025682

Epoch 64/1000
Training Loss: 1.11591564, Training R2: -0.037309
Validation Loss: 1.23701012, Validation R2: -0.059470

Epoch 65/1000
Training Loss: 1.12103216, Training R2: -0.082425
Validation Loss: 1.23488295, Validation R2: -0.052800

Epoch 66/1000
Training Loss: 1.11721354, Training R2: -0.044546
Validation Loss: 1.23351789, Validation R2: -0.014435

Epoch 67/1000
Training Loss: 1.11855822, Training R2: -0.016068
Validation Loss: 1.23530650, Validation R2: -0.009770

Epoch 68/1000
Training Loss: 1.12359865, Training R2: -0.002164
Validation Loss: 1.24707198, Validation R2: -0.000224

Epoch 69/1000
Training Loss: 1.12910038, Training R2: -0.001663
Validation Loss: 1.23535609, Validation R2: -0.009778

Epoch 70/1000
Training Loss: 1.11865317, Training R2: -0.009702
Validation Loss: 1.23304284, Validation R2: -0.016749

Epoch 71/1000
Training Loss: 1.11813489, Training R2: -0.011801
Validation Loss: 1.23461664, Validation R2: -0.011786

Epoch 72/1000
Training Loss: 1.11778338, Training R2: -0.012365
Validation Loss: 1.23252177, Validation R2: -0.022268

Epoch 73/1000
Training Loss: 1.11572580, Training R2: -0.024446
Validation Loss: 1.23118663, Validation R2: -0.026593

Epoch 74/1000
Training Loss: 1.11538887, Training R2: -0.027984
Validation Loss: 1.23115671, Validation R2: -0.023403

Epoch 75/1000
Training Loss: 1.11573040, Training R2: -0.021058
Validation Loss: 1.23193192, Validation R2: -0.021927

Epoch 76/1000
Training Loss: 1.11463950, Training R2: -0.021888
Validation Loss: 1.23165631, Validation R2: -0.040780

Epoch 77/1000
Training Loss: 1.11700782, Training R2: -0.063803
Validation Loss: 1.23530114, Validation R2: -0.057640

Epoch 78/1000
Epoch 00078: reducing learning rate of group 0 to 2.5000e-04.
Training Loss: 1.11692915, Training R2: -0.047720
Validation Loss: 1.23251581, Validation R2: -0.012279

Epoch 79/1000
学习率已减少 2 次
Training Loss: 1.11670252, Training R2: -0.007931
Validation Loss: 1.23193228, Validation R2: -0.011812

Epoch 80/1000
Training Loss: 1.11513993, Training R2: -0.011490
Validation Loss: 1.23013806, Validation R2: -0.028281

Epoch 81/1000
Training Loss: 1.11329328, Training R2: -0.035830
Validation Loss: 1.23134422, Validation R2: -0.045506

Epoch 82/1000
Training Loss: 1.11382608, Training R2: -0.048688
Validation Loss: 1.22938263, Validation R2: -0.040024

Epoch 83/1000
Training Loss: 1.11162082, Training R2: -0.037712
Validation Loss: 1.22979784, Validation R2: -0.032951

Epoch 84/1000
Training Loss: 1.11168940, Training R2: -0.034167
Validation Loss: 1.22831500, Validation R2: -0.028737

Epoch 85/1000
Training Loss: 1.11153823, Training R2: -0.021947
Validation Loss: 1.22750294, Validation R2: -0.018550

Epoch 86/1000
Training Loss: 1.10927719, Training R2: -0.018491
Validation Loss: 1.22558892, Validation R2: -0.026188

Epoch 87/1000
Training Loss: 1.10260582, Training R2: -0.014659
Validation Loss: 1.22843516, Validation R2: -0.015659

Epoch 88/1000
Training Loss: 1.09316510, Training R2: 0.014917
Validation Loss: 1.24382269, Validation R2: -0.047849

Epoch 89/1000
Training Loss: 1.11090502, Training R2: -0.012765
Validation Loss: 1.24513531, Validation R2: -0.096534

Epoch 90/1000
Training Loss: 1.14634812, Training R2: -0.171677
Validation Loss: 1.22590721, Validation R2: -0.005305

Epoch 91/1000
Training Loss: 1.12497538, Training R2: 0.001292
Validation Loss: 1.24239302, Validation R2: -0.005554

Epoch 92/1000
Training Loss: 1.13202808, Training R2: -0.056408
Validation Loss: 1.24668336, Validation R2: -0.084097

Epoch 93/1000
Training Loss: 1.12358258, Training R2: -0.090137
Validation Loss: 1.23482597, Validation R2: -0.052575

Epoch 94/1000
Training Loss: 1.11669260, Training R2: -0.054018
Validation Loss: 1.23125684, Validation R2: -0.030527

Epoch 95/1000
Training Loss: 1.11618920, Training R2: -0.026769
Validation Loss: 1.23105800, Validation R2: -0.023506

Epoch 96/1000
Training Loss: 1.11527925, Training R2: -0.026721
Validation Loss: 1.23184764, Validation R2: -0.042757

Epoch 97/1000
Training Loss: 1.11800257, Training R2: -0.063711
Validation Loss: 1.24190950, Validation R2: -0.075192

Epoch 98/1000
Training Loss: 1.12178160, Training R2: -0.091622
Validation Loss: 1.23538160, Validation R2: -0.055258

Epoch 99/1000
Epoch 00099: reducing learning rate of group 0 to 1.2500e-04.
Training Loss: 1.11557293, Training R2: -0.054096
Validation Loss: 1.23056030, Validation R2: -0.027649

Epoch 100/1000
学习率已减少 3 次
Training Loss: 1.11531122, Training R2: -0.029145
Validation Loss: 1.23063397, Validation R2: -0.030683

Epoch 101/1000
Training Loss: 1.11663280, Training R2: -0.044205
Validation Loss: 1.23374832, Validation R2: -0.049858

Epoch 102/1000
Training Loss: 1.11746324, Training R2: -0.062164
Validation Loss: 1.23156333, Validation R2: -0.042483

Epoch 103/1000
Training Loss: 1.11528905, Training R2: -0.033825
Validation Loss: 1.23166680, Validation R2: -0.013902

Epoch 104/1000
Training Loss: 1.11809833, Training R2: -0.010273
Validation Loss: 1.23227859, Validation R2: -0.011823

Epoch 105/1000
Training Loss: 1.11671018, Training R2: -0.012783
Validation Loss: 1.23035514, Validation R2: -0.025641

Epoch 106/1000
Training Loss: 1.11696692, Training R2: -0.035965
Validation Loss: 1.23089433, Validation R2: -0.040271

Epoch 107/1000
Training Loss: 1.11560375, Training R2: -0.044408
Validation Loss: 1.23047137, Validation R2: -0.031930

Epoch 108/1000
Training Loss: 1.11630063, Training R2: -0.028209
Validation Loss: 1.23106408, Validation R2: -0.017448

Epoch 109/1000
Training Loss: 1.11670404, Training R2: -0.018336
Validation Loss: 1.23079765, Validation R2: -0.023613

Epoch 110/1000
Training Loss: 1.11487310, Training R2: -0.025249
Validation Loss: 1.23049235, Validation R2: -0.034629

Epoch 111/1000
Training Loss: 1.11610607, Training R2: -0.043853
Validation Loss: 1.23156381, Validation R2: -0.044931

Epoch 112/1000
Training Loss: 1.11586662, Training R2: -0.050076
Validation Loss: 1.23012078, Validation R2: -0.034573

Epoch 113/1000
Training Loss: 1.11536391, Training R2: -0.029737
Validation Loss: 1.23112559, Validation R2: -0.016936

Epoch 114/1000
Training Loss: 1.11740576, Training R2: -0.012731
Validation Loss: 1.23225462, Validation R2: -0.012805

Epoch 115/1000
Training Loss: 1.11733659, Training R2: -0.010072
Validation Loss: 1.23155189, Validation R2: -0.015297

Epoch 116/1000
Training Loss: 1.11600549, Training R2: -0.014017
Validation Loss: 1.23034894, Validation R2: -0.023027

Epoch 117/1000
Training Loss: 1.11442376, Training R2: -0.022825
Validation Loss: 1.22992170, Validation R2: -0.032828

Epoch 118/1000
Training Loss: 1.11443884, Training R2: -0.042313
Validation Loss: 1.23247766, Validation R2: -0.049168

Epoch 119/1000
Training Loss: 1.11535625, Training R2: -0.057681
Validation Loss: 1.23209536, Validation R2: -0.048250

Epoch 120/1000
Epoch 00120: reducing learning rate of group 0 to 6.2500e-05.
Training Loss: 1.11433902, Training R2: -0.051232
Validation Loss: 1.22976148, Validation R2: -0.039065

Epoch 121/1000
学习率已减少 4 次
Training Loss: 1.11342609, Training R2: -0.039975
Validation Loss: 1.22936320, Validation R2: -0.036483

Epoch 122/1000
Training Loss: 1.11313814, Training R2: -0.036539
Validation Loss: 1.22935271, Validation R2: -0.037611

Epoch 123/1000
Training Loss: 1.11264451, Training R2: -0.040975
Validation Loss: 1.22987163, Validation R2: -0.042515

Epoch 124/1000
Training Loss: 1.11260468, Training R2: -0.043394
Validation Loss: 1.22825432, Validation R2: -0.035799

Epoch 125/1000
Training Loss: 1.11172895, Training R2: -0.030965
Validation Loss: 1.22778785, Validation R2: -0.025042

Epoch 126/1000
Training Loss: 1.11122636, Training R2: -0.020494
Validation Loss: 1.22711289, Validation R2: -0.019880

Epoch 127/1000
Training Loss: 1.11213768, Training R2: -0.010696
Validation Loss: 1.22804010, Validation R2: -0.012568

Epoch 128/1000
Training Loss: 1.11227114, Training R2: -0.006515
Validation Loss: 1.22463202, Validation R2: -0.020439

Epoch 129/1000
Training Loss: 1.10952570, Training R2: -0.023584
Validation Loss: 1.22742951, Validation R2: -0.040387

Epoch 130/1000
Training Loss: 1.11059758, Training R2: -0.048658
Validation Loss: 1.22793627, Validation R2: -0.044339

Epoch 131/1000
Training Loss: 1.10912335, Training R2: -0.042501
Validation Loss: 1.22344577, Validation R2: -0.033881

Epoch 132/1000
Training Loss: 1.10534373, Training R2: -0.031267
Validation Loss: 1.22387159, Validation R2: -0.042214

Epoch 133/1000
Training Loss: 1.10708768, Training R2: -0.051583
Validation Loss: 1.22440219, Validation R2: -0.049370

Epoch 134/1000
Training Loss: 1.10588204, Training R2: -0.044105
Validation Loss: 1.22042274, Validation R2: -0.027845

Epoch 135/1000
Training Loss: 1.10154634, Training R2: -0.020953
Validation Loss: 1.21724999, Validation R2: -0.027787

Epoch 136/1000
Training Loss: 1.10009023, Training R2: -0.021605
Validation Loss: 1.21056473, Validation R2: -0.017778

Epoch 137/1000
Training Loss: 1.09905406, Training R2: -0.005905
Validation Loss: 1.21560407, Validation R2: -0.008683

Epoch 138/1000
Training Loss: 1.10113592, Training R2: 0.005585
Validation Loss: 1.21003640, Validation R2: -0.005480

Epoch 139/1000
Training Loss: 1.09735487, Training R2: 0.003046
Validation Loss: 1.20753932, Validation R2: -0.012421

Epoch 140/1000
Training Loss: 1.09525634, Training R2: -0.012007
Validation Loss: 1.20658076, Validation R2: -0.014500

Epoch 141/1000
Epoch 00141: reducing learning rate of group 0 to 3.1250e-05.
Training Loss: 1.09616427, Training R2: -0.007725
Validation Loss: 1.20409822, Validation R2: -0.012017

Epoch 142/1000
学习率已减少 5 次
Training Loss: 1.09752039, Training R2: -0.017633
Validation Loss: 1.20598722, Validation R2: -0.012238

Epoch 143/1000
Training Loss: 1.10028092, Training R2: -0.003065
Validation Loss: 1.22280085, Validation R2: -0.003775

Epoch 144/1000
Training Loss: 1.10787605, Training R2: 0.012870
Validation Loss: 1.22195601, Validation R2: 0.001122

Epoch 145/1000
Training Loss: 1.10506001, Training R2: 0.009067
Validation Loss: 1.20912027, Validation R2: -0.004268

Epoch 146/1000
Training Loss: 1.09810334, Training R2: -0.006702
Validation Loss: 1.20954943, Validation R2: -0.021781

Epoch 147/1000
Training Loss: 1.10089439, Training R2: -0.039373
Validation Loss: 1.21053040, Validation R2: -0.029148

Epoch 148/1000
Training Loss: 1.10002452, Training R2: -0.041703
Validation Loss: 1.20026779, Validation R2: -0.008059

Epoch 149/1000
Training Loss: 1.08849100, Training R2: 0.003860
Validation Loss: 1.20414793, Validation R2: 0.002777

Epoch 150/1000
Training Loss: 1.09352020, Training R2: 0.022094
Validation Loss: 1.20022142, Validation R2: 0.002970

Epoch 151/1000
Training Loss: 1.08772040, Training R2: 0.009125
Validation Loss: 1.19662702, Validation R2: -0.010796

Epoch 152/1000
Training Loss: 1.09232720, Training R2: -0.030843
Validation Loss: 1.19458449, Validation R2: -0.004304

Epoch 153/1000
Training Loss: 1.08425931, Training R2: -0.002265
Validation Loss: 1.19775987, Validation R2: 0.026672

Epoch 154/1000
Training Loss: 1.09066810, Training R2: 0.033598
Validation Loss: 1.20351970, Validation R2: 0.028363

Epoch 155/1000
Training Loss: 1.08171602, Training R2: 0.038598
Validation Loss: 1.19163680, Validation R2: 0.019882

Epoch 156/1000
Training Loss: 1.08447701, Training R2: -0.018765
Validation Loss: 1.21835172, Validation R2: -0.045427

Epoch 157/1000
Training Loss: 1.10182463, Training R2: -0.077816
Validation Loss: 1.20871651, Validation R2: -0.021059

Epoch 158/1000
Training Loss: 1.08793598, Training R2: -0.018169
Validation Loss: 1.18558025, Validation R2: 0.035055

Epoch 159/1000
Training Loss: 1.08299503, Training R2: 0.038912
Validation Loss: 1.20591462, Validation R2: 0.039122

Epoch 160/1000
Training Loss: 1.09404207, Training R2: 0.042023
Validation Loss: 1.19644988, Validation R2: 0.042783

Epoch 161/1000
Training Loss: 1.08255000, Training R2: 0.045170
Validation Loss: 1.18611550, Validation R2: 0.018394

Epoch 162/1000
Epoch 00162: reducing learning rate of group 0 to 1.5625e-05.
Training Loss: 1.07753534, Training R2: 0.003151
Validation Loss: 1.20474303, Validation R2: -0.018079

Epoch 163/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/loss_curve_dipole.png
Saved R2 curve to /share/home/alpha/block_predict/block_predict/fine-tune/atom_dim_test/r2_curve_dipole.png
