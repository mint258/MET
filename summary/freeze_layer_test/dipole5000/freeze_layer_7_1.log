Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.39779063, Training R2: -0.436515
Validation Loss: 1.13574865, Validation R2: 0.082882
Saved best model with validation R2 0.082882 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.16120194, Training R2: 0.035941
Validation Loss: 1.10776179, Validation R2: 0.062026

Epoch 3/1000
Training Loss: 1.12698959, Training R2: 0.065363
Validation Loss: 1.09949395, Validation R2: 0.074363

Epoch 4/1000
Training Loss: 1.11198238, Training R2: 0.095880
Validation Loss: 1.07710492, Validation R2: 0.114217
Saved best model with validation R2 0.114217 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.09291657, Training R2: 0.107978
Validation Loss: 1.07019866, Validation R2: 0.143138
Saved best model with validation R2 0.143138 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.09537246, Training R2: 0.120970
Validation Loss: 1.06632959, Validation R2: 0.121767

Epoch 7/1000
Training Loss: 1.07111475, Training R2: 0.139767
Validation Loss: 1.05074586, Validation R2: 0.161705
Saved best model with validation R2 0.161705 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 1.05820488, Training R2: 0.160254
Validation Loss: 1.03151740, Validation R2: 0.202816
Saved best model with validation R2 0.202816 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.04376569, Training R2: 0.178649
Validation Loss: 1.00300288, Validation R2: 0.227071
Saved best model with validation R2 0.227071 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 1.02612681, Training R2: 0.197020
Validation Loss: 0.98877605, Validation R2: 0.245416
Saved best model with validation R2 0.245416 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 1.00173738, Training R2: 0.230208
Validation Loss: 0.98564473, Validation R2: 0.261491
Saved best model with validation R2 0.261491 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.00195815, Training R2: 0.217892
Validation Loss: 1.07750140, Validation R2: 0.180817

Epoch 13/1000
Training Loss: 1.01957163, Training R2: 0.209974
Validation Loss: 0.95421615, Validation R2: 0.296395
Saved best model with validation R2 0.296395 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 0.95281867, Training R2: 0.284260
Validation Loss: 0.95962532, Validation R2: 0.252670

Epoch 15/1000
Training Loss: 0.96803223, Training R2: 0.258370
Validation Loss: 0.94134510, Validation R2: 0.285273

Epoch 16/1000
Training Loss: 0.94866964, Training R2: 0.292950
Validation Loss: 0.97752721, Validation R2: 0.236352

Epoch 17/1000
Training Loss: 0.93794529, Training R2: 0.302885
Validation Loss: 0.89112305, Validation R2: 0.356181
Saved best model with validation R2 0.356181 to best_finetuned_model.pth

Epoch 18/1000
Training Loss: 0.91857116, Training R2: 0.317349
Validation Loss: 0.89406999, Validation R2: 0.344522

Epoch 19/1000
Training Loss: 0.92568586, Training R2: 0.306010
Validation Loss: 0.91246092, Validation R2: 0.348460

Epoch 20/1000
Training Loss: 0.92515886, Training R2: 0.310395
Validation Loss: 0.89452993, Validation R2: 0.368266
Saved best model with validation R2 0.368266 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.91136212, Training R2: 0.332033
Validation Loss: 0.88105580, Validation R2: 0.351890

Epoch 22/1000
Training Loss: 0.90791428, Training R2: 0.327978
Validation Loss: 0.96568823, Validation R2: 0.235217

Epoch 23/1000
Training Loss: 0.92221348, Training R2: 0.319086
Validation Loss: 0.86014034, Validation R2: 0.385733
Saved best model with validation R2 0.385733 to best_finetuned_model.pth

Epoch 24/1000
Training Loss: 0.89652175, Training R2: 0.333030
Validation Loss: 0.85144075, Validation R2: 0.406762
Saved best model with validation R2 0.406762 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 0.86740808, Training R2: 0.375061
Validation Loss: 0.84864515, Validation R2: 0.410650
Saved best model with validation R2 0.410650 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 0.86170622, Training R2: 0.383840
Validation Loss: 0.85194340, Validation R2: 0.413271
Saved best model with validation R2 0.413271 to best_finetuned_model.pth

Epoch 27/1000
Training Loss: 0.87390467, Training R2: 0.367101
Validation Loss: 0.86751219, Validation R2: 0.389888

Epoch 28/1000
Training Loss: 0.88484768, Training R2: 0.353418
Validation Loss: 0.85621832, Validation R2: 0.414670
Saved best model with validation R2 0.414670 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 0.89023052, Training R2: 0.348251
Validation Loss: 0.92703086, Validation R2: 0.291848

Epoch 30/1000
Training Loss: 0.87202503, Training R2: 0.374141
Validation Loss: 0.83988924, Validation R2: 0.420182
Saved best model with validation R2 0.420182 to best_finetuned_model.pth

Epoch 31/1000
Training Loss: 0.87613912, Training R2: 0.366392
Validation Loss: 0.84942856, Validation R2: 0.396308

Epoch 32/1000
Training Loss: 0.89197587, Training R2: 0.350722
Validation Loss: 0.93836024, Validation R2: 0.269954

Epoch 33/1000
Training Loss: 0.86742859, Training R2: 0.373943
Validation Loss: 0.89162467, Validation R2: 0.349660

Epoch 34/1000
Training Loss: 0.82797042, Training R2: 0.415435
Validation Loss: 0.82777791, Validation R2: 0.436636
Saved best model with validation R2 0.436636 to best_finetuned_model.pth

Epoch 35/1000
Training Loss: 0.82521253, Training R2: 0.420892
Validation Loss: 0.83145035, Validation R2: 0.423511

Epoch 36/1000
Training Loss: 0.81471623, Training R2: 0.429336
Validation Loss: 0.82020654, Validation R2: 0.434353

Epoch 37/1000
Training Loss: 0.82317583, Training R2: 0.420566
Validation Loss: 0.82266771, Validation R2: 0.441132
Saved best model with validation R2 0.441132 to best_finetuned_model.pth

Epoch 38/1000
Training Loss: 0.81721226, Training R2: 0.419316
Validation Loss: 0.81442744, Validation R2: 0.464961
Saved best model with validation R2 0.464961 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.80392822, Training R2: 0.437355
Validation Loss: 0.79613545, Validation R2: 0.469724
Saved best model with validation R2 0.469724 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.79235769, Training R2: 0.445722
Validation Loss: 0.80047798, Validation R2: 0.457170

Epoch 41/1000
Training Loss: 0.78692037, Training R2: 0.450865
Validation Loss: 0.79813819, Validation R2: 0.444147

Epoch 42/1000
Training Loss: 0.77537394, Training R2: 0.463865
Validation Loss: 0.80182913, Validation R2: 0.445081

Epoch 43/1000
Training Loss: 0.78474125, Training R2: 0.450541
Validation Loss: 0.78312195, Validation R2: 0.470739
Saved best model with validation R2 0.470739 to best_finetuned_model.pth

Epoch 44/1000
Training Loss: 0.78742310, Training R2: 0.452398
Validation Loss: 0.86717297, Validation R2: 0.383137

Epoch 45/1000
Training Loss: 0.81822478, Training R2: 0.432789
Validation Loss: 0.79557056, Validation R2: 0.448406

Epoch 46/1000
Training Loss: 0.77003106, Training R2: 0.471023
Validation Loss: 0.80272507, Validation R2: 0.450799

Epoch 47/1000
Training Loss: 0.77625163, Training R2: 0.461079
Validation Loss: 0.79431571, Validation R2: 0.463310

Epoch 48/1000
Training Loss: 0.76161395, Training R2: 0.478257
Validation Loss: 0.78444351, Validation R2: 0.469143

Epoch 49/1000
Training Loss: 0.75610976, Training R2: 0.480533
Validation Loss: 0.77420000, Validation R2: 0.490107
Saved best model with validation R2 0.490107 to best_finetuned_model.pth

Epoch 50/1000
Training Loss: 0.75920153, Training R2: 0.480816
Validation Loss: 0.78265865, Validation R2: 0.482240

Epoch 51/1000
Training Loss: 0.78934344, Training R2: 0.459004
Validation Loss: 0.79841291, Validation R2: 0.473541

Epoch 52/1000
Training Loss: 0.74939091, Training R2: 0.488036
Validation Loss: 0.77108842, Validation R2: 0.485453

Epoch 53/1000
Training Loss: 0.73870948, Training R2: 0.503259
Validation Loss: 0.78295077, Validation R2: 0.477268

Epoch 54/1000
Training Loss: 0.74220294, Training R2: 0.497142
Validation Loss: 0.79030863, Validation R2: 0.474808

Epoch 55/1000
Training Loss: 0.77756006, Training R2: 0.461397
Validation Loss: 0.78107538, Validation R2: 0.487345

Epoch 56/1000
Training Loss: 0.73992494, Training R2: 0.500464
Validation Loss: 0.76403709, Validation R2: 0.492379
Saved best model with validation R2 0.492379 to best_finetuned_model.pth

Epoch 57/1000
Training Loss: 0.72163524, Training R2: 0.517023
Validation Loss: 0.77346559, Validation R2: 0.497341
Saved best model with validation R2 0.497341 to best_finetuned_model.pth

Epoch 58/1000
Training Loss: 0.71916294, Training R2: 0.519705
Validation Loss: 0.76501915, Validation R2: 0.492804

Epoch 59/1000
Training Loss: 0.72048718, Training R2: 0.516935
Validation Loss: 0.76085678, Validation R2: 0.501298
Saved best model with validation R2 0.501298 to best_finetuned_model.pth

Epoch 60/1000
Training Loss: 0.71851741, Training R2: 0.522563
Validation Loss: 0.76400504, Validation R2: 0.488732

Epoch 61/1000
Training Loss: 0.70447081, Training R2: 0.532337
Validation Loss: 0.75949098, Validation R2: 0.489850

Epoch 62/1000
Training Loss: 0.72560789, Training R2: 0.513695
Validation Loss: 0.78385900, Validation R2: 0.473251

Epoch 63/1000
Training Loss: 0.72152202, Training R2: 0.519819
Validation Loss: 0.82456135, Validation R2: 0.432986

Epoch 64/1000
Training Loss: 0.70478552, Training R2: 0.537544
Validation Loss: 0.74702946, Validation R2: 0.518825
Saved best model with validation R2 0.518825 to best_finetuned_model.pth

Epoch 65/1000
Training Loss: 0.71040979, Training R2: 0.539442
Validation Loss: 0.74720695, Validation R2: 0.517375

Epoch 66/1000
Training Loss: 0.70198138, Training R2: 0.534912
Validation Loss: 0.75217388, Validation R2: 0.506643

Epoch 67/1000
Training Loss: 0.71687789, Training R2: 0.525450
Validation Loss: 0.75832232, Validation R2: 0.502702

Epoch 68/1000
Training Loss: 0.69140350, Training R2: 0.550620
Validation Loss: 0.75517440, Validation R2: 0.502398

Epoch 69/1000
Training Loss: 0.68883118, Training R2: 0.556799
Validation Loss: 0.76025638, Validation R2: 0.490839

Epoch 70/1000
Training Loss: 0.70276723, Training R2: 0.537439
Validation Loss: 0.75155565, Validation R2: 0.505379

Epoch 71/1000
Training Loss: 0.68625504, Training R2: 0.552299
Validation Loss: 0.76249408, Validation R2: 0.496171

Epoch 72/1000
Training Loss: 0.67449573, Training R2: 0.566136
Validation Loss: 0.74967756, Validation R2: 0.501051

Epoch 73/1000
Training Loss: 0.67330831, Training R2: 0.570863
Validation Loss: 0.75012334, Validation R2: 0.500637

Epoch 74/1000
Training Loss: 0.65049228, Training R2: 0.590121
Validation Loss: 0.76794199, Validation R2: 0.476919

Epoch 75/1000
Training Loss: 0.67431258, Training R2: 0.571876
Validation Loss: 0.77814735, Validation R2: 0.460138

Epoch 76/1000
Training Loss: 0.67870193, Training R2: 0.570561
Validation Loss: 0.76065105, Validation R2: 0.490181

Epoch 77/1000
Training Loss: 0.68273312, Training R2: 0.559699
Validation Loss: 0.76970274, Validation R2: 0.476493

Epoch 78/1000
Training Loss: 0.68772406, Training R2: 0.559789
Validation Loss: 0.75538776, Validation R2: 0.509147

Epoch 79/1000
Training Loss: 0.68157193, Training R2: 0.567688
Validation Loss: 0.88351136, Validation R2: 0.384917

Epoch 80/1000
Training Loss: 0.71392776, Training R2: 0.542030
Validation Loss: 0.74180989, Validation R2: 0.513682

Epoch 81/1000
Training Loss: 0.64933975, Training R2: 0.597049
Validation Loss: 0.74681007, Validation R2: 0.510467

Epoch 82/1000
Training Loss: 0.64667753, Training R2: 0.601733
Validation Loss: 0.76169855, Validation R2: 0.485849

Epoch 83/1000
Training Loss: 0.66926840, Training R2: 0.577144
Validation Loss: 0.81040091, Validation R2: 0.435310

Epoch 84/1000
Training Loss: 0.64521380, Training R2: 0.594727
Validation Loss: 0.74323340, Validation R2: 0.501936

Epoch 85/1000
Epoch 00085: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.64031408, Training R2: 0.605418
Validation Loss: 0.79337188, Validation R2: 0.451586

Epoch 86/1000
学习率已减少 1 次
Training Loss: 0.63217634, Training R2: 0.609596
Validation Loss: 0.73408908, Validation R2: 0.519893
Saved best model with validation R2 0.519893 to best_finetuned_model.pth

Epoch 87/1000
Training Loss: 0.60701871, Training R2: 0.631629
Validation Loss: 0.74788054, Validation R2: 0.490907

Epoch 88/1000
Training Loss: 0.58936197, Training R2: 0.646119
Validation Loss: 0.75105144, Validation R2: 0.491550

Epoch 89/1000
Training Loss: 0.59036348, Training R2: 0.647773
Validation Loss: 0.75384146, Validation R2: 0.480356

Epoch 90/1000
Training Loss: 0.57889565, Training R2: 0.657239
Validation Loss: 0.74248969, Validation R2: 0.507634

Epoch 91/1000
Training Loss: 0.57424272, Training R2: 0.658394
Validation Loss: 0.75340942, Validation R2: 0.487847

Epoch 92/1000
Training Loss: 0.59575085, Training R2: 0.640516
Validation Loss: 0.75511719, Validation R2: 0.487837

Epoch 93/1000
Training Loss: 0.59430221, Training R2: 0.649381
Validation Loss: 0.78442586, Validation R2: 0.450329

Epoch 94/1000
Training Loss: 0.58254464, Training R2: 0.651827
Validation Loss: 0.74293959, Validation R2: 0.504391

Epoch 95/1000
Training Loss: 0.56244820, Training R2: 0.672840
Validation Loss: 0.75085089, Validation R2: 0.485532

Epoch 96/1000
Training Loss: 0.57419826, Training R2: 0.661583
Validation Loss: 0.75976080, Validation R2: 0.473205

Epoch 97/1000
Training Loss: 0.57435634, Training R2: 0.662390
Validation Loss: 0.75253230, Validation R2: 0.484467

Epoch 98/1000
Training Loss: 0.57108308, Training R2: 0.667425
Validation Loss: 0.76116613, Validation R2: 0.474850

Epoch 99/1000
Training Loss: 0.56391792, Training R2: 0.671405
Validation Loss: 0.75468333, Validation R2: 0.488870

Epoch 100/1000
Training Loss: 0.55361309, Training R2: 0.680566
Validation Loss: 0.75170195, Validation R2: 0.482890

Epoch 101/1000
Training Loss: 0.54671868, Training R2: 0.688222
Validation Loss: 0.74514333, Validation R2: 0.497932

Epoch 102/1000
Training Loss: 0.55025505, Training R2: 0.684227
Validation Loss: 0.75960330, Validation R2: 0.478355

Epoch 103/1000
Training Loss: 0.54696347, Training R2: 0.688989
Validation Loss: 0.76282762, Validation R2: 0.473339

Epoch 104/1000
Training Loss: 0.54572518, Training R2: 0.689555
Validation Loss: 0.75645265, Validation R2: 0.482718

Epoch 105/1000
Training Loss: 0.53065331, Training R2: 0.702315
Validation Loss: 0.76169026, Validation R2: 0.470385

Epoch 106/1000
Training Loss: 0.52944237, Training R2: 0.702026
Validation Loss: 0.75857025, Validation R2: 0.486229

Epoch 107/1000
Epoch 00107: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.52005351, Training R2: 0.709654
Validation Loss: 0.75187792, Validation R2: 0.480456

Epoch 108/1000
学习率已减少 2 次
Training Loss: 0.50686132, Training R2: 0.718495
Validation Loss: 0.74513625, Validation R2: 0.493991

Epoch 109/1000
Training Loss: 0.49672130, Training R2: 0.724552
Validation Loss: 0.74238581, Validation R2: 0.495570

Epoch 110/1000
Training Loss: 0.49845462, Training R2: 0.724100
Validation Loss: 0.76244746, Validation R2: 0.466790

Epoch 111/1000
Training Loss: 0.49465179, Training R2: 0.730388
Validation Loss: 0.76079637, Validation R2: 0.462696

Epoch 112/1000
Training Loss: 0.49204266, Training R2: 0.730938
Validation Loss: 0.76134319, Validation R2: 0.470262

Epoch 113/1000
Training Loss: 0.48830212, Training R2: 0.734728
Validation Loss: 0.76507721, Validation R2: 0.473788

Epoch 114/1000
Training Loss: 0.48818389, Training R2: 0.735626
Validation Loss: 0.75718703, Validation R2: 0.475099

Epoch 115/1000
Training Loss: 0.48674587, Training R2: 0.734259
Validation Loss: 0.74334013, Validation R2: 0.493649

Epoch 116/1000
Training Loss: 0.47672061, Training R2: 0.741058
Validation Loss: 0.76145380, Validation R2: 0.465607

Epoch 117/1000
Training Loss: 0.48161045, Training R2: 0.738501
Validation Loss: 0.75988962, Validation R2: 0.472095

Epoch 118/1000
Training Loss: 0.47645173, Training R2: 0.740816
Validation Loss: 0.76026886, Validation R2: 0.467240

Epoch 119/1000
Training Loss: 0.47253315, Training R2: 0.745829
Validation Loss: 0.77305591, Validation R2: 0.445306

Epoch 120/1000
Training Loss: 0.46855401, Training R2: 0.747768
Validation Loss: 0.75585571, Validation R2: 0.477083

Epoch 121/1000
Training Loss: 0.46893764, Training R2: 0.749565
Validation Loss: 0.76366712, Validation R2: 0.455554

Epoch 122/1000
Training Loss: 0.46736618, Training R2: 0.750415
Validation Loss: 0.75072275, Validation R2: 0.479961

Epoch 123/1000
Training Loss: 0.46424771, Training R2: 0.750441
Validation Loss: 0.77260095, Validation R2: 0.434300

Epoch 124/1000
Training Loss: 0.47203424, Training R2: 0.749086
Validation Loss: 0.76530909, Validation R2: 0.461872

Epoch 125/1000
Training Loss: 0.47100878, Training R2: 0.752352
Validation Loss: 0.75117750, Validation R2: 0.478483

Epoch 126/1000
Training Loss: 0.47158990, Training R2: 0.752566
Validation Loss: 0.75053427, Validation R2: 0.476907

Epoch 127/1000
Training Loss: 0.45502999, Training R2: 0.759029
Validation Loss: 0.76604581, Validation R2: 0.447697

Epoch 128/1000
Epoch 00128: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.44934357, Training R2: 0.760903
Validation Loss: 0.75564463, Validation R2: 0.465091

Epoch 129/1000
学习率已减少 3 次
Training Loss: 0.43989954, Training R2: 0.767388
Validation Loss: 0.76207993, Validation R2: 0.457587

Epoch 130/1000
Training Loss: 0.43597856, Training R2: 0.769909
Validation Loss: 0.76264433, Validation R2: 0.456593

Epoch 131/1000
Training Loss: 0.43289161, Training R2: 0.770742
Validation Loss: 0.76317695, Validation R2: 0.459228

Epoch 132/1000
Training Loss: 0.43085467, Training R2: 0.772869
Validation Loss: 0.75966083, Validation R2: 0.461850

Epoch 133/1000
Training Loss: 0.42576229, Training R2: 0.775298
Validation Loss: 0.76343875, Validation R2: 0.455225

Epoch 134/1000
Training Loss: 0.42548787, Training R2: 0.774880
Validation Loss: 0.76519521, Validation R2: 0.447717

Epoch 135/1000
Training Loss: 0.42243993, Training R2: 0.776687
Validation Loss: 0.76825481, Validation R2: 0.449962

Epoch 136/1000
Training Loss: 0.42325982, Training R2: 0.775800
Validation Loss: 0.76565774, Validation R2: 0.445643

Epoch 137/1000
Training Loss: 0.41927489, Training R2: 0.779762
Validation Loss: 0.76805596, Validation R2: 0.447409

Epoch 138/1000
Training Loss: 0.41618270, Training R2: 0.778390
Validation Loss: 0.76568826, Validation R2: 0.447739

Epoch 139/1000
Training Loss: 0.41611247, Training R2: 0.779569
Validation Loss: 0.76796033, Validation R2: 0.449338

Epoch 140/1000
Training Loss: 0.42128377, Training R2: 0.779700
Validation Loss: 0.78312242, Validation R2: 0.419657

Epoch 141/1000
Training Loss: 0.42530717, Training R2: 0.780584
Validation Loss: 0.79129113, Validation R2: 0.406268

Epoch 142/1000
Training Loss: 0.42209279, Training R2: 0.778438
Validation Loss: 0.77508350, Validation R2: 0.430044

Epoch 143/1000
Training Loss: 0.41850567, Training R2: 0.781062
Validation Loss: 0.76184446, Validation R2: 0.457601

Epoch 144/1000
Training Loss: 0.41596785, Training R2: 0.782123
Validation Loss: 0.77573453, Validation R2: 0.433044

Epoch 145/1000
Training Loss: 0.41157840, Training R2: 0.786541
Validation Loss: 0.76583234, Validation R2: 0.453600

Epoch 146/1000
Training Loss: 0.41141822, Training R2: 0.787150
Validation Loss: 0.77775866, Validation R2: 0.436852

Epoch 147/1000
Training Loss: 0.41203313, Training R2: 0.784600
Validation Loss: 0.77444070, Validation R2: 0.431344

Epoch 148/1000
Training Loss: 0.40861217, Training R2: 0.787685
Validation Loss: 0.77347864, Validation R2: 0.436357

Epoch 149/1000
Epoch 00149: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.40689325, Training R2: 0.788295
Validation Loss: 0.77235368, Validation R2: 0.441249

Epoch 150/1000
学习率已减少 4 次
Training Loss: 0.39995561, Training R2: 0.791675
Validation Loss: 0.77194797, Validation R2: 0.437087

Epoch 151/1000
Training Loss: 0.39707119, Training R2: 0.792276
Validation Loss: 0.77760680, Validation R2: 0.426662

Epoch 152/1000
Training Loss: 0.39858516, Training R2: 0.792731
Validation Loss: 0.76928567, Validation R2: 0.441494

Epoch 153/1000
Training Loss: 0.39748372, Training R2: 0.793266
Validation Loss: 0.77105517, Validation R2: 0.441425

Epoch 154/1000
Training Loss: 0.39721110, Training R2: 0.793214
Validation Loss: 0.77333601, Validation R2: 0.437583

Epoch 155/1000
Training Loss: 0.39414787, Training R2: 0.795745
Validation Loss: 0.77181406, Validation R2: 0.435006

Epoch 156/1000
Training Loss: 0.39329579, Training R2: 0.793390
Validation Loss: 0.76638244, Validation R2: 0.450004

Epoch 157/1000
Training Loss: 0.39080088, Training R2: 0.797063
Validation Loss: 0.76795473, Validation R2: 0.443985

Epoch 158/1000
Training Loss: 0.39101962, Training R2: 0.797205
Validation Loss: 0.77358902, Validation R2: 0.436826

Epoch 159/1000
Training Loss: 0.38807282, Training R2: 0.797962
Validation Loss: 0.77297400, Validation R2: 0.433623

Epoch 160/1000
Training Loss: 0.38824127, Training R2: 0.797521
Validation Loss: 0.77285936, Validation R2: 0.437691

Epoch 161/1000
Training Loss: 0.38794519, Training R2: 0.797686
Validation Loss: 0.77176404, Validation R2: 0.439274

Epoch 162/1000
Training Loss: 0.38756040, Training R2: 0.797798
Validation Loss: 0.77198637, Validation R2: 0.436217

Epoch 163/1000
Training Loss: 0.38802430, Training R2: 0.798445
Validation Loss: 0.77217219, Validation R2: 0.436908

Epoch 164/1000
Training Loss: 0.38420971, Training R2: 0.799954
Validation Loss: 0.77328753, Validation R2: 0.434985

Epoch 165/1000
Training Loss: 0.38543296, Training R2: 0.799867
Validation Loss: 0.77171933, Validation R2: 0.439097

Epoch 166/1000
Training Loss: 0.38447214, Training R2: 0.798947
Validation Loss: 0.77476767, Validation R2: 0.434063

Epoch 167/1000
Training Loss: 0.38237116, Training R2: 0.801447
Validation Loss: 0.77318470, Validation R2: 0.432722

Epoch 168/1000
Training Loss: 0.38182997, Training R2: 0.801335
Validation Loss: 0.78271820, Validation R2: 0.417776

Epoch 169/1000
Training Loss: 0.38070394, Training R2: 0.801667
Validation Loss: 0.78062498, Validation R2: 0.423273

Epoch 170/1000
Epoch 00170: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.38031186, Training R2: 0.802678
Validation Loss: 0.77344375, Validation R2: 0.434438

Epoch 171/1000
学习率已减少 5 次
Training Loss: 0.37879498, Training R2: 0.800928
Validation Loss: 0.77222418, Validation R2: 0.435970

Epoch 172/1000
Training Loss: 0.37650147, Training R2: 0.803358
Validation Loss: 0.77399884, Validation R2: 0.434641

Epoch 173/1000
Training Loss: 0.37562054, Training R2: 0.804224
Validation Loss: 0.77455368, Validation R2: 0.432439

Epoch 174/1000
Training Loss: 0.37430483, Training R2: 0.803984
Validation Loss: 0.77456964, Validation R2: 0.433095

Epoch 175/1000
Training Loss: 0.37284632, Training R2: 0.804522
Validation Loss: 0.77503806, Validation R2: 0.432148

Epoch 176/1000
Training Loss: 0.37374582, Training R2: 0.804903
Validation Loss: 0.77493801, Validation R2: 0.431409

Epoch 177/1000
Training Loss: 0.37287841, Training R2: 0.805116
Validation Loss: 0.77538244, Validation R2: 0.430274

Epoch 178/1000
Training Loss: 0.37247174, Training R2: 0.805970
Validation Loss: 0.77467020, Validation R2: 0.433220

Epoch 179/1000
Training Loss: 0.37285689, Training R2: 0.804701
Validation Loss: 0.77876838, Validation R2: 0.422992

Epoch 180/1000
Training Loss: 0.37265267, Training R2: 0.805010
Validation Loss: 0.77378357, Validation R2: 0.433392

Epoch 181/1000
Training Loss: 0.37079455, Training R2: 0.806483
Validation Loss: 0.77227519, Validation R2: 0.435702

Epoch 182/1000
Training Loss: 0.37044454, Training R2: 0.806218
Validation Loss: 0.77793016, Validation R2: 0.425775

Epoch 183/1000
Training Loss: 0.36999438, Training R2: 0.806043
Validation Loss: 0.77551051, Validation R2: 0.430604

Epoch 184/1000
Training Loss: 0.37164895, Training R2: 0.805713
Validation Loss: 0.77485404, Validation R2: 0.431162

Epoch 185/1000
Training Loss: 0.37266476, Training R2: 0.805428
Validation Loss: 0.77314210, Validation R2: 0.435921

Epoch 186/1000
Training Loss: 0.37022610, Training R2: 0.806640
Validation Loss: 0.77554230, Validation R2: 0.430545

Epoch 187/1000
Training Loss: 0.36838199, Training R2: 0.807309
Validation Loss: 0.77431435, Validation R2: 0.432408

Epoch 188/1000
Training Loss: 0.36787768, Training R2: 0.807306
Validation Loss: 0.77545426, Validation R2: 0.429757

Epoch 189/1000
Training Loss: 0.36824909, Training R2: 0.807248
Validation Loss: 0.77700264, Validation R2: 0.428655

Epoch 190/1000
Training Loss: 0.36823769, Training R2: 0.807263
Validation Loss: 0.77895147, Validation R2: 0.424609

Epoch 191/1000
Epoch 00191: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.36746697, Training R2: 0.807561
Validation Loss: 0.77511267, Validation R2: 0.431321

Epoch 192/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
