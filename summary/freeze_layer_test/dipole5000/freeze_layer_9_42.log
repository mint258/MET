Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)
冻结层 9: lins.2 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Frozen
lins.2.bias: Frozen
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1026435

Epoch 1/1000
Training Loss: 1.48051831, Training R2: -0.705003
Validation Loss: 1.19385254, Validation R2: 0.014091
Saved best model with validation R2 0.014091 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.20077357, Training R2: -0.029690
Validation Loss: 1.16496742, Validation R2: 0.043884
Saved best model with validation R2 0.043884 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.15363344, Training R2: 0.046146
Validation Loss: 1.12148365, Validation R2: 0.073760
Saved best model with validation R2 0.073760 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.12752252, Training R2: 0.066358
Validation Loss: 1.11528370, Validation R2: 0.077370
Saved best model with validation R2 0.077370 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.11562546, Training R2: 0.084292
Validation Loss: 1.10995931, Validation R2: 0.102216
Saved best model with validation R2 0.102216 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.11826335, Training R2: 0.080118
Validation Loss: 1.09781757, Validation R2: 0.089710

Epoch 7/1000
Training Loss: 1.11961536, Training R2: 0.073130
Validation Loss: 1.13448886, Validation R2: 0.100810

Epoch 8/1000
Training Loss: 1.12266223, Training R2: 0.076414
Validation Loss: 1.12389798, Validation R2: -0.045592

Epoch 9/1000
Training Loss: 1.11396015, Training R2: 0.092842
Validation Loss: 1.09271194, Validation R2: 0.059646

Epoch 10/1000
Training Loss: 1.10430311, Training R2: 0.092225
Validation Loss: 1.09432613, Validation R2: 0.123889
Saved best model with validation R2 0.123889 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 1.10847573, Training R2: 0.085642
Validation Loss: 1.09353906, Validation R2: 0.131365
Saved best model with validation R2 0.131365 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 1.08646712, Training R2: 0.118883
Validation Loss: 1.06603476, Validation R2: 0.107232

Epoch 13/1000
Training Loss: 1.08570162, Training R2: 0.114587
Validation Loss: 1.06722826, Validation R2: 0.132974
Saved best model with validation R2 0.132974 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 1.09951511, Training R2: 0.108814
Validation Loss: 1.06808825, Validation R2: 0.125236

Epoch 15/1000
Training Loss: 1.09812131, Training R2: 0.102127
Validation Loss: 1.08044919, Validation R2: 0.140494
Saved best model with validation R2 0.140494 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 1.08186566, Training R2: 0.131087
Validation Loss: 1.07310865, Validation R2: 0.061845

Epoch 17/1000
Training Loss: 1.07983948, Training R2: 0.122733
Validation Loss: 1.05913070, Validation R2: 0.081912

Epoch 18/1000
Training Loss: 1.06938453, Training R2: 0.139097
Validation Loss: 1.04877774, Validation R2: 0.144242
Saved best model with validation R2 0.144242 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 1.06986676, Training R2: 0.141434
Validation Loss: 1.05620355, Validation R2: 0.147912
Saved best model with validation R2 0.147912 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 1.08486473, Training R2: 0.113424
Validation Loss: 1.11086178, Validation R2: 0.122444

Epoch 21/1000
Training Loss: 1.09336806, Training R2: 0.112328
Validation Loss: 1.04509946, Validation R2: 0.114915

Epoch 22/1000
Training Loss: 1.06928000, Training R2: 0.143737
Validation Loss: 1.03350117, Validation R2: 0.146890

Epoch 23/1000
Training Loss: 1.07288326, Training R2: 0.134870
Validation Loss: 1.07988863, Validation R2: 0.155990
Saved best model with validation R2 0.155990 to best_finetuned_model.pth

Epoch 24/1000
Training Loss: 1.07755075, Training R2: 0.124684
Validation Loss: 1.04600726, Validation R2: 0.176914
Saved best model with validation R2 0.176914 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 1.07957891, Training R2: 0.126567
Validation Loss: 1.03562780, Validation R2: 0.134179

Epoch 26/1000
Training Loss: 1.04184933, Training R2: 0.173400
Validation Loss: 1.07297111, Validation R2: 0.035933

Epoch 27/1000
Training Loss: 1.05644584, Training R2: 0.149641
Validation Loss: 1.02234924, Validation R2: 0.176026

Epoch 28/1000
Training Loss: 1.02548012, Training R2: 0.191449
Validation Loss: 1.00084221, Validation R2: 0.201919
Saved best model with validation R2 0.201919 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 1.02444750, Training R2: 0.184557
Validation Loss: 1.01562927, Validation R2: 0.170578

Epoch 30/1000
Training Loss: 1.02132569, Training R2: 0.181107
Validation Loss: 1.02338936, Validation R2: 0.214245
Saved best model with validation R2 0.214245 to best_finetuned_model.pth

Epoch 31/1000
Training Loss: 1.05055028, Training R2: 0.158875
Validation Loss: 1.01889450, Validation R2: 0.204712

Epoch 32/1000
Training Loss: 1.03651164, Training R2: 0.171100
Validation Loss: 1.00415107, Validation R2: 0.162983

Epoch 33/1000
Training Loss: 1.00620352, Training R2: 0.205670
Validation Loss: 1.02083530, Validation R2: 0.090547

Epoch 34/1000
Training Loss: 1.02675539, Training R2: 0.178330
Validation Loss: 1.08300286, Validation R2: -0.017669

Epoch 35/1000
Training Loss: 1.02313969, Training R2: 0.179388
Validation Loss: 1.03601569, Validation R2: 0.063415

Epoch 36/1000
Training Loss: 1.01694935, Training R2: 0.191694
Validation Loss: 0.99762611, Validation R2: 0.156670

Epoch 37/1000
Training Loss: 0.98243684, Training R2: 0.221744
Validation Loss: 0.97477997, Validation R2: 0.225288
Saved best model with validation R2 0.225288 to best_finetuned_model.pth

Epoch 38/1000
Training Loss: 0.97111551, Training R2: 0.241313
Validation Loss: 0.96907235, Validation R2: 0.206627

Epoch 39/1000
Training Loss: 0.96374399, Training R2: 0.246284
Validation Loss: 0.99248669, Validation R2: 0.219216

Epoch 40/1000
Training Loss: 1.00202030, Training R2: 0.204337
Validation Loss: 0.98253292, Validation R2: 0.246951
Saved best model with validation R2 0.246951 to best_finetuned_model.pth

Epoch 41/1000
Training Loss: 0.97346079, Training R2: 0.234329
Validation Loss: 0.97192309, Validation R2: 0.190510

Epoch 42/1000
Training Loss: 0.95561911, Training R2: 0.255198
Validation Loss: 0.96003520, Validation R2: 0.220842

Epoch 43/1000
Training Loss: 0.96800854, Training R2: 0.230610
Validation Loss: 0.95544257, Validation R2: 0.252436
Saved best model with validation R2 0.252436 to best_finetuned_model.pth

Epoch 44/1000
Training Loss: 0.96355833, Training R2: 0.248481
Validation Loss: 0.97101416, Validation R2: 0.191838

Epoch 45/1000
Training Loss: 0.95817601, Training R2: 0.246812
Validation Loss: 0.96367224, Validation R2: 0.233645

Epoch 46/1000
Training Loss: 0.93892562, Training R2: 0.270383
Validation Loss: 0.95479883, Validation R2: 0.251471

Epoch 47/1000
Training Loss: 0.94595619, Training R2: 0.266634
Validation Loss: 0.98577566, Validation R2: 0.247370

Epoch 48/1000
Training Loss: 0.94050796, Training R2: 0.273730
Validation Loss: 0.94601295, Validation R2: 0.230439

Epoch 49/1000
Training Loss: 0.94354308, Training R2: 0.259431
Validation Loss: 0.97745153, Validation R2: 0.240227

Epoch 50/1000
Training Loss: 0.94843560, Training R2: 0.266526
Validation Loss: 0.94553300, Validation R2: 0.246244

Epoch 51/1000
Training Loss: 0.95115224, Training R2: 0.262093
Validation Loss: 0.93890180, Validation R2: 0.240945

Epoch 52/1000
Training Loss: 0.94755715, Training R2: 0.264516
Validation Loss: 0.95356033, Validation R2: 0.234018

Epoch 53/1000
Training Loss: 0.92906897, Training R2: 0.284040
Validation Loss: 0.94217469, Validation R2: 0.257177
Saved best model with validation R2 0.257177 to best_finetuned_model.pth

Epoch 54/1000
Training Loss: 0.91213948, Training R2: 0.305438
Validation Loss: 0.97566269, Validation R2: 0.190214

Epoch 55/1000
Training Loss: 0.93123510, Training R2: 0.271995
Validation Loss: 0.99748435, Validation R2: 0.181790

Epoch 56/1000
Training Loss: 0.94237514, Training R2: 0.277933
Validation Loss: 0.94197518, Validation R2: 0.239930

Epoch 57/1000
Training Loss: 0.92935567, Training R2: 0.282456
Validation Loss: 0.93915104, Validation R2: 0.263181
Saved best model with validation R2 0.263181 to best_finetuned_model.pth

Epoch 58/1000
Training Loss: 0.93531652, Training R2: 0.272960
Validation Loss: 0.97195111, Validation R2: 0.178703

Epoch 59/1000
Training Loss: 0.92094395, Training R2: 0.292034
Validation Loss: 0.94565040, Validation R2: 0.236038

Epoch 60/1000
Training Loss: 0.91773485, Training R2: 0.290888
Validation Loss: 0.95886487, Validation R2: 0.243356

Epoch 61/1000
Training Loss: 0.91382792, Training R2: 0.307174
Validation Loss: 0.95062152, Validation R2: 0.265819
Saved best model with validation R2 0.265819 to best_finetuned_model.pth

Epoch 62/1000
Training Loss: 0.91757838, Training R2: 0.299999
Validation Loss: 0.95338823, Validation R2: 0.264210

Epoch 63/1000
Training Loss: 0.89900208, Training R2: 0.325619
Validation Loss: 0.93449294, Validation R2: 0.229581

Epoch 64/1000
Training Loss: 0.93725578, Training R2: 0.266991
Validation Loss: 0.93968206, Validation R2: 0.270152
Saved best model with validation R2 0.270152 to best_finetuned_model.pth

Epoch 65/1000
Training Loss: 0.90260927, Training R2: 0.320449
Validation Loss: 0.94755629, Validation R2: 0.229758

Epoch 66/1000
Training Loss: 0.88449754, Training R2: 0.335908
Validation Loss: 0.93484770, Validation R2: 0.254978

Epoch 67/1000
Training Loss: 0.88603676, Training R2: 0.342067
Validation Loss: 0.98678330, Validation R2: 0.138906

Epoch 68/1000
Training Loss: 0.91020008, Training R2: 0.309373
Validation Loss: 0.95196306, Validation R2: 0.205799

Epoch 69/1000
Training Loss: 0.90292750, Training R2: 0.320723
Validation Loss: 0.93446705, Validation R2: 0.260809

Epoch 70/1000
Training Loss: 0.89942186, Training R2: 0.316823
Validation Loss: 0.92818693, Validation R2: 0.278594
Saved best model with validation R2 0.278594 to best_finetuned_model.pth

Epoch 71/1000
Training Loss: 0.87372236, Training R2: 0.345522
Validation Loss: 0.92955289, Validation R2: 0.249821

Epoch 72/1000
Training Loss: 0.89145624, Training R2: 0.329446
Validation Loss: 0.96747381, Validation R2: 0.188465

Epoch 73/1000
Training Loss: 0.88258442, Training R2: 0.328654
Validation Loss: 0.94904141, Validation R2: 0.244288

Epoch 74/1000
Training Loss: 0.87209724, Training R2: 0.348152
Validation Loss: 0.93165815, Validation R2: 0.251441

Epoch 75/1000
Training Loss: 0.86637808, Training R2: 0.351639
Validation Loss: 0.93042231, Validation R2: 0.274934

Epoch 76/1000
Training Loss: 0.86020902, Training R2: 0.365391
Validation Loss: 0.96578531, Validation R2: 0.243928

Epoch 77/1000
Training Loss: 0.87804261, Training R2: 0.342739
Validation Loss: 0.94193329, Validation R2: 0.243243

Epoch 78/1000
Training Loss: 0.85340340, Training R2: 0.371997
Validation Loss: 0.92711012, Validation R2: 0.258327

Epoch 79/1000
Training Loss: 0.86182750, Training R2: 0.371414
Validation Loss: 0.92366416, Validation R2: 0.265884

Epoch 80/1000
Training Loss: 0.85596603, Training R2: 0.367614
Validation Loss: 0.93127353, Validation R2: 0.240417

Epoch 81/1000
Training Loss: 0.84385633, Training R2: 0.387775
Validation Loss: 1.00804364, Validation R2: 0.117691

Epoch 82/1000
Training Loss: 0.87644619, Training R2: 0.349962
Validation Loss: 0.93159258, Validation R2: 0.270364

Epoch 83/1000
Training Loss: 0.84513055, Training R2: 0.380089
Validation Loss: 0.94714403, Validation R2: 0.236581

Epoch 84/1000
Training Loss: 0.86436771, Training R2: 0.350522
Validation Loss: 0.95562897, Validation R2: 0.234326

Epoch 85/1000
Training Loss: 0.86606874, Training R2: 0.360140
Validation Loss: 0.95814364, Validation R2: 0.226498

Epoch 86/1000
Training Loss: 0.88089198, Training R2: 0.343496
Validation Loss: 0.94414300, Validation R2: 0.217447

Epoch 87/1000
Training Loss: 0.84531047, Training R2: 0.380690
Validation Loss: 0.93711231, Validation R2: 0.243541

Epoch 88/1000
Training Loss: 0.83431236, Training R2: 0.398639
Validation Loss: 0.93093691, Validation R2: 0.279902
Saved best model with validation R2 0.279902 to best_finetuned_model.pth

Epoch 89/1000
Training Loss: 0.84296655, Training R2: 0.383123
Validation Loss: 0.97636089, Validation R2: 0.230663

Epoch 90/1000
Training Loss: 0.86426944, Training R2: 0.359517
Validation Loss: 0.93699180, Validation R2: 0.260054

Epoch 91/1000
Training Loss: 0.82325422, Training R2: 0.401070
Validation Loss: 0.93865063, Validation R2: 0.225126

Epoch 92/1000
Training Loss: 0.82587177, Training R2: 0.405364
Validation Loss: 0.94585082, Validation R2: 0.215915

Epoch 93/1000
Training Loss: 0.80993771, Training R2: 0.412513
Validation Loss: 0.93652598, Validation R2: 0.233949

Epoch 94/1000
Training Loss: 0.79159813, Training R2: 0.437765
Validation Loss: 0.93034619, Validation R2: 0.244086

Epoch 95/1000
Training Loss: 0.82891057, Training R2: 0.402772
Validation Loss: 0.95182434, Validation R2: 0.196282

Epoch 96/1000
Training Loss: 0.82367547, Training R2: 0.406601
Validation Loss: 0.95093412, Validation R2: 0.236829

Epoch 97/1000
Training Loss: 0.80040095, Training R2: 0.430183
Validation Loss: 0.94794971, Validation R2: 0.232905

Epoch 98/1000
Training Loss: 0.79899633, Training R2: 0.430407
Validation Loss: 1.02593808, Validation R2: 0.172790

Epoch 99/1000
Training Loss: 0.80544006, Training R2: 0.432865
Validation Loss: 0.95118588, Validation R2: 0.236646

Epoch 100/1000
Training Loss: 0.78531767, Training R2: 0.449568
Validation Loss: 0.94758779, Validation R2: 0.226954

Epoch 101/1000
Training Loss: 0.77370183, Training R2: 0.456336
Validation Loss: 0.96925314, Validation R2: 0.214868

Epoch 102/1000
Training Loss: 0.80443764, Training R2: 0.428309
Validation Loss: 0.94003513, Validation R2: 0.257673

Epoch 103/1000
Training Loss: 0.78435867, Training R2: 0.447730
Validation Loss: 0.93174115, Validation R2: 0.252796

Epoch 104/1000
Training Loss: 0.77132053, Training R2: 0.464674
Validation Loss: 0.97496153, Validation R2: 0.156552

Epoch 105/1000
Training Loss: 0.76340229, Training R2: 0.470950
Validation Loss: 0.95781043, Validation R2: 0.218631

Epoch 106/1000
Training Loss: 0.81839018, Training R2: 0.416590
Validation Loss: 0.96401429, Validation R2: 0.206663

Epoch 107/1000
Training Loss: 0.81695670, Training R2: 0.418654
Validation Loss: 0.94347663, Validation R2: 0.234502

Epoch 108/1000
Training Loss: 0.76838102, Training R2: 0.469034
Validation Loss: 0.94290702, Validation R2: 0.219390

Epoch 109/1000
Epoch 00109: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.76562348, Training R2: 0.468545
Validation Loss: 0.95706679, Validation R2: 0.223353

Epoch 110/1000
学习率已减少 1 次
Training Loss: 0.73408802, Training R2: 0.498925
Validation Loss: 0.94861666, Validation R2: 0.223318

Epoch 111/1000
Training Loss: 0.70917723, Training R2: 0.520244
Validation Loss: 0.94542104, Validation R2: 0.223041

Epoch 112/1000
Training Loss: 0.71266694, Training R2: 0.521873
Validation Loss: 0.94945627, Validation R2: 0.218460

Epoch 113/1000
Training Loss: 0.69222398, Training R2: 0.535741
Validation Loss: 0.95565078, Validation R2: 0.207396

Epoch 114/1000
Training Loss: 0.70485368, Training R2: 0.524773
Validation Loss: 0.95909238, Validation R2: 0.195355

Epoch 115/1000
Training Loss: 0.69208223, Training R2: 0.539411
Validation Loss: 0.97934796, Validation R2: 0.174954

Epoch 116/1000
Training Loss: 0.69643393, Training R2: 0.537528
Validation Loss: 0.95444388, Validation R2: 0.208137

Epoch 117/1000
Training Loss: 0.68290832, Training R2: 0.554355
Validation Loss: 0.97041432, Validation R2: 0.181140

Epoch 118/1000
Training Loss: 0.68603154, Training R2: 0.546546
Validation Loss: 0.95399948, Validation R2: 0.216439

Epoch 119/1000
Training Loss: 0.67663387, Training R2: 0.559716
Validation Loss: 0.96863882, Validation R2: 0.172216

Epoch 120/1000
Training Loss: 0.68915266, Training R2: 0.542999
Validation Loss: 0.96796575, Validation R2: 0.179918

Epoch 121/1000
Training Loss: 0.69278795, Training R2: 0.542991
Validation Loss: 0.96648537, Validation R2: 0.173903

Epoch 122/1000
Training Loss: 0.67318940, Training R2: 0.558905
Validation Loss: 0.96924268, Validation R2: 0.196682

Epoch 123/1000
Training Loss: 0.66120440, Training R2: 0.569403
Validation Loss: 0.95869346, Validation R2: 0.200018

Epoch 124/1000
Training Loss: 0.64958913, Training R2: 0.583223
Validation Loss: 0.99014534, Validation R2: 0.148117

Epoch 125/1000
Training Loss: 0.66493898, Training R2: 0.567989
Validation Loss: 0.98718972, Validation R2: 0.173508

Epoch 126/1000
Training Loss: 0.69632334, Training R2: 0.544806
Validation Loss: 0.99266100, Validation R2: 0.134432

Epoch 127/1000
Training Loss: 0.66422969, Training R2: 0.573672
Validation Loss: 0.97457832, Validation R2: 0.188201

Epoch 128/1000
Training Loss: 0.65233907, Training R2: 0.585421
Validation Loss: 0.96559749, Validation R2: 0.182461

Epoch 129/1000
Training Loss: 0.67330172, Training R2: 0.571406
Validation Loss: 1.02383428, Validation R2: 0.090490

Epoch 130/1000
Epoch 00130: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.67419525, Training R2: 0.563627
Validation Loss: 0.97496680, Validation R2: 0.185038

Epoch 131/1000
学习率已减少 2 次
Training Loss: 0.62894952, Training R2: 0.605419
Validation Loss: 0.96961450, Validation R2: 0.165861

Epoch 132/1000
Training Loss: 0.61451671, Training R2: 0.619891
Validation Loss: 0.96957121, Validation R2: 0.178590

Epoch 133/1000
Training Loss: 0.60288773, Training R2: 0.626741
Validation Loss: 0.97432112, Validation R2: 0.180659

Epoch 134/1000
Training Loss: 0.59109956, Training R2: 0.633053
Validation Loss: 0.98256530, Validation R2: 0.158059

Epoch 135/1000
Training Loss: 0.57780459, Training R2: 0.644311
Validation Loss: 0.97360519, Validation R2: 0.183197

Epoch 136/1000
Training Loss: 0.57914989, Training R2: 0.643084
Validation Loss: 0.97731311, Validation R2: 0.174928

Epoch 137/1000
Training Loss: 0.57862061, Training R2: 0.641953
Validation Loss: 0.98154584, Validation R2: 0.164616

Epoch 138/1000
Training Loss: 0.56913377, Training R2: 0.650421
Validation Loss: 0.99609318, Validation R2: 0.142202

Epoch 139/1000
Training Loss: 0.57136111, Training R2: 0.651240
Validation Loss: 0.99830157, Validation R2: 0.145368

Epoch 140/1000
Training Loss: 0.56370480, Training R2: 0.657284
Validation Loss: 0.99099896, Validation R2: 0.150000

Epoch 141/1000
Training Loss: 0.55768725, Training R2: 0.662595
Validation Loss: 1.00042531, Validation R2: 0.133340

Epoch 142/1000
Training Loss: 0.56125074, Training R2: 0.663077
Validation Loss: 0.99266606, Validation R2: 0.144434

Epoch 143/1000
Training Loss: 0.54928193, Training R2: 0.668475
Validation Loss: 0.99853582, Validation R2: 0.131479

Epoch 144/1000
Training Loss: 0.55566365, Training R2: 0.663206
Validation Loss: 0.99622550, Validation R2: 0.142529

Epoch 145/1000
Training Loss: 0.54784546, Training R2: 0.670926
Validation Loss: 1.00064708, Validation R2: 0.129260

Epoch 146/1000
Training Loss: 0.54447278, Training R2: 0.674310
Validation Loss: 0.99217841, Validation R2: 0.150270

Epoch 147/1000
Training Loss: 0.54573024, Training R2: 0.672542
Validation Loss: 1.00041577, Validation R2: 0.137528

Epoch 148/1000
Training Loss: 0.53836516, Training R2: 0.680831
Validation Loss: 1.00412417, Validation R2: 0.135843

Epoch 149/1000
Training Loss: 0.53122744, Training R2: 0.685274
Validation Loss: 1.00164156, Validation R2: 0.139538

Epoch 150/1000
Training Loss: 0.52303685, Training R2: 0.690628
Validation Loss: 1.00566022, Validation R2: 0.136693

Epoch 151/1000
Epoch 00151: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.52283722, Training R2: 0.693304
Validation Loss: 1.01130810, Validation R2: 0.130649

Epoch 152/1000
学习率已减少 3 次
Training Loss: 0.50606866, Training R2: 0.702308
Validation Loss: 1.00717217, Validation R2: 0.127525

Epoch 153/1000
Training Loss: 0.49953619, Training R2: 0.703948
Validation Loss: 1.00832795, Validation R2: 0.127374

Epoch 154/1000
Training Loss: 0.49465761, Training R2: 0.705302
Validation Loss: 1.00044819, Validation R2: 0.139530

Epoch 155/1000
Training Loss: 0.48921902, Training R2: 0.709875
Validation Loss: 1.00954825, Validation R2: 0.122032

Epoch 156/1000
Training Loss: 0.48559613, Training R2: 0.710963
Validation Loss: 1.00642186, Validation R2: 0.125520

Epoch 157/1000
Training Loss: 0.48302411, Training R2: 0.713605
Validation Loss: 1.00898661, Validation R2: 0.117459

Epoch 158/1000
Training Loss: 0.48037487, Training R2: 0.716184
Validation Loss: 1.00759323, Validation R2: 0.125699

Epoch 159/1000
Training Loss: 0.47852228, Training R2: 0.714093
Validation Loss: 1.01367677, Validation R2: 0.114314

Epoch 160/1000
Training Loss: 0.47413383, Training R2: 0.718740
Validation Loss: 1.01634555, Validation R2: 0.117207

Epoch 161/1000
Training Loss: 0.47400677, Training R2: 0.717575
Validation Loss: 1.01352019, Validation R2: 0.118653

Epoch 162/1000
Training Loss: 0.47805328, Training R2: 0.720166
Validation Loss: 1.01027017, Validation R2: 0.122225

Epoch 163/1000
Training Loss: 0.47220359, Training R2: 0.720456
Validation Loss: 1.01195567, Validation R2: 0.121913

Epoch 164/1000
Training Loss: 0.47442823, Training R2: 0.721193
Validation Loss: 1.01247637, Validation R2: 0.122552

Epoch 165/1000
Training Loss: 0.47123706, Training R2: 0.722473
Validation Loss: 1.01708562, Validation R2: 0.114128

Epoch 166/1000
Training Loss: 0.46493107, Training R2: 0.724399
Validation Loss: 1.01410739, Validation R2: 0.110756

Epoch 167/1000
Training Loss: 0.46225503, Training R2: 0.727286
Validation Loss: 1.01252151, Validation R2: 0.116154

Epoch 168/1000
Training Loss: 0.46186329, Training R2: 0.728584
Validation Loss: 1.02076237, Validation R2: 0.104843

Epoch 169/1000
Training Loss: 0.46142949, Training R2: 0.729650
Validation Loss: 1.01636493, Validation R2: 0.114885

Epoch 170/1000
Training Loss: 0.45704455, Training R2: 0.733857
Validation Loss: 1.01972668, Validation R2: 0.100673

Epoch 171/1000
Training Loss: 0.45345012, Training R2: 0.732302
Validation Loss: 1.01891624, Validation R2: 0.106486

Epoch 172/1000
Epoch 00172: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.45662867, Training R2: 0.734737
Validation Loss: 1.01848993, Validation R2: 0.107502

Epoch 173/1000
学习率已减少 4 次
Training Loss: 0.44644986, Training R2: 0.737351
Validation Loss: 1.01874906, Validation R2: 0.106735

Epoch 174/1000
Training Loss: 0.44213138, Training R2: 0.738918
Validation Loss: 1.01980517, Validation R2: 0.103222

Epoch 175/1000
Training Loss: 0.44115170, Training R2: 0.737925
Validation Loss: 1.02008353, Validation R2: 0.109566

Epoch 176/1000
Training Loss: 0.43665375, Training R2: 0.742306
Validation Loss: 1.01983743, Validation R2: 0.106679

Epoch 177/1000
Training Loss: 0.43701615, Training R2: 0.740835
Validation Loss: 1.01901761, Validation R2: 0.102674

Epoch 178/1000
Training Loss: 0.43370373, Training R2: 0.741423
Validation Loss: 1.02130399, Validation R2: 0.102687

Epoch 179/1000
Training Loss: 0.43032722, Training R2: 0.743711
Validation Loss: 1.01752108, Validation R2: 0.108105

Epoch 180/1000
Training Loss: 0.42991600, Training R2: 0.745677
Validation Loss: 1.01926703, Validation R2: 0.104802

Epoch 181/1000
Training Loss: 0.42837014, Training R2: 0.744873
Validation Loss: 1.02551341, Validation R2: 0.098610

Epoch 182/1000
Training Loss: 0.42671425, Training R2: 0.746914
Validation Loss: 1.01976355, Validation R2: 0.102963

Epoch 183/1000
Training Loss: 0.42940020, Training R2: 0.745634
Validation Loss: 1.01944393, Validation R2: 0.104716

Epoch 184/1000
Training Loss: 0.42723867, Training R2: 0.746124
Validation Loss: 1.02388331, Validation R2: 0.097738

Epoch 185/1000
Training Loss: 0.42665417, Training R2: 0.748242
Validation Loss: 1.02166984, Validation R2: 0.102187

Epoch 186/1000
Training Loss: 0.42379569, Training R2: 0.749259
Validation Loss: 1.02224393, Validation R2: 0.100453

Epoch 187/1000
Training Loss: 0.42869349, Training R2: 0.746955
Validation Loss: 1.02315487, Validation R2: 0.099237

Epoch 188/1000
Training Loss: 0.42736846, Training R2: 0.749257
Validation Loss: 1.02801222, Validation R2: 0.096247

Epoch 189/1000
Training Loss: 0.42189016, Training R2: 0.751093
Validation Loss: 1.02182389, Validation R2: 0.100363

Epoch 190/1000
Training Loss: 0.42090782, Training R2: 0.750209
Validation Loss: 1.02058746, Validation R2: 0.101580

Epoch 191/1000
Training Loss: 0.41995665, Training R2: 0.751758
Validation Loss: 1.02613791, Validation R2: 0.100143

Epoch 192/1000
Training Loss: 0.41847459, Training R2: 0.752954
Validation Loss: 1.02412392, Validation R2: 0.097336

Epoch 193/1000
Epoch 00193: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.41615007, Training R2: 0.754444
Validation Loss: 1.02375279, Validation R2: 0.099637

Epoch 194/1000
学习率已减少 5 次
Training Loss: 0.41095286, Training R2: 0.754410
Validation Loss: 1.02443891, Validation R2: 0.094403

Epoch 195/1000
Training Loss: 0.41125757, Training R2: 0.753420
Validation Loss: 1.02609069, Validation R2: 0.095730

Epoch 196/1000
Training Loss: 0.41011962, Training R2: 0.755361
Validation Loss: 1.02436659, Validation R2: 0.096345

Epoch 197/1000
Training Loss: 0.40981564, Training R2: 0.755664
Validation Loss: 1.02481558, Validation R2: 0.095196

Epoch 198/1000
Training Loss: 0.40870190, Training R2: 0.756268
Validation Loss: 1.02622671, Validation R2: 0.094253

Epoch 199/1000
Training Loss: 0.40648300, Training R2: 0.757683
Validation Loss: 1.02503955, Validation R2: 0.095615

Epoch 200/1000
Training Loss: 0.40697252, Training R2: 0.756398
Validation Loss: 1.02459596, Validation R2: 0.096679

Epoch 201/1000
Training Loss: 0.40704030, Training R2: 0.757141
Validation Loss: 1.02542187, Validation R2: 0.095962

Epoch 202/1000
Training Loss: 0.40542823, Training R2: 0.757300
Validation Loss: 1.02528490, Validation R2: 0.095131

Epoch 203/1000
Training Loss: 0.40522569, Training R2: 0.757349
Validation Loss: 1.02790101, Validation R2: 0.094310

Epoch 204/1000
Training Loss: 0.40527242, Training R2: 0.759454
Validation Loss: 1.02565735, Validation R2: 0.097167

Epoch 205/1000
Training Loss: 0.40468744, Training R2: 0.757179
Validation Loss: 1.02511752, Validation R2: 0.093367

Epoch 206/1000
Training Loss: 0.40263233, Training R2: 0.760310
Validation Loss: 1.02593193, Validation R2: 0.095894

Epoch 207/1000
Training Loss: 0.40315634, Training R2: 0.757881
Validation Loss: 1.02397292, Validation R2: 0.096561

Epoch 208/1000
Training Loss: 0.40063676, Training R2: 0.760325
Validation Loss: 1.02558678, Validation R2: 0.096854

Epoch 209/1000
Training Loss: 0.40268193, Training R2: 0.759710
Validation Loss: 1.02549734, Validation R2: 0.095230

Epoch 210/1000
Training Loss: 0.40134620, Training R2: 0.760383
Validation Loss: 1.02630245, Validation R2: 0.094249

Epoch 211/1000
Training Loss: 0.40095827, Training R2: 0.758879
Validation Loss: 1.02609367, Validation R2: 0.093411

Epoch 212/1000
Training Loss: 0.40188230, Training R2: 0.759720
Validation Loss: 1.02473950, Validation R2: 0.095861

Epoch 213/1000
Training Loss: 0.40131306, Training R2: 0.760550
Validation Loss: 1.02500609, Validation R2: 0.097148

Epoch 214/1000
Epoch 00214: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.39913185, Training R2: 0.762453
Validation Loss: 1.02647958, Validation R2: 0.093460

Epoch 215/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
