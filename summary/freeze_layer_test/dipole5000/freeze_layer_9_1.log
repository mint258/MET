Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)
冻结层 9: lins.2 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Frozen
lins.2.bias: Frozen
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1026435

Epoch 1/1000
Training Loss: 1.40139212, Training R2: -0.443634
Validation Loss: 1.12452480, Validation R2: 0.073424
Saved best model with validation R2 0.073424 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.14127645, Training R2: 0.061614
Validation Loss: 1.12621336, Validation R2: -0.019945

Epoch 3/1000
Training Loss: 1.13887584, Training R2: 0.036925
Validation Loss: 1.10585234, Validation R2: 0.090118
Saved best model with validation R2 0.090118 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.12485732, Training R2: 0.072751
Validation Loss: 1.11061304, Validation R2: 0.095383
Saved best model with validation R2 0.095383 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.10952532, Training R2: 0.091378
Validation Loss: 1.08637826, Validation R2: 0.112514
Saved best model with validation R2 0.112514 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.10140751, Training R2: 0.106045
Validation Loss: 1.08246180, Validation R2: 0.120641
Saved best model with validation R2 0.120641 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 1.09534859, Training R2: 0.109407
Validation Loss: 1.08826005, Validation R2: 0.138513
Saved best model with validation R2 0.138513 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 1.09843191, Training R2: 0.101454
Validation Loss: 1.06424162, Validation R2: 0.154439
Saved best model with validation R2 0.154439 to best_finetuned_model.pth

Epoch 9/1000
Training Loss: 1.08494771, Training R2: 0.127297
Validation Loss: 1.07450786, Validation R2: 0.096058

Epoch 10/1000
Training Loss: 1.08022335, Training R2: 0.129353
Validation Loss: 1.05154379, Validation R2: 0.134721

Epoch 11/1000
Training Loss: 1.06246124, Training R2: 0.153258
Validation Loss: 1.05521260, Validation R2: 0.119416

Epoch 12/1000
Training Loss: 1.06847554, Training R2: 0.135417
Validation Loss: 1.18133877, Validation R2: 0.044096

Epoch 13/1000
Training Loss: 1.15739472, Training R2: 0.036014
Validation Loss: 1.13673608, Validation R2: -0.042495

Epoch 14/1000
Training Loss: 1.08906928, Training R2: 0.115610
Validation Loss: 1.04883377, Validation R2: 0.165234
Saved best model with validation R2 0.165234 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 1.06302266, Training R2: 0.150467
Validation Loss: 1.04283599, Validation R2: 0.189681
Saved best model with validation R2 0.189681 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 1.05661104, Training R2: 0.162512
Validation Loss: 1.05762569, Validation R2: 0.112259

Epoch 17/1000
Training Loss: 1.04908990, Training R2: 0.169196
Validation Loss: 1.03166320, Validation R2: 0.199521
Saved best model with validation R2 0.199521 to best_finetuned_model.pth

Epoch 18/1000
Training Loss: 1.02407111, Training R2: 0.198822
Validation Loss: 1.00927557, Validation R2: 0.209267
Saved best model with validation R2 0.209267 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 1.03122904, Training R2: 0.193502
Validation Loss: 0.98435682, Validation R2: 0.243173
Saved best model with validation R2 0.243173 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 1.07035587, Training R2: 0.134512
Validation Loss: 1.03832384, Validation R2: 0.163702

Epoch 21/1000
Training Loss: 1.04868457, Training R2: 0.175048
Validation Loss: 1.01714331, Validation R2: 0.176953

Epoch 22/1000
Training Loss: 1.01506085, Training R2: 0.208481
Validation Loss: 0.98159361, Validation R2: 0.248980
Saved best model with validation R2 0.248980 to best_finetuned_model.pth

Epoch 23/1000
Training Loss: 1.00812503, Training R2: 0.220414
Validation Loss: 1.01806391, Validation R2: 0.157453

Epoch 24/1000
Training Loss: 0.99023894, Training R2: 0.234667
Validation Loss: 0.94468522, Validation R2: 0.291578
Saved best model with validation R2 0.291578 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 0.97875280, Training R2: 0.245761
Validation Loss: 0.94832585, Validation R2: 0.301818
Saved best model with validation R2 0.301818 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 1.01350105, Training R2: 0.204292
Validation Loss: 1.00435642, Validation R2: 0.176040

Epoch 27/1000
Training Loss: 0.97715372, Training R2: 0.241153
Validation Loss: 0.94472871, Validation R2: 0.265389

Epoch 28/1000
Training Loss: 0.97257777, Training R2: 0.253913
Validation Loss: 0.94776855, Validation R2: 0.280824

Epoch 29/1000
Training Loss: 0.97327477, Training R2: 0.249326
Validation Loss: 1.01422737, Validation R2: 0.186477

Epoch 30/1000
Training Loss: 0.99079816, Training R2: 0.223499
Validation Loss: 0.94802495, Validation R2: 0.276507

Epoch 31/1000
Training Loss: 1.00590808, Training R2: 0.213935
Validation Loss: 0.96221831, Validation R2: 0.266528

Epoch 32/1000
Training Loss: 0.96649207, Training R2: 0.265550
Validation Loss: 0.93899160, Validation R2: 0.289610

Epoch 33/1000
Training Loss: 0.96317569, Training R2: 0.254763
Validation Loss: 0.92465872, Validation R2: 0.302038
Saved best model with validation R2 0.302038 to best_finetuned_model.pth

Epoch 34/1000
Training Loss: 0.94592791, Training R2: 0.280406
Validation Loss: 0.93422665, Validation R2: 0.280787

Epoch 35/1000
Training Loss: 0.92907778, Training R2: 0.295742
Validation Loss: 0.92878760, Validation R2: 0.298647

Epoch 36/1000
Training Loss: 0.92936870, Training R2: 0.300161
Validation Loss: 0.94308844, Validation R2: 0.269110

Epoch 37/1000
Training Loss: 0.93046869, Training R2: 0.296198
Validation Loss: 0.92238370, Validation R2: 0.297755

Epoch 38/1000
Training Loss: 0.92566498, Training R2: 0.301382
Validation Loss: 0.95845783, Validation R2: 0.282882

Epoch 39/1000
Training Loss: 1.01469935, Training R2: 0.198130
Validation Loss: 1.02182098, Validation R2: 0.122868

Epoch 40/1000
Training Loss: 0.95000784, Training R2: 0.274527
Validation Loss: 0.96660753, Validation R2: 0.232563

Epoch 41/1000
Training Loss: 0.93379241, Training R2: 0.294422
Validation Loss: 0.94976116, Validation R2: 0.249065

Epoch 42/1000
Training Loss: 0.90938455, Training R2: 0.311213
Validation Loss: 0.91853393, Validation R2: 0.303629
Saved best model with validation R2 0.303629 to best_finetuned_model.pth

Epoch 43/1000
Training Loss: 0.90489464, Training R2: 0.321976
Validation Loss: 0.91478090, Validation R2: 0.329725
Saved best model with validation R2 0.329725 to best_finetuned_model.pth

Epoch 44/1000
Training Loss: 0.92093120, Training R2: 0.309762
Validation Loss: 0.98060232, Validation R2: 0.204340

Epoch 45/1000
Training Loss: 0.95322627, Training R2: 0.258146
Validation Loss: 0.92341373, Validation R2: 0.293034

Epoch 46/1000
Training Loss: 0.91538376, Training R2: 0.307994
Validation Loss: 0.89169323, Validation R2: 0.353560
Saved best model with validation R2 0.353560 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.95126449, Training R2: 0.269682
Validation Loss: 0.91261981, Validation R2: 0.309165

Epoch 48/1000
Training Loss: 0.93338445, Training R2: 0.283960
Validation Loss: 0.93198216, Validation R2: 0.304225

Epoch 49/1000
Training Loss: 0.89907126, Training R2: 0.325176
Validation Loss: 0.88891144, Validation R2: 0.344064

Epoch 50/1000
Training Loss: 0.88718770, Training R2: 0.338103
Validation Loss: 0.88654327, Validation R2: 0.347969

Epoch 51/1000
Training Loss: 0.91000148, Training R2: 0.315528
Validation Loss: 0.90785349, Validation R2: 0.316975

Epoch 52/1000
Training Loss: 0.92630547, Training R2: 0.299139
Validation Loss: 0.90335130, Validation R2: 0.319728

Epoch 53/1000
Training Loss: 0.90849951, Training R2: 0.312021
Validation Loss: 0.92063088, Validation R2: 0.273916

Epoch 54/1000
Training Loss: 0.90875883, Training R2: 0.308648
Validation Loss: 0.91218242, Validation R2: 0.335702

Epoch 55/1000
Training Loss: 0.90000430, Training R2: 0.326706
Validation Loss: 0.92707077, Validation R2: 0.320169

Epoch 56/1000
Training Loss: 0.88449545, Training R2: 0.342900
Validation Loss: 0.90891192, Validation R2: 0.327213

Epoch 57/1000
Training Loss: 0.89388304, Training R2: 0.326547
Validation Loss: 0.89942723, Validation R2: 0.335077

Epoch 58/1000
Training Loss: 0.90330346, Training R2: 0.324878
Validation Loss: 0.87482317, Validation R2: 0.373245
Saved best model with validation R2 0.373245 to best_finetuned_model.pth

Epoch 59/1000
Training Loss: 0.88075142, Training R2: 0.339624
Validation Loss: 0.90557938, Validation R2: 0.325588

Epoch 60/1000
Training Loss: 0.90325774, Training R2: 0.314063
Validation Loss: 0.90070073, Validation R2: 0.316469

Epoch 61/1000
Training Loss: 0.87513991, Training R2: 0.349041
Validation Loss: 0.88165211, Validation R2: 0.346284

Epoch 62/1000
Training Loss: 0.86675259, Training R2: 0.362106
Validation Loss: 0.89433780, Validation R2: 0.328851

Epoch 63/1000
Training Loss: 0.87411052, Training R2: 0.345383
Validation Loss: 0.89275235, Validation R2: 0.319497

Epoch 64/1000
Training Loss: 0.86101001, Training R2: 0.364780
Validation Loss: 0.88139610, Validation R2: 0.342587

Epoch 65/1000
Training Loss: 0.87681720, Training R2: 0.351683
Validation Loss: 0.89811903, Validation R2: 0.323866

Epoch 66/1000
Training Loss: 0.86114961, Training R2: 0.357741
Validation Loss: 0.87361430, Validation R2: 0.356343

Epoch 67/1000
Training Loss: 0.84951153, Training R2: 0.377204
Validation Loss: 0.87865947, Validation R2: 0.338762

Epoch 68/1000
Training Loss: 0.84735487, Training R2: 0.375004
Validation Loss: 0.87615926, Validation R2: 0.358388

Epoch 69/1000
Training Loss: 0.86891514, Training R2: 0.350118
Validation Loss: 0.88242296, Validation R2: 0.350015

Epoch 70/1000
Training Loss: 0.85979266, Training R2: 0.363322
Validation Loss: 0.89961222, Validation R2: 0.304498

Epoch 71/1000
Training Loss: 0.85717939, Training R2: 0.364998
Validation Loss: 0.86846480, Validation R2: 0.350106

Epoch 72/1000
Training Loss: 0.83338166, Training R2: 0.397126
Validation Loss: 0.87924677, Validation R2: 0.338803

Epoch 73/1000
Training Loss: 0.85965726, Training R2: 0.369036
Validation Loss: 0.89358962, Validation R2: 0.326225

Epoch 74/1000
Training Loss: 0.84950553, Training R2: 0.375545
Validation Loss: 0.91874608, Validation R2: 0.267083

Epoch 75/1000
Training Loss: 0.83810666, Training R2: 0.391615
Validation Loss: 0.92721467, Validation R2: 0.280316

Epoch 76/1000
Training Loss: 0.83353207, Training R2: 0.390499
Validation Loss: 0.87373454, Validation R2: 0.343168

Epoch 77/1000
Training Loss: 0.82063089, Training R2: 0.402744
Validation Loss: 0.96476782, Validation R2: 0.197496

Epoch 78/1000
Training Loss: 0.88719925, Training R2: 0.333492
Validation Loss: 0.94676939, Validation R2: 0.298864

Epoch 79/1000
Epoch 00079: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.87191179, Training R2: 0.349742
Validation Loss: 0.88637212, Validation R2: 0.346317

Epoch 80/1000
学习率已减少 1 次
Training Loss: 0.82690954, Training R2: 0.396199
Validation Loss: 0.88949960, Validation R2: 0.316247

Epoch 81/1000
Training Loss: 0.79514147, Training R2: 0.427798
Validation Loss: 0.86954349, Validation R2: 0.360629

Epoch 82/1000
Training Loss: 0.77893982, Training R2: 0.444129
Validation Loss: 0.86394120, Validation R2: 0.361287

Epoch 83/1000
Training Loss: 0.77513723, Training R2: 0.445196
Validation Loss: 0.85042586, Validation R2: 0.378541
Saved best model with validation R2 0.378541 to best_finetuned_model.pth

Epoch 84/1000
Training Loss: 0.78097918, Training R2: 0.439873
Validation Loss: 0.87158412, Validation R2: 0.357369

Epoch 85/1000
Training Loss: 0.79076725, Training R2: 0.434717
Validation Loss: 0.86016338, Validation R2: 0.365315

Epoch 86/1000
Training Loss: 0.79032969, Training R2: 0.431436
Validation Loss: 0.87110214, Validation R2: 0.356094

Epoch 87/1000
Training Loss: 0.78566390, Training R2: 0.442189
Validation Loss: 0.85696953, Validation R2: 0.383014
Saved best model with validation R2 0.383014 to best_finetuned_model.pth

Epoch 88/1000
Training Loss: 0.75730576, Training R2: 0.470829
Validation Loss: 0.88350970, Validation R2: 0.325815

Epoch 89/1000
Training Loss: 0.75988438, Training R2: 0.464628
Validation Loss: 0.86637274, Validation R2: 0.364426

Epoch 90/1000
Training Loss: 0.76163685, Training R2: 0.465836
Validation Loss: 0.87740695, Validation R2: 0.347318

Epoch 91/1000
Training Loss: 0.76775298, Training R2: 0.454526
Validation Loss: 0.86213053, Validation R2: 0.366746

Epoch 92/1000
Training Loss: 0.76379445, Training R2: 0.463592
Validation Loss: 0.86374714, Validation R2: 0.362953

Epoch 93/1000
Training Loss: 0.74646418, Training R2: 0.483691
Validation Loss: 0.86372369, Validation R2: 0.365701

Epoch 94/1000
Training Loss: 0.73289289, Training R2: 0.491940
Validation Loss: 0.86555150, Validation R2: 0.356401

Epoch 95/1000
Training Loss: 0.73471465, Training R2: 0.493802
Validation Loss: 0.87612134, Validation R2: 0.352282

Epoch 96/1000
Training Loss: 0.73486123, Training R2: 0.492450
Validation Loss: 0.87936841, Validation R2: 0.350654

Epoch 97/1000
Training Loss: 0.75271569, Training R2: 0.477531
Validation Loss: 0.87458091, Validation R2: 0.358307

Epoch 98/1000
Training Loss: 0.72801779, Training R2: 0.502738
Validation Loss: 0.87699369, Validation R2: 0.344512

Epoch 99/1000
Training Loss: 0.71651999, Training R2: 0.510440
Validation Loss: 0.87138995, Validation R2: 0.347874

Epoch 100/1000
Training Loss: 0.72834577, Training R2: 0.495482
Validation Loss: 0.87521754, Validation R2: 0.357516

Epoch 101/1000
Training Loss: 0.70833081, Training R2: 0.524515
Validation Loss: 0.86845255, Validation R2: 0.353042

Epoch 102/1000
Training Loss: 0.70604829, Training R2: 0.521726
Validation Loss: 0.89421578, Validation R2: 0.317320

Epoch 103/1000
Training Loss: 0.69406419, Training R2: 0.538266
Validation Loss: 0.88786790, Validation R2: 0.332843

Epoch 104/1000
Training Loss: 0.71314364, Training R2: 0.515861
Validation Loss: 0.87135228, Validation R2: 0.352272

Epoch 105/1000
Training Loss: 0.71289480, Training R2: 0.517847
Validation Loss: 0.87662994, Validation R2: 0.344682

Epoch 106/1000
Training Loss: 0.71656637, Training R2: 0.516672
Validation Loss: 0.91201018, Validation R2: 0.312924

Epoch 107/1000
Training Loss: 0.71878102, Training R2: 0.513489
Validation Loss: 0.87954845, Validation R2: 0.347071

Epoch 108/1000
Epoch 00108: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.68831187, Training R2: 0.547078
Validation Loss: 0.90423913, Validation R2: 0.293959

Epoch 109/1000
学习率已减少 2 次
Training Loss: 0.68404784, Training R2: 0.549273
Validation Loss: 0.87935654, Validation R2: 0.346649

Epoch 110/1000
Training Loss: 0.65120659, Training R2: 0.571740
Validation Loss: 0.88070744, Validation R2: 0.338682

Epoch 111/1000
Training Loss: 0.63831043, Training R2: 0.581695
Validation Loss: 0.89001841, Validation R2: 0.322337

Epoch 112/1000
Training Loss: 0.63397281, Training R2: 0.587223
Validation Loss: 0.87699676, Validation R2: 0.337410

Epoch 113/1000
Training Loss: 0.63432769, Training R2: 0.585502
Validation Loss: 0.87124991, Validation R2: 0.345948

Epoch 114/1000
Training Loss: 0.62804991, Training R2: 0.593081
Validation Loss: 0.87758285, Validation R2: 0.337079

Epoch 115/1000
Training Loss: 0.62246458, Training R2: 0.594812
Validation Loss: 0.88821154, Validation R2: 0.320292

Epoch 116/1000
Training Loss: 0.62309535, Training R2: 0.596023
Validation Loss: 0.88038031, Validation R2: 0.345942

Epoch 117/1000
Training Loss: 0.61793840, Training R2: 0.600895
Validation Loss: 0.88528010, Validation R2: 0.334277

Epoch 118/1000
Training Loss: 0.62044430, Training R2: 0.601702
Validation Loss: 0.88018189, Validation R2: 0.341666

Epoch 119/1000
Training Loss: 0.62219911, Training R2: 0.598326
Validation Loss: 0.88945156, Validation R2: 0.324424

Epoch 120/1000
Training Loss: 0.61070392, Training R2: 0.610895
Validation Loss: 0.88919298, Validation R2: 0.331151

Epoch 121/1000
Training Loss: 0.60528881, Training R2: 0.610807
Validation Loss: 0.89108409, Validation R2: 0.317170

Epoch 122/1000
Training Loss: 0.60634963, Training R2: 0.609488
Validation Loss: 0.87840059, Validation R2: 0.333496

Epoch 123/1000
Training Loss: 0.60074039, Training R2: 0.614257
Validation Loss: 0.88694038, Validation R2: 0.328837

Epoch 124/1000
Training Loss: 0.59255738, Training R2: 0.624986
Validation Loss: 0.88762783, Validation R2: 0.329477

Epoch 125/1000
Training Loss: 0.59504572, Training R2: 0.626456
Validation Loss: 0.89529474, Validation R2: 0.305333

Epoch 126/1000
Training Loss: 0.59360040, Training R2: 0.624119
Validation Loss: 0.88908664, Validation R2: 0.324766

Epoch 127/1000
Training Loss: 0.59741628, Training R2: 0.621998
Validation Loss: 0.89801989, Validation R2: 0.305285

Epoch 128/1000
Training Loss: 0.58426611, Training R2: 0.633155
Validation Loss: 0.88367499, Validation R2: 0.332060

Epoch 129/1000
Epoch 00129: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.58475613, Training R2: 0.630093
Validation Loss: 0.88734961, Validation R2: 0.329798

Epoch 130/1000
学习率已减少 3 次
Training Loss: 0.56942538, Training R2: 0.640368
Validation Loss: 0.88896778, Validation R2: 0.325707

Epoch 131/1000
Training Loss: 0.55518069, Training R2: 0.650871
Validation Loss: 0.88999504, Validation R2: 0.314983

Epoch 132/1000
Training Loss: 0.55186793, Training R2: 0.657670
Validation Loss: 0.88906402, Validation R2: 0.321584

Epoch 133/1000
Training Loss: 0.54826384, Training R2: 0.656112
Validation Loss: 0.88624505, Validation R2: 0.325502

Epoch 134/1000
Training Loss: 0.54258669, Training R2: 0.660583
Validation Loss: 0.89451590, Validation R2: 0.313718

Epoch 135/1000
Training Loss: 0.54445455, Training R2: 0.661391
Validation Loss: 0.88228782, Validation R2: 0.331282

Epoch 136/1000
Training Loss: 0.54467564, Training R2: 0.660070
Validation Loss: 0.89752371, Validation R2: 0.309699

Epoch 137/1000
Training Loss: 0.53678759, Training R2: 0.663889
Validation Loss: 0.88328952, Validation R2: 0.326422

Epoch 138/1000
Training Loss: 0.53527984, Training R2: 0.664328
Validation Loss: 0.89381281, Validation R2: 0.309614

Epoch 139/1000
Training Loss: 0.53611040, Training R2: 0.663691
Validation Loss: 0.88486261, Validation R2: 0.326108

Epoch 140/1000
Training Loss: 0.53015304, Training R2: 0.671276
Validation Loss: 0.89642747, Validation R2: 0.308490

Epoch 141/1000
Training Loss: 0.52909915, Training R2: 0.669336
Validation Loss: 0.89463749, Validation R2: 0.315573

Epoch 142/1000
Training Loss: 0.52779740, Training R2: 0.672053
Validation Loss: 0.89472657, Validation R2: 0.313795

Epoch 143/1000
Training Loss: 0.52638708, Training R2: 0.673614
Validation Loss: 0.89836018, Validation R2: 0.312532

Epoch 144/1000
Training Loss: 0.52295521, Training R2: 0.675475
Validation Loss: 0.89431832, Validation R2: 0.313626

Epoch 145/1000
Training Loss: 0.52505752, Training R2: 0.674097
Validation Loss: 0.89495946, Validation R2: 0.312957

Epoch 146/1000
Training Loss: 0.52290826, Training R2: 0.675797
Validation Loss: 0.89434211, Validation R2: 0.309929

Epoch 147/1000
Training Loss: 0.52262487, Training R2: 0.676114
Validation Loss: 0.90186401, Validation R2: 0.297814

Epoch 148/1000
Training Loss: 0.52112562, Training R2: 0.678061
Validation Loss: 0.90437079, Validation R2: 0.303712

Epoch 149/1000
Training Loss: 0.51560649, Training R2: 0.681102
Validation Loss: 0.89207291, Validation R2: 0.317296

Epoch 150/1000
Epoch 00150: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.51461356, Training R2: 0.684093
Validation Loss: 0.89223325, Validation R2: 0.314865

Epoch 151/1000
学习率已减少 4 次
Training Loss: 0.50819827, Training R2: 0.687808
Validation Loss: 0.89373819, Validation R2: 0.312600

Epoch 152/1000
Training Loss: 0.50211498, Training R2: 0.689529
Validation Loss: 0.89248715, Validation R2: 0.319549

Epoch 153/1000
Training Loss: 0.50155621, Training R2: 0.690759
Validation Loss: 0.89277584, Validation R2: 0.313734

Epoch 154/1000
Training Loss: 0.49816394, Training R2: 0.693085
Validation Loss: 0.89416160, Validation R2: 0.310892

Epoch 155/1000
Training Loss: 0.49565351, Training R2: 0.693003
Validation Loss: 0.89612746, Validation R2: 0.315234

Epoch 156/1000
Training Loss: 0.49830480, Training R2: 0.690957
Validation Loss: 0.90165898, Validation R2: 0.300980

Epoch 157/1000
Training Loss: 0.49848611, Training R2: 0.691751
Validation Loss: 0.89387818, Validation R2: 0.310755

Epoch 158/1000
Training Loss: 0.49567205, Training R2: 0.692444
Validation Loss: 0.89368172, Validation R2: 0.312562

Epoch 159/1000
Training Loss: 0.49216794, Training R2: 0.696341
Validation Loss: 0.89715600, Validation R2: 0.306905

Epoch 160/1000
Training Loss: 0.49530952, Training R2: 0.694822
Validation Loss: 0.89693027, Validation R2: 0.310184

Epoch 161/1000
Training Loss: 0.48823370, Training R2: 0.697180
Validation Loss: 0.89806532, Validation R2: 0.310934

Epoch 162/1000
Training Loss: 0.48713782, Training R2: 0.697403
Validation Loss: 0.90071631, Validation R2: 0.300476

Epoch 163/1000
Training Loss: 0.48840954, Training R2: 0.697575
Validation Loss: 0.89841358, Validation R2: 0.308304

Epoch 164/1000
Training Loss: 0.48928729, Training R2: 0.699243
Validation Loss: 0.89471855, Validation R2: 0.310227

Epoch 165/1000
Training Loss: 0.48792495, Training R2: 0.697461
Validation Loss: 0.89729467, Validation R2: 0.306940

Epoch 166/1000
Training Loss: 0.48599210, Training R2: 0.699985
Validation Loss: 0.89467779, Validation R2: 0.311989

Epoch 167/1000
Training Loss: 0.48239711, Training R2: 0.702584
Validation Loss: 0.89852661, Validation R2: 0.303743

Epoch 168/1000
Training Loss: 0.48044550, Training R2: 0.702665
Validation Loss: 0.89813529, Validation R2: 0.309388

Epoch 169/1000
Training Loss: 0.48321497, Training R2: 0.702029
Validation Loss: 0.89827249, Validation R2: 0.306567

Epoch 170/1000
Training Loss: 0.47985347, Training R2: 0.703116
Validation Loss: 0.89989189, Validation R2: 0.305985

Epoch 171/1000
Epoch 00171: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.47859288, Training R2: 0.704852
Validation Loss: 0.89554315, Validation R2: 0.308479

Epoch 172/1000
学习率已减少 5 次
Training Loss: 0.47468672, Training R2: 0.704816
Validation Loss: 0.89650843, Validation R2: 0.309071

Epoch 173/1000
Training Loss: 0.47612267, Training R2: 0.705380
Validation Loss: 0.89917422, Validation R2: 0.305787

Epoch 174/1000
Training Loss: 0.47415242, Training R2: 0.706376
Validation Loss: 0.89753442, Validation R2: 0.306022

Epoch 175/1000
Training Loss: 0.47315316, Training R2: 0.706456
Validation Loss: 0.89864232, Validation R2: 0.303940

Epoch 176/1000
Training Loss: 0.47236477, Training R2: 0.706560
Validation Loss: 0.90160671, Validation R2: 0.299053

Epoch 177/1000
Training Loss: 0.47241340, Training R2: 0.707049
Validation Loss: 0.89655771, Validation R2: 0.308537

Epoch 178/1000
Training Loss: 0.47088567, Training R2: 0.708131
Validation Loss: 0.89916249, Validation R2: 0.304647

Epoch 179/1000
Training Loss: 0.46920621, Training R2: 0.708805
Validation Loss: 0.89884050, Validation R2: 0.304288

Epoch 180/1000
Training Loss: 0.46822321, Training R2: 0.708532
Validation Loss: 0.89851286, Validation R2: 0.305762

Epoch 181/1000
Training Loss: 0.46783133, Training R2: 0.709465
Validation Loss: 0.90056196, Validation R2: 0.302746

Epoch 182/1000
Training Loss: 0.46767585, Training R2: 0.709532
Validation Loss: 0.89823049, Validation R2: 0.304604

Epoch 183/1000
Training Loss: 0.46694047, Training R2: 0.709510
Validation Loss: 0.89860163, Validation R2: 0.305284

Epoch 184/1000
Training Loss: 0.46652206, Training R2: 0.710714
Validation Loss: 0.89820532, Validation R2: 0.304126

Epoch 185/1000
Training Loss: 0.46628167, Training R2: 0.710127
Validation Loss: 0.90026373, Validation R2: 0.301349

Epoch 186/1000
Training Loss: 0.46680128, Training R2: 0.709848
Validation Loss: 0.89832968, Validation R2: 0.307011

Epoch 187/1000
Training Loss: 0.46665768, Training R2: 0.709612
Validation Loss: 0.89967164, Validation R2: 0.303198

Epoch 188/1000
Training Loss: 0.46556837, Training R2: 0.711429
Validation Loss: 0.90190033, Validation R2: 0.300108

Epoch 189/1000
Training Loss: 0.46500693, Training R2: 0.711225
Validation Loss: 0.89811053, Validation R2: 0.305699

Epoch 190/1000
Training Loss: 0.46392832, Training R2: 0.711492
Validation Loss: 0.90178183, Validation R2: 0.300324

Epoch 191/1000
Training Loss: 0.46276775, Training R2: 0.713018
Validation Loss: 0.90079969, Validation R2: 0.299576

Epoch 192/1000
Epoch 00192: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.46888941, Training R2: 0.709664
Validation Loss: 0.90242748, Validation R2: 0.299566

Epoch 193/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
