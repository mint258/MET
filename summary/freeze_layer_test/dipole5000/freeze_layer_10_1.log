Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)
冻结层 9: lins.2 (Linear)
冻结层 10: encoder (Sequential)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Frozen
lins.2.bias: Frozen
encoder.0.weight: Frozen
encoder.0.bias: Frozen
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 993539

Epoch 1/1000
Training Loss: 1.40412390, Training R2: -0.452290
Validation Loss: 1.13048097, Validation R2: 0.072226
Saved best model with validation R2 0.072226 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.14186334, Training R2: 0.062383
Validation Loss: 1.11688645, Validation R2: 0.048664

Epoch 3/1000
Training Loss: 1.12673277, Training R2: 0.064388
Validation Loss: 1.11401852, Validation R2: 0.071274

Epoch 4/1000
Training Loss: 1.12105799, Training R2: 0.079138
Validation Loss: 1.11408236, Validation R2: 0.077938
Saved best model with validation R2 0.077938 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.11928180, Training R2: 0.077916
Validation Loss: 1.10129785, Validation R2: 0.091995
Saved best model with validation R2 0.091995 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.12187822, Training R2: 0.085034
Validation Loss: 1.11669590, Validation R2: 0.021563

Epoch 7/1000
Training Loss: 1.10960857, Training R2: 0.088473
Validation Loss: 1.09214757, Validation R2: 0.089361

Epoch 8/1000
Training Loss: 1.10654809, Training R2: 0.104253
Validation Loss: 1.14052691, Validation R2: -0.029215

Epoch 9/1000
Training Loss: 1.11203199, Training R2: 0.094535
Validation Loss: 1.09716677, Validation R2: 0.066666

Epoch 10/1000
Training Loss: 1.10836132, Training R2: 0.090988
Validation Loss: 1.08258262, Validation R2: 0.098690
Saved best model with validation R2 0.098690 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 1.10557241, Training R2: 0.100395
Validation Loss: 1.13432119, Validation R2: -0.015589

Epoch 12/1000
Training Loss: 1.10929210, Training R2: 0.082998
Validation Loss: 1.09544703, Validation R2: 0.091762

Epoch 13/1000
Training Loss: 1.09297331, Training R2: 0.105203
Validation Loss: 1.06709280, Validation R2: 0.137064
Saved best model with validation R2 0.137064 to best_finetuned_model.pth

Epoch 14/1000
Training Loss: 1.07939627, Training R2: 0.123930
Validation Loss: 1.06752236, Validation R2: 0.127052

Epoch 15/1000
Training Loss: 1.10046366, Training R2: 0.099891
Validation Loss: 1.11419418, Validation R2: 0.122055

Epoch 16/1000
Training Loss: 1.09112925, Training R2: 0.104475
Validation Loss: 1.06585240, Validation R2: 0.155398
Saved best model with validation R2 0.155398 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 1.06257339, Training R2: 0.146038
Validation Loss: 1.06807883, Validation R2: 0.137293

Epoch 18/1000
Training Loss: 1.05668822, Training R2: 0.156402
Validation Loss: 1.03843457, Validation R2: 0.189869
Saved best model with validation R2 0.189869 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 1.04311872, Training R2: 0.175144
Validation Loss: 1.02798756, Validation R2: 0.197919
Saved best model with validation R2 0.197919 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 1.06233402, Training R2: 0.145795
Validation Loss: 1.07943515, Validation R2: 0.163372

Epoch 21/1000
Training Loss: 1.05971652, Training R2: 0.160804
Validation Loss: 1.05560091, Validation R2: 0.117078

Epoch 22/1000
Training Loss: 1.06047801, Training R2: 0.149206
Validation Loss: 1.05225835, Validation R2: 0.111570

Epoch 23/1000
Training Loss: 1.03984336, Training R2: 0.172315
Validation Loss: 1.00189590, Validation R2: 0.216712
Saved best model with validation R2 0.216712 to best_finetuned_model.pth

Epoch 24/1000
Training Loss: 1.02080419, Training R2: 0.201052
Validation Loss: 1.00430968, Validation R2: 0.193131

Epoch 25/1000
Training Loss: 1.01130247, Training R2: 0.198067
Validation Loss: 0.99108505, Validation R2: 0.223673
Saved best model with validation R2 0.223673 to best_finetuned_model.pth

Epoch 26/1000
Training Loss: 1.05558426, Training R2: 0.145613
Validation Loss: 1.03214513, Validation R2: 0.154903

Epoch 27/1000
Training Loss: 1.03648511, Training R2: 0.169898
Validation Loss: 0.98241757, Validation R2: 0.239501
Saved best model with validation R2 0.239501 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 1.02069933, Training R2: 0.201081
Validation Loss: 0.96031977, Validation R2: 0.261031
Saved best model with validation R2 0.261031 to best_finetuned_model.pth

Epoch 29/1000
Training Loss: 1.05913366, Training R2: 0.154798
Validation Loss: 1.07524697, Validation R2: 0.042023

Epoch 30/1000
Training Loss: 1.11677559, Training R2: 0.052567
Validation Loss: 1.04280725, Validation R2: 0.145129

Epoch 31/1000
Training Loss: 1.05595334, Training R2: 0.168045
Validation Loss: 1.02356586, Validation R2: 0.191703

Epoch 32/1000
Training Loss: 1.01347536, Training R2: 0.210450
Validation Loss: 0.96169612, Validation R2: 0.264093
Saved best model with validation R2 0.264093 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 0.99432291, Training R2: 0.227728
Validation Loss: 0.96645579, Validation R2: 0.248195

Epoch 34/1000
Training Loss: 0.98895342, Training R2: 0.230564
Validation Loss: 0.95743537, Validation R2: 0.252215

Epoch 35/1000
Training Loss: 0.99054716, Training R2: 0.229348
Validation Loss: 0.97702739, Validation R2: 0.212536

Epoch 36/1000
Training Loss: 0.98755449, Training R2: 0.234748
Validation Loss: 0.96891204, Validation R2: 0.229280

Epoch 37/1000
Training Loss: 0.97725659, Training R2: 0.239630
Validation Loss: 0.97797145, Validation R2: 0.250090

Epoch 38/1000
Training Loss: 1.00544315, Training R2: 0.204627
Validation Loss: 0.96086386, Validation R2: 0.265937
Saved best model with validation R2 0.265937 to best_finetuned_model.pth

Epoch 39/1000
Training Loss: 0.97153943, Training R2: 0.235644
Validation Loss: 0.99835209, Validation R2: 0.249138

Epoch 40/1000
Training Loss: 1.02583535, Training R2: 0.192531
Validation Loss: 1.00756377, Validation R2: 0.233220

Epoch 41/1000
Training Loss: 1.00606201, Training R2: 0.216907
Validation Loss: 0.95799081, Validation R2: 0.241250

Epoch 42/1000
Training Loss: 0.96110257, Training R2: 0.262614
Validation Loss: 0.96011989, Validation R2: 0.244362

Epoch 43/1000
Training Loss: 0.97174138, Training R2: 0.252376
Validation Loss: 0.97374803, Validation R2: 0.221423

Epoch 44/1000
Training Loss: 0.97188209, Training R2: 0.246069
Validation Loss: 0.93364677, Validation R2: 0.288496
Saved best model with validation R2 0.288496 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.96184094, Training R2: 0.262901
Validation Loss: 0.95133575, Validation R2: 0.254971

Epoch 46/1000
Training Loss: 0.95541873, Training R2: 0.268805
Validation Loss: 0.93626601, Validation R2: 0.309500
Saved best model with validation R2 0.309500 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.95904201, Training R2: 0.258602
Validation Loss: 0.92512766, Validation R2: 0.300696

Epoch 48/1000
Training Loss: 0.94529508, Training R2: 0.280135
Validation Loss: 0.94867513, Validation R2: 0.282058

Epoch 49/1000
Training Loss: 0.94811800, Training R2: 0.266886
Validation Loss: 0.94455382, Validation R2: 0.292489

Epoch 50/1000
Training Loss: 0.95371088, Training R2: 0.271869
Validation Loss: 0.95283944, Validation R2: 0.239603

Epoch 51/1000
Training Loss: 0.96236183, Training R2: 0.243629
Validation Loss: 0.96719840, Validation R2: 0.214621

Epoch 52/1000
Training Loss: 0.96291929, Training R2: 0.259754
Validation Loss: 0.99857800, Validation R2: 0.192949

Epoch 53/1000
Training Loss: 0.97138629, Training R2: 0.251103
Validation Loss: 1.03493411, Validation R2: 0.118283

Epoch 54/1000
Training Loss: 0.98361903, Training R2: 0.226562
Validation Loss: 0.94567257, Validation R2: 0.276377

Epoch 55/1000
Training Loss: 0.96727206, Training R2: 0.254840
Validation Loss: 0.96415030, Validation R2: 0.208247

Epoch 56/1000
Training Loss: 0.93640502, Training R2: 0.281270
Validation Loss: 0.91685024, Validation R2: 0.308780

Epoch 57/1000
Training Loss: 0.92643195, Training R2: 0.297331
Validation Loss: 0.94237936, Validation R2: 0.274381

Epoch 58/1000
Training Loss: 0.94056663, Training R2: 0.283535
Validation Loss: 0.92263335, Validation R2: 0.313998
Saved best model with validation R2 0.313998 to best_finetuned_model.pth

Epoch 59/1000
Training Loss: 0.92602834, Training R2: 0.296065
Validation Loss: 0.91510064, Validation R2: 0.312440

Epoch 60/1000
Training Loss: 0.92374422, Training R2: 0.299521
Validation Loss: 0.93192176, Validation R2: 0.297763

Epoch 61/1000
Training Loss: 0.95992604, Training R2: 0.241535
Validation Loss: 0.94997149, Validation R2: 0.256730

Epoch 62/1000
Training Loss: 0.91424062, Training R2: 0.308112
Validation Loss: 0.89910403, Validation R2: 0.325423
Saved best model with validation R2 0.325423 to best_finetuned_model.pth

Epoch 63/1000
Training Loss: 0.90693535, Training R2: 0.310174
Validation Loss: 0.90917653, Validation R2: 0.306525

Epoch 64/1000
Training Loss: 0.89620706, Training R2: 0.329492
Validation Loss: 0.89814445, Validation R2: 0.323001

Epoch 65/1000
Training Loss: 0.90509570, Training R2: 0.316714
Validation Loss: 0.90460788, Validation R2: 0.327006
Saved best model with validation R2 0.327006 to best_finetuned_model.pth

Epoch 66/1000
Training Loss: 0.89994933, Training R2: 0.318566
Validation Loss: 0.91086584, Validation R2: 0.305397

Epoch 67/1000
Training Loss: 0.90848251, Training R2: 0.314845
Validation Loss: 0.90771395, Validation R2: 0.312196

Epoch 68/1000
Training Loss: 0.91150663, Training R2: 0.306866
Validation Loss: 0.90176558, Validation R2: 0.322807

Epoch 69/1000
Training Loss: 0.89135862, Training R2: 0.319343
Validation Loss: 0.91201145, Validation R2: 0.302664

Epoch 70/1000
Training Loss: 0.92808309, Training R2: 0.290706
Validation Loss: 0.90559115, Validation R2: 0.315471

Epoch 71/1000
Training Loss: 0.89073455, Training R2: 0.326563
Validation Loss: 0.92951566, Validation R2: 0.273726

Epoch 72/1000
Training Loss: 0.90870777, Training R2: 0.311931
Validation Loss: 0.90862769, Validation R2: 0.331749
Saved best model with validation R2 0.331749 to best_finetuned_model.pth

Epoch 73/1000
Training Loss: 0.88705426, Training R2: 0.335439
Validation Loss: 0.90078577, Validation R2: 0.320687

Epoch 74/1000
Training Loss: 0.88933996, Training R2: 0.330308
Validation Loss: 0.90793360, Validation R2: 0.308391

Epoch 75/1000
Training Loss: 0.89058468, Training R2: 0.339668
Validation Loss: 0.90383321, Validation R2: 0.303337

Epoch 76/1000
Training Loss: 0.89838868, Training R2: 0.317531
Validation Loss: 0.93602133, Validation R2: 0.236729

Epoch 77/1000
Training Loss: 0.89956248, Training R2: 0.317811
Validation Loss: 0.90761701, Validation R2: 0.318826

Epoch 78/1000
Training Loss: 0.87675760, Training R2: 0.351272
Validation Loss: 0.87646621, Validation R2: 0.342316
Saved best model with validation R2 0.342316 to best_finetuned_model.pth

Epoch 79/1000
Training Loss: 0.87382618, Training R2: 0.344521
Validation Loss: 0.88698242, Validation R2: 0.351407
Saved best model with validation R2 0.351407 to best_finetuned_model.pth

Epoch 80/1000
Training Loss: 0.86465992, Training R2: 0.362411
Validation Loss: 0.89264297, Validation R2: 0.341782

Epoch 81/1000
Training Loss: 0.85870708, Training R2: 0.365585
Validation Loss: 0.88110635, Validation R2: 0.356787
Saved best model with validation R2 0.356787 to best_finetuned_model.pth

Epoch 82/1000
Training Loss: 0.86575025, Training R2: 0.359491
Validation Loss: 0.92862239, Validation R2: 0.286722

Epoch 83/1000
Training Loss: 0.87781127, Training R2: 0.346431
Validation Loss: 0.87330513, Validation R2: 0.375594
Saved best model with validation R2 0.375594 to best_finetuned_model.pth

Epoch 84/1000
Training Loss: 0.87161554, Training R2: 0.347624
Validation Loss: 0.90657670, Validation R2: 0.318635

Epoch 85/1000
Training Loss: 0.86235738, Training R2: 0.361904
Validation Loss: 0.90889291, Validation R2: 0.318510

Epoch 86/1000
Training Loss: 0.84435391, Training R2: 0.383720
Validation Loss: 0.90479999, Validation R2: 0.298138

Epoch 87/1000
Training Loss: 0.83210462, Training R2: 0.394835
Validation Loss: 0.87223662, Validation R2: 0.346724

Epoch 88/1000
Training Loss: 0.81215053, Training R2: 0.415999
Validation Loss: 0.87322840, Validation R2: 0.364836

Epoch 89/1000
Training Loss: 0.81563985, Training R2: 0.409496
Validation Loss: 0.87965352, Validation R2: 0.317634

Epoch 90/1000
Training Loss: 0.82384404, Training R2: 0.404361
Validation Loss: 0.88496737, Validation R2: 0.359749

Epoch 91/1000
Training Loss: 0.83048994, Training R2: 0.402600
Validation Loss: 0.89274257, Validation R2: 0.319206

Epoch 92/1000
Training Loss: 0.81444812, Training R2: 0.417581
Validation Loss: 0.86604745, Validation R2: 0.368189

Epoch 93/1000
Training Loss: 0.79975766, Training R2: 0.433301
Validation Loss: 0.89896425, Validation R2: 0.302098

Epoch 94/1000
Training Loss: 0.83210185, Training R2: 0.402640
Validation Loss: 0.90570830, Validation R2: 0.321041

Epoch 95/1000
Training Loss: 0.80992317, Training R2: 0.425932
Validation Loss: 0.87653585, Validation R2: 0.359497

Epoch 96/1000
Training Loss: 0.80928600, Training R2: 0.419219
Validation Loss: 0.87974282, Validation R2: 0.352634

Epoch 97/1000
Training Loss: 0.80929612, Training R2: 0.428491
Validation Loss: 0.86819039, Validation R2: 0.378034
Saved best model with validation R2 0.378034 to best_finetuned_model.pth

Epoch 98/1000
Training Loss: 0.79980118, Training R2: 0.431722
Validation Loss: 0.89658387, Validation R2: 0.319277

Epoch 99/1000
Training Loss: 0.80022512, Training R2: 0.430897
Validation Loss: 0.86651394, Validation R2: 0.366027

Epoch 100/1000
Training Loss: 0.78252506, Training R2: 0.448517
Validation Loss: 0.86594416, Validation R2: 0.362086

Epoch 101/1000
Training Loss: 0.79113430, Training R2: 0.444119
Validation Loss: 0.89346391, Validation R2: 0.342229

Epoch 102/1000
Training Loss: 0.78894972, Training R2: 0.445821
Validation Loss: 0.85394755, Validation R2: 0.387217
Saved best model with validation R2 0.387217 to best_finetuned_model.pth

Epoch 103/1000
Training Loss: 0.80224999, Training R2: 0.429756
Validation Loss: 0.89629323, Validation R2: 0.335579

Epoch 104/1000
Training Loss: 0.78756652, Training R2: 0.448192
Validation Loss: 0.87998912, Validation R2: 0.338171

Epoch 105/1000
Training Loss: 0.81712522, Training R2: 0.409586
Validation Loss: 0.86846894, Validation R2: 0.353111

Epoch 106/1000
Training Loss: 0.78083259, Training R2: 0.453261
Validation Loss: 0.87870066, Validation R2: 0.338319

Epoch 107/1000
Training Loss: 0.77947920, Training R2: 0.463063
Validation Loss: 0.85876870, Validation R2: 0.371989

Epoch 108/1000
Training Loss: 0.78508333, Training R2: 0.442290
Validation Loss: 0.88257009, Validation R2: 0.320776

Epoch 109/1000
Training Loss: 0.77717420, Training R2: 0.464795
Validation Loss: 0.91109753, Validation R2: 0.312014

Epoch 110/1000
Training Loss: 0.76779857, Training R2: 0.470374
Validation Loss: 0.88459878, Validation R2: 0.345383

Epoch 111/1000
Training Loss: 0.74400170, Training R2: 0.493022
Validation Loss: 0.89517043, Validation R2: 0.304283

Epoch 112/1000
Training Loss: 0.74658055, Training R2: 0.487808
Validation Loss: 0.84934254, Validation R2: 0.389556
Saved best model with validation R2 0.389556 to best_finetuned_model.pth

Epoch 113/1000
Training Loss: 0.71643536, Training R2: 0.520743
Validation Loss: 0.85030610, Validation R2: 0.374581

Epoch 114/1000
Training Loss: 0.72313118, Training R2: 0.510153
Validation Loss: 0.86121676, Validation R2: 0.366369

Epoch 115/1000
Training Loss: 0.71420483, Training R2: 0.525641
Validation Loss: 0.85647308, Validation R2: 0.367683

Epoch 116/1000
Training Loss: 0.70807511, Training R2: 0.524937
Validation Loss: 0.88347617, Validation R2: 0.332478

Epoch 117/1000
Training Loss: 0.71132140, Training R2: 0.530399
Validation Loss: 0.88596033, Validation R2: 0.317087

Epoch 118/1000
Training Loss: 0.70372079, Training R2: 0.532811
Validation Loss: 0.87298271, Validation R2: 0.333435

Epoch 119/1000
Training Loss: 0.71491631, Training R2: 0.521490
Validation Loss: 0.87773504, Validation R2: 0.341650

Epoch 120/1000
Training Loss: 0.74027064, Training R2: 0.498672
Validation Loss: 0.89935785, Validation R2: 0.309310

Epoch 121/1000
Training Loss: 0.70322738, Training R2: 0.528575
Validation Loss: 0.86667517, Validation R2: 0.347984

Epoch 122/1000
Training Loss: 0.70213901, Training R2: 0.537685
Validation Loss: 0.86116444, Validation R2: 0.368349

Epoch 123/1000
Training Loss: 0.67330467, Training R2: 0.561237
Validation Loss: 0.86129825, Validation R2: 0.364623

Epoch 124/1000
Training Loss: 0.66460642, Training R2: 0.568681
Validation Loss: 0.86054926, Validation R2: 0.362849

Epoch 125/1000
Training Loss: 0.67792676, Training R2: 0.562759
Validation Loss: 0.91013306, Validation R2: 0.296022

Epoch 126/1000
Training Loss: 0.70223054, Training R2: 0.539765
Validation Loss: 0.85946708, Validation R2: 0.366130

Epoch 127/1000
Training Loss: 0.71662379, Training R2: 0.529699
Validation Loss: 0.91428630, Validation R2: 0.312964

Epoch 128/1000
Training Loss: 0.68978743, Training R2: 0.552655
Validation Loss: 0.85171784, Validation R2: 0.387567

Epoch 129/1000
Training Loss: 0.68717821, Training R2: 0.568364
Validation Loss: 0.88724043, Validation R2: 0.318036

Epoch 130/1000
Training Loss: 0.67355959, Training R2: 0.569066
Validation Loss: 0.89186527, Validation R2: 0.296834

Epoch 131/1000
Training Loss: 0.66124797, Training R2: 0.579964
Validation Loss: 0.86609431, Validation R2: 0.359893

Epoch 132/1000
Training Loss: 0.64966438, Training R2: 0.591402
Validation Loss: 0.86585730, Validation R2: 0.351355

Epoch 133/1000
Epoch 00133: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.63680729, Training R2: 0.603882
Validation Loss: 0.87240152, Validation R2: 0.345333

Epoch 134/1000
学习率已减少 1 次
Training Loss: 0.62689992, Training R2: 0.612054
Validation Loss: 0.86866300, Validation R2: 0.348057

Epoch 135/1000
Training Loss: 0.58576170, Training R2: 0.645843
Validation Loss: 0.86330315, Validation R2: 0.348100

Epoch 136/1000
Training Loss: 0.57437345, Training R2: 0.650600
Validation Loss: 0.87872872, Validation R2: 0.337447

Epoch 137/1000
Training Loss: 0.56352080, Training R2: 0.662237
Validation Loss: 0.87358495, Validation R2: 0.333186

Epoch 138/1000
Training Loss: 0.56296889, Training R2: 0.667512
Validation Loss: 0.86416597, Validation R2: 0.353657

Epoch 139/1000
Training Loss: 0.56976859, Training R2: 0.661340
Validation Loss: 0.90556440, Validation R2: 0.298230

Epoch 140/1000
Training Loss: 0.55108515, Training R2: 0.677382
Validation Loss: 0.87372992, Validation R2: 0.341025

Epoch 141/1000
Training Loss: 0.55313045, Training R2: 0.680925
Validation Loss: 0.88315641, Validation R2: 0.324210

Epoch 142/1000
Training Loss: 0.54517982, Training R2: 0.682777
Validation Loss: 0.88716053, Validation R2: 0.307537

Epoch 143/1000
Training Loss: 0.54371153, Training R2: 0.686519
Validation Loss: 0.87569855, Validation R2: 0.332653

Epoch 144/1000
Training Loss: 0.53048791, Training R2: 0.701307
Validation Loss: 0.88700904, Validation R2: 0.305964

Epoch 145/1000
Training Loss: 0.52573981, Training R2: 0.704789
Validation Loss: 0.87204298, Validation R2: 0.317088

Epoch 146/1000
Training Loss: 0.52186210, Training R2: 0.711490
Validation Loss: 0.88730063, Validation R2: 0.307362

Epoch 147/1000
Training Loss: 0.52407919, Training R2: 0.703640
Validation Loss: 0.88630641, Validation R2: 0.307101

Epoch 148/1000
Training Loss: 0.50566957, Training R2: 0.719312
Validation Loss: 0.88199688, Validation R2: 0.309544

Epoch 149/1000
Training Loss: 0.50396585, Training R2: 0.720877
Validation Loss: 0.88505677, Validation R2: 0.308277

Epoch 150/1000
Training Loss: 0.49156083, Training R2: 0.728398
Validation Loss: 0.88720149, Validation R2: 0.307923

Epoch 151/1000
Training Loss: 0.49002972, Training R2: 0.732469
Validation Loss: 0.88106814, Validation R2: 0.314609

Epoch 152/1000
Training Loss: 0.49500708, Training R2: 0.733901
Validation Loss: 0.87412743, Validation R2: 0.324712

Epoch 153/1000
Training Loss: 0.50333904, Training R2: 0.724675
Validation Loss: 0.87825689, Validation R2: 0.326291

Epoch 154/1000
Epoch 00154: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.49727889, Training R2: 0.730866
Validation Loss: 0.89029357, Validation R2: 0.306941

Epoch 155/1000
学习率已减少 2 次
Training Loss: 0.45889376, Training R2: 0.755048
Validation Loss: 0.89338888, Validation R2: 0.304556

Epoch 156/1000
Training Loss: 0.43671099, Training R2: 0.770147
Validation Loss: 0.88817882, Validation R2: 0.312657

Epoch 157/1000
Training Loss: 0.42204988, Training R2: 0.777764
Validation Loss: 0.89529931, Validation R2: 0.299738

Epoch 158/1000
Training Loss: 0.41913238, Training R2: 0.778434
Validation Loss: 0.89235364, Validation R2: 0.299398

Epoch 159/1000
Training Loss: 0.41139321, Training R2: 0.784107
Validation Loss: 0.89929889, Validation R2: 0.291151

Epoch 160/1000
Training Loss: 0.40792460, Training R2: 0.786272
Validation Loss: 0.89758608, Validation R2: 0.299752

Epoch 161/1000
Training Loss: 0.41201307, Training R2: 0.786287
Validation Loss: 0.89179950, Validation R2: 0.306706

Epoch 162/1000
Training Loss: 0.41059440, Training R2: 0.789015
Validation Loss: 0.90605989, Validation R2: 0.279431

Epoch 163/1000
Training Loss: 0.40305291, Training R2: 0.794478
Validation Loss: 0.89434247, Validation R2: 0.303809

Epoch 164/1000
Training Loss: 0.39446100, Training R2: 0.799337
Validation Loss: 0.89003571, Validation R2: 0.306734

Epoch 165/1000
Training Loss: 0.39572293, Training R2: 0.798018
Validation Loss: 0.89963322, Validation R2: 0.298058

Epoch 166/1000
Training Loss: 0.39533133, Training R2: 0.797876
Validation Loss: 0.90139619, Validation R2: 0.285753

Epoch 167/1000
Training Loss: 0.38637452, Training R2: 0.803271
Validation Loss: 0.90263591, Validation R2: 0.285550

Epoch 168/1000
Training Loss: 0.38461913, Training R2: 0.805201
Validation Loss: 0.91330795, Validation R2: 0.274034

Epoch 169/1000
Training Loss: 0.39141817, Training R2: 0.804314
Validation Loss: 0.89638628, Validation R2: 0.294830

Epoch 170/1000
Training Loss: 0.39306497, Training R2: 0.806490
Validation Loss: 0.90714902, Validation R2: 0.288981

Epoch 171/1000
Training Loss: 0.40842372, Training R2: 0.793247
Validation Loss: 0.89658888, Validation R2: 0.293066

Epoch 172/1000
Training Loss: 0.38855268, Training R2: 0.808232
Validation Loss: 0.90082064, Validation R2: 0.295904

Epoch 173/1000
Training Loss: 0.37178136, Training R2: 0.816220
Validation Loss: 0.90783668, Validation R2: 0.280034

Epoch 174/1000
Training Loss: 0.37689039, Training R2: 0.811813
Validation Loss: 0.90000279, Validation R2: 0.297734

Epoch 175/1000
Epoch 00175: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.37606650, Training R2: 0.816580
Validation Loss: 0.90069175, Validation R2: 0.294647

Epoch 176/1000
学习率已减少 3 次
Training Loss: 0.35814193, Training R2: 0.824038
Validation Loss: 0.90414073, Validation R2: 0.288043

Epoch 177/1000
Training Loss: 0.35125626, Training R2: 0.826662
Validation Loss: 0.90828820, Validation R2: 0.278249

Epoch 178/1000
Training Loss: 0.35014132, Training R2: 0.827002
Validation Loss: 0.90820197, Validation R2: 0.279260

Epoch 179/1000
Training Loss: 0.34085607, Training R2: 0.830491
Validation Loss: 0.90386121, Validation R2: 0.286967

Epoch 180/1000
Training Loss: 0.34106266, Training R2: 0.830932
Validation Loss: 0.90746377, Validation R2: 0.281391

Epoch 181/1000
Training Loss: 0.33506377, Training R2: 0.833352
Validation Loss: 0.91074405, Validation R2: 0.278342

Epoch 182/1000
Training Loss: 0.32884001, Training R2: 0.836796
Validation Loss: 0.91231017, Validation R2: 0.275134

Epoch 183/1000
Training Loss: 0.33020009, Training R2: 0.836851
Validation Loss: 0.90975626, Validation R2: 0.279705

Epoch 184/1000
Training Loss: 0.32487408, Training R2: 0.837207
Validation Loss: 0.90770026, Validation R2: 0.284018

Epoch 185/1000
Training Loss: 0.32087356, Training R2: 0.840038
Validation Loss: 0.91002177, Validation R2: 0.279027

Epoch 186/1000
Training Loss: 0.32656914, Training R2: 0.837466
Validation Loss: 0.90721788, Validation R2: 0.280951

Epoch 187/1000
Training Loss: 0.32200580, Training R2: 0.840379
Validation Loss: 0.91075104, Validation R2: 0.278810

Epoch 188/1000
Training Loss: 0.32065516, Training R2: 0.842711
Validation Loss: 0.90541350, Validation R2: 0.285498

Epoch 189/1000
Training Loss: 0.31984374, Training R2: 0.840610
Validation Loss: 0.91816879, Validation R2: 0.264509

Epoch 190/1000
Training Loss: 0.31549322, Training R2: 0.842723
Validation Loss: 0.91420976, Validation R2: 0.269072

Epoch 191/1000
Training Loss: 0.31406195, Training R2: 0.844168
Validation Loss: 0.91365802, Validation R2: 0.273719

Epoch 192/1000
Training Loss: 0.31069553, Training R2: 0.845075
Validation Loss: 0.91406630, Validation R2: 0.273999

Epoch 193/1000
Training Loss: 0.30949608, Training R2: 0.846800
Validation Loss: 0.91326325, Validation R2: 0.272634

Epoch 194/1000
Training Loss: 0.31269114, Training R2: 0.845555
Validation Loss: 0.91294124, Validation R2: 0.273381

Epoch 195/1000
Training Loss: 0.31072672, Training R2: 0.846816
Validation Loss: 0.91327345, Validation R2: 0.273773

Epoch 196/1000
Epoch 00196: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.30626180, Training R2: 0.850117
Validation Loss: 0.91681351, Validation R2: 0.267491

Epoch 197/1000
学习率已减少 4 次
Training Loss: 0.29883708, Training R2: 0.852042
Validation Loss: 0.91211467, Validation R2: 0.277493

Epoch 198/1000
Training Loss: 0.29243202, Training R2: 0.853231
Validation Loss: 0.91775612, Validation R2: 0.270250

Epoch 199/1000
Training Loss: 0.28997253, Training R2: 0.853843
Validation Loss: 0.91662021, Validation R2: 0.271030

Epoch 200/1000
Training Loss: 0.28893116, Training R2: 0.854314
Validation Loss: 0.91357050, Validation R2: 0.275617

Epoch 201/1000
Training Loss: 0.29012438, Training R2: 0.853026
Validation Loss: 0.91623949, Validation R2: 0.271465

Epoch 202/1000
Training Loss: 0.29053887, Training R2: 0.853482
Validation Loss: 0.91373429, Validation R2: 0.275489

Epoch 203/1000
Training Loss: 0.28966682, Training R2: 0.855115
Validation Loss: 0.91171016, Validation R2: 0.278766

Epoch 204/1000
Training Loss: 0.28773848, Training R2: 0.854415
Validation Loss: 0.91611805, Validation R2: 0.271942

Epoch 205/1000
Training Loss: 0.28527133, Training R2: 0.856161
Validation Loss: 0.91518919, Validation R2: 0.271431

Epoch 206/1000
Training Loss: 0.28363654, Training R2: 0.857453
Validation Loss: 0.91531334, Validation R2: 0.272740

Epoch 207/1000
Training Loss: 0.28278995, Training R2: 0.856444
Validation Loss: 0.91606530, Validation R2: 0.273226

Epoch 208/1000
Training Loss: 0.28215592, Training R2: 0.855140
Validation Loss: 0.91524825, Validation R2: 0.272784

Epoch 209/1000
Training Loss: 0.28289015, Training R2: 0.857789
Validation Loss: 0.91754831, Validation R2: 0.268928

Epoch 210/1000
Training Loss: 0.27966095, Training R2: 0.858614
Validation Loss: 0.91604266, Validation R2: 0.273708

Epoch 211/1000
Training Loss: 0.28025929, Training R2: 0.857212
Validation Loss: 0.92041842, Validation R2: 0.267554

Epoch 212/1000
Training Loss: 0.27889303, Training R2: 0.857165
Validation Loss: 0.91657857, Validation R2: 0.270847

Epoch 213/1000
Training Loss: 0.28207624, Training R2: 0.859447
Validation Loss: 0.92007845, Validation R2: 0.266425

Epoch 214/1000
Training Loss: 0.28284901, Training R2: 0.858581
Validation Loss: 0.91892108, Validation R2: 0.268025

Epoch 215/1000
Training Loss: 0.27689728, Training R2: 0.860214
Validation Loss: 0.91943240, Validation R2: 0.268172

Epoch 216/1000
Training Loss: 0.27418821, Training R2: 0.861154
Validation Loss: 0.91960699, Validation R2: 0.267353

Epoch 217/1000
Epoch 00217: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.27940329, Training R2: 0.859076
Validation Loss: 0.91965777, Validation R2: 0.266962

Epoch 218/1000
学习率已减少 5 次
Training Loss: 0.27221710, Training R2: 0.862382
Validation Loss: 0.91809492, Validation R2: 0.269042

Epoch 219/1000
Training Loss: 0.27167256, Training R2: 0.861041
Validation Loss: 0.91762665, Validation R2: 0.270531

Epoch 220/1000
Training Loss: 0.26813504, Training R2: 0.863053
Validation Loss: 0.91841848, Validation R2: 0.269609

Epoch 221/1000
Training Loss: 0.26762122, Training R2: 0.863351
Validation Loss: 0.91977777, Validation R2: 0.265828

Epoch 222/1000
Training Loss: 0.26773351, Training R2: 0.861546
Validation Loss: 0.92035734, Validation R2: 0.265862

Epoch 223/1000
Training Loss: 0.26710298, Training R2: 0.863651
Validation Loss: 0.92039878, Validation R2: 0.267012

Epoch 224/1000
Training Loss: 0.26715272, Training R2: 0.862543
Validation Loss: 0.91996066, Validation R2: 0.265567

Epoch 225/1000
Training Loss: 0.26603218, Training R2: 0.863951
Validation Loss: 0.92054396, Validation R2: 0.265135

Epoch 226/1000
Training Loss: 0.26600451, Training R2: 0.862296
Validation Loss: 0.92109916, Validation R2: 0.264657

Epoch 227/1000
Training Loss: 0.26576089, Training R2: 0.862727
Validation Loss: 0.92145765, Validation R2: 0.264468

Epoch 228/1000
Training Loss: 0.26456120, Training R2: 0.863729
Validation Loss: 0.91939896, Validation R2: 0.268061

Epoch 229/1000
Training Loss: 0.26569141, Training R2: 0.863822
Validation Loss: 0.92028516, Validation R2: 0.266336

Epoch 230/1000
Training Loss: 0.26439364, Training R2: 0.864530
Validation Loss: 0.92037820, Validation R2: 0.265635

Epoch 231/1000
Training Loss: 0.26542777, Training R2: 0.862595
Validation Loss: 0.91926335, Validation R2: 0.268014

Epoch 232/1000
Training Loss: 0.26427743, Training R2: 0.862837
Validation Loss: 0.92205497, Validation R2: 0.264141

Epoch 233/1000
Training Loss: 0.26278911, Training R2: 0.865129
Validation Loss: 0.92057025, Validation R2: 0.265444

Epoch 234/1000
Training Loss: 0.26175624, Training R2: 0.864102
Validation Loss: 0.92236740, Validation R2: 0.263600

Epoch 235/1000
Training Loss: 0.26319556, Training R2: 0.863272
Validation Loss: 0.92096805, Validation R2: 0.265757

Epoch 236/1000
Training Loss: 0.26101408, Training R2: 0.865304
Validation Loss: 0.92155925, Validation R2: 0.264915

Epoch 237/1000
Training Loss: 0.26010881, Training R2: 0.865570
Validation Loss: 0.92202254, Validation R2: 0.264020

Epoch 238/1000
Epoch 00238: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.25910378, Training R2: 0.867058
Validation Loss: 0.92094093, Validation R2: 0.266341

Epoch 239/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
