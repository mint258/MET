Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Trainable
lins.1.bias: Trainable
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1158019

Epoch 1/1000
Training Loss: 1.24915872, Training R2: -0.122045
Validation Loss: 1.19962462, Validation R2: -0.027672
Saved best model with validation R2 -0.027672 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.17095780, Training R2: -0.003095
Validation Loss: 1.17641276, Validation R2: 0.008943
Saved best model with validation R2 0.008943 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.13556035, Training R2: 0.019360
Validation Loss: 1.20468985, Validation R2: 0.049319
Saved best model with validation R2 0.049319 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.10042657, Training R2: 0.087007
Validation Loss: 1.13938473, Validation R2: 0.094152
Saved best model with validation R2 0.094152 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.07445898, Training R2: 0.129410
Validation Loss: 1.12358725, Validation R2: 0.104572
Saved best model with validation R2 0.104572 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.04461565, Training R2: 0.166362
Validation Loss: 1.09288980, Validation R2: 0.126578
Saved best model with validation R2 0.126578 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 1.02888665, Training R2: 0.190141
Validation Loss: 1.10470873, Validation R2: 0.148331
Saved best model with validation R2 0.148331 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 1.02450534, Training R2: 0.189291
Validation Loss: 1.10566686, Validation R2: 0.141305

Epoch 9/1000
Training Loss: 1.00004261, Training R2: 0.217721
Validation Loss: 1.03727252, Validation R2: 0.195560
Saved best model with validation R2 0.195560 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.96883332, Training R2: 0.255312
Validation Loss: 1.01559190, Validation R2: 0.203781
Saved best model with validation R2 0.203781 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 0.95185776, Training R2: 0.278130
Validation Loss: 1.00105340, Validation R2: 0.229904
Saved best model with validation R2 0.229904 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 0.93887224, Training R2: 0.282374
Validation Loss: 0.96880130, Validation R2: 0.288634
Saved best model with validation R2 0.288634 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 0.93095660, Training R2: 0.298377
Validation Loss: 1.01310925, Validation R2: 0.272885

Epoch 14/1000
Training Loss: 0.91508425, Training R2: 0.316366
Validation Loss: 0.95009844, Validation R2: 0.304395
Saved best model with validation R2 0.304395 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 0.89492299, Training R2: 0.340540
Validation Loss: 0.92965992, Validation R2: 0.335704
Saved best model with validation R2 0.335704 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 0.85987444, Training R2: 0.378220
Validation Loss: 0.90720863, Validation R2: 0.344811
Saved best model with validation R2 0.344811 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.84868523, Training R2: 0.387207
Validation Loss: 0.87477556, Validation R2: 0.385062
Saved best model with validation R2 0.385062 to best_finetuned_model.pth

Epoch 18/1000
Training Loss: 0.84044899, Training R2: 0.389692
Validation Loss: 0.88516890, Validation R2: 0.379051

Epoch 19/1000
Training Loss: 0.83413181, Training R2: 0.401640
Validation Loss: 0.87812190, Validation R2: 0.366207

Epoch 20/1000
Training Loss: 0.88893621, Training R2: 0.346299
Validation Loss: 0.87916411, Validation R2: 0.371445

Epoch 21/1000
Training Loss: 0.82809837, Training R2: 0.411080
Validation Loss: 0.87544520, Validation R2: 0.389672
Saved best model with validation R2 0.389672 to best_finetuned_model.pth

Epoch 22/1000
Training Loss: 0.83452414, Training R2: 0.410224
Validation Loss: 0.87861248, Validation R2: 0.364119

Epoch 23/1000
Training Loss: 0.81374474, Training R2: 0.425162
Validation Loss: 0.84433801, Validation R2: 0.424498
Saved best model with validation R2 0.424498 to best_finetuned_model.pth

Epoch 24/1000
Training Loss: 0.81039083, Training R2: 0.436975
Validation Loss: 0.88373476, Validation R2: 0.369350

Epoch 25/1000
Training Loss: 0.81404582, Training R2: 0.432264
Validation Loss: 0.84996496, Validation R2: 0.414011

Epoch 26/1000
Training Loss: 0.80275305, Training R2: 0.444915
Validation Loss: 0.83510480, Validation R2: 0.444744
Saved best model with validation R2 0.444744 to best_finetuned_model.pth

Epoch 27/1000
Training Loss: 0.79340219, Training R2: 0.452414
Validation Loss: 0.84149203, Validation R2: 0.420089

Epoch 28/1000
Training Loss: 0.79302911, Training R2: 0.451924
Validation Loss: 0.85483570, Validation R2: 0.410235

Epoch 29/1000
Training Loss: 0.79042243, Training R2: 0.458209
Validation Loss: 0.84391315, Validation R2: 0.412742

Epoch 30/1000
Training Loss: 0.78064887, Training R2: 0.467168
Validation Loss: 0.84224846, Validation R2: 0.427613

Epoch 31/1000
Training Loss: 0.77584546, Training R2: 0.473492
Validation Loss: 0.83394277, Validation R2: 0.425330

Epoch 32/1000
Training Loss: 0.76491611, Training R2: 0.482727
Validation Loss: 0.84124264, Validation R2: 0.431155

Epoch 33/1000
Training Loss: 0.76060902, Training R2: 0.485804
Validation Loss: 0.82604422, Validation R2: 0.444725

Epoch 34/1000
Training Loss: 0.77172620, Training R2: 0.478656
Validation Loss: 0.83379127, Validation R2: 0.441110

Epoch 35/1000
Training Loss: 0.75914067, Training R2: 0.489789
Validation Loss: 0.84678943, Validation R2: 0.402495

Epoch 36/1000
Training Loss: 0.78582762, Training R2: 0.463529
Validation Loss: 0.81861598, Validation R2: 0.452876
Saved best model with validation R2 0.452876 to best_finetuned_model.pth

Epoch 37/1000
Training Loss: 0.75124113, Training R2: 0.489458
Validation Loss: 0.80982501, Validation R2: 0.459317
Saved best model with validation R2 0.459317 to best_finetuned_model.pth

Epoch 38/1000
Training Loss: 0.73517442, Training R2: 0.514114
Validation Loss: 0.82667515, Validation R2: 0.446732

Epoch 39/1000
Training Loss: 0.74919224, Training R2: 0.498347
Validation Loss: 0.79745117, Validation R2: 0.477477
Saved best model with validation R2 0.477477 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.72774815, Training R2: 0.516147
Validation Loss: 0.80824687, Validation R2: 0.471604

Epoch 41/1000
Training Loss: 0.72918983, Training R2: 0.518441
Validation Loss: 0.79550620, Validation R2: 0.470914

Epoch 42/1000
Training Loss: 0.75824136, Training R2: 0.489637
Validation Loss: 0.82114169, Validation R2: 0.435584

Epoch 43/1000
Training Loss: 0.73417077, Training R2: 0.512214
Validation Loss: 0.81081552, Validation R2: 0.456558

Epoch 44/1000
Training Loss: 0.73453796, Training R2: 0.511828
Validation Loss: 0.80218152, Validation R2: 0.467800

Epoch 45/1000
Training Loss: 0.70534708, Training R2: 0.539257
Validation Loss: 0.79803924, Validation R2: 0.474629

Epoch 46/1000
Training Loss: 0.71111171, Training R2: 0.538136
Validation Loss: 0.82278605, Validation R2: 0.457864

Epoch 47/1000
Training Loss: 0.71251442, Training R2: 0.534814
Validation Loss: 0.83762633, Validation R2: 0.449708

Epoch 48/1000
Training Loss: 0.69992454, Training R2: 0.544880
Validation Loss: 0.78458064, Validation R2: 0.490834
Saved best model with validation R2 0.490834 to best_finetuned_model.pth

Epoch 49/1000
Training Loss: 0.72069882, Training R2: 0.531447
Validation Loss: 0.81974570, Validation R2: 0.415532

Epoch 50/1000
Training Loss: 0.71893947, Training R2: 0.532010
Validation Loss: 0.77925673, Validation R2: 0.492822
Saved best model with validation R2 0.492822 to best_finetuned_model.pth

Epoch 51/1000
Training Loss: 0.69211357, Training R2: 0.552224
Validation Loss: 0.80737856, Validation R2: 0.464402

Epoch 52/1000
Training Loss: 0.69632636, Training R2: 0.552900
Validation Loss: 0.79511425, Validation R2: 0.462257

Epoch 53/1000
Training Loss: 0.68319589, Training R2: 0.566804
Validation Loss: 0.82037726, Validation R2: 0.436519

Epoch 54/1000
Training Loss: 0.68851710, Training R2: 0.563844
Validation Loss: 0.79411281, Validation R2: 0.484879

Epoch 55/1000
Training Loss: 0.66245239, Training R2: 0.583435
Validation Loss: 0.83541789, Validation R2: 0.437322

Epoch 56/1000
Training Loss: 0.67719084, Training R2: 0.570213
Validation Loss: 0.79316514, Validation R2: 0.485932

Epoch 57/1000
Training Loss: 0.67096877, Training R2: 0.578473
Validation Loss: 0.82457862, Validation R2: 0.426576

Epoch 58/1000
Training Loss: 0.67946230, Training R2: 0.574724
Validation Loss: 0.79314185, Validation R2: 0.487655

Epoch 59/1000
Training Loss: 0.68196068, Training R2: 0.565961
Validation Loss: 0.82337464, Validation R2: 0.448604

Epoch 60/1000
Training Loss: 0.69341928, Training R2: 0.557465
Validation Loss: 0.79726891, Validation R2: 0.454757

Epoch 61/1000
Training Loss: 0.65861522, Training R2: 0.595857
Validation Loss: 0.78783157, Validation R2: 0.478788

Epoch 62/1000
Training Loss: 0.65937075, Training R2: 0.592453
Validation Loss: 0.82554514, Validation R2: 0.416659

Epoch 63/1000
Training Loss: 0.68284042, Training R2: 0.563457
Validation Loss: 0.77543727, Validation R2: 0.496170
Saved best model with validation R2 0.496170 to best_finetuned_model.pth

Epoch 64/1000
Training Loss: 0.65936474, Training R2: 0.589074
Validation Loss: 0.79960934, Validation R2: 0.472804

Epoch 65/1000
Training Loss: 0.63933984, Training R2: 0.605048
Validation Loss: 0.80437446, Validation R2: 0.467098

Epoch 66/1000
Training Loss: 0.65944352, Training R2: 0.592453
Validation Loss: 0.78793656, Validation R2: 0.490329

Epoch 67/1000
Training Loss: 0.66949424, Training R2: 0.584698
Validation Loss: 0.82879237, Validation R2: 0.407708

Epoch 68/1000
Training Loss: 0.63711361, Training R2: 0.609083
Validation Loss: 0.79465963, Validation R2: 0.481001

Epoch 69/1000
Training Loss: 0.62784032, Training R2: 0.622542
Validation Loss: 0.77720206, Validation R2: 0.487349

Epoch 70/1000
Training Loss: 0.61597606, Training R2: 0.631896
Validation Loss: 0.78143497, Validation R2: 0.491915

Epoch 71/1000
Training Loss: 0.60628032, Training R2: 0.637271
Validation Loss: 0.77947266, Validation R2: 0.485774

Epoch 72/1000
Training Loss: 0.59270534, Training R2: 0.649656
Validation Loss: 0.77598737, Validation R2: 0.495977

Epoch 73/1000
Training Loss: 0.60237453, Training R2: 0.644164
Validation Loss: 0.78456707, Validation R2: 0.486604

Epoch 74/1000
Training Loss: 0.62489983, Training R2: 0.630189
Validation Loss: 0.79170536, Validation R2: 0.465105

Epoch 75/1000
Training Loss: 0.61003489, Training R2: 0.638123
Validation Loss: 0.77634630, Validation R2: 0.490661

Epoch 76/1000
Training Loss: 0.60966206, Training R2: 0.638815
Validation Loss: 0.78015861, Validation R2: 0.495506

Epoch 77/1000
Training Loss: 0.59329461, Training R2: 0.654200
Validation Loss: 0.77487357, Validation R2: 0.488600

Epoch 78/1000
Training Loss: 0.62075902, Training R2: 0.633708
Validation Loss: 0.77145908, Validation R2: 0.506311
Saved best model with validation R2 0.506311 to best_finetuned_model.pth

Epoch 79/1000
Training Loss: 0.60785544, Training R2: 0.647836
Validation Loss: 0.79219040, Validation R2: 0.476923

Epoch 80/1000
Training Loss: 0.59044687, Training R2: 0.661086
Validation Loss: 0.79558231, Validation R2: 0.474355

Epoch 81/1000
Training Loss: 0.59513470, Training R2: 0.656456
Validation Loss: 0.79902180, Validation R2: 0.467597

Epoch 82/1000
Training Loss: 0.58414002, Training R2: 0.671089
Validation Loss: 0.78423163, Validation R2: 0.484565

Epoch 83/1000
Training Loss: 0.57566657, Training R2: 0.668663
Validation Loss: 0.77651789, Validation R2: 0.499310

Epoch 84/1000
Training Loss: 0.58256368, Training R2: 0.664026
Validation Loss: 0.78997307, Validation R2: 0.468814

Epoch 85/1000
Training Loss: 0.57806889, Training R2: 0.673880
Validation Loss: 0.84880942, Validation R2: 0.407331

Epoch 86/1000
Training Loss: 0.56856445, Training R2: 0.679980
Validation Loss: 0.81737667, Validation R2: 0.450203

Epoch 87/1000
Training Loss: 0.55505836, Training R2: 0.692252
Validation Loss: 0.77833862, Validation R2: 0.483353

Epoch 88/1000
Training Loss: 0.55825843, Training R2: 0.688635
Validation Loss: 0.79188944, Validation R2: 0.487191

Epoch 89/1000
Training Loss: 0.55358725, Training R2: 0.692490
Validation Loss: 0.77699799, Validation R2: 0.495973

Epoch 90/1000
Training Loss: 0.54937281, Training R2: 0.701586
Validation Loss: 0.79348730, Validation R2: 0.463921

Epoch 91/1000
Training Loss: 0.53857336, Training R2: 0.708878
Validation Loss: 0.77758456, Validation R2: 0.483447

Epoch 92/1000
Training Loss: 0.52525258, Training R2: 0.718623
Validation Loss: 0.78702174, Validation R2: 0.474567

Epoch 93/1000
Training Loss: 0.52148025, Training R2: 0.728176
Validation Loss: 0.79804755, Validation R2: 0.455661

Epoch 94/1000
Training Loss: 0.50564662, Training R2: 0.737595
Validation Loss: 0.76745598, Validation R2: 0.501379

Epoch 95/1000
Training Loss: 0.52176733, Training R2: 0.721748
Validation Loss: 0.78745855, Validation R2: 0.470028

Epoch 96/1000
Training Loss: 0.50436922, Training R2: 0.736231
Validation Loss: 0.79627417, Validation R2: 0.463292

Epoch 97/1000
Training Loss: 0.49583773, Training R2: 0.745161
Validation Loss: 0.77927616, Validation R2: 0.482813

Epoch 98/1000
Training Loss: 0.50083078, Training R2: 0.742774
Validation Loss: 0.78161825, Validation R2: 0.475697

Epoch 99/1000
Epoch 00099: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.48616522, Training R2: 0.751608
Validation Loss: 0.77968480, Validation R2: 0.487279

Epoch 100/1000
学习率已减少 1 次
Training Loss: 0.46392268, Training R2: 0.767889
Validation Loss: 0.77564686, Validation R2: 0.485546

Epoch 101/1000
Training Loss: 0.44404943, Training R2: 0.777363
Validation Loss: 0.77842820, Validation R2: 0.482894

Epoch 102/1000
Training Loss: 0.42920536, Training R2: 0.788326
Validation Loss: 0.78381002, Validation R2: 0.476134

Epoch 103/1000
Training Loss: 0.41824542, Training R2: 0.794930
Validation Loss: 0.77980653, Validation R2: 0.473388

Epoch 104/1000
Training Loss: 0.42185836, Training R2: 0.794774
Validation Loss: 0.78510749, Validation R2: 0.477322

Epoch 105/1000
Training Loss: 0.42827009, Training R2: 0.794449
Validation Loss: 0.81116496, Validation R2: 0.437015

Epoch 106/1000
Training Loss: 0.41878742, Training R2: 0.794597
Validation Loss: 0.77601537, Validation R2: 0.480522

Epoch 107/1000
Training Loss: 0.41352710, Training R2: 0.799991
Validation Loss: 0.77420615, Validation R2: 0.482313

Epoch 108/1000
Training Loss: 0.40154160, Training R2: 0.807234
Validation Loss: 0.79086379, Validation R2: 0.460396

Epoch 109/1000
Training Loss: 0.40475931, Training R2: 0.805356
Validation Loss: 0.78489457, Validation R2: 0.462738

Epoch 110/1000
Training Loss: 0.39505167, Training R2: 0.812513
Validation Loss: 0.78833652, Validation R2: 0.464644

Epoch 111/1000
Training Loss: 0.38933690, Training R2: 0.818369
Validation Loss: 0.78072362, Validation R2: 0.474258

Epoch 112/1000
Training Loss: 0.38271986, Training R2: 0.822064
Validation Loss: 0.78508786, Validation R2: 0.467603

Epoch 113/1000
Training Loss: 0.38003912, Training R2: 0.820071
Validation Loss: 0.77810966, Validation R2: 0.484997

Epoch 114/1000
Training Loss: 0.38559611, Training R2: 0.820943
Validation Loss: 0.79152762, Validation R2: 0.465502

Epoch 115/1000
Training Loss: 0.37913981, Training R2: 0.827112
Validation Loss: 0.78575889, Validation R2: 0.479984

Epoch 116/1000
Training Loss: 0.37321371, Training R2: 0.830568
Validation Loss: 0.78912963, Validation R2: 0.472252

Epoch 117/1000
Training Loss: 0.38253337, Training R2: 0.826432
Validation Loss: 0.79956253, Validation R2: 0.452468

Epoch 118/1000
Training Loss: 0.36490321, Training R2: 0.834662
Validation Loss: 0.78696192, Validation R2: 0.468686

Epoch 119/1000
Training Loss: 0.35563313, Training R2: 0.841631
Validation Loss: 0.79460114, Validation R2: 0.462488

Epoch 120/1000
Epoch 00120: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.35591991, Training R2: 0.839405
Validation Loss: 0.79000081, Validation R2: 0.463361

Epoch 121/1000
学习率已减少 2 次
Training Loss: 0.33723684, Training R2: 0.849088
Validation Loss: 0.79545482, Validation R2: 0.456866

Epoch 122/1000
Training Loss: 0.32400752, Training R2: 0.853828
Validation Loss: 0.78838044, Validation R2: 0.463678

Epoch 123/1000
Training Loss: 0.31921191, Training R2: 0.857006
Validation Loss: 0.79046415, Validation R2: 0.467785

Epoch 124/1000
Training Loss: 0.31762386, Training R2: 0.856986
Validation Loss: 0.79297925, Validation R2: 0.462473

Epoch 125/1000
Training Loss: 0.31457559, Training R2: 0.858262
Validation Loss: 0.79881329, Validation R2: 0.457793

Epoch 126/1000
Training Loss: 0.31646637, Training R2: 0.859055
Validation Loss: 0.78248670, Validation R2: 0.475973

Epoch 127/1000
Training Loss: 0.31598725, Training R2: 0.861447
Validation Loss: 0.81620288, Validation R2: 0.431035

Epoch 128/1000
Training Loss: 0.31446278, Training R2: 0.860768
Validation Loss: 0.79676115, Validation R2: 0.469256

Epoch 129/1000
Training Loss: 0.30565829, Training R2: 0.864358
Validation Loss: 0.80105555, Validation R2: 0.455045

Epoch 130/1000
Training Loss: 0.30998714, Training R2: 0.863476
Validation Loss: 0.78905336, Validation R2: 0.469356

Epoch 131/1000
Training Loss: 0.32724473, Training R2: 0.858059
Validation Loss: 0.80208261, Validation R2: 0.460912

Epoch 132/1000
Training Loss: 0.30919172, Training R2: 0.865526
Validation Loss: 0.80973425, Validation R2: 0.442558

Epoch 133/1000
Training Loss: 0.30453842, Training R2: 0.868486
Validation Loss: 0.79680809, Validation R2: 0.456314

Epoch 134/1000
Training Loss: 0.29630951, Training R2: 0.868693
Validation Loss: 0.79257281, Validation R2: 0.468443

Epoch 135/1000
Training Loss: 0.30086377, Training R2: 0.869912
Validation Loss: 0.81836702, Validation R2: 0.431829

Epoch 136/1000
Training Loss: 0.30098173, Training R2: 0.869774
Validation Loss: 0.79908972, Validation R2: 0.462667

Epoch 137/1000
Training Loss: 0.28165405, Training R2: 0.875707
Validation Loss: 0.79716969, Validation R2: 0.456803

Epoch 138/1000
Training Loss: 0.29148228, Training R2: 0.873037
Validation Loss: 0.80147966, Validation R2: 0.460355

Epoch 139/1000
Training Loss: 0.28986996, Training R2: 0.873870
Validation Loss: 0.80739112, Validation R2: 0.448578

Epoch 140/1000
Training Loss: 0.28585824, Training R2: 0.875750
Validation Loss: 0.80347599, Validation R2: 0.457687

Epoch 141/1000
Epoch 00141: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.28047094, Training R2: 0.878390
Validation Loss: 0.80899829, Validation R2: 0.447705

Epoch 142/1000
学习率已减少 3 次
Training Loss: 0.27106831, Training R2: 0.879778
Validation Loss: 0.79927868, Validation R2: 0.457353

Epoch 143/1000
Training Loss: 0.26405350, Training R2: 0.882342
Validation Loss: 0.80290842, Validation R2: 0.452224

Epoch 144/1000
Training Loss: 0.26084532, Training R2: 0.884463
Validation Loss: 0.80488361, Validation R2: 0.451397

Epoch 145/1000
Training Loss: 0.25605999, Training R2: 0.884775
Validation Loss: 0.79918549, Validation R2: 0.456891

Epoch 146/1000
Training Loss: 0.25984757, Training R2: 0.884092
Validation Loss: 0.80496529, Validation R2: 0.452385

Epoch 147/1000
Training Loss: 0.25891725, Training R2: 0.883405
Validation Loss: 0.79858505, Validation R2: 0.462191

Epoch 148/1000
Training Loss: 0.25178329, Training R2: 0.886915
Validation Loss: 0.80445495, Validation R2: 0.453781

Epoch 149/1000
Training Loss: 0.25314696, Training R2: 0.886099
Validation Loss: 0.80415680, Validation R2: 0.454225

Epoch 150/1000
Training Loss: 0.25275097, Training R2: 0.886148
Validation Loss: 0.79738570, Validation R2: 0.459163

Epoch 151/1000
Training Loss: 0.25144215, Training R2: 0.887873
Validation Loss: 0.80127350, Validation R2: 0.458802

Epoch 152/1000
Training Loss: 0.25257831, Training R2: 0.888028
Validation Loss: 0.80302169, Validation R2: 0.452629

Epoch 153/1000
Training Loss: 0.24838208, Training R2: 0.887728
Validation Loss: 0.80362568, Validation R2: 0.454728

Epoch 154/1000
Training Loss: 0.24646560, Training R2: 0.888464
Validation Loss: 0.79807085, Validation R2: 0.460257

Epoch 155/1000
Training Loss: 0.24678502, Training R2: 0.888868
Validation Loss: 0.80409126, Validation R2: 0.453730

Epoch 156/1000
Training Loss: 0.24450385, Training R2: 0.889809
Validation Loss: 0.80622789, Validation R2: 0.453069

Epoch 157/1000
Training Loss: 0.24540520, Training R2: 0.890048
Validation Loss: 0.80305566, Validation R2: 0.456707

Epoch 158/1000
Training Loss: 0.24757145, Training R2: 0.890611
Validation Loss: 0.80500084, Validation R2: 0.451516

Epoch 159/1000
Training Loss: 0.24705063, Training R2: 0.891151
Validation Loss: 0.80379198, Validation R2: 0.454959

Epoch 160/1000
Training Loss: 0.24270021, Training R2: 0.891978
Validation Loss: 0.80988504, Validation R2: 0.445078

Epoch 161/1000
Training Loss: 0.24110866, Training R2: 0.891519
Validation Loss: 0.80648319, Validation R2: 0.451510

Epoch 162/1000
Epoch 00162: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.23807720, Training R2: 0.892445
Validation Loss: 0.80238615, Validation R2: 0.453684

Epoch 163/1000
学习率已减少 4 次
Training Loss: 0.23104872, Training R2: 0.894729
Validation Loss: 0.80477051, Validation R2: 0.453693

Epoch 164/1000
Training Loss: 0.23079392, Training R2: 0.894138
Validation Loss: 0.80720051, Validation R2: 0.450649

Epoch 165/1000
Training Loss: 0.22791061, Training R2: 0.895884
Validation Loss: 0.80426962, Validation R2: 0.455144

Epoch 166/1000
Training Loss: 0.22860384, Training R2: 0.894698
Validation Loss: 0.80732791, Validation R2: 0.449900

Epoch 167/1000
Training Loss: 0.22587642, Training R2: 0.895267
Validation Loss: 0.80623438, Validation R2: 0.450314

Epoch 168/1000
Training Loss: 0.22403660, Training R2: 0.896433
Validation Loss: 0.80697840, Validation R2: 0.449488

Epoch 169/1000
Training Loss: 0.22429834, Training R2: 0.894986
Validation Loss: 0.80507530, Validation R2: 0.453529

Epoch 170/1000
Training Loss: 0.22206866, Training R2: 0.897317
Validation Loss: 0.80868639, Validation R2: 0.447159

Epoch 171/1000
Training Loss: 0.22467874, Training R2: 0.897214
Validation Loss: 0.80669693, Validation R2: 0.450769

Epoch 172/1000
Training Loss: 0.22335429, Training R2: 0.897540
Validation Loss: 0.80663794, Validation R2: 0.449378

Epoch 173/1000
Training Loss: 0.22294459, Training R2: 0.896279
Validation Loss: 0.80706105, Validation R2: 0.448822

Epoch 174/1000
Training Loss: 0.22278905, Training R2: 0.896843
Validation Loss: 0.80608002, Validation R2: 0.451210

Epoch 175/1000
Training Loss: 0.22127583, Training R2: 0.897312
Validation Loss: 0.80476546, Validation R2: 0.452462

Epoch 176/1000
Training Loss: 0.22037346, Training R2: 0.897678
Validation Loss: 0.80771328, Validation R2: 0.447097

Epoch 177/1000
Training Loss: 0.22044863, Training R2: 0.897409
Validation Loss: 0.80773373, Validation R2: 0.449796

Epoch 178/1000
Training Loss: 0.22001908, Training R2: 0.898147
Validation Loss: 0.80686644, Validation R2: 0.452305

Epoch 179/1000
Training Loss: 0.21982572, Training R2: 0.898332
Validation Loss: 0.81028077, Validation R2: 0.445340

Epoch 180/1000
Training Loss: 0.21836355, Training R2: 0.897745
Validation Loss: 0.80527419, Validation R2: 0.451623

Epoch 181/1000
Training Loss: 0.21964567, Training R2: 0.898691
Validation Loss: 0.80680012, Validation R2: 0.448496

Epoch 182/1000
Training Loss: 0.21915091, Training R2: 0.898858
Validation Loss: 0.81171417, Validation R2: 0.443150

Epoch 183/1000
Epoch 00183: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.21876683, Training R2: 0.898599
Validation Loss: 0.80827703, Validation R2: 0.448960

Epoch 184/1000
学习率已减少 5 次
Training Loss: 0.21430565, Training R2: 0.899627
Validation Loss: 0.80634967, Validation R2: 0.450135

Epoch 185/1000
Training Loss: 0.21320738, Training R2: 0.899951
Validation Loss: 0.80803340, Validation R2: 0.447295

Epoch 186/1000
Training Loss: 0.21270907, Training R2: 0.899258
Validation Loss: 0.80595858, Validation R2: 0.451045

Epoch 187/1000
Training Loss: 0.21169808, Training R2: 0.900587
Validation Loss: 0.80556075, Validation R2: 0.450641

Epoch 188/1000
Training Loss: 0.21210197, Training R2: 0.899684
Validation Loss: 0.80810805, Validation R2: 0.447971

Epoch 189/1000
Training Loss: 0.21108774, Training R2: 0.899762
Validation Loss: 0.80778126, Validation R2: 0.449093

Epoch 190/1000
Training Loss: 0.21014876, Training R2: 0.899668
Validation Loss: 0.80797425, Validation R2: 0.449668

Epoch 191/1000
Training Loss: 0.20994489, Training R2: 0.900018
Validation Loss: 0.80588439, Validation R2: 0.449533

Epoch 192/1000
Training Loss: 0.20971045, Training R2: 0.900327
Validation Loss: 0.80856571, Validation R2: 0.447755

Epoch 193/1000
Training Loss: 0.20962679, Training R2: 0.900134
Validation Loss: 0.80824229, Validation R2: 0.448126

Epoch 194/1000
Training Loss: 0.20849876, Training R2: 0.900877
Validation Loss: 0.80859708, Validation R2: 0.447013

Epoch 195/1000
Training Loss: 0.20837268, Training R2: 0.900129
Validation Loss: 0.80862010, Validation R2: 0.447662

Epoch 196/1000
Training Loss: 0.20940085, Training R2: 0.900163
Validation Loss: 0.81039286, Validation R2: 0.445490

Epoch 197/1000
Training Loss: 0.21014788, Training R2: 0.900889
Validation Loss: 0.80831942, Validation R2: 0.447999

Epoch 198/1000
Training Loss: 0.20761020, Training R2: 0.901338
Validation Loss: 0.80837721, Validation R2: 0.447683

Epoch 199/1000
Training Loss: 0.20779733, Training R2: 0.901177
Validation Loss: 0.80817235, Validation R2: 0.447906

Epoch 200/1000
Training Loss: 0.20725133, Training R2: 0.901181
Validation Loss: 0.80898382, Validation R2: 0.446850

Epoch 201/1000
Training Loss: 0.20828599, Training R2: 0.900758
Validation Loss: 0.80867471, Validation R2: 0.446780

Epoch 202/1000
Training Loss: 0.20725391, Training R2: 0.901105
Validation Loss: 0.80761347, Validation R2: 0.447870

Epoch 203/1000
Training Loss: 0.20594225, Training R2: 0.902630
Validation Loss: 0.81016078, Validation R2: 0.446259

Epoch 204/1000
Epoch 00204: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.20606079, Training R2: 0.901793
Validation Loss: 0.80647837, Validation R2: 0.448435

Epoch 205/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
