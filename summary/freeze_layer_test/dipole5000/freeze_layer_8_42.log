Using device: cuda
Selected target_properties: ['dipole']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 5000, Training: 4000, Validation: 1000
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1092227

Epoch 1/1000
Training Loss: 1.48004311, Training R2: -0.703681
Validation Loss: 1.19370258, Validation R2: 0.012141
Saved best model with validation R2 0.012141 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 1.19460540, Training R2: -0.017727
Validation Loss: 1.16917963, Validation R2: 0.045870
Saved best model with validation R2 0.045870 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 1.14713555, Training R2: 0.049251
Validation Loss: 1.10920175, Validation R2: 0.055154
Saved best model with validation R2 0.055154 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 1.12532024, Training R2: 0.068087
Validation Loss: 1.12344297, Validation R2: 0.063145
Saved best model with validation R2 0.063145 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 1.10825211, Training R2: 0.102325
Validation Loss: 1.08690243, Validation R2: 0.120721
Saved best model with validation R2 0.120721 to best_finetuned_model.pth

Epoch 6/1000
Training Loss: 1.09450201, Training R2: 0.115666
Validation Loss: 1.07058027, Validation R2: 0.136596
Saved best model with validation R2 0.136596 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 1.09229102, Training R2: 0.123723
Validation Loss: 1.07494279, Validation R2: 0.148513
Saved best model with validation R2 0.148513 to best_finetuned_model.pth

Epoch 8/1000
Training Loss: 1.09542583, Training R2: 0.116692
Validation Loss: 1.05232868, Validation R2: 0.116980

Epoch 9/1000
Training Loss: 1.06603699, Training R2: 0.154677
Validation Loss: 1.05134693, Validation R2: 0.127598

Epoch 10/1000
Training Loss: 1.06090624, Training R2: 0.162607
Validation Loss: 1.03652208, Validation R2: 0.159874
Saved best model with validation R2 0.159874 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 1.05580564, Training R2: 0.161360
Validation Loss: 1.04017074, Validation R2: 0.137068

Epoch 12/1000
Training Loss: 1.05802706, Training R2: 0.163749
Validation Loss: 1.04608481, Validation R2: 0.188091
Saved best model with validation R2 0.188091 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 1.05427027, Training R2: 0.171150
Validation Loss: 1.00998743, Validation R2: 0.186715

Epoch 14/1000
Training Loss: 1.04000201, Training R2: 0.185824
Validation Loss: 1.02704325, Validation R2: 0.206152
Saved best model with validation R2 0.206152 to best_finetuned_model.pth

Epoch 15/1000
Training Loss: 1.05082398, Training R2: 0.175909
Validation Loss: 1.00975769, Validation R2: 0.192736

Epoch 16/1000
Training Loss: 1.03202869, Training R2: 0.190804
Validation Loss: 1.01178709, Validation R2: 0.190934

Epoch 17/1000
Training Loss: 1.03621933, Training R2: 0.188662
Validation Loss: 1.02690434, Validation R2: 0.137892

Epoch 18/1000
Training Loss: 1.02100294, Training R2: 0.203777
Validation Loss: 0.99723839, Validation R2: 0.216429
Saved best model with validation R2 0.216429 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 1.00779323, Training R2: 0.218297
Validation Loss: 1.03878335, Validation R2: 0.105378

Epoch 20/1000
Training Loss: 1.09187870, Training R2: 0.107167
Validation Loss: 1.03179587, Validation R2: 0.142832

Epoch 21/1000
Training Loss: 1.05509875, Training R2: 0.173665
Validation Loss: 1.02843405, Validation R2: 0.143170

Epoch 22/1000
Training Loss: 1.01959528, Training R2: 0.208100
Validation Loss: 0.99608499, Validation R2: 0.205104

Epoch 23/1000
Training Loss: 1.03082018, Training R2: 0.188031
Validation Loss: 1.05051238, Validation R2: 0.196225

Epoch 24/1000
Training Loss: 1.03555948, Training R2: 0.189393
Validation Loss: 0.98886484, Validation R2: 0.236670
Saved best model with validation R2 0.236670 to best_finetuned_model.pth

Epoch 25/1000
Training Loss: 1.02946994, Training R2: 0.190331
Validation Loss: 0.99769717, Validation R2: 0.188178

Epoch 26/1000
Training Loss: 0.99354936, Training R2: 0.237258
Validation Loss: 0.98710557, Validation R2: 0.213182

Epoch 27/1000
Training Loss: 0.98726451, Training R2: 0.237397
Validation Loss: 0.98632371, Validation R2: 0.246657
Saved best model with validation R2 0.246657 to best_finetuned_model.pth

Epoch 28/1000
Training Loss: 0.99387997, Training R2: 0.234941
Validation Loss: 0.98996737, Validation R2: 0.229440

Epoch 29/1000
Training Loss: 0.99178863, Training R2: 0.222102
Validation Loss: 1.04715847, Validation R2: 0.185506

Epoch 30/1000
Training Loss: 0.99893724, Training R2: 0.225021
Validation Loss: 1.00434179, Validation R2: 0.234659

Epoch 31/1000
Training Loss: 1.00495193, Training R2: 0.226397
Validation Loss: 0.99397414, Validation R2: 0.234435

Epoch 32/1000
Training Loss: 0.98762014, Training R2: 0.237956
Validation Loss: 0.96474474, Validation R2: 0.255205
Saved best model with validation R2 0.255205 to best_finetuned_model.pth

Epoch 33/1000
Training Loss: 0.97302718, Training R2: 0.255595
Validation Loss: 0.96733908, Validation R2: 0.245257

Epoch 34/1000
Training Loss: 0.99091971, Training R2: 0.235998
Validation Loss: 0.97510457, Validation R2: 0.234406

Epoch 35/1000
Training Loss: 0.99289656, Training R2: 0.227884
Validation Loss: 0.96168835, Validation R2: 0.240965

Epoch 36/1000
Training Loss: 0.96472975, Training R2: 0.263072
Validation Loss: 0.98163318, Validation R2: 0.196029

Epoch 37/1000
Training Loss: 0.94582256, Training R2: 0.283180
Validation Loss: 0.98994616, Validation R2: 0.174434

Epoch 38/1000
Training Loss: 0.97088505, Training R2: 0.253441
Validation Loss: 0.99318511, Validation R2: 0.162979

Epoch 39/1000
Training Loss: 0.98003635, Training R2: 0.242603
Validation Loss: 1.00571923, Validation R2: 0.150973

Epoch 40/1000
Training Loss: 0.94880635, Training R2: 0.272143
Validation Loss: 0.95660144, Validation R2: 0.242006

Epoch 41/1000
Training Loss: 0.94119640, Training R2: 0.291784
Validation Loss: 0.95754079, Validation R2: 0.274836
Saved best model with validation R2 0.274836 to best_finetuned_model.pth

Epoch 42/1000
Training Loss: 0.92711722, Training R2: 0.303416
Validation Loss: 0.93233443, Validation R2: 0.263942

Epoch 43/1000
Training Loss: 0.91437006, Training R2: 0.310300
Validation Loss: 0.91008737, Validation R2: 0.285737
Saved best model with validation R2 0.285737 to best_finetuned_model.pth

Epoch 44/1000
Training Loss: 0.87956593, Training R2: 0.349933
Validation Loss: 0.87275118, Validation R2: 0.330829
Saved best model with validation R2 0.330829 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.89391997, Training R2: 0.330134
Validation Loss: 0.95651727, Validation R2: 0.202075

Epoch 46/1000
Training Loss: 0.88899494, Training R2: 0.329880
Validation Loss: 0.87593130, Validation R2: 0.341663
Saved best model with validation R2 0.341663 to best_finetuned_model.pth

Epoch 47/1000
Training Loss: 0.86631442, Training R2: 0.354897
Validation Loss: 0.87455121, Validation R2: 0.322497

Epoch 48/1000
Training Loss: 0.84466648, Training R2: 0.379573
Validation Loss: 0.89042591, Validation R2: 0.299829

Epoch 49/1000
Training Loss: 0.83049871, Training R2: 0.393669
Validation Loss: 0.89920339, Validation R2: 0.339342

Epoch 50/1000
Training Loss: 0.84248512, Training R2: 0.378793
Validation Loss: 0.84828944, Validation R2: 0.374097
Saved best model with validation R2 0.374097 to best_finetuned_model.pth

Epoch 51/1000
Training Loss: 0.83724256, Training R2: 0.385349
Validation Loss: 0.92259319, Validation R2: 0.255871

Epoch 52/1000
Training Loss: 0.85615933, Training R2: 0.363924
Validation Loss: 0.91510143, Validation R2: 0.304604

Epoch 53/1000
Training Loss: 0.82944922, Training R2: 0.394423
Validation Loss: 0.85910985, Validation R2: 0.366276

Epoch 54/1000
Training Loss: 0.84090139, Training R2: 0.384214
Validation Loss: 0.85680042, Validation R2: 0.350967

Epoch 55/1000
Training Loss: 0.82262546, Training R2: 0.406702
Validation Loss: 0.84288381, Validation R2: 0.369724

Epoch 56/1000
Training Loss: 0.79972741, Training R2: 0.426529
Validation Loss: 0.85491218, Validation R2: 0.350341

Epoch 57/1000
Training Loss: 0.79484334, Training R2: 0.426109
Validation Loss: 0.86931766, Validation R2: 0.333902

Epoch 58/1000
Training Loss: 0.80105968, Training R2: 0.429770
Validation Loss: 0.83955628, Validation R2: 0.374434
Saved best model with validation R2 0.374434 to best_finetuned_model.pth

Epoch 59/1000
Training Loss: 0.77974954, Training R2: 0.442481
Validation Loss: 0.82916112, Validation R2: 0.397644
Saved best model with validation R2 0.397644 to best_finetuned_model.pth

Epoch 60/1000
Training Loss: 0.79817388, Training R2: 0.427253
Validation Loss: 0.85588366, Validation R2: 0.365946

Epoch 61/1000
Training Loss: 0.80437143, Training R2: 0.426164
Validation Loss: 0.86675465, Validation R2: 0.332136

Epoch 62/1000
Training Loss: 0.81551017, Training R2: 0.419929
Validation Loss: 0.87382693, Validation R2: 0.359390

Epoch 63/1000
Training Loss: 0.79954380, Training R2: 0.429800
Validation Loss: 0.83828079, Validation R2: 0.380105

Epoch 64/1000
Training Loss: 0.77880593, Training R2: 0.454849
Validation Loss: 0.83786514, Validation R2: 0.377491

Epoch 65/1000
Training Loss: 0.75917655, Training R2: 0.466564
Validation Loss: 0.83811300, Validation R2: 0.395388

Epoch 66/1000
Training Loss: 0.76408184, Training R2: 0.466530
Validation Loss: 0.86427844, Validation R2: 0.353841

Epoch 67/1000
Training Loss: 0.76255685, Training R2: 0.467361
Validation Loss: 0.87515671, Validation R2: 0.308337

Epoch 68/1000
Training Loss: 0.80463961, Training R2: 0.413382
Validation Loss: 0.85502869, Validation R2: 0.364283

Epoch 69/1000
Training Loss: 0.80230740, Training R2: 0.439526
Validation Loss: 0.85405843, Validation R2: 0.338288

Epoch 70/1000
Training Loss: 0.77419620, Training R2: 0.458086
Validation Loss: 0.82054194, Validation R2: 0.388118

Epoch 71/1000
Training Loss: 0.75134851, Training R2: 0.476412
Validation Loss: 0.82564038, Validation R2: 0.407738
Saved best model with validation R2 0.407738 to best_finetuned_model.pth

Epoch 72/1000
Training Loss: 0.73407747, Training R2: 0.498377
Validation Loss: 0.85910727, Validation R2: 0.336493

Epoch 73/1000
Training Loss: 0.76046560, Training R2: 0.481300
Validation Loss: 0.82492254, Validation R2: 0.391755

Epoch 74/1000
Training Loss: 0.74374069, Training R2: 0.485206
Validation Loss: 0.82131235, Validation R2: 0.392618

Epoch 75/1000
Training Loss: 0.72310293, Training R2: 0.510322
Validation Loss: 0.82795575, Validation R2: 0.387539

Epoch 76/1000
Training Loss: 0.71818623, Training R2: 0.518577
Validation Loss: 0.82125677, Validation R2: 0.386960

Epoch 77/1000
Training Loss: 0.70370535, Training R2: 0.526605
Validation Loss: 0.82602077, Validation R2: 0.374880

Epoch 78/1000
Training Loss: 0.71316072, Training R2: 0.519783
Validation Loss: 0.87284994, Validation R2: 0.310660

Epoch 79/1000
Training Loss: 0.73462176, Training R2: 0.504059
Validation Loss: 0.82820468, Validation R2: 0.379829

Epoch 80/1000
Training Loss: 0.71289058, Training R2: 0.519139
Validation Loss: 0.83987876, Validation R2: 0.374130

Epoch 81/1000
Training Loss: 0.69920189, Training R2: 0.537928
Validation Loss: 0.83228533, Validation R2: 0.372719

Epoch 82/1000
Training Loss: 0.71775722, Training R2: 0.510946
Validation Loss: 0.83550595, Validation R2: 0.371939

Epoch 83/1000
Training Loss: 0.73433924, Training R2: 0.503662
Validation Loss: 0.86859988, Validation R2: 0.341159

Epoch 84/1000
Training Loss: 0.69081949, Training R2: 0.547708
Validation Loss: 0.84841599, Validation R2: 0.345240

Epoch 85/1000
Training Loss: 0.67650277, Training R2: 0.558990
Validation Loss: 0.83299100, Validation R2: 0.376525

Epoch 86/1000
Training Loss: 0.68165470, Training R2: 0.559452
Validation Loss: 0.82577902, Validation R2: 0.362766

Epoch 87/1000
Training Loss: 0.67924130, Training R2: 0.559258
Validation Loss: 0.81238406, Validation R2: 0.385033

Epoch 88/1000
Training Loss: 0.67850627, Training R2: 0.560287
Validation Loss: 0.82356932, Validation R2: 0.374262

Epoch 89/1000
Training Loss: 0.68425455, Training R2: 0.554755
Validation Loss: 0.84150769, Validation R2: 0.343488

Epoch 90/1000
Training Loss: 0.66223415, Training R2: 0.576758
Validation Loss: 0.83567369, Validation R2: 0.362939

Epoch 91/1000
Training Loss: 0.65572066, Training R2: 0.588809
Validation Loss: 0.83083804, Validation R2: 0.372564

Epoch 92/1000
Epoch 00092: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.66446126, Training R2: 0.577666
Validation Loss: 0.83150676, Validation R2: 0.359553

Epoch 93/1000
学习率已减少 1 次
Training Loss: 0.62424462, Training R2: 0.611999
Validation Loss: 0.81757016, Validation R2: 0.379169

Epoch 94/1000
Training Loss: 0.60950924, Training R2: 0.620852
Validation Loss: 0.80495377, Validation R2: 0.398958

Epoch 95/1000
Training Loss: 0.60615903, Training R2: 0.627872
Validation Loss: 0.82525932, Validation R2: 0.365768

Epoch 96/1000
Training Loss: 0.59314530, Training R2: 0.638000
Validation Loss: 0.81586064, Validation R2: 0.378628

Epoch 97/1000
Training Loss: 0.58141496, Training R2: 0.647446
Validation Loss: 0.82386173, Validation R2: 0.375372

Epoch 98/1000
Training Loss: 0.58569728, Training R2: 0.649576
Validation Loss: 0.82904122, Validation R2: 0.365648

Epoch 99/1000
Training Loss: 0.57803451, Training R2: 0.653946
Validation Loss: 0.82551444, Validation R2: 0.371449

Epoch 100/1000
Training Loss: 0.58002142, Training R2: 0.656454
Validation Loss: 0.83214594, Validation R2: 0.348627

Epoch 101/1000
Training Loss: 0.58980217, Training R2: 0.647734
Validation Loss: 0.82161771, Validation R2: 0.367655

Epoch 102/1000
Training Loss: 0.57995866, Training R2: 0.653991
Validation Loss: 0.81444770, Validation R2: 0.381776

Epoch 103/1000
Training Loss: 0.56406812, Training R2: 0.666998
Validation Loss: 0.82486563, Validation R2: 0.366961

Epoch 104/1000
Training Loss: 0.56621672, Training R2: 0.668877
Validation Loss: 0.81100982, Validation R2: 0.385469

Epoch 105/1000
Training Loss: 0.55431262, Training R2: 0.675937
Validation Loss: 0.82131835, Validation R2: 0.377434

Epoch 106/1000
Training Loss: 0.54382412, Training R2: 0.682986
Validation Loss: 0.83249037, Validation R2: 0.360618

Epoch 107/1000
Training Loss: 0.55762321, Training R2: 0.676653
Validation Loss: 0.82405782, Validation R2: 0.371882

Epoch 108/1000
Training Loss: 0.54009053, Training R2: 0.690316
Validation Loss: 0.82898486, Validation R2: 0.368886

Epoch 109/1000
Training Loss: 0.54049140, Training R2: 0.691626
Validation Loss: 0.85117673, Validation R2: 0.325956

Epoch 110/1000
Training Loss: 0.52699115, Training R2: 0.701416
Validation Loss: 0.82953860, Validation R2: 0.357474

Epoch 111/1000
Training Loss: 0.52672147, Training R2: 0.703788
Validation Loss: 0.83713368, Validation R2: 0.355404

Epoch 112/1000
Training Loss: 0.51477575, Training R2: 0.709758
Validation Loss: 0.84706533, Validation R2: 0.332134

Epoch 113/1000
Epoch 00113: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.51360377, Training R2: 0.714787
Validation Loss: 0.83675468, Validation R2: 0.347977

Epoch 114/1000
学习率已减少 2 次
Training Loss: 0.49954828, Training R2: 0.720612
Validation Loss: 0.83845316, Validation R2: 0.348244

Epoch 115/1000
Training Loss: 0.48512869, Training R2: 0.731407
Validation Loss: 0.82686429, Validation R2: 0.357495

Epoch 116/1000
Training Loss: 0.48375668, Training R2: 0.734708
Validation Loss: 0.83384064, Validation R2: 0.352334

Epoch 117/1000
Training Loss: 0.47120086, Training R2: 0.740085
Validation Loss: 0.83860146, Validation R2: 0.344323

Epoch 118/1000
Training Loss: 0.46471234, Training R2: 0.744166
Validation Loss: 0.84205527, Validation R2: 0.335592

Epoch 119/1000
Training Loss: 0.45932342, Training R2: 0.749994
Validation Loss: 0.83960141, Validation R2: 0.341171

Epoch 120/1000
Training Loss: 0.46061333, Training R2: 0.748851
Validation Loss: 0.84732309, Validation R2: 0.329236

Epoch 121/1000
Training Loss: 0.45997470, Training R2: 0.748855
Validation Loss: 0.84305119, Validation R2: 0.337240

Epoch 122/1000
Training Loss: 0.45602884, Training R2: 0.755109
Validation Loss: 0.83978837, Validation R2: 0.341288

Epoch 123/1000
Training Loss: 0.45495273, Training R2: 0.753699
Validation Loss: 0.84936742, Validation R2: 0.319580

Epoch 124/1000
Training Loss: 0.45475348, Training R2: 0.756918
Validation Loss: 0.84359951, Validation R2: 0.336734

Epoch 125/1000
Training Loss: 0.44961907, Training R2: 0.761238
Validation Loss: 0.85429565, Validation R2: 0.319410

Epoch 126/1000
Training Loss: 0.45106129, Training R2: 0.758357
Validation Loss: 0.85337403, Validation R2: 0.317146

Epoch 127/1000
Training Loss: 0.44118812, Training R2: 0.764320
Validation Loss: 0.85118217, Validation R2: 0.321506

Epoch 128/1000
Training Loss: 0.43989720, Training R2: 0.763504
Validation Loss: 0.85662421, Validation R2: 0.324550

Epoch 129/1000
Training Loss: 0.43183251, Training R2: 0.774073
Validation Loss: 0.84519366, Validation R2: 0.333363

Epoch 130/1000
Training Loss: 0.44052311, Training R2: 0.767772
Validation Loss: 0.86425980, Validation R2: 0.299944

Epoch 131/1000
Training Loss: 0.44880167, Training R2: 0.764170
Validation Loss: 0.85376956, Validation R2: 0.321791

Epoch 132/1000
Training Loss: 0.42651495, Training R2: 0.778438
Validation Loss: 0.85731361, Validation R2: 0.315298

Epoch 133/1000
Training Loss: 0.42955007, Training R2: 0.775391
Validation Loss: 0.86203850, Validation R2: 0.315192

Epoch 134/1000
Epoch 00134: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.42592704, Training R2: 0.776927
Validation Loss: 0.86203860, Validation R2: 0.299754

Epoch 135/1000
学习率已减少 3 次
Training Loss: 0.41037146, Training R2: 0.785592
Validation Loss: 0.85436932, Validation R2: 0.319690

Epoch 136/1000
Training Loss: 0.40017540, Training R2: 0.791256
Validation Loss: 0.85480368, Validation R2: 0.318247

Epoch 137/1000
Training Loss: 0.39633792, Training R2: 0.791157
Validation Loss: 0.86004819, Validation R2: 0.310637

Epoch 138/1000
Training Loss: 0.39245604, Training R2: 0.795699
Validation Loss: 0.85596074, Validation R2: 0.312091

Epoch 139/1000
Training Loss: 0.38994844, Training R2: 0.793578
Validation Loss: 0.85524088, Validation R2: 0.315748

Epoch 140/1000
Training Loss: 0.39035802, Training R2: 0.797313
Validation Loss: 0.85093497, Validation R2: 0.322898

Epoch 141/1000
Training Loss: 0.38461005, Training R2: 0.800361
Validation Loss: 0.85430709, Validation R2: 0.319611

Epoch 142/1000
Training Loss: 0.38364660, Training R2: 0.798705
Validation Loss: 0.85676158, Validation R2: 0.312736

Epoch 143/1000
Training Loss: 0.38089996, Training R2: 0.800401
Validation Loss: 0.85422669, Validation R2: 0.316995

Epoch 144/1000
Training Loss: 0.37943864, Training R2: 0.801056
Validation Loss: 0.85991918, Validation R2: 0.310836

Epoch 145/1000
Training Loss: 0.37907210, Training R2: 0.802378
Validation Loss: 0.85546099, Validation R2: 0.312170

Epoch 146/1000
Training Loss: 0.37943035, Training R2: 0.802610
Validation Loss: 0.85799579, Validation R2: 0.313780

Epoch 147/1000
Training Loss: 0.39141712, Training R2: 0.800286
Validation Loss: 0.86102427, Validation R2: 0.308739

Epoch 148/1000
Training Loss: 0.37704051, Training R2: 0.805684
Validation Loss: 0.85955445, Validation R2: 0.303880

Epoch 149/1000
Training Loss: 0.37499992, Training R2: 0.805591
Validation Loss: 0.86839715, Validation R2: 0.292897

Epoch 150/1000
Training Loss: 0.37656758, Training R2: 0.805832
Validation Loss: 0.86185699, Validation R2: 0.304498

Epoch 151/1000
Training Loss: 0.37345319, Training R2: 0.807124
Validation Loss: 0.86184901, Validation R2: 0.301530

Epoch 152/1000
Training Loss: 0.36568325, Training R2: 0.811283
Validation Loss: 0.86009605, Validation R2: 0.305647

Epoch 153/1000
Training Loss: 0.36723681, Training R2: 0.809532
Validation Loss: 0.86486605, Validation R2: 0.295325

Epoch 154/1000
Training Loss: 0.36466322, Training R2: 0.811109
Validation Loss: 0.85801826, Validation R2: 0.309599

Epoch 155/1000
Epoch 00155: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.36598210, Training R2: 0.811017
Validation Loss: 0.86569075, Validation R2: 0.297306

Epoch 156/1000
学习率已减少 4 次
Training Loss: 0.35884169, Training R2: 0.812462
Validation Loss: 0.86255044, Validation R2: 0.300596

Epoch 157/1000
Training Loss: 0.35582727, Training R2: 0.815461
Validation Loss: 0.85776832, Validation R2: 0.312028

Epoch 158/1000
Training Loss: 0.35384538, Training R2: 0.816294
Validation Loss: 0.86415928, Validation R2: 0.298564

Epoch 159/1000
Training Loss: 0.35095304, Training R2: 0.817406
Validation Loss: 0.86477628, Validation R2: 0.298192

Epoch 160/1000
Training Loss: 0.35087138, Training R2: 0.816699
Validation Loss: 0.86227460, Validation R2: 0.299157

Epoch 161/1000
Training Loss: 0.34694128, Training R2: 0.818712
Validation Loss: 0.86222463, Validation R2: 0.300733

Epoch 162/1000
Training Loss: 0.34554950, Training R2: 0.818455
Validation Loss: 0.86366780, Validation R2: 0.301002

Epoch 163/1000
Training Loss: 0.34616497, Training R2: 0.818829
Validation Loss: 0.86125146, Validation R2: 0.303469

Epoch 164/1000
Training Loss: 0.34422538, Training R2: 0.820800
Validation Loss: 0.86292643, Validation R2: 0.301668

Epoch 165/1000
Training Loss: 0.34395496, Training R2: 0.820294
Validation Loss: 0.86256911, Validation R2: 0.301120

Epoch 166/1000
Training Loss: 0.34384057, Training R2: 0.820566
Validation Loss: 0.86458049, Validation R2: 0.299692

Epoch 167/1000
Training Loss: 0.34608450, Training R2: 0.820198
Validation Loss: 0.86051560, Validation R2: 0.306567

Epoch 168/1000
Training Loss: 0.34200722, Training R2: 0.821397
Validation Loss: 0.85960665, Validation R2: 0.308268

Epoch 169/1000
Training Loss: 0.34146354, Training R2: 0.821937
Validation Loss: 0.86280457, Validation R2: 0.300326

Epoch 170/1000
Training Loss: 0.34004655, Training R2: 0.821491
Validation Loss: 0.86598644, Validation R2: 0.295248

Epoch 171/1000
Training Loss: 0.34218218, Training R2: 0.822241
Validation Loss: 0.86738087, Validation R2: 0.291347

Epoch 172/1000
Training Loss: 0.34229897, Training R2: 0.824040
Validation Loss: 0.86240003, Validation R2: 0.300233

Epoch 173/1000
Training Loss: 0.34676915, Training R2: 0.820842
Validation Loss: 0.86552314, Validation R2: 0.300331

Epoch 174/1000
Training Loss: 0.34106822, Training R2: 0.824227
Validation Loss: 0.86516738, Validation R2: 0.297386

Epoch 175/1000
Training Loss: 0.34370804, Training R2: 0.821749
Validation Loss: 0.86361508, Validation R2: 0.298519

Epoch 176/1000
Epoch 00176: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.33757763, Training R2: 0.824092
Validation Loss: 0.86213742, Validation R2: 0.301704

Epoch 177/1000
学习率已减少 5 次
Training Loss: 0.33174363, Training R2: 0.825247
Validation Loss: 0.86222608, Validation R2: 0.302434

Epoch 178/1000
Training Loss: 0.32983561, Training R2: 0.825342
Validation Loss: 0.86384448, Validation R2: 0.299023

Epoch 179/1000
Training Loss: 0.32895194, Training R2: 0.825543
Validation Loss: 0.86543966, Validation R2: 0.298460

Epoch 180/1000
Training Loss: 0.32744340, Training R2: 0.826176
Validation Loss: 0.86473039, Validation R2: 0.298980

Epoch 181/1000
Training Loss: 0.32675748, Training R2: 0.827452
Validation Loss: 0.86678578, Validation R2: 0.293994

Epoch 182/1000
Training Loss: 0.32904007, Training R2: 0.826254
Validation Loss: 0.86362491, Validation R2: 0.297503

Epoch 183/1000
Training Loss: 0.32579881, Training R2: 0.827888
Validation Loss: 0.86544510, Validation R2: 0.297477

Epoch 184/1000
Training Loss: 0.32672839, Training R2: 0.826898
Validation Loss: 0.86446538, Validation R2: 0.297739

Epoch 185/1000
Training Loss: 0.32461559, Training R2: 0.827685
Validation Loss: 0.86521523, Validation R2: 0.296040

Epoch 186/1000
Training Loss: 0.32590913, Training R2: 0.827476
Validation Loss: 0.86364313, Validation R2: 0.299916

Epoch 187/1000
Training Loss: 0.32495854, Training R2: 0.828094
Validation Loss: 0.86496459, Validation R2: 0.297418

Epoch 188/1000
Training Loss: 0.32427859, Training R2: 0.827073
Validation Loss: 0.86496754, Validation R2: 0.296512

Epoch 189/1000
Training Loss: 0.32380350, Training R2: 0.826351
Validation Loss: 0.86607477, Validation R2: 0.295936

Epoch 190/1000
Training Loss: 0.32153049, Training R2: 0.830404
Validation Loss: 0.86580944, Validation R2: 0.295356

Epoch 191/1000
Training Loss: 0.32248578, Training R2: 0.828418
Validation Loss: 0.86622109, Validation R2: 0.297780

Epoch 192/1000
Training Loss: 0.32257163, Training R2: 0.829329
Validation Loss: 0.86510205, Validation R2: 0.298344

Epoch 193/1000
Training Loss: 0.32151318, Training R2: 0.829243
Validation Loss: 0.86651852, Validation R2: 0.296128

Epoch 194/1000
Training Loss: 0.32235353, Training R2: 0.830932
Validation Loss: 0.86508888, Validation R2: 0.296199

Epoch 195/1000
Training Loss: 0.32230889, Training R2: 0.827826
Validation Loss: 0.86644074, Validation R2: 0.295928

Epoch 196/1000
Training Loss: 0.32118865, Training R2: 0.830205
Validation Loss: 0.86708376, Validation R2: 0.292002

Epoch 197/1000
Epoch 00197: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.32335344, Training R2: 0.828553
Validation Loss: 0.86431453, Validation R2: 0.296213

Epoch 198/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_dipole.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_dipole.png
