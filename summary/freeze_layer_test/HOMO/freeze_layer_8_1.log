Using device: cuda
Selected target_properties: ['HOMO_energy']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Trainable
lins.2.bias: Trainable
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1092227

Epoch 1/1000
Training Loss: 0.93411628, Training R2: -974.744629
Validation Loss: 0.31491846, Validation R2: -76.131340
Saved best model with validation R2 -76.131340 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 0.31312439, Training R2: -109.027969
Validation Loss: 0.26616424, Validation R2: -53.597389
Saved best model with validation R2 -53.597389 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 0.17295376, Training R2: -35.705833
Validation Loss: 0.11658663, Validation R2: -11.044031
Saved best model with validation R2 -11.044031 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 0.10331493, Training R2: -12.144042
Validation Loss: 0.07534712, Validation R2: -4.561259
Saved best model with validation R2 -4.561259 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 0.07557721, Training R2: -6.675725
Validation Loss: 0.09306291, Validation R2: -6.273897

Epoch 6/1000
Training Loss: 0.06996054, Training R2: -5.491033
Validation Loss: 0.03909493, Validation R2: -0.647498
Saved best model with validation R2 -0.647498 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 0.06748440, Training R2: -5.006016
Validation Loss: 0.09056101, Validation R2: -6.203192

Epoch 8/1000
Training Loss: 0.08942453, Training R2: -8.565805
Validation Loss: 0.08449510, Validation R2: -5.004491

Epoch 9/1000
Training Loss: 0.05822155, Training R2: -3.354818
Validation Loss: 0.03275457, Validation R2: -0.340707
Saved best model with validation R2 -0.340707 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.05453559, Training R2: -2.963587
Validation Loss: 0.06501617, Validation R2: -2.972655

Epoch 11/1000
Training Loss: 0.05624685, Training R2: -3.284964
Validation Loss: 0.08110850, Validation R2: -4.556935

Epoch 12/1000
Training Loss: 0.06065044, Training R2: -3.849086
Validation Loss: 0.04899928, Validation R2: -1.307314

Epoch 13/1000
Training Loss: 0.05884839, Training R2: -3.324610
Validation Loss: 0.04873877, Validation R2: -1.353142

Epoch 14/1000
Training Loss: 0.05522240, Training R2: -2.891456
Validation Loss: 0.06374349, Validation R2: -2.576232

Epoch 15/1000
Training Loss: 0.04694339, Training R2: -1.998637
Validation Loss: 0.02660579, Validation R2: 0.009138
Saved best model with validation R2 0.009138 to best_finetuned_model.pth

Epoch 16/1000
Training Loss: 0.03564533, Training R2: -0.962413
Validation Loss: 0.03787146, Validation R2: -0.467304

Epoch 17/1000
Training Loss: 0.03094815, Training R2: -0.455328
Validation Loss: 0.02682746, Validation R2: 0.057704
Saved best model with validation R2 0.057704 to best_finetuned_model.pth

Epoch 18/1000
Training Loss: 0.02342635, Training R2: 0.017587
Validation Loss: 0.02508191, Validation R2: 0.104734
Saved best model with validation R2 0.104734 to best_finetuned_model.pth

Epoch 19/1000
Training Loss: 0.02240958, Training R2: 0.079275
Validation Loss: 0.02452751, Validation R2: 0.138561
Saved best model with validation R2 0.138561 to best_finetuned_model.pth

Epoch 20/1000
Training Loss: 0.02237532, Training R2: 0.090057
Validation Loss: 0.02460326, Validation R2: 0.161153
Saved best model with validation R2 0.161153 to best_finetuned_model.pth

Epoch 21/1000
Training Loss: 0.02243683, Training R2: 0.086588
Validation Loss: 0.02475366, Validation R2: 0.150603

Epoch 22/1000
Training Loss: 0.02196018, Training R2: 0.120808
Validation Loss: 0.02671096, Validation R2: 0.056064

Epoch 23/1000
Training Loss: 0.02282449, Training R2: 0.076067
Validation Loss: 0.03283152, Validation R2: -0.180036

Epoch 24/1000
Training Loss: 0.02661522, Training R2: -0.132003
Validation Loss: 0.03022316, Validation R2: -0.050272

Epoch 25/1000
Training Loss: 0.02412196, Training R2: -0.010173
Validation Loss: 0.02541415, Validation R2: 0.104333

Epoch 26/1000
Training Loss: 0.02385356, Training R2: 0.010039
Validation Loss: 0.02840590, Validation R2: 0.015453

Epoch 27/1000
Training Loss: 0.02553122, Training R2: -0.060013
Validation Loss: 0.02632861, Validation R2: 0.103626

Epoch 28/1000
Training Loss: 0.02419133, Training R2: 0.011943
Validation Loss: 0.04197722, Validation R2: -0.795787

Epoch 29/1000
Training Loss: 0.03707463, Training R2: -0.975700
Validation Loss: 0.04921910, Validation R2: -1.384097

Epoch 30/1000
Training Loss: 0.04290601, Training R2: -1.369440
Validation Loss: 0.02697346, Validation R2: 0.049185

Epoch 31/1000
Training Loss: 0.02878909, Training R2: -0.269212
Validation Loss: 0.03793062, Validation R2: -0.486022

Epoch 32/1000
Training Loss: 0.03561640, Training R2: -0.769558
Validation Loss: 0.05056757, Validation R2: -1.443601

Epoch 33/1000
Training Loss: 0.04168673, Training R2: -1.317541
Validation Loss: 0.02561865, Validation R2: 0.072747

Epoch 34/1000
Training Loss: 0.03039943, Training R2: -0.372879
Validation Loss: 0.04471324, Validation R2: -0.984573

Epoch 35/1000
Training Loss: 0.03639408, Training R2: -0.763391
Validation Loss: 0.03752884, Validation R2: -0.488092

Epoch 36/1000
Training Loss: 0.03306472, Training R2: -0.574080
Validation Loss: 0.03718064, Validation R2: -0.469501

Epoch 37/1000
Training Loss: 0.03546814, Training R2: -0.711905
Validation Loss: 0.03645802, Validation R2: -0.497060

Epoch 38/1000
Training Loss: 0.03124815, Training R2: -0.396583
Validation Loss: 0.02664417, Validation R2: 0.057099

Epoch 39/1000
Training Loss: 0.02519424, Training R2: -0.022768
Validation Loss: 0.02449896, Validation R2: 0.172517
Saved best model with validation R2 0.172517 to best_finetuned_model.pth

Epoch 40/1000
Training Loss: 0.02560049, Training R2: -0.066967
Validation Loss: 0.03140224, Validation R2: -0.177019

Epoch 41/1000
Training Loss: 0.02541091, Training R2: -0.073027
Validation Loss: 0.02918302, Validation R2: -0.010554

Epoch 42/1000
Training Loss: 0.02415019, Training R2: 0.054453
Validation Loss: 0.02523723, Validation R2: 0.153146

Epoch 43/1000
Training Loss: 0.02130786, Training R2: 0.184633
Validation Loss: 0.02409519, Validation R2: 0.190814
Saved best model with validation R2 0.190814 to best_finetuned_model.pth

Epoch 44/1000
Training Loss: 0.02103503, Training R2: 0.202460
Validation Loss: 0.02368637, Validation R2: 0.202481
Saved best model with validation R2 0.202481 to best_finetuned_model.pth

Epoch 45/1000
Training Loss: 0.02155160, Training R2: 0.164493
Validation Loss: 0.02452282, Validation R2: 0.144293

Epoch 46/1000
Training Loss: 0.02355242, Training R2: 0.042520
Validation Loss: 0.02807311, Validation R2: 0.056970

Epoch 47/1000
Training Loss: 0.02415659, Training R2: 0.043338
Validation Loss: 0.02381162, Validation R2: 0.185845

Epoch 48/1000
Training Loss: 0.02119866, Training R2: 0.176253
Validation Loss: 0.02787729, Validation R2: 0.075318

Epoch 49/1000
Training Loss: 0.02245619, Training R2: 0.114029
Validation Loss: 0.03187033, Validation R2: -0.126578

Epoch 50/1000
Training Loss: 0.02638328, Training R2: -0.097570
Validation Loss: 0.02726103, Validation R2: 0.088447

Epoch 51/1000
Training Loss: 0.02398126, Training R2: 0.044107
Validation Loss: 0.04153161, Validation R2: -0.762289

Epoch 52/1000
Training Loss: 0.03845313, Training R2: -1.066116
Validation Loss: 0.04434206, Validation R2: -0.949108

Epoch 53/1000
Training Loss: 0.04136784, Training R2: -1.236969
Validation Loss: 0.03433263, Validation R2: -0.253613

Epoch 54/1000
Training Loss: 0.03272642, Training R2: -0.518956
Validation Loss: 0.03738307, Validation R2: -0.527705

Epoch 55/1000
Training Loss: 0.03869166, Training R2: -1.088463
Validation Loss: 0.04530907, Validation R2: -1.082107

Epoch 56/1000
Training Loss: 0.03981481, Training R2: -1.197006
Validation Loss: 0.02992889, Validation R2: -0.021028

Epoch 57/1000
Training Loss: 0.02777332, Training R2: -0.182932
Validation Loss: 0.02772611, Validation R2: 0.067409

Epoch 58/1000
Training Loss: 0.02349187, Training R2: 0.103907
Validation Loss: 0.02558398, Validation R2: 0.153785

Epoch 59/1000
Training Loss: 0.02556143, Training R2: -0.048191
Validation Loss: 0.03127827, Validation R2: -0.096756

Epoch 60/1000
Training Loss: 0.02647360, Training R2: -0.083108
Validation Loss: 0.02794122, Validation R2: 0.064903

Epoch 61/1000
Training Loss: 0.02607824, Training R2: -0.069951
Validation Loss: 0.03144048, Validation R2: -0.105324

Epoch 62/1000
Training Loss: 0.02793590, Training R2: -0.178077
Validation Loss: 0.05108459, Validation R2: -1.493608

Epoch 63/1000
Training Loss: 0.04318757, Training R2: -1.408722
Validation Loss: 0.03958660, Validation R2: -0.606302

Epoch 64/1000
Training Loss: 0.03705639, Training R2: -0.936337
Validation Loss: 0.03103205, Validation R2: -0.089057

Epoch 65/1000
Epoch 00065: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.02848565, Training R2: -0.234771
Validation Loss: 0.03712237, Validation R2: -0.421046

Epoch 66/1000
学习率已减少 1 次
Training Loss: 0.02888941, Training R2: -0.281930
Validation Loss: 0.02375521, Validation R2: 0.202833
Saved best model with validation R2 0.202833 to best_finetuned_model.pth

Epoch 67/1000
Training Loss: 0.02430344, Training R2: 0.000901
Validation Loss: 0.03038088, Validation R2: -0.068206

Epoch 68/1000
Training Loss: 0.02363208, Training R2: 0.078745
Validation Loss: 0.02491945, Validation R2: 0.177911

Epoch 69/1000
Training Loss: 0.02089467, Training R2: 0.213580
Validation Loss: 0.02834350, Validation R2: 0.050594

Epoch 70/1000
Training Loss: 0.02253672, Training R2: 0.095902
Validation Loss: 0.02359806, Validation R2: 0.213250
Saved best model with validation R2 0.213250 to best_finetuned_model.pth

Epoch 71/1000
Training Loss: 0.02169000, Training R2: 0.172400
Validation Loss: 0.02351999, Validation R2: 0.214163
Saved best model with validation R2 0.214163 to best_finetuned_model.pth

Epoch 72/1000
Training Loss: 0.02096068, Training R2: 0.207294
Validation Loss: 0.02540563, Validation R2: 0.146332

Epoch 73/1000
Training Loss: 0.02207036, Training R2: 0.164296
Validation Loss: 0.03006792, Validation R2: -0.049536

Epoch 74/1000
Training Loss: 0.02529430, Training R2: -0.036168
Validation Loss: 0.02508667, Validation R2: 0.172829

Epoch 75/1000
Training Loss: 0.02376323, Training R2: 0.095062
Validation Loss: 0.03260331, Validation R2: -0.170905

Epoch 76/1000
Training Loss: 0.02672367, Training R2: -0.095488
Validation Loss: 0.02412747, Validation R2: 0.207345

Epoch 77/1000
Training Loss: 0.02364213, Training R2: 0.066284
Validation Loss: 0.03093013, Validation R2: -0.074068

Epoch 78/1000
Training Loss: 0.02521551, Training R2: -0.002992
Validation Loss: 0.03080229, Validation R2: -0.067197

Epoch 79/1000
Training Loss: 0.02613648, Training R2: -0.047112
Validation Loss: 0.02599337, Validation R2: 0.148227

Epoch 80/1000
Training Loss: 0.02498548, Training R2: 0.013915
Validation Loss: 0.03255644, Validation R2: -0.146090

Epoch 81/1000
Training Loss: 0.02624465, Training R2: -0.042112
Validation Loss: 0.02303125, Validation R2: 0.250538
Saved best model with validation R2 0.250538 to best_finetuned_model.pth

Epoch 82/1000
Training Loss: 0.02258315, Training R2: 0.125889
Validation Loss: 0.02948977, Validation R2: 0.001883

Epoch 83/1000
Training Loss: 0.02451018, Training R2: 0.037222
Validation Loss: 0.03102412, Validation R2: -0.070178

Epoch 84/1000
Training Loss: 0.02564960, Training R2: -0.035646
Validation Loss: 0.02345870, Validation R2: 0.237564

Epoch 85/1000
Training Loss: 0.02371111, Training R2: 0.094768
Validation Loss: 0.02826945, Validation R2: 0.061174

Epoch 86/1000
Training Loss: 0.02281318, Training R2: 0.111245
Validation Loss: 0.02512211, Validation R2: 0.190289

Epoch 87/1000
Training Loss: 0.02079529, Training R2: 0.222551
Validation Loss: 0.02305116, Validation R2: 0.249411

Epoch 88/1000
Training Loss: 0.02117373, Training R2: 0.209825
Validation Loss: 0.02456241, Validation R2: 0.192727

Epoch 89/1000
Training Loss: 0.02288014, Training R2: 0.109063
Validation Loss: 0.02497347, Validation R2: 0.166167

Epoch 90/1000
Training Loss: 0.02063899, Training R2: 0.244691
Validation Loss: 0.02333316, Validation R2: 0.231308

Epoch 91/1000
Training Loss: 0.02030902, Training R2: 0.252787
Validation Loss: 0.02411881, Validation R2: 0.192669

Epoch 92/1000
Training Loss: 0.02077772, Training R2: 0.216992
Validation Loss: 0.02304213, Validation R2: 0.255232
Saved best model with validation R2 0.255232 to best_finetuned_model.pth

Epoch 93/1000
Training Loss: 0.02050049, Training R2: 0.240264
Validation Loss: 0.02293658, Validation R2: 0.249951

Epoch 94/1000
Training Loss: 0.02015310, Training R2: 0.259476
Validation Loss: 0.02360844, Validation R2: 0.229826

Epoch 95/1000
Training Loss: 0.02029099, Training R2: 0.257209
Validation Loss: 0.02364090, Validation R2: 0.218868

Epoch 96/1000
Training Loss: 0.02072129, Training R2: 0.246661
Validation Loss: 0.02303397, Validation R2: 0.253473

Epoch 97/1000
Training Loss: 0.01983338, Training R2: 0.280847
Validation Loss: 0.02340066, Validation R2: 0.238448

Epoch 98/1000
Training Loss: 0.01993811, Training R2: 0.278856
Validation Loss: 0.02571850, Validation R2: 0.169349

Epoch 99/1000
Training Loss: 0.02111248, Training R2: 0.223828
Validation Loss: 0.02535202, Validation R2: 0.181371

Epoch 100/1000
Training Loss: 0.02127367, Training R2: 0.227354
Validation Loss: 0.02337580, Validation R2: 0.238344

Epoch 101/1000
Training Loss: 0.01973496, Training R2: 0.282912
Validation Loss: 0.02411753, Validation R2: 0.220473

Epoch 102/1000
Training Loss: 0.02020083, Training R2: 0.276631
Validation Loss: 0.03685347, Validation R2: -0.398993

Epoch 103/1000
Training Loss: 0.03036602, Training R2: -0.320970
Validation Loss: 0.02519793, Validation R2: 0.173550

Epoch 104/1000
Training Loss: 0.02325645, Training R2: 0.073311
Validation Loss: 0.02341513, Validation R2: 0.233887

Epoch 105/1000
Training Loss: 0.02228168, Training R2: 0.142608
Validation Loss: 0.02423402, Validation R2: 0.227521

Epoch 106/1000
Training Loss: 0.02230016, Training R2: 0.150681
Validation Loss: 0.02594921, Validation R2: 0.158086

Epoch 107/1000
Training Loss: 0.02410565, Training R2: 0.074855
Validation Loss: 0.02598272, Validation R2: 0.163224

Epoch 108/1000
Training Loss: 0.02230361, Training R2: 0.150797
Validation Loss: 0.02361837, Validation R2: 0.247215

Epoch 109/1000
Training Loss: 0.02306315, Training R2: 0.103398
Validation Loss: 0.02712302, Validation R2: 0.109657

Epoch 110/1000
Training Loss: 0.02474285, Training R2: 0.010076
Validation Loss: 0.02757014, Validation R2: 0.104733

Epoch 111/1000
Training Loss: 0.02275305, Training R2: 0.167959
Validation Loss: 0.02765774, Validation R2: 0.095249

Epoch 112/1000
Training Loss: 0.02247991, Training R2: 0.178995
Validation Loss: 0.02404318, Validation R2: 0.215783

Epoch 113/1000
Epoch 00113: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.02105996, Training R2: 0.236641
Validation Loss: 0.02595558, Validation R2: 0.136810

Epoch 114/1000
学习率已减少 2 次
Training Loss: 0.02145098, Training R2: 0.217189
Validation Loss: 0.02629509, Validation R2: 0.152474

Epoch 115/1000
Training Loss: 0.02033171, Training R2: 0.257260
Validation Loss: 0.02415333, Validation R2: 0.217139

Epoch 116/1000
Training Loss: 0.02022471, Training R2: 0.275340
Validation Loss: 0.02301275, Validation R2: 0.261292
Saved best model with validation R2 0.261292 to best_finetuned_model.pth

Epoch 117/1000
Training Loss: 0.02060700, Training R2: 0.251175
Validation Loss: 0.02646496, Validation R2: 0.142597

Epoch 118/1000
Training Loss: 0.02160867, Training R2: 0.195296
Validation Loss: 0.02476866, Validation R2: 0.194190

Epoch 119/1000
Training Loss: 0.02119156, Training R2: 0.212943
Validation Loss: 0.02337063, Validation R2: 0.245513

Epoch 120/1000
Training Loss: 0.02117476, Training R2: 0.234876
Validation Loss: 0.02488884, Validation R2: 0.209454

Epoch 121/1000
Training Loss: 0.02014559, Training R2: 0.278574
Validation Loss: 0.02333687, Validation R2: 0.257562

Epoch 122/1000
Training Loss: 0.01962434, Training R2: 0.305628
Validation Loss: 0.02277519, Validation R2: 0.275224
Saved best model with validation R2 0.275224 to best_finetuned_model.pth

Epoch 123/1000
Training Loss: 0.01958311, Training R2: 0.313430
Validation Loss: 0.02340238, Validation R2: 0.258852

Epoch 124/1000
Training Loss: 0.01953695, Training R2: 0.303174
Validation Loss: 0.02287584, Validation R2: 0.271899

Epoch 125/1000
Training Loss: 0.01934550, Training R2: 0.315628
Validation Loss: 0.02287233, Validation R2: 0.273161

Epoch 126/1000
Training Loss: 0.01921017, Training R2: 0.323309
Validation Loss: 0.02275155, Validation R2: 0.277280
Saved best model with validation R2 0.277280 to best_finetuned_model.pth

Epoch 127/1000
Training Loss: 0.01918473, Training R2: 0.323691
Validation Loss: 0.02294940, Validation R2: 0.271328

Epoch 128/1000
Training Loss: 0.01926909, Training R2: 0.316192
Validation Loss: 0.02346557, Validation R2: 0.254001

Epoch 129/1000
Training Loss: 0.01947712, Training R2: 0.304383
Validation Loss: 0.02327846, Validation R2: 0.255677

Epoch 130/1000
Training Loss: 0.01958986, Training R2: 0.301236
Validation Loss: 0.02370090, Validation R2: 0.238426

Epoch 131/1000
Training Loss: 0.01975555, Training R2: 0.298993
Validation Loss: 0.02486586, Validation R2: 0.196302

Epoch 132/1000
Training Loss: 0.01998145, Training R2: 0.273119
Validation Loss: 0.02263224, Validation R2: 0.272132

Epoch 133/1000
Training Loss: 0.02025854, Training R2: 0.264597
Validation Loss: 0.02588014, Validation R2: 0.164661

Epoch 134/1000
Training Loss: 0.02113181, Training R2: 0.247369
Validation Loss: 0.02319167, Validation R2: 0.259078

Epoch 135/1000
Training Loss: 0.02042403, Training R2: 0.269920
Validation Loss: 0.02550008, Validation R2: 0.191459

Epoch 136/1000
Training Loss: 0.02038520, Training R2: 0.257905
Validation Loss: 0.02327598, Validation R2: 0.252443

Epoch 137/1000
Training Loss: 0.01977828, Training R2: 0.303650
Validation Loss: 0.02275693, Validation R2: 0.278694
Saved best model with validation R2 0.278694 to best_finetuned_model.pth

Epoch 138/1000
Training Loss: 0.01905090, Training R2: 0.336013
Validation Loss: 0.02399348, Validation R2: 0.236287

Epoch 139/1000
Training Loss: 0.02039611, Training R2: 0.266492
Validation Loss: 0.02349242, Validation R2: 0.252845

Epoch 140/1000
Training Loss: 0.01983006, Training R2: 0.281165
Validation Loss: 0.02637223, Validation R2: 0.140409

Epoch 141/1000
Training Loss: 0.02122566, Training R2: 0.221978
Validation Loss: 0.02341376, Validation R2: 0.261200

Epoch 142/1000
Training Loss: 0.02224111, Training R2: 0.202378
Validation Loss: 0.02466008, Validation R2: 0.227305

Epoch 143/1000
Training Loss: 0.01987480, Training R2: 0.284220
Validation Loss: 0.02479652, Validation R2: 0.199057

Epoch 144/1000
Training Loss: 0.02069702, Training R2: 0.275451
Validation Loss: 0.02435244, Validation R2: 0.235199

Epoch 145/1000
Training Loss: 0.02003777, Training R2: 0.282475
Validation Loss: 0.02291722, Validation R2: 0.279501
Saved best model with validation R2 0.279501 to best_finetuned_model.pth

Epoch 146/1000
Training Loss: 0.01974811, Training R2: 0.295189
Validation Loss: 0.02295357, Validation R2: 0.279031

Epoch 147/1000
Training Loss: 0.01946373, Training R2: 0.308564
Validation Loss: 0.02300533, Validation R2: 0.273764

Epoch 148/1000
Training Loss: 0.01934400, Training R2: 0.330791
Validation Loss: 0.02710750, Validation R2: 0.129815

Epoch 149/1000
Training Loss: 0.02130846, Training R2: 0.229112
Validation Loss: 0.02286804, Validation R2: 0.282962
Saved best model with validation R2 0.282962 to best_finetuned_model.pth

Epoch 150/1000
Training Loss: 0.02044220, Training R2: 0.264090
Validation Loss: 0.02409540, Validation R2: 0.244412

Epoch 151/1000
Training Loss: 0.01992696, Training R2: 0.300476
Validation Loss: 0.02329475, Validation R2: 0.270274

Epoch 152/1000
Training Loss: 0.01931416, Training R2: 0.324368
Validation Loss: 0.02387652, Validation R2: 0.253990

Epoch 153/1000
Training Loss: 0.01922540, Training R2: 0.324540
Validation Loss: 0.02882762, Validation R2: 0.042148

Epoch 154/1000
Training Loss: 0.02269691, Training R2: 0.168197
Validation Loss: 0.02451326, Validation R2: 0.236901

Epoch 155/1000
Training Loss: 0.02085852, Training R2: 0.250255
Validation Loss: 0.02539926, Validation R2: 0.203266

Epoch 156/1000
Training Loss: 0.02033731, Training R2: 0.262898
Validation Loss: 0.02368756, Validation R2: 0.246318

Epoch 157/1000
Training Loss: 0.01998318, Training R2: 0.288588
Validation Loss: 0.02270143, Validation R2: 0.281951

Epoch 158/1000
Training Loss: 0.01916026, Training R2: 0.330073
Validation Loss: 0.02248298, Validation R2: 0.290768
Saved best model with validation R2 0.290768 to best_finetuned_model.pth

Epoch 159/1000
Training Loss: 0.01872802, Training R2: 0.355105
Validation Loss: 0.02264330, Validation R2: 0.285137

Epoch 160/1000
Training Loss: 0.01880837, Training R2: 0.353490
Validation Loss: 0.02347788, Validation R2: 0.258450

Epoch 161/1000
Training Loss: 0.01932974, Training R2: 0.333648
Validation Loss: 0.02379292, Validation R2: 0.249292

Epoch 162/1000
Training Loss: 0.01927101, Training R2: 0.331301
Validation Loss: 0.02293424, Validation R2: 0.262962

Epoch 163/1000
Training Loss: 0.01978168, Training R2: 0.289072
Validation Loss: 0.02657503, Validation R2: 0.143054

Epoch 164/1000
Training Loss: 0.02162139, Training R2: 0.219111
Validation Loss: 0.02313767, Validation R2: 0.265777

Epoch 165/1000
Training Loss: 0.02128256, Training R2: 0.240682
Validation Loss: 0.02852987, Validation R2: 0.066311

Epoch 166/1000
Training Loss: 0.02129776, Training R2: 0.230402
Validation Loss: 0.02252167, Validation R2: 0.291201
Saved best model with validation R2 0.291201 to best_finetuned_model.pth

Epoch 167/1000
Training Loss: 0.01975626, Training R2: 0.288902
Validation Loss: 0.02461383, Validation R2: 0.211486

Epoch 168/1000
Training Loss: 0.02052755, Training R2: 0.274461
Validation Loss: 0.02284330, Validation R2: 0.276427

Epoch 169/1000
Training Loss: 0.01963634, Training R2: 0.327313
Validation Loss: 0.02803719, Validation R2: 0.071574

Epoch 170/1000
Training Loss: 0.02162575, Training R2: 0.202700
Validation Loss: 0.02242765, Validation R2: 0.279853

Epoch 171/1000
Training Loss: 0.01964597, Training R2: 0.298158
Validation Loss: 0.02305741, Validation R2: 0.262616

Epoch 172/1000
Training Loss: 0.01937806, Training R2: 0.329224
Validation Loss: 0.02306661, Validation R2: 0.264662

Epoch 173/1000
Training Loss: 0.01928635, Training R2: 0.326535
Validation Loss: 0.02295229, Validation R2: 0.267762

Epoch 174/1000
Training Loss: 0.01894535, Training R2: 0.344652
Validation Loss: 0.02265820, Validation R2: 0.276539

Epoch 175/1000
Training Loss: 0.01851608, Training R2: 0.366728
Validation Loss: 0.02570462, Validation R2: 0.171029

Epoch 176/1000
Training Loss: 0.02091879, Training R2: 0.261331
Validation Loss: 0.02263712, Validation R2: 0.267388

Epoch 177/1000
Training Loss: 0.01905084, Training R2: 0.335299
Validation Loss: 0.02441215, Validation R2: 0.210907

Epoch 178/1000
Training Loss: 0.01960241, Training R2: 0.325667
Validation Loss: 0.02283899, Validation R2: 0.269282

Epoch 179/1000
Training Loss: 0.02000182, Training R2: 0.312479
Validation Loss: 0.02785289, Validation R2: 0.091201

Epoch 180/1000
Training Loss: 0.02113695, Training R2: 0.220925
Validation Loss: 0.02252530, Validation R2: 0.275946

Epoch 181/1000
Training Loss: 0.01968397, Training R2: 0.295684
Validation Loss: 0.02344867, Validation R2: 0.245005

Epoch 182/1000
Training Loss: 0.01929478, Training R2: 0.345002
Validation Loss: 0.02371232, Validation R2: 0.236827

Epoch 183/1000
Training Loss: 0.01966973, Training R2: 0.323609
Validation Loss: 0.02287290, Validation R2: 0.267053

Epoch 184/1000
Training Loss: 0.01913986, Training R2: 0.343453
Validation Loss: 0.02330706, Validation R2: 0.254583

Epoch 185/1000
Training Loss: 0.01928224, Training R2: 0.338849
Validation Loss: 0.02338617, Validation R2: 0.251123

Epoch 186/1000
Training Loss: 0.01863962, Training R2: 0.354627
Validation Loss: 0.02252192, Validation R2: 0.276069

Epoch 187/1000
Epoch 00187: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.01853745, Training R2: 0.366881
Validation Loss: 0.02491305, Validation R2: 0.198898

Epoch 188/1000
学习率已减少 3 次
Training Loss: 0.01899387, Training R2: 0.340115
Validation Loss: 0.02394416, Validation R2: 0.223332

Epoch 189/1000
Training Loss: 0.01915853, Training R2: 0.334746
Validation Loss: 0.02313243, Validation R2: 0.257405

Epoch 190/1000
Training Loss: 0.01881145, Training R2: 0.361022
Validation Loss: 0.02245502, Validation R2: 0.279423

Epoch 191/1000
Training Loss: 0.01867801, Training R2: 0.354489
Validation Loss: 0.02280281, Validation R2: 0.262426

Epoch 192/1000
Training Loss: 0.01829392, Training R2: 0.370481
Validation Loss: 0.02265980, Validation R2: 0.264799

Epoch 193/1000
Training Loss: 0.01820735, Training R2: 0.373386
Validation Loss: 0.02258920, Validation R2: 0.268434

Epoch 194/1000
Training Loss: 0.01809352, Training R2: 0.379775
Validation Loss: 0.02260737, Validation R2: 0.271004

Epoch 195/1000
Training Loss: 0.01808238, Training R2: 0.380369
Validation Loss: 0.02272291, Validation R2: 0.272332

Epoch 196/1000
Training Loss: 0.01834962, Training R2: 0.373803
Validation Loss: 0.02246775, Validation R2: 0.277732

Epoch 197/1000
Training Loss: 0.01813210, Training R2: 0.382385
Validation Loss: 0.02255424, Validation R2: 0.273077

Epoch 198/1000
Training Loss: 0.01808622, Training R2: 0.379094
Validation Loss: 0.02254464, Validation R2: 0.273792

Epoch 199/1000
Training Loss: 0.01805707, Training R2: 0.379137
Validation Loss: 0.02290739, Validation R2: 0.265228

Epoch 200/1000
Training Loss: 0.01821601, Training R2: 0.369748
Validation Loss: 0.02275491, Validation R2: 0.270946

Epoch 201/1000
Training Loss: 0.01808783, Training R2: 0.382531
Validation Loss: 0.02265217, Validation R2: 0.271549

Epoch 202/1000
Training Loss: 0.01812185, Training R2: 0.382072
Validation Loss: 0.02257184, Validation R2: 0.276143

Epoch 203/1000
Training Loss: 0.01801992, Training R2: 0.384345
Validation Loss: 0.02259693, Validation R2: 0.276084

Epoch 204/1000
Training Loss: 0.01795126, Training R2: 0.389544
Validation Loss: 0.02323673, Validation R2: 0.251330

Epoch 205/1000
Training Loss: 0.01868525, Training R2: 0.353706
Validation Loss: 0.02366617, Validation R2: 0.236634

Epoch 206/1000
Training Loss: 0.01910176, Training R2: 0.356046
Validation Loss: 0.02392652, Validation R2: 0.228614

Epoch 207/1000
Training Loss: 0.01914302, Training R2: 0.346416
Validation Loss: 0.02252708, Validation R2: 0.273912

Epoch 208/1000
Epoch 00208: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.01825501, Training R2: 0.388472
Validation Loss: 0.02271790, Validation R2: 0.270731

Epoch 209/1000
学习率已减少 4 次
Training Loss: 0.01802978, Training R2: 0.390575
Validation Loss: 0.02263881, Validation R2: 0.272066

Epoch 210/1000
Training Loss: 0.01823313, Training R2: 0.377202
Validation Loss: 0.02298762, Validation R2: 0.263001

Epoch 211/1000
Training Loss: 0.01797857, Training R2: 0.392153
Validation Loss: 0.02277821, Validation R2: 0.266005

Epoch 212/1000
Training Loss: 0.01848165, Training R2: 0.382258
Validation Loss: 0.02272450, Validation R2: 0.264676

Epoch 213/1000
Training Loss: 0.01848365, Training R2: 0.364066
Validation Loss: 0.02244180, Validation R2: 0.273634

Epoch 214/1000
Training Loss: 0.01798710, Training R2: 0.391937
Validation Loss: 0.02247880, Validation R2: 0.274208

Epoch 215/1000
Training Loss: 0.01794405, Training R2: 0.389278
Validation Loss: 0.02253972, Validation R2: 0.272526

Epoch 216/1000
Training Loss: 0.01786183, Training R2: 0.394408
Validation Loss: 0.02252781, Validation R2: 0.276697

Epoch 217/1000
Training Loss: 0.01788105, Training R2: 0.389150
Validation Loss: 0.02249106, Validation R2: 0.276888

Epoch 218/1000
Training Loss: 0.01789682, Training R2: 0.394339
Validation Loss: 0.02250914, Validation R2: 0.275629

Epoch 219/1000
Training Loss: 0.01787367, Training R2: 0.392613
Validation Loss: 0.02256623, Validation R2: 0.270892

Epoch 220/1000
Training Loss: 0.01784181, Training R2: 0.392949
Validation Loss: 0.02261554, Validation R2: 0.270265

Epoch 221/1000
Training Loss: 0.01777530, Training R2: 0.392610
Validation Loss: 0.02283508, Validation R2: 0.263061

Epoch 222/1000
Training Loss: 0.01803915, Training R2: 0.380079
Validation Loss: 0.02294472, Validation R2: 0.260585

Epoch 223/1000
Training Loss: 0.01924181, Training R2: 0.352382
Validation Loss: 0.02245316, Validation R2: 0.278343

Epoch 224/1000
Training Loss: 0.01818379, Training R2: 0.373790
Validation Loss: 0.02271413, Validation R2: 0.268057

Epoch 225/1000
Training Loss: 0.01805437, Training R2: 0.389265
Validation Loss: 0.02254469, Validation R2: 0.273063

Epoch 226/1000
Training Loss: 0.01790678, Training R2: 0.391241
Validation Loss: 0.02269942, Validation R2: 0.267578

Epoch 227/1000
Training Loss: 0.01799071, Training R2: 0.390695
Validation Loss: 0.02248960, Validation R2: 0.275108

Epoch 228/1000
Training Loss: 0.01797012, Training R2: 0.384097
Validation Loss: 0.02247402, Validation R2: 0.274401

Epoch 229/1000
Epoch 00229: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.01779333, Training R2: 0.397485
Validation Loss: 0.02250814, Validation R2: 0.274479

Epoch 230/1000
学习率已减少 5 次
Training Loss: 0.01789542, Training R2: 0.387662
Validation Loss: 0.02256496, Validation R2: 0.273767

Epoch 231/1000
Training Loss: 0.01776178, Training R2: 0.396686
Validation Loss: 0.02246898, Validation R2: 0.278118

Epoch 232/1000
Training Loss: 0.01767487, Training R2: 0.399207
Validation Loss: 0.02259784, Validation R2: 0.272926

Epoch 233/1000
Training Loss: 0.01780105, Training R2: 0.392611
Validation Loss: 0.02254828, Validation R2: 0.276222

Epoch 234/1000
Training Loss: 0.01775754, Training R2: 0.398037
Validation Loss: 0.02259983, Validation R2: 0.273345

Epoch 235/1000
Training Loss: 0.01785805, Training R2: 0.388462
Validation Loss: 0.02260914, Validation R2: 0.272872

Epoch 236/1000
Training Loss: 0.01767828, Training R2: 0.396393
Validation Loss: 0.02250048, Validation R2: 0.276910

Epoch 237/1000
Training Loss: 0.01779136, Training R2: 0.398387
Validation Loss: 0.02248978, Validation R2: 0.276495

Epoch 238/1000
Training Loss: 0.01778281, Training R2: 0.393048
Validation Loss: 0.02252638, Validation R2: 0.276290

Epoch 239/1000
Training Loss: 0.01780135, Training R2: 0.393667
Validation Loss: 0.02249451, Validation R2: 0.280553

Epoch 240/1000
Training Loss: 0.01766267, Training R2: 0.401184
Validation Loss: 0.02281368, Validation R2: 0.266430

Epoch 241/1000
Training Loss: 0.01801299, Training R2: 0.381435
Validation Loss: 0.02256764, Validation R2: 0.274480

Epoch 242/1000
Training Loss: 0.01772958, Training R2: 0.399843
Validation Loss: 0.02267347, Validation R2: 0.270502

Epoch 243/1000
Training Loss: 0.01812090, Training R2: 0.392686
Validation Loss: 0.02248453, Validation R2: 0.277011

Epoch 244/1000
Training Loss: 0.01770699, Training R2: 0.398288
Validation Loss: 0.02266514, Validation R2: 0.269332

Epoch 245/1000
Training Loss: 0.01778678, Training R2: 0.397330
Validation Loss: 0.02243844, Validation R2: 0.278327

Epoch 246/1000
Training Loss: 0.01779869, Training R2: 0.401498
Validation Loss: 0.02241346, Validation R2: 0.279459

Epoch 247/1000
Training Loss: 0.01762833, Training R2: 0.401785
Validation Loss: 0.02247894, Validation R2: 0.277785

Epoch 248/1000
Training Loss: 0.01769334, Training R2: 0.399252
Validation Loss: 0.02241964, Validation R2: 0.278982

Epoch 249/1000
Training Loss: 0.01767847, Training R2: 0.402516
Validation Loss: 0.02249463, Validation R2: 0.275749

Epoch 250/1000
Epoch 00250: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.01767633, Training R2: 0.399507
Validation Loss: 0.02251854, Validation R2: 0.276487

Epoch 251/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_HOMO_energy.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_HOMO_energy.png
