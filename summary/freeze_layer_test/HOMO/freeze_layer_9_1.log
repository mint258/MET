Using device: cuda
Selected target_properties: ['HOMO_energy']
Available target properties: ['rot_A', 'rot_B', 'rot_C', 'dipole', 'polarizability', 'HOMO_energy', 'LUMO_energy', 'gap', 'R2', 'zpve', 'U0', 'U298', 'H298', 'G298', 'Cv']
Total samples: 1000, Training: 800, Validation: 200
Pretrained ComENetAutoEncoder layers:
0: feature1 (torsion_emb)
1: feature2 (angle_emb)
2: emb_z (EmbeddingBlock)
3: interaction_blocks.0 (SimpleInteractionBlock)
4: interaction_blocks.1 (SimpleInteractionBlock)
5: interaction_blocks.2 (SimpleInteractionBlock)
6: interaction_blocks.3 (SimpleInteractionBlock)
7: lins.0 (Linear)
8: lins.1 (Linear)
9: lins.2 (Linear)
10: encoder (Sequential)
11: transformer_decoders_z.0 (TransformerEncoder)
12: output_layers_z.0 (Linear)
冻结层 0: feature1 (torsion_emb)
冻结层 1: feature2 (angle_emb)
冻结层 2: emb_z (EmbeddingBlock)
冻结层 3: interaction_blocks.0 (SimpleInteractionBlock)
冻结层 4: interaction_blocks.1 (SimpleInteractionBlock)
冻结层 5: interaction_blocks.2 (SimpleInteractionBlock)
冻结层 6: interaction_blocks.3 (SimpleInteractionBlock)
冻结层 7: lins.0 (Linear)
冻结层 8: lins.1 (Linear)
冻结层 9: lins.2 (Linear)

Frozen layers status:
emb_z.emb.weight: Frozen
interaction_blocks.0.conv1.lin_rel.weight: Frozen
interaction_blocks.0.conv1.lin_rel.bias: Frozen
interaction_blocks.0.conv1.lin_root.weight: Frozen
interaction_blocks.0.conv2.lin_rel.weight: Frozen
interaction_blocks.0.conv2.lin_rel.bias: Frozen
interaction_blocks.0.conv2.lin_root.weight: Frozen
interaction_blocks.0.lin1.weight: Frozen
interaction_blocks.0.lin1.bias: Frozen
interaction_blocks.0.lin2.weight: Frozen
interaction_blocks.0.lin2.bias: Frozen
interaction_blocks.0.lin_cat.weight: Frozen
interaction_blocks.0.lin_cat.bias: Frozen
interaction_blocks.0.norm.weight: Frozen
interaction_blocks.0.norm.bias: Frozen
interaction_blocks.0.norm.mean_scale: Frozen
interaction_blocks.0.lin_feature1.lin1.weight: Frozen
interaction_blocks.0.lin_feature1.lin2.weight: Frozen
interaction_blocks.0.lin_feature2.lin1.weight: Frozen
interaction_blocks.0.lin_feature2.lin2.weight: Frozen
interaction_blocks.0.lin.weight: Frozen
interaction_blocks.0.lin.bias: Frozen
interaction_blocks.0.lins.0.weight: Frozen
interaction_blocks.0.lins.0.bias: Frozen
interaction_blocks.0.lins.1.weight: Frozen
interaction_blocks.0.lins.1.bias: Frozen
interaction_blocks.0.lins.2.weight: Frozen
interaction_blocks.0.lins.2.bias: Frozen
interaction_blocks.0.lins.3.weight: Frozen
interaction_blocks.0.lins.3.bias: Frozen
interaction_blocks.0.final.weight: Frozen
interaction_blocks.0.final.bias: Frozen
interaction_blocks.1.conv1.lin_rel.weight: Frozen
interaction_blocks.1.conv1.lin_rel.bias: Frozen
interaction_blocks.1.conv1.lin_root.weight: Frozen
interaction_blocks.1.conv2.lin_rel.weight: Frozen
interaction_blocks.1.conv2.lin_rel.bias: Frozen
interaction_blocks.1.conv2.lin_root.weight: Frozen
interaction_blocks.1.lin1.weight: Frozen
interaction_blocks.1.lin1.bias: Frozen
interaction_blocks.1.lin2.weight: Frozen
interaction_blocks.1.lin2.bias: Frozen
interaction_blocks.1.lin_cat.weight: Frozen
interaction_blocks.1.lin_cat.bias: Frozen
interaction_blocks.1.norm.weight: Frozen
interaction_blocks.1.norm.bias: Frozen
interaction_blocks.1.norm.mean_scale: Frozen
interaction_blocks.1.lin_feature1.lin1.weight: Frozen
interaction_blocks.1.lin_feature1.lin2.weight: Frozen
interaction_blocks.1.lin_feature2.lin1.weight: Frozen
interaction_blocks.1.lin_feature2.lin2.weight: Frozen
interaction_blocks.1.lin.weight: Frozen
interaction_blocks.1.lin.bias: Frozen
interaction_blocks.1.lins.0.weight: Frozen
interaction_blocks.1.lins.0.bias: Frozen
interaction_blocks.1.lins.1.weight: Frozen
interaction_blocks.1.lins.1.bias: Frozen
interaction_blocks.1.lins.2.weight: Frozen
interaction_blocks.1.lins.2.bias: Frozen
interaction_blocks.1.lins.3.weight: Frozen
interaction_blocks.1.lins.3.bias: Frozen
interaction_blocks.1.final.weight: Frozen
interaction_blocks.1.final.bias: Frozen
interaction_blocks.2.conv1.lin_rel.weight: Frozen
interaction_blocks.2.conv1.lin_rel.bias: Frozen
interaction_blocks.2.conv1.lin_root.weight: Frozen
interaction_blocks.2.conv2.lin_rel.weight: Frozen
interaction_blocks.2.conv2.lin_rel.bias: Frozen
interaction_blocks.2.conv2.lin_root.weight: Frozen
interaction_blocks.2.lin1.weight: Frozen
interaction_blocks.2.lin1.bias: Frozen
interaction_blocks.2.lin2.weight: Frozen
interaction_blocks.2.lin2.bias: Frozen
interaction_blocks.2.lin_cat.weight: Frozen
interaction_blocks.2.lin_cat.bias: Frozen
interaction_blocks.2.norm.weight: Frozen
interaction_blocks.2.norm.bias: Frozen
interaction_blocks.2.norm.mean_scale: Frozen
interaction_blocks.2.lin_feature1.lin1.weight: Frozen
interaction_blocks.2.lin_feature1.lin2.weight: Frozen
interaction_blocks.2.lin_feature2.lin1.weight: Frozen
interaction_blocks.2.lin_feature2.lin2.weight: Frozen
interaction_blocks.2.lin.weight: Frozen
interaction_blocks.2.lin.bias: Frozen
interaction_blocks.2.lins.0.weight: Frozen
interaction_blocks.2.lins.0.bias: Frozen
interaction_blocks.2.lins.1.weight: Frozen
interaction_blocks.2.lins.1.bias: Frozen
interaction_blocks.2.lins.2.weight: Frozen
interaction_blocks.2.lins.2.bias: Frozen
interaction_blocks.2.lins.3.weight: Frozen
interaction_blocks.2.lins.3.bias: Frozen
interaction_blocks.2.final.weight: Frozen
interaction_blocks.2.final.bias: Frozen
interaction_blocks.3.conv1.lin_rel.weight: Frozen
interaction_blocks.3.conv1.lin_rel.bias: Frozen
interaction_blocks.3.conv1.lin_root.weight: Frozen
interaction_blocks.3.conv2.lin_rel.weight: Frozen
interaction_blocks.3.conv2.lin_rel.bias: Frozen
interaction_blocks.3.conv2.lin_root.weight: Frozen
interaction_blocks.3.lin1.weight: Frozen
interaction_blocks.3.lin1.bias: Frozen
interaction_blocks.3.lin2.weight: Frozen
interaction_blocks.3.lin2.bias: Frozen
interaction_blocks.3.lin_cat.weight: Frozen
interaction_blocks.3.lin_cat.bias: Frozen
interaction_blocks.3.norm.weight: Frozen
interaction_blocks.3.norm.bias: Frozen
interaction_blocks.3.norm.mean_scale: Frozen
interaction_blocks.3.lin_feature1.lin1.weight: Frozen
interaction_blocks.3.lin_feature1.lin2.weight: Frozen
interaction_blocks.3.lin_feature2.lin1.weight: Frozen
interaction_blocks.3.lin_feature2.lin2.weight: Frozen
interaction_blocks.3.lin.weight: Frozen
interaction_blocks.3.lin.bias: Frozen
interaction_blocks.3.lins.0.weight: Frozen
interaction_blocks.3.lins.0.bias: Frozen
interaction_blocks.3.lins.1.weight: Frozen
interaction_blocks.3.lins.1.bias: Frozen
interaction_blocks.3.lins.2.weight: Frozen
interaction_blocks.3.lins.2.bias: Frozen
interaction_blocks.3.lins.3.weight: Frozen
interaction_blocks.3.lins.3.bias: Frozen
interaction_blocks.3.final.weight: Frozen
interaction_blocks.3.final.bias: Frozen
lins.0.weight: Frozen
lins.0.bias: Frozen
lins.1.weight: Frozen
lins.1.bias: Frozen
lins.2.weight: Frozen
lins.2.bias: Frozen
encoder.0.weight: Trainable
encoder.0.bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.in_proj_bias: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.weight: Trainable
transformer_decoders_z.0.layers.0.self_attn.out_proj.bias: Trainable
transformer_decoders_z.0.layers.0.linear1.weight: Trainable
transformer_decoders_z.0.layers.0.linear1.bias: Trainable
transformer_decoders_z.0.layers.0.linear2.weight: Trainable
transformer_decoders_z.0.layers.0.linear2.bias: Trainable
transformer_decoders_z.0.layers.0.norm1.weight: Trainable
transformer_decoders_z.0.layers.0.norm1.bias: Trainable
transformer_decoders_z.0.layers.0.norm2.weight: Trainable
transformer_decoders_z.0.layers.0.norm2.bias: Trainable
output_layers_z.0.weight: Trainable
output_layers_z.0.bias: Trainable
模型的总可训练参数量: 1026435

Epoch 1/1000
Training Loss: 0.92367851, Training R2: -949.641724
Validation Loss: 0.31242752, Validation R2: -74.735313
Saved best model with validation R2 -74.735313 to best_finetuned_model.pth

Epoch 2/1000
Training Loss: 0.31949666, Training R2: -112.875244
Validation Loss: 0.26210403, Validation R2: -51.290245
Saved best model with validation R2 -51.290245 to best_finetuned_model.pth

Epoch 3/1000
Training Loss: 0.17274089, Training R2: -34.314018
Validation Loss: 0.10038427, Validation R2: -7.801769
Saved best model with validation R2 -7.801769 to best_finetuned_model.pth

Epoch 4/1000
Training Loss: 0.10000868, Training R2: -11.103559
Validation Loss: 0.09151205, Validation R2: -6.591084
Saved best model with validation R2 -6.591084 to best_finetuned_model.pth

Epoch 5/1000
Training Loss: 0.09005247, Training R2: -9.021968
Validation Loss: 0.11534703, Validation R2: -9.761210

Epoch 6/1000
Training Loss: 0.07582487, Training R2: -6.371445
Validation Loss: 0.04534983, Validation R2: -1.305649
Saved best model with validation R2 -1.305649 to best_finetuned_model.pth

Epoch 7/1000
Training Loss: 0.05865419, Training R2: -3.532777
Validation Loss: 0.05631010, Validation R2: -2.159374

Epoch 8/1000
Training Loss: 0.05584244, Training R2: -3.191250
Validation Loss: 0.06077374, Validation R2: -2.298537

Epoch 9/1000
Training Loss: 0.04568109, Training R2: -1.924079
Validation Loss: 0.04026689, Validation R2: -0.697734
Saved best model with validation R2 -0.697734 to best_finetuned_model.pth

Epoch 10/1000
Training Loss: 0.04075138, Training R2: -1.397868
Validation Loss: 0.03506088, Validation R2: -0.343269
Saved best model with validation R2 -0.343269 to best_finetuned_model.pth

Epoch 11/1000
Training Loss: 0.03806733, Training R2: -1.047758
Validation Loss: 0.02863022, Validation R2: 0.019785
Saved best model with validation R2 0.019785 to best_finetuned_model.pth

Epoch 12/1000
Training Loss: 0.02661307, Training R2: -0.150130
Validation Loss: 0.02568900, Validation R2: 0.113840
Saved best model with validation R2 0.113840 to best_finetuned_model.pth

Epoch 13/1000
Training Loss: 0.02501417, Training R2: -0.068685
Validation Loss: 0.02658845, Validation R2: 0.067183

Epoch 14/1000
Training Loss: 0.02534542, Training R2: -0.088526
Validation Loss: 0.02485176, Validation R2: 0.112333

Epoch 15/1000
Training Loss: 0.02341521, Training R2: 0.015909
Validation Loss: 0.02638446, Validation R2: 0.040036

Epoch 16/1000
Training Loss: 0.02337469, Training R2: 0.040428
Validation Loss: 0.02446917, Validation R2: 0.180538
Saved best model with validation R2 0.180538 to best_finetuned_model.pth

Epoch 17/1000
Training Loss: 0.02527674, Training R2: -0.069312
Validation Loss: 0.03004235, Validation R2: 0.006005

Epoch 18/1000
Training Loss: 0.02533475, Training R2: -0.085320
Validation Loss: 0.02433572, Validation R2: 0.167103

Epoch 19/1000
Training Loss: 0.02181625, Training R2: 0.124174
Validation Loss: 0.03053504, Validation R2: -0.046549

Epoch 20/1000
Training Loss: 0.02502865, Training R2: -0.080947
Validation Loss: 0.02573078, Validation R2: 0.085042

Epoch 21/1000
Training Loss: 0.02227205, Training R2: 0.089878
Validation Loss: 0.03231097, Validation R2: -0.137786

Epoch 22/1000
Training Loss: 0.02673027, Training R2: -0.130486
Validation Loss: 0.02580534, Validation R2: 0.132071

Epoch 23/1000
Training Loss: 0.02867583, Training R2: -0.343526
Validation Loss: 0.04512626, Validation R2: -0.985163

Epoch 24/1000
Training Loss: 0.03583192, Training R2: -0.802613
Validation Loss: 0.03412751, Validation R2: -0.249099

Epoch 25/1000
Training Loss: 0.03025758, Training R2: -0.380908
Validation Loss: 0.02964100, Validation R2: -0.023392

Epoch 26/1000
Training Loss: 0.03844373, Training R2: -1.032225
Validation Loss: 0.04669837, Validation R2: -1.138068

Epoch 27/1000
Training Loss: 0.03348641, Training R2: -0.705701
Validation Loss: 0.02613236, Validation R2: 0.137444

Epoch 28/1000
Training Loss: 0.02634624, Training R2: -0.115948
Validation Loss: 0.02643430, Validation R2: 0.131258

Epoch 29/1000
Training Loss: 0.02958416, Training R2: -0.378236
Validation Loss: 0.02488020, Validation R2: 0.167140

Epoch 30/1000
Training Loss: 0.03044517, Training R2: -0.506342
Validation Loss: 0.03542437, Validation R2: -0.291079

Epoch 31/1000
Training Loss: 0.04007580, Training R2: -1.095528
Validation Loss: 0.04407931, Validation R2: -0.901377

Epoch 32/1000
Training Loss: 0.03440467, Training R2: -0.688255
Validation Loss: 0.02934002, Validation R2: 0.014319

Epoch 33/1000
Training Loss: 0.02575042, Training R2: -0.105118
Validation Loss: 0.02627057, Validation R2: 0.067008

Epoch 34/1000
Training Loss: 0.02296667, Training R2: 0.084103
Validation Loss: 0.02413172, Validation R2: 0.187026
Saved best model with validation R2 0.187026 to best_finetuned_model.pth

Epoch 35/1000
Training Loss: 0.02158069, Training R2: 0.144696
Validation Loss: 0.02707662, Validation R2: 0.024699

Epoch 36/1000
Training Loss: 0.02351891, Training R2: 0.027103
Validation Loss: 0.02473032, Validation R2: 0.122290

Epoch 37/1000
Training Loss: 0.02210799, Training R2: 0.139784
Validation Loss: 0.02426369, Validation R2: 0.169939

Epoch 38/1000
Training Loss: 0.02316323, Training R2: 0.088480
Validation Loss: 0.02599849, Validation R2: 0.152019

Epoch 39/1000
Training Loss: 0.02357229, Training R2: 0.068042
Validation Loss: 0.03266939, Validation R2: -0.222544

Epoch 40/1000
Training Loss: 0.02480128, Training R2: -0.000352
Validation Loss: 0.02382197, Validation R2: 0.239013
Saved best model with validation R2 0.239013 to best_finetuned_model.pth

Epoch 41/1000
Training Loss: 0.02088971, Training R2: 0.212269
Validation Loss: 0.03073615, Validation R2: -0.113075

Epoch 42/1000
Training Loss: 0.02597706, Training R2: -0.059680
Validation Loss: 0.02451861, Validation R2: 0.173639

Epoch 43/1000
Training Loss: 0.02105026, Training R2: 0.190521
Validation Loss: 0.02349162, Validation R2: 0.227729

Epoch 44/1000
Training Loss: 0.02043134, Training R2: 0.221664
Validation Loss: 0.02590790, Validation R2: 0.097599

Epoch 45/1000
Training Loss: 0.02340339, Training R2: 0.047953
Validation Loss: 0.02675298, Validation R2: 0.127507

Epoch 46/1000
Training Loss: 0.02172423, Training R2: 0.156808
Validation Loss: 0.02728164, Validation R2: 0.025760

Epoch 47/1000
Training Loss: 0.02395396, Training R2: 0.028626
Validation Loss: 0.02337296, Validation R2: 0.228558

Epoch 48/1000
Training Loss: 0.02039191, Training R2: 0.228284
Validation Loss: 0.02857919, Validation R2: 0.056935

Epoch 49/1000
Training Loss: 0.02528008, Training R2: -0.039312
Validation Loss: 0.02410198, Validation R2: 0.208850

Epoch 50/1000
Training Loss: 0.02217361, Training R2: 0.145552
Validation Loss: 0.02755255, Validation R2: 0.080957

Epoch 51/1000
Training Loss: 0.02761585, Training R2: -0.180917
Validation Loss: 0.03743106, Validation R2: -0.437653

Epoch 52/1000
Training Loss: 0.03620366, Training R2: -0.862336
Validation Loss: 0.05354754, Validation R2: -1.691404

Epoch 53/1000
Training Loss: 0.04881315, Training R2: -1.949126
Validation Loss: 0.03922059, Validation R2: -0.564412

Epoch 54/1000
Training Loss: 0.03851259, Training R2: -0.955650
Validation Loss: 0.03705538, Validation R2: -0.456672

Epoch 55/1000
Training Loss: 0.03936743, Training R2: -1.080897
Validation Loss: 0.05200545, Validation R2: -1.590947

Epoch 56/1000
Training Loss: 0.04568203, Training R2: -1.703832
Validation Loss: 0.03781493, Validation R2: -0.441402

Epoch 57/1000
Training Loss: 0.03504953, Training R2: -0.700328
Validation Loss: 0.03618675, Validation R2: -0.365242

Epoch 58/1000
Training Loss: 0.03656321, Training R2: -0.824550
Validation Loss: 0.04734574, Validation R2: -1.204121

Epoch 59/1000
Training Loss: 0.04388386, Training R2: -1.461723
Validation Loss: 0.03159779, Validation R2: -0.085056

Epoch 60/1000
Training Loss: 0.03218807, Training R2: -0.442989
Validation Loss: 0.03248082, Validation R2: -0.113888

Epoch 61/1000
Epoch 00061: reducing learning rate of group 0 to 5.0000e-05.
Training Loss: 0.02923166, Training R2: -0.302567
Validation Loss: 0.04509289, Validation R2: -0.992616

Epoch 62/1000
学习率已减少 1 次
Training Loss: 0.03495360, Training R2: -0.712718
Validation Loss: 0.03152015, Validation R2: -0.132244

Epoch 63/1000
Training Loss: 0.02979509, Training R2: -0.303314
Validation Loss: 0.03387679, Validation R2: -0.255231

Epoch 64/1000
Training Loss: 0.02743392, Training R2: -0.193099
Validation Loss: 0.03688159, Validation R2: -0.426022

Epoch 65/1000
Training Loss: 0.02972427, Training R2: -0.340791
Validation Loss: 0.02357043, Validation R2: 0.229830

Epoch 66/1000
Training Loss: 0.02486661, Training R2: -0.012199
Validation Loss: 0.02921027, Validation R2: 0.008048

Epoch 67/1000
Training Loss: 0.02451493, Training R2: 0.029299
Validation Loss: 0.02518030, Validation R2: 0.169053

Epoch 68/1000
Training Loss: 0.02141857, Training R2: 0.191134
Validation Loss: 0.02564117, Validation R2: 0.198124

Epoch 69/1000
Training Loss: 0.02097396, Training R2: 0.207858
Validation Loss: 0.02886336, Validation R2: 0.061053

Epoch 70/1000
Training Loss: 0.02387558, Training R2: 0.045382
Validation Loss: 0.02547225, Validation R2: 0.183984

Epoch 71/1000
Training Loss: 0.02230769, Training R2: 0.165631
Validation Loss: 0.02403955, Validation R2: 0.215352

Epoch 72/1000
Training Loss: 0.02264843, Training R2: 0.134951
Validation Loss: 0.02429440, Validation R2: 0.203994

Epoch 73/1000
Training Loss: 0.02089680, Training R2: 0.234991
Validation Loss: 0.03656249, Validation R2: -0.413475

Epoch 74/1000
Training Loss: 0.02925285, Training R2: -0.293474
Validation Loss: 0.02300625, Validation R2: 0.259939
Saved best model with validation R2 0.259939 to best_finetuned_model.pth

Epoch 75/1000
Training Loss: 0.02358759, Training R2: 0.091123
Validation Loss: 0.03696468, Validation R2: -0.400110

Epoch 76/1000
Training Loss: 0.03051869, Training R2: -0.348809
Validation Loss: 0.02372639, Validation R2: 0.228879

Epoch 77/1000
Training Loss: 0.02661299, Training R2: -0.076437
Validation Loss: 0.03053512, Validation R2: -0.060902

Epoch 78/1000
Training Loss: 0.02483249, Training R2: 0.024636
Validation Loss: 0.03299037, Validation R2: -0.175636

Epoch 79/1000
Training Loss: 0.02816906, Training R2: -0.206436
Validation Loss: 0.03002310, Validation R2: -0.018729

Epoch 80/1000
Training Loss: 0.02572753, Training R2: -0.043256
Validation Loss: 0.02732261, Validation R2: 0.122337

Epoch 81/1000
Training Loss: 0.02335445, Training R2: 0.127828
Validation Loss: 0.02291911, Validation R2: 0.283477
Saved best model with validation R2 0.283477 to best_finetuned_model.pth

Epoch 82/1000
Training Loss: 0.02049354, Training R2: 0.254474
Validation Loss: 0.02280194, Validation R2: 0.284012
Saved best model with validation R2 0.284012 to best_finetuned_model.pth

Epoch 83/1000
Training Loss: 0.02093403, Training R2: 0.239425
Validation Loss: 0.02819307, Validation R2: 0.019276

Epoch 84/1000
Training Loss: 0.02300062, Training R2: 0.121920
Validation Loss: 0.03366661, Validation R2: -0.260850

Epoch 85/1000
Training Loss: 0.02563331, Training R2: -0.036361
Validation Loss: 0.02418932, Validation R2: 0.203784

Epoch 86/1000
Training Loss: 0.02294246, Training R2: 0.125217
Validation Loss: 0.02583268, Validation R2: 0.181242

Epoch 87/1000
Training Loss: 0.02342053, Training R2: 0.107857
Validation Loss: 0.02768726, Validation R2: 0.106982

Epoch 88/1000
Training Loss: 0.02246269, Training R2: 0.152446
Validation Loss: 0.02396716, Validation R2: 0.258886

Epoch 89/1000
Training Loss: 0.02142355, Training R2: 0.233940
Validation Loss: 0.02283984, Validation R2: 0.289730
Saved best model with validation R2 0.289730 to best_finetuned_model.pth

Epoch 90/1000
Training Loss: 0.02108034, Training R2: 0.230848
Validation Loss: 0.02667636, Validation R2: 0.164175

Epoch 91/1000
Training Loss: 0.02180160, Training R2: 0.196562
Validation Loss: 0.02319927, Validation R2: 0.269856

Epoch 92/1000
Training Loss: 0.02074946, Training R2: 0.258310
Validation Loss: 0.02272532, Validation R2: 0.285954

Epoch 93/1000
Training Loss: 0.02100709, Training R2: 0.235221
Validation Loss: 0.02265271, Validation R2: 0.287137

Epoch 94/1000
Training Loss: 0.02049751, Training R2: 0.262659
Validation Loss: 0.02365133, Validation R2: 0.244718

Epoch 95/1000
Training Loss: 0.02045581, Training R2: 0.263849
Validation Loss: 0.02476056, Validation R2: 0.190991

Epoch 96/1000
Training Loss: 0.02046151, Training R2: 0.261593
Validation Loss: 0.02265752, Validation R2: 0.293569
Saved best model with validation R2 0.293569 to best_finetuned_model.pth

Epoch 97/1000
Training Loss: 0.01945605, Training R2: 0.302232
Validation Loss: 0.02276539, Validation R2: 0.284209

Epoch 98/1000
Training Loss: 0.01991402, Training R2: 0.283591
Validation Loss: 0.02327582, Validation R2: 0.283668

Epoch 99/1000
Training Loss: 0.02109085, Training R2: 0.229669
Validation Loss: 0.02257626, Validation R2: 0.301029
Saved best model with validation R2 0.301029 to best_finetuned_model.pth

Epoch 100/1000
Training Loss: 0.02015349, Training R2: 0.279631
Validation Loss: 0.02514450, Validation R2: 0.177155

Epoch 101/1000
Training Loss: 0.02173308, Training R2: 0.207562
Validation Loss: 0.02540958, Validation R2: 0.129334

Epoch 102/1000
Training Loss: 0.02074060, Training R2: 0.210477
Validation Loss: 0.02423223, Validation R2: 0.242240

Epoch 103/1000
Training Loss: 0.02129523, Training R2: 0.235577
Validation Loss: 0.02893480, Validation R2: 0.028966

Epoch 104/1000
Training Loss: 0.02408178, Training R2: 0.067636
Validation Loss: 0.03271221, Validation R2: -0.147812

Epoch 105/1000
Training Loss: 0.02934401, Training R2: -0.236800
Validation Loss: 0.02586813, Validation R2: 0.186941

Epoch 106/1000
Training Loss: 0.02592725, Training R2: -0.036894
Validation Loss: 0.02554818, Validation R2: 0.170017

Epoch 107/1000
Training Loss: 0.02688046, Training R2: -0.097875
Validation Loss: 0.02601952, Validation R2: 0.159806

Epoch 108/1000
Training Loss: 0.02234380, Training R2: 0.158572
Validation Loss: 0.02568314, Validation R2: 0.157561

Epoch 109/1000
Training Loss: 0.02169230, Training R2: 0.207059
Validation Loss: 0.02345314, Validation R2: 0.242303

Epoch 110/1000
Training Loss: 0.02105723, Training R2: 0.229653
Validation Loss: 0.03057757, Validation R2: -0.054501

Epoch 111/1000
Training Loss: 0.02461685, Training R2: 0.084706
Validation Loss: 0.03243138, Validation R2: -0.136659

Epoch 112/1000
Training Loss: 0.02557176, Training R2: 0.008095
Validation Loss: 0.02287254, Validation R2: 0.268990

Epoch 113/1000
Training Loss: 0.02140617, Training R2: 0.216969
Validation Loss: 0.02346073, Validation R2: 0.231742

Epoch 114/1000
Training Loss: 0.02132917, Training R2: 0.231668
Validation Loss: 0.02267425, Validation R2: 0.270320

Epoch 115/1000
Training Loss: 0.02043262, Training R2: 0.257059
Validation Loss: 0.02392395, Validation R2: 0.219450

Epoch 116/1000
Training Loss: 0.02005654, Training R2: 0.299288
Validation Loss: 0.02451380, Validation R2: 0.182421

Epoch 117/1000
Training Loss: 0.01998076, Training R2: 0.299775
Validation Loss: 0.02259672, Validation R2: 0.278307

Epoch 118/1000
Training Loss: 0.01937269, Training R2: 0.330047
Validation Loss: 0.02302933, Validation R2: 0.267830

Epoch 119/1000
Training Loss: 0.01972205, Training R2: 0.311609
Validation Loss: 0.02483043, Validation R2: 0.171510

Epoch 120/1000
Epoch 00120: reducing learning rate of group 0 to 2.5000e-05.
Training Loss: 0.02035508, Training R2: 0.262582
Validation Loss: 0.02567966, Validation R2: 0.128635

Epoch 121/1000
学习率已减少 2 次
Training Loss: 0.02059924, Training R2: 0.274543
Validation Loss: 0.02276398, Validation R2: 0.259383

Epoch 122/1000
Training Loss: 0.02099604, Training R2: 0.256503
Validation Loss: 0.02519172, Validation R2: 0.181464

Epoch 123/1000
Training Loss: 0.02033540, Training R2: 0.270086
Validation Loss: 0.02359316, Validation R2: 0.222782

Epoch 124/1000
Training Loss: 0.01967552, Training R2: 0.304148
Validation Loss: 0.02328313, Validation R2: 0.236618

Epoch 125/1000
Training Loss: 0.01948792, Training R2: 0.316877
Validation Loss: 0.02273491, Validation R2: 0.269013

Epoch 126/1000
Training Loss: 0.01893204, Training R2: 0.333693
Validation Loss: 0.02321335, Validation R2: 0.266515

Epoch 127/1000
Training Loss: 0.01911210, Training R2: 0.332797
Validation Loss: 0.02304551, Validation R2: 0.249245

Epoch 128/1000
Training Loss: 0.01885354, Training R2: 0.348262
Validation Loss: 0.02255004, Validation R2: 0.277256

Epoch 129/1000
Training Loss: 0.01868009, Training R2: 0.356770
Validation Loss: 0.02257341, Validation R2: 0.274187

Epoch 130/1000
Training Loss: 0.01879806, Training R2: 0.353582
Validation Loss: 0.02321137, Validation R2: 0.241861

Epoch 131/1000
Training Loss: 0.01912434, Training R2: 0.333085
Validation Loss: 0.02292146, Validation R2: 0.282386

Epoch 132/1000
Training Loss: 0.01875757, Training R2: 0.350379
Validation Loss: 0.02248124, Validation R2: 0.281533

Epoch 133/1000
Training Loss: 0.01890119, Training R2: 0.337411
Validation Loss: 0.02607943, Validation R2: 0.112692

Epoch 134/1000
Training Loss: 0.02082579, Training R2: 0.249033
Validation Loss: 0.02325020, Validation R2: 0.231486

Epoch 135/1000
Training Loss: 0.01995096, Training R2: 0.267746
Validation Loss: 0.02426532, Validation R2: 0.230687

Epoch 136/1000
Training Loss: 0.02011917, Training R2: 0.283262
Validation Loss: 0.02292754, Validation R2: 0.282496

Epoch 137/1000
Training Loss: 0.01908103, Training R2: 0.332818
Validation Loss: 0.02241879, Validation R2: 0.294291

Epoch 138/1000
Training Loss: 0.01882907, Training R2: 0.346649
Validation Loss: 0.02228471, Validation R2: 0.287656

Epoch 139/1000
Training Loss: 0.01885533, Training R2: 0.340622
Validation Loss: 0.02264925, Validation R2: 0.276031

Epoch 140/1000
Training Loss: 0.01853213, Training R2: 0.362393
Validation Loss: 0.02383389, Validation R2: 0.223103

Epoch 141/1000
Epoch 00141: reducing learning rate of group 0 to 1.2500e-05.
Training Loss: 0.01968491, Training R2: 0.305110
Validation Loss: 0.02228593, Validation R2: 0.300638

Epoch 142/1000
学习率已减少 3 次
Training Loss: 0.01949571, Training R2: 0.332593
Validation Loss: 0.02254907, Validation R2: 0.277753

Epoch 143/1000
Training Loss: 0.01897200, Training R2: 0.348592
Validation Loss: 0.02236776, Validation R2: 0.297015

Epoch 144/1000
Training Loss: 0.01864949, Training R2: 0.348874
Validation Loss: 0.02281482, Validation R2: 0.284054

Epoch 145/1000
Training Loss: 0.01919392, Training R2: 0.336126
Validation Loss: 0.02262823, Validation R2: 0.279751

Epoch 146/1000
Training Loss: 0.01842553, Training R2: 0.362037
Validation Loss: 0.02259913, Validation R2: 0.287940

Epoch 147/1000
Training Loss: 0.01880928, Training R2: 0.349826
Validation Loss: 0.02270404, Validation R2: 0.282545

Epoch 148/1000
Training Loss: 0.01860469, Training R2: 0.364338
Validation Loss: 0.02313639, Validation R2: 0.273360

Epoch 149/1000
Training Loss: 0.01930238, Training R2: 0.332888
Validation Loss: 0.02269148, Validation R2: 0.280920

Epoch 150/1000
Training Loss: 0.01879942, Training R2: 0.354504
Validation Loss: 0.02330641, Validation R2: 0.281184

Epoch 151/1000
Training Loss: 0.01953234, Training R2: 0.323226
Validation Loss: 0.02297575, Validation R2: 0.267649

Epoch 152/1000
Training Loss: 0.01867283, Training R2: 0.355421
Validation Loss: 0.02291019, Validation R2: 0.294926

Epoch 153/1000
Training Loss: 0.01840693, Training R2: 0.371673
Validation Loss: 0.02407007, Validation R2: 0.211410

Epoch 154/1000
Training Loss: 0.01927812, Training R2: 0.328355
Validation Loss: 0.02367560, Validation R2: 0.271655

Epoch 155/1000
Training Loss: 0.01920166, Training R2: 0.335023
Validation Loss: 0.02296854, Validation R2: 0.258724

Epoch 156/1000
Training Loss: 0.01885887, Training R2: 0.360314
Validation Loss: 0.02212887, Validation R2: 0.308993
Saved best model with validation R2 0.308993 to best_finetuned_model.pth

Epoch 157/1000
Training Loss: 0.01884888, Training R2: 0.357004
Validation Loss: 0.02256695, Validation R2: 0.292572

Epoch 158/1000
Training Loss: 0.02030905, Training R2: 0.299507
Validation Loss: 0.02280913, Validation R2: 0.279123

Epoch 159/1000
Training Loss: 0.01901306, Training R2: 0.347437
Validation Loss: 0.02249209, Validation R2: 0.290947

Epoch 160/1000
Training Loss: 0.01881624, Training R2: 0.358929
Validation Loss: 0.02366957, Validation R2: 0.236791

Epoch 161/1000
Training Loss: 0.01919586, Training R2: 0.336501
Validation Loss: 0.02391685, Validation R2: 0.254761

Epoch 162/1000
Training Loss: 0.01952852, Training R2: 0.330367
Validation Loss: 0.02269029, Validation R2: 0.273696

Epoch 163/1000
Training Loss: 0.01868948, Training R2: 0.364516
Validation Loss: 0.02214330, Validation R2: 0.303585

Epoch 164/1000
Training Loss: 0.01824492, Training R2: 0.378310
Validation Loss: 0.02300298, Validation R2: 0.265829

Epoch 165/1000
Training Loss: 0.01857684, Training R2: 0.358020
Validation Loss: 0.02291489, Validation R2: 0.284831

Epoch 166/1000
Training Loss: 0.01844850, Training R2: 0.369939
Validation Loss: 0.02224900, Validation R2: 0.300926

Epoch 167/1000
Training Loss: 0.01826130, Training R2: 0.373629
Validation Loss: 0.02230476, Validation R2: 0.297171

Epoch 168/1000
Training Loss: 0.01856123, Training R2: 0.363396
Validation Loss: 0.02264869, Validation R2: 0.305913

Epoch 169/1000
Training Loss: 0.01845783, Training R2: 0.368750
Validation Loss: 0.02225910, Validation R2: 0.300153

Epoch 170/1000
Training Loss: 0.01806963, Training R2: 0.384290
Validation Loss: 0.02253860, Validation R2: 0.302166

Epoch 171/1000
Training Loss: 0.01829321, Training R2: 0.372005
Validation Loss: 0.02231782, Validation R2: 0.298060

Epoch 172/1000
Training Loss: 0.01830238, Training R2: 0.376580
Validation Loss: 0.02235858, Validation R2: 0.293236

Epoch 173/1000
Training Loss: 0.01802274, Training R2: 0.380495
Validation Loss: 0.02230760, Validation R2: 0.298754

Epoch 174/1000
Training Loss: 0.01806231, Training R2: 0.382732
Validation Loss: 0.02256410, Validation R2: 0.276040

Epoch 175/1000
Training Loss: 0.01829100, Training R2: 0.371360
Validation Loss: 0.02329824, Validation R2: 0.277724

Epoch 176/1000
Training Loss: 0.01888262, Training R2: 0.356067
Validation Loss: 0.02290028, Validation R2: 0.265127

Epoch 177/1000
Epoch 00177: reducing learning rate of group 0 to 6.2500e-06.
Training Loss: 0.01841491, Training R2: 0.374236
Validation Loss: 0.02253174, Validation R2: 0.280343

Epoch 178/1000
学习率已减少 4 次
Training Loss: 0.01827225, Training R2: 0.377626
Validation Loss: 0.02244736, Validation R2: 0.283534

Epoch 179/1000
Training Loss: 0.01797126, Training R2: 0.389037
Validation Loss: 0.02227347, Validation R2: 0.290994

Epoch 180/1000
Training Loss: 0.01814038, Training R2: 0.385189
Validation Loss: 0.02224185, Validation R2: 0.293679

Epoch 181/1000
Training Loss: 0.01826878, Training R2: 0.379961
Validation Loss: 0.02228935, Validation R2: 0.288202

Epoch 182/1000
Training Loss: 0.01819265, Training R2: 0.377938
Validation Loss: 0.02230369, Validation R2: 0.289328

Epoch 183/1000
Training Loss: 0.01830717, Training R2: 0.377230
Validation Loss: 0.02232553, Validation R2: 0.288130

Epoch 184/1000
Training Loss: 0.01832509, Training R2: 0.369252
Validation Loss: 0.02294140, Validation R2: 0.259006

Epoch 185/1000
Training Loss: 0.01814463, Training R2: 0.378730
Validation Loss: 0.02254153, Validation R2: 0.282413

Epoch 186/1000
Training Loss: 0.01804577, Training R2: 0.380680
Validation Loss: 0.02276909, Validation R2: 0.267652

Epoch 187/1000
Training Loss: 0.01806529, Training R2: 0.380138
Validation Loss: 0.02230804, Validation R2: 0.287911

Epoch 188/1000
Training Loss: 0.01791565, Training R2: 0.389747
Validation Loss: 0.02224156, Validation R2: 0.286493

Epoch 189/1000
Training Loss: 0.01796729, Training R2: 0.387220
Validation Loss: 0.02221058, Validation R2: 0.286934

Epoch 190/1000
Training Loss: 0.01794588, Training R2: 0.388512
Validation Loss: 0.02220112, Validation R2: 0.293190

Epoch 191/1000
Training Loss: 0.01797661, Training R2: 0.387898
Validation Loss: 0.02235849, Validation R2: 0.287833

Epoch 192/1000
Training Loss: 0.01805832, Training R2: 0.384652
Validation Loss: 0.02230353, Validation R2: 0.285816

Epoch 193/1000
Training Loss: 0.01784064, Training R2: 0.391052
Validation Loss: 0.02220646, Validation R2: 0.292269

Epoch 194/1000
Training Loss: 0.01803163, Training R2: 0.386700
Validation Loss: 0.02220443, Validation R2: 0.289211

Epoch 195/1000
Training Loss: 0.01802707, Training R2: 0.388939
Validation Loss: 0.02211626, Validation R2: 0.295494

Epoch 196/1000
Training Loss: 0.01791315, Training R2: 0.389204
Validation Loss: 0.02217795, Validation R2: 0.292144

Epoch 197/1000
Training Loss: 0.01806360, Training R2: 0.383926
Validation Loss: 0.02234233, Validation R2: 0.282980

Epoch 198/1000
Epoch 00198: reducing learning rate of group 0 to 3.1250e-06.
Training Loss: 0.01794452, Training R2: 0.394397
Validation Loss: 0.02231085, Validation R2: 0.291708

Epoch 199/1000
学习率已减少 5 次
Training Loss: 0.01797634, Training R2: 0.390558
Validation Loss: 0.02220169, Validation R2: 0.288077

Epoch 200/1000
Training Loss: 0.01784683, Training R2: 0.395922
Validation Loss: 0.02223877, Validation R2: 0.292880

Epoch 201/1000
Training Loss: 0.01791453, Training R2: 0.393038
Validation Loss: 0.02214172, Validation R2: 0.291000

Epoch 202/1000
Training Loss: 0.01780863, Training R2: 0.396796
Validation Loss: 0.02219207, Validation R2: 0.289009

Epoch 203/1000
Training Loss: 0.01783711, Training R2: 0.395443
Validation Loss: 0.02214606, Validation R2: 0.291185

Epoch 204/1000
Training Loss: 0.01776319, Training R2: 0.397536
Validation Loss: 0.02209173, Validation R2: 0.296120

Epoch 205/1000
Training Loss: 0.01794129, Training R2: 0.392487
Validation Loss: 0.02198165, Validation R2: 0.299560

Epoch 206/1000
Training Loss: 0.01779693, Training R2: 0.399008
Validation Loss: 0.02198080, Validation R2: 0.297606

Epoch 207/1000
Training Loss: 0.01786811, Training R2: 0.398498
Validation Loss: 0.02194836, Validation R2: 0.301028

Epoch 208/1000
Training Loss: 0.01784155, Training R2: 0.398762
Validation Loss: 0.02204029, Validation R2: 0.297766

Epoch 209/1000
Training Loss: 0.01776611, Training R2: 0.398639
Validation Loss: 0.02212120, Validation R2: 0.292572

Epoch 210/1000
Training Loss: 0.01775018, Training R2: 0.398617
Validation Loss: 0.02221506, Validation R2: 0.291032

Epoch 211/1000
Training Loss: 0.01780264, Training R2: 0.395503
Validation Loss: 0.02236449, Validation R2: 0.284091

Epoch 212/1000
Training Loss: 0.01800126, Training R2: 0.385189
Validation Loss: 0.02237242, Validation R2: 0.283486

Epoch 213/1000
Training Loss: 0.01792226, Training R2: 0.391244
Validation Loss: 0.02262220, Validation R2: 0.283932

Epoch 214/1000
Training Loss: 0.01820602, Training R2: 0.382781
Validation Loss: 0.02223484, Validation R2: 0.289266

Epoch 215/1000
Training Loss: 0.01795199, Training R2: 0.392104
Validation Loss: 0.02225925, Validation R2: 0.288996

Epoch 216/1000
Training Loss: 0.01775829, Training R2: 0.399006
Validation Loss: 0.02222611, Validation R2: 0.296837

Epoch 217/1000
Training Loss: 0.01792549, Training R2: 0.396640
Validation Loss: 0.02214431, Validation R2: 0.294706

Epoch 218/1000
Training Loss: 0.01799506, Training R2: 0.392943
Validation Loss: 0.02250087, Validation R2: 0.281714

Epoch 219/1000
Epoch 00219: reducing learning rate of group 0 to 1.5625e-06.
Training Loss: 0.01794063, Training R2: 0.395399
Validation Loss: 0.02212716, Validation R2: 0.296752

Epoch 220/1000
学习率已减少 6 次
学习率已减少 6 次，达到最大允许次数 5，提前终止训练

Training completed.
Saved loss curve to /share/home/zixiao/block_predict/fine-tune/loss_curve_HOMO_energy.png
Saved R2 curve to /share/home/zixiao/block_predict/fine-tune/r2_curve_HOMO_energy.png
